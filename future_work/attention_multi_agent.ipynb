{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c5a8a",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization - Temporal Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f8e10",
   "metadata": {},
   "source": [
    "This experiment demonstrates the application of deep reinforcement learning (DRL) techniques for portfolio optimization.\n",
    "\n",
    "- **Off-policy algorithms**: `SAC`, `DDPG`, `TD3` (use Temporal Self Attention-based models).  \n",
    "- **On-policy algorithms**: `A2C`, `PPO` (do not use Temporal Self Attention-based models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfb03e",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy matplotlib \\\n",
    "#                stable-baselines3 \\\n",
    "#                PyPortfolioOpt \\\n",
    "#                pandas_market_calendars quantstats gymnasium \\\n",
    "#                git+https://github.com/AI4Finance-Foundation/FinRL.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51776d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzitoh/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/pyfolio/pos.py:25: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, LayerNorm\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import (\n",
    "    backtest_stats,\n",
    "    get_daily_return,\n",
    "    get_baseline, backtest_plot\n",
    ")\n",
    "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import (\n",
    "    PortfolioOptimizationEnv,\n",
    ")\n",
    "from finrl.agents.portfolio_optimization.models import DRLAgent as PGAgent\n",
    "from finrl.agents.portfolio_optimization.architectures import EIIE\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5cf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8f66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e16a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"attention_multi_agent\"\n",
    "results_dir = f\"results/models/{experiment_name}\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c1461",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefbe65",
   "metadata": {},
   "source": [
    "Define training and trading/test periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542703af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: ('2013-05-06', '2023-05-04')\n",
      "Testing period: ('2023-05-05', '2025-05-03')\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2015-01-01\"\n",
    "end_date = (datetime.now() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")  # Yesterday\n",
    "\n",
    "trade_period = 2  # 2 years for testing\n",
    "train_period = 10  # 10 years for training\n",
    "\n",
    "train_end_date = (\n",
    "    datetime.strptime(end_date, \"%Y-%m-%d\") - timedelta(days=trade_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "train_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") - timedelta(days=train_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "test_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") + timedelta(days=1)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "train_dates = (train_start_date, train_end_date)\n",
    "test_dates = (test_start_date, end_date)\n",
    "\n",
    "print(f\"Training period: {train_dates}\")\n",
    "print(f\"Testing period: {test_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a425c",
   "metadata": {},
   "source": [
    "- Fetch historical stock data for a given list of tickers within a specified date range.\n",
    "- We use the DOW_30_TICKER stocks\n",
    "- The data includes `date`, `close`, `high`, `low`, `open`, `volume`, and `tic` (ticker symbol).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c577ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2015-01-01 → 2025-05-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (18193, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def download_data(tickers, start_date, end_date):\n",
    "    print(f\"Downloading {start_date} → {end_date}\")\n",
    "    return YahooDownloader(\n",
    "        start_date=start_date, end_date=end_date, ticker_list=tickers\n",
    "    ).fetch_data()\n",
    "\n",
    "\n",
    "# Uncomment the following line to use the DOW 30 tickers\n",
    "# tickers = config_tickers.DOW_30_TICKER\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \"JPM\"]\n",
    "df = download_data(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb738f",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We apply feature engineering to the dataset of stock data:\n",
    "\n",
    "- Add technical indicators (e.g., moving averages, RSI).\n",
    "- Calculate turbulence indicators, which measure market volatility.\n",
    "\n",
    "This Enhance the dataset with features that are critical for modeling market dynamics and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47dcd423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    fe = FeatureEngineer(\n",
    "        use_technical_indicator=True,\n",
    "        tech_indicator_list=[\"macd\", \"cci\", \"rsi\", \"dx\"],  # TODO: Check\n",
    "        use_turbulence=False,\n",
    "    )\n",
    "    return fe.preprocess_data(df)\n",
    "\n",
    "\n",
    "df_feat = preprocess_data(df)\n",
    "\n",
    "# TODO: Normalise the data??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdeb82",
   "metadata": {},
   "source": [
    "## Covariance & Returns for State\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002710f6",
   "metadata": {},
   "source": [
    "- Calculate the rolling covariance matrices and daily returns for the given dataset of stock prices.\n",
    "- This prepares the state representation (the state of the portfolio) for the RL models in the RL environments for portfolio optimization.\n",
    "- The **rolling covariance matrices** (`cov_list`) capture the relationships between asset returns, while the daily returns (`return_list`) provide information about recent price movements.\n",
    "- These metrics are critical for modeling the dynamics of the financial market and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b6f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance_and_returns(df_feat, lookback=252):\n",
    "    df_sorted = df_feat.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df_sorted.index = df_sorted.date.factorize()[0]\n",
    "    cov_list, return_list = [], []\n",
    "\n",
    "    dates = df_sorted.date.unique()\n",
    "    for i in range(lookback, len(dates)):\n",
    "        win = df_sorted.loc[i - lookback : i]\n",
    "        pm = win.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        rm = pm.pct_change().dropna()\n",
    "        cov_list.append(rm.cov().values)\n",
    "        return_list.append(rm)\n",
    "    df_cov = pd.DataFrame(\n",
    "        {\"date\": dates[lookback:], \"cov_list\": cov_list, \"return_list\": return_list}\n",
    "    )\n",
    "\n",
    "    return pd.merge(df_feat, df_cov, on=\"date\", how=\"left\").dropna(subset=[\"cov_list\"])\n",
    "\n",
    "\n",
    "df_all = compute_covariance_and_returns(df_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7d720",
   "metadata": {},
   "source": [
    "## Train/Trade split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886a8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_all, train_dates, test_dates):\n",
    "    train = data_split(df_all, *train_dates)\n",
    "    test = data_split(df_all, *test_dates)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_df, test_df = split_data(df_all, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bcfe",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273f79",
   "metadata": {},
   "source": [
    "- Create instances of the **PortfolioOptimizationEnv** class for both training and testing datasets.\n",
    "- It also wrap the training environment for use with Stable-Baselines3 (SB3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd7cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_portfolio_env(df):\n",
    "    env = PortfolioOptimizationEnv(\n",
    "        df,\n",
    "        initial_amount=100_000,\n",
    "        comission_fee_pct=0.0025,\n",
    "        time_window=50,\n",
    "        features=[\"close\", \"high\", \"low\"],\n",
    "        normalize_df=None,\n",
    "        new_gym_api=True,\n",
    "    )\n",
    "\n",
    "    env.df = df.reset_index(drop=True)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "train_env = initialize_portfolio_env(train_df)\n",
    "test_env = initialize_portfolio_env(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a8ccd",
   "metadata": {},
   "source": [
    "## Temporal Self Attention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02386b43",
   "metadata": {},
   "source": [
    "Takes a Box(obs_shape=(f, n, t)) and returns a flat vector of size n * d_model,\n",
    "where each asset’s t-step history of f features is run through a 1-layer TransformerEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740c76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalSelfAttention(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, d_model=64, nhead=4):\n",
    "        # the env’s obs shape is (features, n_assets, time_window)\n",
    "        f, n_assets, time_window = observation_space.shape  \n",
    "        super().__init__(observation_space, features_dim=n_assets * d_model)\n",
    "\n",
    "        self.n_assets = n_assets\n",
    "        self.time_window = time_window\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # project f → d_model per timestep\n",
    "        self.input_proj = nn.Linear(f, d_model)\n",
    "        # single-layer transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        # obs: [batch, f, n_assets, time_window]\n",
    "        b, f, n, t = obs.shape\n",
    "\n",
    "        # reorder → [batch, n_assets, time_window, f]\n",
    "        x = obs.permute(0, 2, 3, 1)\n",
    "\n",
    "        # project features → [batch, n_assets, time_window, d_model]\n",
    "        x = self.input_proj(x)\n",
    "\n",
    "        # merge batch+asset dims → [b*n, time_window, d_model]\n",
    "        x = x.view(b * n, t, self.d_model)\n",
    "\n",
    "        # run attention over the time axis\n",
    "        x = self.transformer(x)           # [b*n, t, d_model]\n",
    "\n",
    "        # mean-pool over time → [b*n, d_model]\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        # restore batch → [batch, n_assets * d_model]\n",
    "        return x.view(b, n * self.d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2602e21",
   "metadata": {},
   "source": [
    "## Model Configs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b89e4",
   "metadata": {},
   "source": [
    "Configure model algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2434d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_shape = train_env.observation_space.shape  # (features, n_assets, time_window)\n",
    "\n",
    "\n",
    "def prepare_model_configs():\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=TemporalSelfAttention,\n",
    "        features_extractor_kwargs=dict(\n",
    "            d_model=64,  # embedding dim per asset\n",
    "            nhead=4,  # number of attention heads\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        (\n",
    "            SAC,\n",
    "            \"SAC\",\n",
    "            dict(\n",
    "                learning_rate=0.0007,\n",
    "                gamma=0.99,\n",
    "                buffer_size=100_000,\n",
    "                tau=0.005,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            TD3,\n",
    "            \"TD3\",\n",
    "            dict(\n",
    "                learning_rate=0.0007,\n",
    "                gamma=0.99,\n",
    "                buffer_size=100_000,\n",
    "                tau=0.005,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            DDPG,\n",
    "            \"DDPG\",\n",
    "            dict(\n",
    "                learning_rate=0.0001,\n",
    "                gamma=0.99,\n",
    "                buffer_size=100_000,\n",
    "                tau=0.005,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "            ),\n",
    "        ),\n",
    "        # A2C/PPO entries will ignore the extractor.\n",
    "        (\n",
    "            A2C,\n",
    "            \"A2C\",\n",
    "            dict(\n",
    "                learning_rate=0.0007,\n",
    "                gamma=0.99,\n",
    "                n_steps=5000,\n",
    "                ent_coef=0.0001,\n",
    "                policy_kwargs=dict(net_arch=[64, 64]),\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            PPO,\n",
    "            \"PPO\",\n",
    "            dict(\n",
    "                learning_rate=0.0007,\n",
    "                gamma=0.99,\n",
    "                n_steps=2048,\n",
    "                clip_range=0.2,\n",
    "                policy_kwargs=dict(net_arch=[64, 64]),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "model_configs = prepare_model_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6387a",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1272b4",
   "metadata": {},
   "source": [
    "Train multiple reinforcement learning (RL) models using the specified training environment and configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce6cf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(agent, model_configs, results_dir, total_timesteps=200_000):\n",
    "    training_times = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for model_class, model_name, model_kwargs in model_configs:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 1) Copy your model_kwargs and pop off the policy_kwargs bundle\n",
    "        mk = model_kwargs.copy()\n",
    "        pk = mk.pop(\"policy_kwargs\", {}) or {}\n",
    "\n",
    "        # 2) If this is an *off-policy* algo, strip out use_sde flags\n",
    "        if model_name.lower() in (\"sac\", \"td3\", \"ddpg\"):\n",
    "            pk.pop(\"use_sde\", None)\n",
    "            pk.pop(\"use_sde_at_warmup\", None)\n",
    "\n",
    "        # 3) Call get_model exactly once with model_kwargs and policy_kwargs\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            model_kwargs=mk,\n",
    "            policy_kwargs=pk,\n",
    "        )\n",
    "\n",
    "        trained_model = agent.train_model(\n",
    "            model,\n",
    "            tb_log_name=f\"{experiment_name}_{model_name.lower()}\",\n",
    "            total_timesteps=total_timesteps,\n",
    "        )\n",
    "\n",
    "        # Save & record times\n",
    "        model_path = f\"{results_dir}/{model_name.lower()}_model\"\n",
    "        trained_model.save(model_path)\n",
    "        trained_models[model_name] = trained_model\n",
    "        training_times[model_name] = (time.time() - start_time) / 60\n",
    "        print(f\"{model_name} training completed in {training_times[model_name]:.2f} minutes.\")\n",
    "\n",
    "    return trained_models, training_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90baca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SAC...\n",
      "{'learning_rate': 0.0007, 'gamma': 0.99, 'buffer_size': 100000, 'tau': 0.005}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trained_models, training_times = \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDRLAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_env\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtrain_models\u001b[39m\u001b[34m(agent, model_configs, results_dir, total_timesteps)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 3) Call get_model exactly once with model_kwargs and policy_kwargs\u001b[39;00m\n\u001b[32m     19\u001b[39m model = agent.get_model(\n\u001b[32m     20\u001b[39m     model_name=model_name.lower(),\n\u001b[32m     21\u001b[39m     model_kwargs=mk,\n\u001b[32m     22\u001b[39m     policy_kwargs=pk,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m trained_model = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Save & record times\u001b[39;00m\n\u001b[32m     32\u001b[39m model_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name.lower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/finrl/agents/stablebaselines3/models.py:117\u001b[39m, in \u001b[36mDRLAgent.train_model\u001b[39m\u001b[34m(model, tb_log_name, total_timesteps)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m(\n\u001b[32m    115\u001b[39m     model, tb_log_name, total_timesteps=\u001b[32m5000\u001b[39m\n\u001b[32m    116\u001b[39m ):  \u001b[38;5;66;03m# this function is static method, so it can be called without creating an instance of the class\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     model = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTensorboardCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/sac/sac.py:308\u001b[39m, in \u001b[36mSAC.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    300\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfSAC,\n\u001b[32m    301\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    307\u001b[39m ) -> SelfSAC:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/common/off_policy_algorithm.py:347\u001b[39m, in \u001b[36mOffPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    345\u001b[39m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[32m    346\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m callback.on_training_end()\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/sac/sac.py:281\u001b[39m, in \u001b[36mSAC.train\u001b[39m\u001b[34m(self, gradient_steps, batch_size)\u001b[39m\n\u001b[32m    279\u001b[39m \u001b[38;5;66;03m# Optimize the actor\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[38;5;28mself\u001b[39m.actor.optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[43mactor_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;28mself\u001b[39m.actor.optimizer.step()\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Update target networks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trained_models, training_times = train_models(\n",
    "    DRLAgent(train_env), model_configs, results_dir, total_timesteps=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d312bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times_df = pd.DataFrame(\n",
    "    list(training_times.items()), columns=[\"model\", \"training_duration (min)\"]\n",
    ")\n",
    "training_times_df.to_csv(f\"{results_dir}/training_times.csv\", index=False)\n",
    "\n",
    "print(\"Training summary:\")\n",
    "display(training_times_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b1712",
   "metadata": {},
   "source": [
    "## Model loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13c75e",
   "metadata": {},
   "source": [
    "Load the trained models from memory for analysis without the need for time consuming retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_configs, results_dir):\n",
    "    models = {}\n",
    "    for model_class, name, _ in model_configs:\n",
    "        model_path = f\"{results_dir}/{name.lower()}_model.zip\"\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading saved model for {name}...\")\n",
    "            models[name] = model_class.load(model_path)\n",
    "        else:\n",
    "            print(f\"No saved model found for {name}.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "# If you already trained above you can skip this; otherwise:\n",
    "# trained_models = load_models(model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ec26e",
   "metadata": {},
   "source": [
    "## Backtesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f8c6",
   "metadata": {},
   "source": [
    "- Evaluates the performance of the RL models/algorithms in a trading environment.\n",
    "- We do this by calculating the **cumulative portfolio value** and **performance metrics** for each RL model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\"initial_amount\": 100_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_backtest(model, env, initial_amount):\n",
    "    \"\"\"\n",
    "    Runs the env step by step, predicting actions with `model`, and\n",
    "    builds a DataFrame of dates, daily returns, and account values.\n",
    "    \"\"\"\n",
    "    # reset and get initial obs\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # start from initial capital\n",
    "    portfolio_value = initial_amount\n",
    "\n",
    "    dates, daily_rets, account_vals = [], [], []\n",
    "\n",
    "    while not done:\n",
    "        # predict an action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # step the environment\n",
    "        result = env.step(action)\n",
    "\n",
    "        # handle gymnasium vs. gym return signature\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "\n",
    "        # update portfolio value from the reward\n",
    "        portfolio_value *= 1 + reward\n",
    "\n",
    "        # record\n",
    "        daily_rets.append(reward)\n",
    "        account_vals.append(portfolio_value)\n",
    "\n",
    "        # grab the current date from info\n",
    "        dates.append(info[\"end_time\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"daily_return\": daily_rets,\n",
    "            \"account_value\": account_vals,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def backtest_rl_strategies_manual(models, test_env, env_kwargs):\n",
    "    out = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nManual backtest: {name}\")\n",
    "        df_ret = manual_backtest(model, test_env, env_kwargs[\"initial_amount\"])\n",
    "        # ensure it's sorted by date\n",
    "        df_ret = df_ret.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        # compute performance stats\n",
    "        stats = backtest_stats(df_ret, value_col_name=\"account_value\")\n",
    "        out[name] = {\"df\": df_ret, \"stats\": stats}\n",
    "    return out\n",
    "\n",
    "\n",
    "results = backtest_rl_strategies_manual(trained_models, test_env, env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a4903",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_results():\n",
    "    os.makedirs(f\"{results_dir}/backtest_plots\", exist_ok=True)\n",
    "    for name, res in results.items():\n",
    "        print(f\"Plotting {name}…\")\n",
    "        backtest_plot(\n",
    "            account_value=res[\"df\"],\n",
    "            baseline_start=test_start_date,\n",
    "            baseline_end=end_date,\n",
    "            baseline_ticker=\"SPY\",\n",
    "            value_col_name=\"account_value\",\n",
    "        )\n",
    "\n",
    "\n",
    "plot_backtest_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        df = res[\"df\"]\n",
    "        # compute cumulative returns from account_value\n",
    "        cum = df[\"account_value\"] / df[\"account_value\"].iloc[0] - 1\n",
    "        plt.plot(df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns vs. SPY\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945e551",
   "metadata": {},
   "source": [
    "## Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee740d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mpt_benchmark(test, env_kwargs):\n",
    "    dates_test = test.date.unique()\n",
    "    min_vals = [env_kwargs[\"initial_amount\"]]\n",
    "    for i in range(len(dates_test) - 1):\n",
    "        curr = test[test.date == dates_test[i]]\n",
    "        nxt = test[test.date == dates_test[i + 1]]\n",
    "        covm = np.array(curr.cov_list.values[0])\n",
    "        ef = EfficientFrontier(None, covm, weight_bounds=(0, 1))\n",
    "        ef.min_volatility()\n",
    "        w = ef.clean_weights()\n",
    "        prices = curr.close.values\n",
    "        nextp = nxt.close.values\n",
    "        shares = np.array(list(w.values())) * min_vals[-1] / prices\n",
    "        min_vals.append(np.dot(shares, nextp))\n",
    "    min_df = pd.DataFrame({\"date\": dates_test, \"account_value\": min_vals})\n",
    "    stats_mpt = backtest_stats(min_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": min_df, \"stats\": stats_mpt}\n",
    "\n",
    "\n",
    "mpt_benchmark = compute_mpt_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd051b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(test, env_kwargs):\n",
    "    ew_daily = test.groupby(\"date\")[\"close\"].apply(\n",
    "        lambda d: d.pct_change().fillna(0).mean()\n",
    "    )\n",
    "\n",
    "    ew_df = ew_daily.reset_index(name=\"daily_return\")\n",
    "    ew_df[\"account_value\"] = (ew_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": ew_df, \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(df, initial_amount=100_000):\n",
    "    # Pivot to have one column per ticker\n",
    "    price_wide = df.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).sort_index()\n",
    "\n",
    "    # Compute each ticker's daily return, then average equally\n",
    "    daily_rets = price_wide.pct_change().fillna(0).mean(axis=1)\n",
    "\n",
    "    # Build the equity curve\n",
    "    ew_df = pd.DataFrame({\"date\": daily_rets.index, \"daily_return\": daily_rets.values})\n",
    "    ew_df[\"account_value\"] = (ew_df[\"daily_return\"] + 1).cumprod() * initial_amount\n",
    "\n",
    "    # Compute performance statistics\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "\n",
    "    return {\"df\": ew_df.reset_index(drop=True), \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs[\"initial_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spy_benchmark(test, env_kwargs):\n",
    "    spy_close = get_baseline(\"SPY\", test.date.min(), test.date.max())[\"close\"]\n",
    "    spy_ret = spy_close.pct_change().dropna()\n",
    "    spy_df = pd.DataFrame({\"date\": spy_ret.index, \"daily_return\": spy_ret.values})\n",
    "    spy_df[\"account_value\"] = (spy_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_spy = backtest_stats(spy_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": spy_df, \"stats\": stats_spy}\n",
    "\n",
    "\n",
    "spy_benchmark = compute_spy_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a147661",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = {\n",
    "    \"MPT\": mpt_benchmark,\n",
    "    \"EW\": ew_benchmark,\n",
    "    \"SPY\": spy_benchmark,\n",
    "}\n",
    "\n",
    "results.update(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c912897",
   "metadata": {},
   "source": [
    "## Performance Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_stats = pd.DataFrame({key.upper(): res[\"stats\"] for key, res in results.items()})\n",
    "display(perf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_include = [\n",
    "    \"Cumulative returns\",\n",
    "    \"Annual return\",\n",
    "    \"Annual volatility\",\n",
    "    \"Sharpe ratio\",\n",
    "    \"Max drawdown\",\n",
    "]\n",
    "filtered_perf_stats = perf_stats.loc[metrics_to_include]\n",
    "\n",
    "filtered_perf_stats.T.plot(kind=\"bar\", figsize=(14, 8), legend=True)\n",
    "plt.title(\"Performance Metrics Comparison\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        # Ensure the date column is converted to datetime\n",
    "        res[\"df\"][\"date\"] = pd.to_datetime(res[\"df\"][\"date\"])\n",
    "        # Filter data to start from the trade start date\n",
    "        filtered_df = res[\"df\"][res[\"df\"][\"date\"] >= test_start_date]\n",
    "        cum = (\n",
    "            (filtered_df[\"daily_return\"] + 1).cumprod() - 1\n",
    "            if \"daily_return\" in filtered_df\n",
    "            else filtered_df[\"account_value\"] / filtered_df[\"account_value\"].iloc[0] - 1\n",
    "        )\n",
    "        plt.plot(filtered_df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
