{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c5a8a",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f8e10",
   "metadata": {},
   "source": [
    "This experiment demonstrates the application of deep reinforcement learning (DRL) techniques for portfolio optimization.\n",
    "\n",
    "- The experiment leverages the **Attention Feature Extractor** to integrate **temporal self-attention** and **inter-asset graph-attention** mechanisms. \n",
    "- This feature extractor processes historical data and asset relationships to generate embeddings that are used by reinforcement learning models for portfolio optimization.\n",
    "- The **inter-asset graph-attention** captures cross-asset relationships.\n",
    "- Applies a **Multi-Head self-attention** mechanism across the per-asset embeddings, enabling each asset to “attend” to its peers before passing through the final MLP for feature extraction.\n",
    "\n",
    "Algotihms:\n",
    "- **Off-policy algorithms**: `SAC`, `DDPG`, `TD3` (use Temporal Self Attention-based models).  \n",
    "- **On-policy algorithms**: `A2C`, `PPO` (do not use Temporal Self Attention-based models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfb03e",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy matplotlib \\\n",
    "#                ipywidgets \\\n",
    "#                xarray \\\n",
    "#                stable-baselines3 \\\n",
    "#                PyPortfolioOpt \\\n",
    "#                pandas_market_calendars quantstats gymnasium \\\n",
    "#                git+https://github.com/AI4Finance-Foundation/FinRL.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51776d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoderLayer, LayerNorm\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import ObservationWrapper\n",
    " \n",
    "from stable_baselines3 import A2C, PPO, SAC, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import (\n",
    "    backtest_stats,\n",
    "    get_daily_return,\n",
    "    get_baseline, backtest_plot\n",
    ")\n",
    "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import (\n",
    "    PortfolioOptimizationEnv,\n",
    ")\n",
    "from finrl.agents.portfolio_optimization.models import DRLAgent as PGAgent\n",
    "from finrl.agents.portfolio_optimization.architectures import EIIE\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ab8f0",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e5cf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "experiment_name = \"attention_grapgh_multi_agent\"\n",
    "results_dir = f\"results/models/{experiment_name}\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c1461",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefbe65",
   "metadata": {},
   "source": [
    "Define training and trading/test periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "542703af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: ('2013-05-05', '2023-05-03')\n",
      "Testing period: ('2023-05-04', '2025-05-02')\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2015-01-01\"\n",
    "end_date = (datetime.now() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")  # Yesterday\n",
    "\n",
    "trade_period = 2  # 2 years for testing\n",
    "train_period = 10  # 10 years for training\n",
    "\n",
    "train_end_date = (\n",
    "    datetime.strptime(end_date, \"%Y-%m-%d\") - timedelta(days=trade_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "train_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") - timedelta(days=train_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "test_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") + timedelta(days=1)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "train_dates = (train_start_date, train_end_date)\n",
    "test_dates = (test_start_date, end_date)\n",
    "\n",
    "print(f\"Training period: {train_dates}\")\n",
    "print(f\"Testing period: {test_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a425c",
   "metadata": {},
   "source": [
    "- Fetch historical stock data for a given list of tickers within a specified date range.\n",
    "- We use the DOW_30_TICKER stocks\n",
    "- The data includes `date`, `close`, `high`, `low`, `open`, `volume`, and `tic` (ticker symbol).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46c577ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2015-01-01 → 2025-05-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (18186, 8)\n"
     ]
    }
   ],
   "source": [
    "def download_data(tickers, start_date, end_date):\n",
    "    print(f\"Downloading {start_date} → {end_date}\")\n",
    "    return YahooDownloader(\n",
    "        start_date=start_date, end_date=end_date, ticker_list=tickers\n",
    "    ).fetch_data()\n",
    "\n",
    "\n",
    "# Uncomment the following line to use the DOW 30 tickers\n",
    "# tickers = config_tickers.DOW_30_TICKER\n",
    "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"META\", \"TSLA\", \"JPM\"]\n",
    "df = download_data(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb738f",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We apply feature engineering to the dataset of stock data:\n",
    "\n",
    "- Add technical indicators (e.g., moving averages, RSI).\n",
    "- Calculate turbulence indicators, which measure market volatility.\n",
    "\n",
    "This Enhance the dataset with features that are critical for modeling market dynamics and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47dcd423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    fe = FeatureEngineer(\n",
    "        use_technical_indicator=True,\n",
    "        tech_indicator_list=[\"macd\", \"cci\", \"rsi\", \"dx\"],  # TODO: Check\n",
    "        use_turbulence=False,\n",
    "    )\n",
    "    return fe.preprocess_data(df)\n",
    "\n",
    "\n",
    "df_feat = preprocess_data(df)\n",
    "\n",
    "# TODO: Normalise the data??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdeb82",
   "metadata": {},
   "source": [
    "## Covariance & Returns for State\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002710f6",
   "metadata": {},
   "source": [
    "- Calculate the rolling covariance matrices and daily returns for the given dataset of stock prices.\n",
    "- This prepares the state representation (the state of the portfolio) for the RL models in the RL environments for portfolio optimization.\n",
    "- The **rolling covariance matrices** (`cov_list`) capture the relationships between asset returns, while the daily returns (`return_list`) provide information about recent price movements.\n",
    "- These metrics are critical for modeling the dynamics of the financial market and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b6f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing covariance and returns with lookback 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5c53d56087448f88866dee39d73846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing cov/returns:   0%|          | 0/2346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_covariance_and_returns(df_feat, lookback=252):\n",
    "    print(f\"Computing covariance and returns with lookback {lookback}\")\n",
    "    \n",
    "    df_sorted = df_feat.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df_sorted.index = df_sorted.date.factorize()[0]\n",
    "    cov_list, return_list = [], []\n",
    "\n",
    "    dates = df_sorted.date.unique()\n",
    "    for i in tqdm(range(lookback, len(dates)),\n",
    "                  total=len(dates) - lookback,\n",
    "                  desc=\"Computing cov/returns\"):\n",
    "        win = df_sorted.loc[i - lookback : i]\n",
    "        pm = win.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        rm = pm.pct_change().dropna()\n",
    "        cov_list.append(rm.cov().values)\n",
    "        return_list.append(rm)\n",
    "    df_cov = pd.DataFrame(\n",
    "        {\"date\": dates[lookback:], \"cov_list\": cov_list, \"return_list\": return_list}\n",
    "    )\n",
    "\n",
    "    return pd.merge(df_feat, df_cov, on=\"date\", how=\"left\").dropna(subset=[\"cov_list\"])\n",
    "\n",
    "\n",
    "df_all = compute_covariance_and_returns(df_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41e5d97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of df_all: (16422, 14)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"Shape of df_all: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7d720",
   "metadata": {},
   "source": [
    "## Train/Trade split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "886a8a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train and test sets\n",
      "Train shape: (12915, 14)\n",
      "Test shape: (3500, 14)\n"
     ]
    }
   ],
   "source": [
    "def split_data(df_all, train_dates, test_dates):\n",
    "    print(f\"Splitting data into train and test sets\")\n",
    "    \n",
    "    train = data_split(df_all, *train_dates)\n",
    "    test = data_split(df_all, *test_dates)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_df, test_df = split_data(df_all, train_dates, test_dates)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bcfe",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9c38a",
   "metadata": {},
   "source": [
    "Casts every observation to np.float16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccc622ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the environment\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting up the environment\")\n",
    "\n",
    "class CastObservationToFloat16(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "    def observation(self, obs):\n",
    "        return obs.astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273f79",
   "metadata": {},
   "source": [
    "- Create instances of the **PortfolioOptimizationEnv** class for both training and testing datasets.\n",
    "- It also wrap the training environment for use with Stable-Baselines3 (SB3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90269cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_portfolio_env(df, time_window=30):\n",
    "    env = PortfolioOptimizationEnv(\n",
    "        df,\n",
    "        initial_amount=100_000,\n",
    "        comission_fee_pct=0.0025,\n",
    "        time_window=time_window,  # now 30 instead of 50\n",
    "        features=[\"close\", \"high\", \"low\"],\n",
    "        normalize_df=None,\n",
    "        new_gym_api=True,\n",
    "    )\n",
    "    env.df = df.reset_index(drop=True)\n",
    "\n",
    "    # wrap to cast obs to float16\n",
    "    env = CastObservationToFloat16(env)\n",
    "    return env\n",
    "\n",
    "train_env = initialize_portfolio_env(train_df, time_window=30)\n",
    "test_env = initialize_portfolio_env(test_df, time_window=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17d546c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError(\"Test error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5415e03",
   "metadata": {},
   "source": [
    "## Inter-Asset Graph Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699c47",
   "metadata": {},
   "source": [
    "Apply a Multi-Head self-attention across the per-asset embeddings, so each asset “attends” to its peers before the final MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29d9665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterAssetGraphAttention(nn.Module):\n",
    "    def __init__(self, d_model=64, nhead=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # PyTorch’s MultiheadAttention as a graph layer\n",
    "        #   embed_dim = d_model, nhead heads\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_model, num_heads=nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.norm = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, emb: torch.Tensor) -> torch.Tensor:\n",
    "        # MultiheadAttention expects (batch, seq, feature) when batch_first=True\n",
    "        # here seq = n_assets\n",
    "        attn_out, _ = self.attn(emb, emb, emb)\n",
    "        # residual + norm\n",
    "        return self.norm(attn_out + emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a8ccd",
   "metadata": {},
   "source": [
    "## Attention Feature Extractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02386b43",
   "metadata": {},
   "source": [
    "- Combines temporal self-attention per asset with inter-asset graph-attention,\n",
    "- Then reduces via MLP to a fixed-size feature vector for SB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "740c76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space,\n",
    "        feature_dim: int,\n",
    "        n_assets: int,\n",
    "        time_window: int,\n",
    "        d_model: int = 64,\n",
    "        nhead: int = 4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Combines temporal self-attention per asset with inter-asset graph-attention,\n",
    "        then reduces via MLP to a fixed-size feature vector for SB3.\n",
    "\n",
    "        - feature_dim: number of input features per asset (e.g., 3 for close/high/low)\n",
    "        - n_assets: size of portfolio (number of tickers)\n",
    "        - time_window: history length (number of timesteps)\n",
    "        - d_model: embedding dimension for attention\n",
    "        - nhead: attention heads\n",
    "        \"\"\"\n",
    "        # internal dims\n",
    "        self.feature_dim = feature_dim\n",
    "        self.n_assets = n_assets\n",
    "        self.time_window = time_window\n",
    "        self.d_model = d_model\n",
    "        # flattened embedding before MLP: per-asset embeddings + weights\n",
    "        flat_emb_dim = n_assets * d_model + n_assets\n",
    "        # final output dimension after extractor MLP\n",
    "        mlp_output_dim = 256\n",
    "        super().__init__(observation_space, features_dim=mlp_output_dim)\n",
    "\n",
    "        # --- Attention blocks ---\n",
    "        # per-timestep projection from feature_dim -> d_model\n",
    "        self.input_proj = nn.Linear(feature_dim, d_model)\n",
    "        # temporal transformer encoder (per-asset)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=nhead, batch_first=True\n",
    "        )\n",
    "        self.temporal = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        # inter-asset graph attention\n",
    "        self.graph_attn = InterAssetGraphAttention(d_model=d_model, nhead=nhead)\n",
    "\n",
    "        # --- MLP head to reduce to mlp_output_dim ---\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(flat_emb_dim, mlp_output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_output_dim, mlp_output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs: torch.Tensor) -> torch.Tensor:\n",
    "        # obs is flat: [batch, obs_dim]\n",
    "        b = obs.size(0)\n",
    "        flat = obs.reshape(b, -1)\n",
    "\n",
    "        # extract history part and reshape to [b, feature_dim, n_assets, time_window]\n",
    "        hist_size = self.feature_dim * self.n_assets * self.time_window\n",
    "        hist_flat = flat[:, :hist_size]\n",
    "        hist = hist_flat.reshape(b, self.feature_dim, self.n_assets, self.time_window)\n",
    "\n",
    "        # 1) Temporal Self-Attention per asset\n",
    "        #    → [b, n_assets, time_window, feature_dim]\n",
    "        x = hist.permute(0, 2, 3, 1)\n",
    "        # project features -> d_model → [b, n_assets, time_window, d_model]\n",
    "        x = self.input_proj(x)\n",
    "        # merge batch+asset dims → [b*n_assets, time_window, d_model]\n",
    "        bna = b * self.n_assets\n",
    "        x = x.reshape(bna, self.time_window, self.d_model)\n",
    "        # apply transformer\n",
    "        x = self.temporal(x)                 # [b*n, t, d_model]\n",
    "        x = x.mean(dim=1)                   # [b*n, d_model]\n",
    "        # restore batch dims → [b, n_assets, d_model]\n",
    "        x = x.reshape(b, self.n_assets, self.d_model)\n",
    "\n",
    "        # 2) Inter-Asset Graph Attention → [b, n_assets, d_model]\n",
    "        x = self.graph_attn(x)\n",
    "\n",
    "        # 3) Extract current weights (last n_assets entries)\n",
    "        weights = flat[:, -self.n_assets:]\n",
    "\n",
    "        # 4) Concatenate embeddings + weights → [b, flat_emb_dim]\n",
    "        emb_flat = x.reshape(b, self.n_assets * self.d_model)\n",
    "        concat = torch.cat([emb_flat, weights], dim=1)\n",
    "\n",
    "        # 5) MLP to mlp_output_dim\n",
    "        return self.mlp(concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2602e21",
   "metadata": {},
   "source": [
    "## Model Configs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b89e4",
   "metadata": {},
   "source": [
    "Configure model algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2434d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_shape = train_env.observation_space.shape  # (features, n_assets, time_window)\n",
    "\n",
    "\n",
    "def prepare_model_configs():\n",
    "\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class=AttentionFeatureExtractor,\n",
    "        features_extractor_kwargs=dict(\n",
    "            feature_dim=3,  # number of features/asset\n",
    "            n_assets=7,  # your ticker count\n",
    "            time_window=30,  # match your env\n",
    "            d_model=64,\n",
    "            nhead=4,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return [\n",
    "        # (\n",
    "        #     SAC,\n",
    "        #     \"SAC\",\n",
    "        #     dict(\n",
    "        #         learning_rate=0.0007,\n",
    "        #         gamma=0.99,\n",
    "        #         buffer_size=50_000,\n",
    "        #         tau=0.005,\n",
    "        #         policy_kwargs=policy_kwargs,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\n",
    "        #     TD3,\n",
    "        #     \"TD3\",\n",
    "        #     dict(\n",
    "        #         learning_rate=0.0007,\n",
    "        #         gamma=0.99,\n",
    "        #         buffer_size=50_000,\n",
    "        #         tau=0.005,\n",
    "        #         policy_kwargs=policy_kwargs,\n",
    "        #     ),\n",
    "        # ),\n",
    "        (\n",
    "            DDPG,\n",
    "            \"DDPG\",\n",
    "            dict(\n",
    "                learning_rate=0.0001,\n",
    "                gamma=0.99,\n",
    "                buffer_size=50_000,\n",
    "                tau=0.005,\n",
    "                policy_kwargs=policy_kwargs,\n",
    "            ),\n",
    "        ),\n",
    "        # A2C/PPO entries will ignore the extractor.\n",
    "        # (\n",
    "        #     A2C,\n",
    "        #     \"A2C\",\n",
    "        #     dict(\n",
    "        #         learning_rate=0.0007,\n",
    "        #         gamma=0.99,\n",
    "        #         n_steps=5000,\n",
    "        #         ent_coef=0.0001,\n",
    "        #         policy_kwargs=dict(net_arch=[64, 64]),\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\n",
    "        #     PPO,\n",
    "        #     \"PPO\",\n",
    "        #     dict(\n",
    "        #         learning_rate=0.0007,\n",
    "        #         gamma=0.99,\n",
    "        #         n_steps=2048,\n",
    "        #         clip_range=0.2,\n",
    "        #         policy_kwargs=dict(net_arch=[64, 64]),\n",
    "        #     ),\n",
    "        # ),\n",
    "    ]\n",
    "\n",
    "\n",
    "model_configs = prepare_model_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6387a",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1272b4",
   "metadata": {},
   "source": [
    "Train multiple reinforcement learning (RL) models using the specified training environment and configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce6cf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(agent, model_configs, results_dir, total_timesteps=200_000):\n",
    "    training_times = {}\n",
    "    trained_models = {}\n",
    "\n",
    "    for model_class, model_name, model_kwargs in model_configs:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # 1) Copy your model_kwargs and pop off the policy_kwargs bundle\n",
    "        mk = model_kwargs.copy()\n",
    "        pk = mk.pop(\"policy_kwargs\", {}) or {}\n",
    "\n",
    "        # 2) If this is an *off-policy* algo, strip out use_sde flags\n",
    "        if model_name.lower() in (\"sac\", \"td3\", \"ddpg\"):\n",
    "            pk.pop(\"use_sde\", None)\n",
    "            pk.pop(\"use_sde_at_warmup\", None)\n",
    "\n",
    "        # 3) Call get_model exactly once with model_kwargs and policy_kwargs\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            model_kwargs=mk,\n",
    "            policy_kwargs=pk,\n",
    "        )\n",
    "\n",
    "        trained_model = agent.train_model(\n",
    "            model,\n",
    "            tb_log_name=f\"{experiment_name}_{model_name.lower()}\",\n",
    "            total_timesteps=total_timesteps,\n",
    "        )\n",
    "\n",
    "        # Save & record times\n",
    "        model_path = f\"{results_dir}/{model_name.lower()}_model\"\n",
    "        trained_model.save(model_path)\n",
    "        trained_models[model_name] = trained_model\n",
    "        training_times[model_name] = (time.time() - start_time) / 60\n",
    "        print(f\"{model_name} training completed in {training_times[model_name]:.2f} minutes.\")\n",
    "\n",
    "    return trained_models, training_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90baca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DDPG...\n",
      "{'learning_rate': 0.0001, 'gamma': 0.99, 'buffer_size': 50000, 'tau': 0.005}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 522368.15625\n",
      "Final accumulative portfolio value: 5.223681449890137\n",
      "Maximum DrawDown: -0.4261020658406679\n",
      "Sharpe ratio: 1.0658298148003997\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 444811.6875\n",
      "Final accumulative portfolio value: 4.448116779327393\n",
      "Maximum DrawDown: -0.44828097333521755\n",
      "Sharpe ratio: 0.9862650174738314\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 501069.59375\n",
      "Final accumulative portfolio value: 5.010695934295654\n",
      "Maximum DrawDown: -0.4482803305300813\n",
      "Sharpe ratio: 1.048955705071255\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 431460.875\n",
      "Final accumulative portfolio value: 4.314608573913574\n",
      "Maximum DrawDown: -0.36687694625374445\n",
      "Sharpe ratio: 1.0435834925190939\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 1.82e+03     |\n",
      "|    ep_rew_mean     | 1.55         |\n",
      "| time/              |              |\n",
      "|    episodes        | 4            |\n",
      "|    fps             | 0            |\n",
      "|    time_elapsed    | 29754        |\n",
      "|    total_timesteps | 7264         |\n",
      "| train/             |              |\n",
      "|    actor_loss      | -0.0551      |\n",
      "|    critic_loss     | 0.000161     |\n",
      "|    learning_rate   | 0.0001       |\n",
      "|    n_updates       | 7163         |\n",
      "|    reward          | -0.008121299 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 386617.3125\n",
      "Final accumulative portfolio value: 3.866173028945923\n",
      "Maximum DrawDown: -0.39986845456135867\n",
      "Sharpe ratio: 0.9626438528083041\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 465834.125\n",
      "Final accumulative portfolio value: 4.658341407775879\n",
      "Maximum DrawDown: -0.42610125704095714\n",
      "Sharpe ratio: 1.0433652229232575\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 441278.625\n",
      "Final accumulative portfolio value: 4.412786483764648\n",
      "Maximum DrawDown: -0.4261012620270098\n",
      "Sharpe ratio: 1.015172236893896\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 493959.0625\n",
      "Final accumulative portfolio value: 4.9395904541015625\n",
      "Maximum DrawDown: -0.4291767084230218\n",
      "Sharpe ratio: 1.0542494728574825\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/           |               |\n",
      "|    ep_len_mean     | 1.82e+03      |\n",
      "|    ep_rew_mean     | 1.52          |\n",
      "| time/              |               |\n",
      "|    episodes        | 8             |\n",
      "|    fps             | 0             |\n",
      "|    time_elapsed    | 56504         |\n",
      "|    total_timesteps | 14528         |\n",
      "| train/             |               |\n",
      "|    actor_loss      | -0.103        |\n",
      "|    critic_loss     | 7.68e-05      |\n",
      "|    learning_rate   | 0.0001        |\n",
      "|    n_updates       | 14427         |\n",
      "|    reward          | -0.0064504314 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 519976.90625\n",
      "Final accumulative portfolio value: 5.199769020080566\n",
      "Maximum DrawDown: -0.42917670070342295\n",
      "Sharpe ratio: 1.0802933402325947\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_models, training_times = train_models(\n",
    "    DRLAgent(train_env), model_configs, results_dir, total_timesteps=50_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d312bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times_df = pd.DataFrame(\n",
    "    list(training_times.items()), columns=[\"model\", \"training_duration (min)\"]\n",
    ")\n",
    "training_times_df.to_csv(f\"{results_dir}/training_times.csv\", index=False)\n",
    "\n",
    "print(\"Training summary:\")\n",
    "display(training_times_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b1712",
   "metadata": {},
   "source": [
    "## Model loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13c75e",
   "metadata": {},
   "source": [
    "Load the trained models from memory for analysis without the need for time consuming retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_configs, results_dir):\n",
    "    models = {}\n",
    "    for model_class, name, _ in model_configs:\n",
    "        model_path = f\"{results_dir}/{name.lower()}_model.zip\"\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading saved model for {name}...\")\n",
    "            models[name] = model_class.load(model_path)\n",
    "        else:\n",
    "            print(f\"No saved model found for {name}.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "# If you already trained above you can skip this; otherwise:\n",
    "# trained_models = load_models(model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ec26e",
   "metadata": {},
   "source": [
    "## Backtesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f8c6",
   "metadata": {},
   "source": [
    "- Evaluates the performance of the RL models/algorithms in a trading environment.\n",
    "- We do this by calculating the **cumulative portfolio value** and **performance metrics** for each RL model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\"initial_amount\": 100_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_backtest(model, env, initial_amount):\n",
    "    \"\"\"\n",
    "    Runs the env step by step, predicting actions with `model`, and\n",
    "    builds a DataFrame of dates, daily returns, and account values.\n",
    "    \"\"\"\n",
    "    # reset and get initial obs\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # start from initial capital\n",
    "    portfolio_value = initial_amount\n",
    "\n",
    "    dates, daily_rets, account_vals = [], [], []\n",
    "\n",
    "    while not done:\n",
    "        # predict an action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # step the environment\n",
    "        result = env.step(action)\n",
    "\n",
    "        # handle gymnasium vs. gym return signature\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "\n",
    "        # update portfolio value from the reward\n",
    "        portfolio_value *= 1 + reward\n",
    "\n",
    "        # record\n",
    "        daily_rets.append(reward)\n",
    "        account_vals.append(portfolio_value)\n",
    "\n",
    "        # grab the current date from info\n",
    "        dates.append(info[\"end_time\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"daily_return\": daily_rets,\n",
    "            \"account_value\": account_vals,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def backtest_rl_strategies_manual(models, test_env, env_kwargs):\n",
    "    out = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nManual backtest: {name}\")\n",
    "        df_ret = manual_backtest(model, test_env, env_kwargs[\"initial_amount\"])\n",
    "        # ensure it's sorted by date\n",
    "        df_ret = df_ret.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        # compute performance stats\n",
    "        stats = backtest_stats(df_ret, value_col_name=\"account_value\")\n",
    "        out[name] = {\"df\": df_ret, \"stats\": stats}\n",
    "    return out\n",
    "\n",
    "\n",
    "results = backtest_rl_strategies_manual(trained_models, test_env, env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a4903",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_results():\n",
    "    os.makedirs(f\"{results_dir}/backtest_plots\", exist_ok=True)\n",
    "    for name, res in results.items():\n",
    "        print(f\"Plotting {name}…\")\n",
    "        backtest_plot(\n",
    "            account_value=res[\"df\"],\n",
    "            baseline_start=test_start_date,\n",
    "            baseline_end=end_date,\n",
    "            baseline_ticker=\"SPY\",\n",
    "            value_col_name=\"account_value\",\n",
    "        )\n",
    "\n",
    "plot_backtest_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        df = res[\"df\"]\n",
    "        # compute cumulative returns from account_value\n",
    "        cum = df[\"account_value\"] / df[\"account_value\"].iloc[0] - 1\n",
    "        plt.plot(df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns vs. SPY\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945e551",
   "metadata": {},
   "source": [
    "## Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee740d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mpt_benchmark(test, env_kwargs):\n",
    "    dates_test = test.date.unique()\n",
    "    min_vals = [env_kwargs[\"initial_amount\"]]\n",
    "    for i in range(len(dates_test) - 1):\n",
    "        curr = test[test.date == dates_test[i]]\n",
    "        nxt = test[test.date == dates_test[i + 1]]\n",
    "        covm = np.array(curr.cov_list.values[0])\n",
    "        ef = EfficientFrontier(None, covm, weight_bounds=(0, 1))\n",
    "        ef.min_volatility()\n",
    "        w = ef.clean_weights()\n",
    "        prices = curr.close.values\n",
    "        nextp = nxt.close.values\n",
    "        shares = np.array(list(w.values())) * min_vals[-1] / prices\n",
    "        min_vals.append(np.dot(shares, nextp))\n",
    "    min_df = pd.DataFrame({\"date\": dates_test, \"account_value\": min_vals})\n",
    "    stats_mpt = backtest_stats(min_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": min_df, \"stats\": stats_mpt}\n",
    "\n",
    "\n",
    "mpt_benchmark = compute_mpt_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd051b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(test, env_kwargs):\n",
    "    ew_daily = test.groupby(\"date\")[\"close\"].apply(\n",
    "        lambda d: d.pct_change().fillna(0).mean()\n",
    "    )\n",
    "\n",
    "    ew_df = ew_daily.reset_index(name=\"daily_return\")\n",
    "    ew_df[\"account_value\"] = (ew_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": ew_df, \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(df, initial_amount=100_000):\n",
    "    # Pivot to have one column per ticker\n",
    "    price_wide = df.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).sort_index()\n",
    "\n",
    "    # Compute each ticker's daily return, then average equally\n",
    "    daily_rets = price_wide.pct_change().fillna(0).mean(axis=1)\n",
    "\n",
    "    # Build the equity curve\n",
    "    ew_df = pd.DataFrame({\"date\": daily_rets.index, \"daily_return\": daily_rets.values})\n",
    "    ew_df[\"account_value\"] = (ew_df[\"daily_return\"] + 1).cumprod() * initial_amount\n",
    "\n",
    "    # Compute performance statistics\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "\n",
    "    return {\"df\": ew_df.reset_index(drop=True), \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs[\"initial_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spy_benchmark(test, env_kwargs):\n",
    "    spy_close = get_baseline(\"SPY\", test.date.min(), test.date.max())[\"close\"]\n",
    "    spy_ret = spy_close.pct_change().dropna()\n",
    "    spy_df = pd.DataFrame({\"date\": spy_ret.index, \"daily_return\": spy_ret.values})\n",
    "    spy_df[\"account_value\"] = (spy_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_spy = backtest_stats(spy_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": spy_df, \"stats\": stats_spy}\n",
    "\n",
    "\n",
    "spy_benchmark = compute_spy_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a147661",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = {\n",
    "    \"MPT\": mpt_benchmark,\n",
    "    \"EW\": ew_benchmark,\n",
    "    \"SPY\": spy_benchmark,\n",
    "}\n",
    "\n",
    "results.update(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c912897",
   "metadata": {},
   "source": [
    "## Performance Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_stats = pd.DataFrame({key.upper(): res[\"stats\"] for key, res in results.items()})\n",
    "display(perf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_include = [\n",
    "    \"Cumulative returns\",\n",
    "    \"Annual return\",\n",
    "    \"Annual volatility\",\n",
    "    \"Sharpe ratio\",\n",
    "    \"Max drawdown\",\n",
    "]\n",
    "filtered_perf_stats = perf_stats.loc[metrics_to_include]\n",
    "\n",
    "filtered_perf_stats.T.plot(kind=\"bar\", figsize=(14, 8), legend=True)\n",
    "plt.title(\"Performance Metrics Comparison\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        # Ensure the date column is converted to datetime\n",
    "        res[\"df\"][\"date\"] = pd.to_datetime(res[\"df\"][\"date\"])\n",
    "        # Filter data to start from the trade start date\n",
    "        filtered_df = res[\"df\"][res[\"df\"][\"date\"] >= test_start_date]\n",
    "        cum = (\n",
    "            (filtered_df[\"daily_return\"] + 1).cumprod() - 1\n",
    "            if \"daily_return\" in filtered_df\n",
    "            else filtered_df[\"account_value\"] / filtered_df[\"account_value\"].iloc[0] - 1\n",
    "        )\n",
    "        plt.plot(filtered_df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
