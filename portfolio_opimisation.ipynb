{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c5a8a",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f8e10",
   "metadata": {},
   "source": [
    "This experiment demonstrates the application of Deep Reinforcement Learning (DRL) algorithms (`A2C`, `PPO`, `SAC`) for portfolio optimization.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. Downloads & preprocesses Dow 30 data\n",
    "2. Engineers features & computes covariances\n",
    "3. Splits into train/test sets with validation\n",
    "4. Configures Gym environment with tunable parameters\n",
    "5. Trains `A2C`, `PPO`, and `SAC` with hyperparameter options\n",
    "6. Backtests strategies and computes risk-adjusted stats\n",
    "7. Builds a minimum-variance benchmark\n",
    "8. Plots comparative returns\n",
    "9. Provides commented options for further tuning and validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfb03e",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -n portfolio_opt ipykernel --update-deps --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas numpy matplotlib \\\n",
    "               stable-baselines3 \\\n",
    "               PyPortfolioOpt \\\n",
    "               pandas_market_calendars quantstats gymnasium \\\n",
    "               git+https://github.com/AI4Finance-Foundation/FinRL.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51776d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC\n",
    "\n",
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, get_daily_return, get_baseline, convert_daily_return_to_pyfolio_ts\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "# import quantstats as qs\n",
    "\n",
    "# Set up matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c29127c",
   "metadata": {},
   "source": [
    "## Configure train/trade date ranges\n",
    "\n",
    "Define the date ranges for training, validation, and trading(testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35d1a16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: '2015-01-01' to '2023-12-31'\n",
      "Trade: '2024-01-01' to '2025-04-24'\n"
     ]
    }
   ],
   "source": [
    "train_start = \"2015-01-01\"\n",
    "train_end = \"2023-12-31\"\n",
    "\n",
    "trade_start = \"2024-01-01\"\n",
    "trade_end = (datetime.now() - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(f\"Train: '{train_start}' to '{train_end}'\")\n",
    "print(f\"Trade: '{trade_start}' to '{trade_end}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bcfe",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94d2a4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Downloading data from 2015-01-01 to 2025-04-24'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Tickers: ['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (76701, 8)\n"
     ]
    }
   ],
   "source": [
    "ticker_list = config_tickers.DOW_30_TICKER\n",
    "start_date = train_start\n",
    "end_date = trade_end\n",
    "\n",
    "display(f\"Downloading data from {start_date} to {end_date}\")\n",
    "display(f\"Tickers: {ticker_list}\")\n",
    "\n",
    "df = YahooDownloader(\n",
    "    start_date=start_date, end_date=end_date, ticker_list=ticker_list\n",
    ").fetch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a0aad",
   "metadata": {},
   "source": [
    "## Preprocess data and append technical indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52a9adfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Successfully added technical indicators\n",
      "df_tech shape: (75168, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing data...\")\n",
    "# TODO: Test with turbulence\n",
    "fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=False)\n",
    "df_tech = fe.preprocess_data(df)\n",
    "\n",
    "print(f\"df_tech shape: {df_tech.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4d1f5",
   "metadata": {},
   "source": [
    "# Covariance & Returns for State\n",
    "\n",
    "Rolling window of 252 trading days → build `cov_list` and `return_list`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing covariance matrices...\n",
      "df_final shape with cov_list: (67860, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing covariance matrices...\")\n",
    "\n",
    "df_sorted = df_tech.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "df_sorted.index = df_sorted.date.factorize()[0]\n",
    "\n",
    "cov_list, return_list = [], []\n",
    "lookback = 252\n",
    "unique_dates = df_sorted.date.unique()\n",
    "\n",
    "for i in range(lookback, len(unique_dates)):\n",
    "    window = df_sorted.loc[i - lookback : i]\n",
    "    price_mat = window.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "    ret_mat = price_mat.pct_change().dropna()\n",
    "    return_list.append(ret_mat)\n",
    "    cov_list.append(ret_mat.cov().values)\n",
    "\n",
    "# Merge back\n",
    "df_cov = pd.DataFrame(\n",
    "    {\"date\": unique_dates[lookback:], \"cov_list\": cov_list, \"return_list\": return_list}\n",
    ")\n",
    "df_merged = pd.merge(df_tech, df_cov, on=\"date\", how=\"left\")\n",
    "df_final = df_merged[df_merged[\"cov_list\"].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"df_final shape with cov_list: {df_final.shape}\")\n",
    "assert (\n",
    "    \"cov_list\" in df_final.columns\n",
    "), \"cov_list missing ― check lookback or merge logic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e6fe0",
   "metadata": {},
   "source": [
    "## Train/Trade split\n",
    "\n",
    "Split by date-range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a1317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (58348, 18)\n",
      "Validation data: (21837, 18)\n",
      "Trade data: (9512, 18)\n"
     ]
    }
   ],
   "source": [
    "train_data = data_split(df_final, train_start, train_end)\n",
    "trade_data = data_split(df_final, trade_start, trade_end)\n",
    "\n",
    "print(f\"Train data: {train_data.shape}\")\n",
    "print(f\"Trade data: {trade_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd4570",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27acbb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dim: 29, State Space: 29, Indicators: ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n"
     ]
    }
   ],
   "source": [
    "stock_dim = len(train_data.tic.unique())\n",
    "state_space = stock_dim\n",
    "tech_indicators = config.INDICATORS\n",
    "\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dim,\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1e6,\n",
    "    \"transaction_cost_pct\": 0.001,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space,\n",
    "    \"action_space\": stock_dim,\n",
    "    \"tech_indicator_list\": tech_indicators,\n",
    "    \"turbulence_threshold\": 100,  # TODO: Set a threshold for turbulence. Penalize extreme volatility\n",
    "}\n",
    "print(\n",
    "    f\"\"\"Stock Dim: {stock_dim}\n",
    "    State Space: {state_space}\n",
    "    Indicators: {tech_indicators}\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Create Gym environments\n",
    "e_train = StockPortfolioEnv(df=train_data, **env_kwargs)\n",
    "env_train, _ = e_train.get_sb_env()\n",
    "e_trade = StockPortfolioEnv(df=trade_data, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc6bdb",
   "metadata": {},
   "source": [
    "## Train DRL agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8081ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training A2C...\n",
      "{'learning_rate': 7e-05, 'ent_coef': 0.01, 'n_steps': 5}\n",
      "Using cpu device\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 732       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 1.77e+08  |\n",
      "|    reward             | 1507876.4 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 2.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 805       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.36e+08  |\n",
      "|    reward             | 1942178.1 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 3.89e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 811       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 3.08e+08  |\n",
      "|    reward             | 2649897.2 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 7.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 809       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.6e+08   |\n",
      "|    reward             | 3024931.0 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 9.22e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3066613.1776650394\n",
      "Sharpe:  0.8707731057257575\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 793       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 1.69e+08  |\n",
      "|    reward             | 1453763.9 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 2.23e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 810       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.19e+08  |\n",
      "|    reward             | 1886423.1 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 3.86e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 816       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 3.37e+08  |\n",
      "|    reward             | 2558091.2 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 7.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 804       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 4         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 3.42e+08  |\n",
      "|    reward             | 2805310.2 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 8.16e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2999783.6499864375\n",
      "Sharpe:  0.8556697895751484\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 790       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 1.6e+08   |\n",
      "|    reward             | 1430817.5 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 2.14e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 796       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 2.32e+08  |\n",
      "|    reward             | 1920033.2 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 3.83e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 789       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 3.38e+08  |\n",
      "|    reward             | 2592679.0 |\n",
      "|    std                | 0.999     |\n",
      "|    value_loss         | 7.15e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 785       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 2.79e+08  |\n",
      "|    reward             | 2416003.2 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 5.82e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2709307.687639948\n",
      "Sharpe:  0.7802657788102806\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 781       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 1.77e+08  |\n",
      "|    reward             | 1390372.2 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 2.03e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 779       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.07e+08  |\n",
      "|    reward             | 1826213.8 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 3.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 779       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2713260.5 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 7.77e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 785       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 3.39e+08  |\n",
      "|    reward             | 2675889.8 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 8.01e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3080887.4398827283\n",
      "Sharpe:  0.8730421797530478\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 783       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 1.66e+08  |\n",
      "|    reward             | 1370768.5 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 1.96e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 787       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 2.14e+08  |\n",
      "|    reward             | 1905863.4 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 3.68e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 790       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 3.48e+08  |\n",
      "|    reward             | 2626483.5 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 7.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 790       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.17e+08  |\n",
      "|    reward             | 2574824.0 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 7.25e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2960223.517843064\n",
      "Sharpe:  0.83997953141868\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 788       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 1.49e+08  |\n",
      "|    reward             | 1367978.0 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.97e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 788       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 2.2e+08   |\n",
      "|    reward             | 1845100.5 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 3.68e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 792       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 3.29e+08  |\n",
      "|    reward             | 2625674.2 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 7.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 794       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 3.19e+08  |\n",
      "|    reward             | 2642535.0 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 7.55e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2890812.1313727465\n",
      "Sharpe:  0.828148657566141\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 791       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 1.69e+08  |\n",
      "|    reward             | 1320476.1 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.8e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 792       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 2.05e+08  |\n",
      "|    reward             | 1805018.0 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 3.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 795       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 3.18e+08  |\n",
      "|    reward             | 2463207.2 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 6.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 2554826.8 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 6.8e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2759690.8589989436\n",
      "Sharpe:  0.7951810966529547\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 794       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 1.45e+08  |\n",
      "|    reward             | 1334727.6 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.89e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.93e+08  |\n",
      "|    reward             | 1728472.0 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.24e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 798       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 3.35e+08  |\n",
      "|    reward             | 2558700.2 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 7.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 800       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 3.12e+08  |\n",
      "|    reward             | 2656417.8 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 7.7e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2922179.584760886\n",
      "Sharpe:  0.8362702145664144\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 796       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 1.64e+08  |\n",
      "|    reward             | 1313605.4 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.87e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 2.08e+08  |\n",
      "|    reward             | 1713347.5 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 798       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 3.05e+08  |\n",
      "|    reward             | 2556183.5 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 7.01e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 799       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 3.12e+08  |\n",
      "|    reward             | 2748180.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 7.82e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2948035.9773702407\n",
      "Sharpe:  0.844633998175021\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 1.44e+08  |\n",
      "|    reward             | 1293918.0 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.76e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 798       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 2.16e+08  |\n",
      "|    reward             | 1832135.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 3.61e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 799       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 3.28e+08  |\n",
      "|    reward             | 2661496.0 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 7.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 800       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 3.41e+08  |\n",
      "|    reward             | 2887064.2 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 8.83e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3209042.700559051\n",
      "Sharpe:  0.902299721846775\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.5e+08   |\n",
      "|    reward             | 1262162.6 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.69e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 797       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 2.06e+08  |\n",
      "|    reward             | 1727885.6 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 3.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 796       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 2.82e+08  |\n",
      "|    reward             | 2286522.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 5.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 796       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 2.96e+08  |\n",
      "|    reward             | 2427973.2 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 6.44e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2723131.438578904\n",
      "Sharpe:  0.7885642066534777\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 790       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 1.52e+08  |\n",
      "|    reward             | 1240141.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 789       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 2.18e+08  |\n",
      "|    reward             | 1706065.5 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 3.04e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 788       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 2.84e+08  |\n",
      "|    reward             | 2451165.0 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 6.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 788       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 2.94e+08  |\n",
      "|    reward             | 2488170.2 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 6.28e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2767667.791395651\n",
      "Sharpe:  0.7927703999067721\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 785       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 1.41e+08  |\n",
      "|    reward             | 1282712.5 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 1.7e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 786       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 2.17e+08  |\n",
      "|    reward             | 1753877.2 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 3.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 786       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 3.23e+08  |\n",
      "|    reward             | 2641293.0 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 7.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 786       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 3.47e+08  |\n",
      "|    reward             | 2791768.5 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 8.29e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3170335.5107880416\n",
      "Sharpe:  0.8913814389836224\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 783       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 1.49e+08  |\n",
      "|    reward             | 1219757.0 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 782       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 1.81e+08  |\n",
      "|    reward             | 1571666.2 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 2.85e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 781       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 2325248.8 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 5.6e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 781       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 2.68e+08  |\n",
      "|    reward             | 2333567.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 5.86e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2676920.0884558894\n",
      "Sharpe:  0.776017782337121\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 778       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 1.41e+08  |\n",
      "|    reward             | 1233806.2 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.57e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 777       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 2.1e+08   |\n",
      "|    reward             | 1692320.8 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 3.03e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 777       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 3.04e+08  |\n",
      "|    reward             | 2437683.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 6.34e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 777       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 3.18e+08  |\n",
      "|    reward             | 2601813.5 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 7.1e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2983030.541572819\n",
      "Sharpe:  0.8423601094828617\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 775       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 1.47e+08  |\n",
      "|    reward             | 1260644.1 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.7e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 775       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 2.13e+08  |\n",
      "|    reward             | 1823761.8 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 3.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 775       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 40        |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 3.13e+08  |\n",
      "|    reward             | 2623242.8 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 7.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 776       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 3.34e+08  |\n",
      "|    reward             | 2671133.0 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 7.49e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3141692.498883025\n",
      "Sharpe:  0.88617241616259\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 776       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 1.48e+08  |\n",
      "|    reward             | 1227504.1 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.65e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 775       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 2.14e+08  |\n",
      "|    reward             | 1703856.4 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 2.98e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 776       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 2.82e+08  |\n",
      "|    reward             | 2406976.8 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 5.69e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 778       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2423799.0 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 6.68e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2887137.529996667\n",
      "Sharpe:  0.8233516705606401\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 775       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1236337.1 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.64e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 774       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 2.01e+08  |\n",
      "|    reward             | 1715501.0 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 3.18e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 774       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 2.83e+08  |\n",
      "|    reward             | 2313462.2 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 5.91e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 774       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 3.36e+08  |\n",
      "|    reward             | 2586698.5 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 7.56e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2976392.832538362\n",
      "Sharpe:  0.8510435467524512\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 772       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.5e+08   |\n",
      "|    reward             | 1245105.8 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.57e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 771       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 1.94e+08  |\n",
      "|    reward             | 1664066.8 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 2.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 764       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.79e+08  |\n",
      "|    reward             | 2381963.0 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 5.67e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 762       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2587094.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 7.05e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2884967.4845472057\n",
      "Sharpe:  0.8245771536738763\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1174868.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 761       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 1.86e+08  |\n",
      "|    reward             | 1555285.4 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 2.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 762       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 2.83e+08  |\n",
      "|    reward             | 2180487.5 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 5.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 3.12e+08  |\n",
      "|    reward             | 2354871.5 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 5.97e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2703254.006651342\n",
      "Sharpe:  0.7774686969667646\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 1.42e+08  |\n",
      "|    reward             | 1172785.9 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 761       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.91e+08  |\n",
      "|    reward             | 1575852.5 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 2.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 761       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 2.33e+08  |\n",
      "|    reward             | 2124187.8 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 4.75e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 761       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 2.82e+08  |\n",
      "|    reward             | 2301644.2 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 5.57e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2672585.9644033182\n",
      "Sharpe:  0.7708694536606614\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 1.32e+08  |\n",
      "|    reward             | 1145583.6 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 1.88e+08  |\n",
      "|    reward             | 1426634.1 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 2.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 2.53e+08  |\n",
      "|    reward             | 2052719.8 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 4.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 2.92e+08  |\n",
      "|    reward             | 2332809.8 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 5.88e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2633301.140617445\n",
      "Sharpe:  0.7568318664022443\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1154619.2 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 1.81e+08  |\n",
      "|    reward             | 1652175.1 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 2.77e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 2.5e+08   |\n",
      "|    reward             | 2179650.2 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 5.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 2.97e+08  |\n",
      "|    reward             | 2577446.2 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 6.85e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2908454.6633645934\n",
      "Sharpe:  0.8354367505058544\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 1.29e+08  |\n",
      "|    reward             | 1138020.8 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 2.03e+08  |\n",
      "|    reward             | 1686147.0 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 3.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 2.35e+08  |\n",
      "|    reward             | 2095742.1 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 4.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 2.88e+08  |\n",
      "|    reward             | 2329422.2 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 5.61e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2830854.8517566375\n",
      "Sharpe:  0.8095305313977158\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 1.35e+08  |\n",
      "|    reward             | 1072408.5 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.28e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 2.09e+08  |\n",
      "|    reward             | 1639884.9 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 2.93e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 754       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 2.44e+08  |\n",
      "|    reward             | 2036858.9 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 4.68e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 2.78e+08  |\n",
      "|    reward             | 2331514.2 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 5.41e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3014977.228815813\n",
      "Sharpe:  0.8552012363645575\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 754       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | 1.3e+08   |\n",
      "|    reward             | 1081227.8 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.27e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 10200     |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 51000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10199     |\n",
      "|    policy_loss        | 1.93e+08  |\n",
      "|    reward             | 1614153.0 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 3.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 756       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | 2.41e+08  |\n",
      "|    reward             | 2016630.9 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 4.09e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 756       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 68        |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 2.6e+08   |\n",
      "|    reward             | 2165558.0 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 4.75e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2844653.5493538547\n",
      "Sharpe:  0.8151138568202294\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 1.29e+08  |\n",
      "|    reward             | 1107677.8 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.31e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 10600     |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 53000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10599     |\n",
      "|    policy_loss        | 1.9e+08   |\n",
      "|    reward             | 1689436.1 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 3e+13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 2.51e+08  |\n",
      "|    reward             | 1972823.4 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 4.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | 2.95e+08  |\n",
      "|    reward             | 2270467.0 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 5.83e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2914115.470725892\n",
      "Sharpe:  0.8286036427367534\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 1.38e+08  |\n",
      "|    reward             | 1102966.5 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | 1.9e+08   |\n",
      "|    reward             | 1645421.6 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 2.92e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 754       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | 2.41e+08  |\n",
      "|    reward             | 1980428.0 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 4.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | 2.73e+08  |\n",
      "|    reward             | 2284562.5 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 6.18e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2803465.960356562\n",
      "Sharpe:  0.7995174657399337\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | 1.35e+08  |\n",
      "|    reward             | 1094870.4 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 75        |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 2e+08     |\n",
      "|    reward             | 1645250.2 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 2.77e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 2.22e+08  |\n",
      "|    reward             | 1912161.8 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 3.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 77        |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | 2.75e+08  |\n",
      "|    reward             | 2456913.2 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 6.02e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2866127.9151353478\n",
      "Sharpe:  0.8210021224708618\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | 1.31e+08  |\n",
      "|    reward             | 1101491.4 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.27e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | 1.99e+08  |\n",
      "|    reward             | 1604964.8 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 2.7e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 11900     |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 59500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11899     |\n",
      "|    policy_loss        | 2.3e+08   |\n",
      "|    reward             | 1925279.9 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 4.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | 2.92e+08  |\n",
      "|    reward             | 2479737.5 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 6.25e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2978076.5970557802\n",
      "Sharpe:  0.8452675159393347\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 747       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 1.32e+08  |\n",
      "|    reward             | 1086889.9 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 1.75e+08  |\n",
      "|    reward             | 1556948.4 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 2.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 2.27e+08  |\n",
      "|    reward             | 1889181.1 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.59e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 2.37e+08  |\n",
      "|    reward             | 2129399.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 4.84e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2661908.1689851307\n",
      "Sharpe:  0.7705295076704246\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | 1.24e+08  |\n",
      "|    reward             | 1061660.6 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.14e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | 1.7e+08   |\n",
      "|    reward             | 1546562.4 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 2.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 12700     |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 63500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12699     |\n",
      "|    policy_loss        | 2.34e+08  |\n",
      "|    reward             | 1807608.6 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 3.79e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | 3e+08     |\n",
      "|    reward             | 2361102.5 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 6.14e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3083470.3127944306\n",
      "Sharpe:  0.8688792856472171\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | 1.27e+08  |\n",
      "|    reward             | 1042584.4 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.17e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 751       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 86        |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | 1.74e+08  |\n",
      "|    reward             | 1556455.2 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 2.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 751       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | 2.46e+08  |\n",
      "|    reward             | 1971412.0 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 3.75e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 751       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 2.98e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | 2.63e+08  |\n",
      "|    reward             | 2496197.8 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 6.21e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2946899.188121948\n",
      "Sharpe:  0.8410870338700904\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 751       |\n",
      "|    iterations         | 13300     |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 66500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13299     |\n",
      "|    policy_loss        | 1.22e+08  |\n",
      "|    reward             | 1053462.0 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.14e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 13400     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 67000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13399     |\n",
      "|    policy_loss        | 1.9e+08   |\n",
      "|    reward             | 1531298.6 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 2.56e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 13500     |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 67500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13499     |\n",
      "|    policy_loss        | 2.21e+08  |\n",
      "|    reward             | 1828123.8 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 3.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 13600     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 68000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13599     |\n",
      "|    policy_loss        | 3.08e+08  |\n",
      "|    reward             | 2543225.5 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 6.93e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3074217.889843295\n",
      "Sharpe:  0.8687974736898076\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 13700     |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 68500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13699     |\n",
      "|    policy_loss        | 1.22e+08  |\n",
      "|    reward             | 1022488.2 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 753       |\n",
      "|    iterations         | 13800     |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 69000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13799     |\n",
      "|    policy_loss        | 1.7e+08   |\n",
      "|    reward             | 1524429.9 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 2.36e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 754       |\n",
      "|    iterations         | 13900     |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 69500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13899     |\n",
      "|    policy_loss        | 1.98e+08  |\n",
      "|    reward             | 1688350.2 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 3.22e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 14000     |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 70000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 13999     |\n",
      "|    policy_loss        | 3.05e+08  |\n",
      "|    reward             | 2355453.2 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 6.5e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2729554.273355441\n",
      "Sharpe:  0.7917147907163662\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 14100     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 70500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14099     |\n",
      "|    policy_loss        | 1.38e+08  |\n",
      "|    reward             | 1073369.9 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.27e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 14200     |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 71000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14199     |\n",
      "|    policy_loss        | 1.88e+08  |\n",
      "|    reward             | 1508699.8 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 2.49e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 756       |\n",
      "|    iterations         | 14300     |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 71500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14299     |\n",
      "|    policy_loss        | 2.02e+08  |\n",
      "|    reward             | 1755312.8 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 3.15e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 757       |\n",
      "|    iterations         | 14400     |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 72000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14399     |\n",
      "|    policy_loss        | 3.14e+08  |\n",
      "|    reward             | 2522475.0 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 7.04e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2764598.4251195393\n",
      "Sharpe:  0.7921378919264639\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 757       |\n",
      "|    iterations         | 14500     |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 72500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14499     |\n",
      "|    policy_loss        | 1.22e+08  |\n",
      "|    reward             | 1054963.8 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.19e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 14600     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 73000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14599     |\n",
      "|    policy_loss        | 1.75e+08  |\n",
      "|    reward             | 1454083.6 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.28e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 14700     |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 73500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14699     |\n",
      "|    policy_loss        | 1.69e+08  |\n",
      "|    reward             | 1488618.9 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 14800     |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 74000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14799     |\n",
      "|    policy_loss        | 2.94e+08  |\n",
      "|    reward             | 2519822.2 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 6.47e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2677750.1501392056\n",
      "Sharpe:  0.7742725737164738\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 758        |\n",
      "|    iterations         | 14900      |\n",
      "|    time_elapsed       | 98         |\n",
      "|    total_timesteps    | 74500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -40.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 7e-05      |\n",
      "|    n_updates          | 14899      |\n",
      "|    policy_loss        | 1.24e+08   |\n",
      "|    reward             | 1036444.25 |\n",
      "|    std                | 0.982      |\n",
      "|    value_loss         | 1.12e+13   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 15000     |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 75000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 14999     |\n",
      "|    policy_loss        | 1.75e+08  |\n",
      "|    reward             | 1546117.5 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.62e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 15100     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 75500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15099     |\n",
      "|    policy_loss        | 2.19e+08  |\n",
      "|    reward             | 1501093.8 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 3.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15200     |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 76000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15199     |\n",
      "|    policy_loss        | 3.15e+08  |\n",
      "|    reward             | 2664341.2 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 7.7e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3048826.380146107\n",
      "Sharpe:  0.8566475874189864\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15300     |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 76500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15299     |\n",
      "|    policy_loss        | 1.22e+08  |\n",
      "|    reward             | 999938.25 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15400     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 77000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15399     |\n",
      "|    policy_loss        | 1.92e+08  |\n",
      "|    reward             | 1550876.4 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 2.61e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15500     |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 77500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15499     |\n",
      "|    policy_loss        | 2.36e+08  |\n",
      "|    reward             | 1797400.8 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 4.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15600     |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 78000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15599     |\n",
      "|    policy_loss        | 3.14e+08  |\n",
      "|    reward             | 2559335.5 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 7.32e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2899063.043306498\n",
      "Sharpe:  0.8216026588071565\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 759      |\n",
      "|    iterations         | 15700    |\n",
      "|    time_elapsed       | 103      |\n",
      "|    total_timesteps    | 78500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -40.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 7e-05    |\n",
      "|    n_updates          | 15699    |\n",
      "|    policy_loss        | 1.12e+08 |\n",
      "|    reward             | 965189.8 |\n",
      "|    std                | 0.981    |\n",
      "|    value_loss         | 9.21e+12 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 15800     |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 79000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15799     |\n",
      "|    policy_loss        | 1.81e+08  |\n",
      "|    reward             | 1513033.2 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 2.56e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 15900     |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 79500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15899     |\n",
      "|    policy_loss        | 2.49e+08  |\n",
      "|    reward             | 2024470.0 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.2e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 760       |\n",
      "|    iterations         | 16000     |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 80000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 15999     |\n",
      "|    policy_loss        | 3.21e+08  |\n",
      "|    reward             | 2767049.2 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 7.75e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2924246.11943297\n",
      "Sharpe:  0.8330051504911847\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 16100     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 80500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16099     |\n",
      "|    policy_loss        | 1.09e+08  |\n",
      "|    reward             | 949588.75 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 9.48e+12  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 759       |\n",
      "|    iterations         | 16200     |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 81000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16199     |\n",
      "|    policy_loss        | 1.87e+08  |\n",
      "|    reward             | 1599934.4 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 2.6e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16300     |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 81500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16299     |\n",
      "|    policy_loss        | 2.36e+08  |\n",
      "|    reward             | 1999928.6 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.19e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16400     |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 82000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16399     |\n",
      "|    policy_loss        | 3.18e+08  |\n",
      "|    reward             | 2726297.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 8.03e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2829869.1633611936\n",
      "Sharpe:  0.8114536148997701\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16500     |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 82500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16499     |\n",
      "|    policy_loss        | 1.12e+08  |\n",
      "|    reward             | 960272.56 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16600     |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 83000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16599     |\n",
      "|    policy_loss        | 1.78e+08  |\n",
      "|    reward             | 1519050.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 2.38e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 757       |\n",
      "|    iterations         | 16700     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 83500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16699     |\n",
      "|    policy_loss        | 2.23e+08  |\n",
      "|    reward             | 1958480.9 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16800     |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 84000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16799     |\n",
      "|    policy_loss        | 3.21e+08  |\n",
      "|    reward             | 2609820.2 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 6.84e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 16900     |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 84500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16899     |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2900243.5 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 8.77e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2907779.290098025\n",
      "Sharpe:  0.827888689696183\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 758       |\n",
      "|    iterations         | 17000     |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 85000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 16999     |\n",
      "|    policy_loss        | 1.78e+08  |\n",
      "|    reward             | 1456648.1 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 2.19e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 17100     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 85500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17099     |\n",
      "|    policy_loss        | 2.08e+08  |\n",
      "|    reward             | 1935263.4 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 3.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 17200     |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 86000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17199     |\n",
      "|    policy_loss        | 2.81e+08  |\n",
      "|    reward             | 2498802.0 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 6.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 755       |\n",
      "|    iterations         | 17300     |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 86500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17299     |\n",
      "|    policy_loss        | 2.97e+08  |\n",
      "|    reward             | 2655461.2 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 7.31e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2781541.462280206\n",
      "Sharpe:  0.794628085857668\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 752       |\n",
      "|    iterations         | 17400     |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 87000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17399     |\n",
      "|    policy_loss        | 1.67e+08  |\n",
      "|    reward             | 1526311.2 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 2.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 751       |\n",
      "|    iterations         | 17500     |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 87500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17499     |\n",
      "|    policy_loss        | 2.22e+08  |\n",
      "|    reward             | 1931720.9 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 3.94e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 17600     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 88000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17599     |\n",
      "|    policy_loss        | 3.39e+08  |\n",
      "|    reward             | 2613739.2 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 7.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 17700     |\n",
      "|    time_elapsed       | 117       |\n",
      "|    total_timesteps    | 88500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17699     |\n",
      "|    policy_loss        | 2.88e+08  |\n",
      "|    reward             | 2640536.8 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 6.95e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2832136.714437254\n",
      "Sharpe:  0.8135423615472508\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 17800     |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 89000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17799     |\n",
      "|    policy_loss        | 1.71e+08  |\n",
      "|    reward             | 1400262.2 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 2.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 17900     |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 89500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17899     |\n",
      "|    policy_loss        | 2.17e+08  |\n",
      "|    reward             | 1823119.6 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 3.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18000     |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 90000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 17999     |\n",
      "|    policy_loss        | 3.18e+08  |\n",
      "|    reward             | 2615468.5 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 6.95e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 750       |\n",
      "|    iterations         | 18100     |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 90500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18099     |\n",
      "|    policy_loss        | 2.8e+08   |\n",
      "|    reward             | 2505273.8 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 6.28e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2802688.004932769\n",
      "Sharpe:  0.802970367412783\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 18200     |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 91000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18199     |\n",
      "|    policy_loss        | 1.54e+08  |\n",
      "|    reward             | 1338234.1 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18300     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 91500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18299     |\n",
      "|    policy_loss        | 2.2e+08   |\n",
      "|    reward             | 1772627.1 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 3.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18400     |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 92000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18399     |\n",
      "|    policy_loss        | 3.09e+08  |\n",
      "|    reward             | 2514739.5 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 6.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18500     |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 92500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18499     |\n",
      "|    policy_loss        | 3.19e+08  |\n",
      "|    reward             | 2449714.8 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 6.21e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2769440.7295946307\n",
      "Sharpe:  0.7914005429657778\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18600     |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 93000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18599     |\n",
      "|    policy_loss        | 1.56e+08  |\n",
      "|    reward             | 1350320.4 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.94e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18700     |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 93500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18699     |\n",
      "|    policy_loss        | 1.99e+08  |\n",
      "|    reward             | 1762472.9 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 3.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 18800     |\n",
      "|    time_elapsed       | 125       |\n",
      "|    total_timesteps    | 94000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18799     |\n",
      "|    policy_loss        | 3.04e+08  |\n",
      "|    reward             | 2475486.0 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 6.77e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 18900     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 94500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18899     |\n",
      "|    policy_loss        | 3e+08     |\n",
      "|    reward             | 2506840.0 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 7.01e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2897832.8267323496\n",
      "Sharpe:  0.8254371954974128\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19000     |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 95000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 18999     |\n",
      "|    policy_loss        | 1.51e+08  |\n",
      "|    reward             | 1339278.1 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.92e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19100     |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 95500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19099     |\n",
      "|    policy_loss        | 2.41e+08  |\n",
      "|    reward             | 1850831.2 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 3.67e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19200     |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 96000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19199     |\n",
      "|    policy_loss        | 2.86e+08  |\n",
      "|    reward             | 2555757.8 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 7.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 749       |\n",
      "|    iterations         | 19300     |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 96500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19299     |\n",
      "|    policy_loss        | 3.09e+08  |\n",
      "|    reward             | 2642050.0 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 7.5e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2909961.6368414974\n",
      "Sharpe:  0.8293612111431659\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19400     |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 97000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19399     |\n",
      "|    policy_loss        | 1.51e+08  |\n",
      "|    reward             | 1329350.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.88e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19500     |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 97500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19499     |\n",
      "|    policy_loss        | 2.16e+08  |\n",
      "|    reward             | 1853056.6 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 3.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19600     |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 98000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19599     |\n",
      "|    policy_loss        | 3.34e+08  |\n",
      "|    reward             | 2682068.0 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 7.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19700     |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 98500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19699     |\n",
      "|    policy_loss        | 3.16e+08  |\n",
      "|    reward             | 2775171.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 8.43e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3094024.028449796\n",
      "Sharpe:  0.8802609061879706\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19800     |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 99000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19799     |\n",
      "|    policy_loss        | 1.68e+08  |\n",
      "|    reward             | 1318821.8 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.86e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 19900     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 99500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19899     |\n",
      "|    policy_loss        | 2.21e+08  |\n",
      "|    reward             | 1880763.6 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 3.73e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 748       |\n",
      "|    iterations         | 20000     |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 100000    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 7e-05     |\n",
      "|    n_updates          | 19999     |\n",
      "|    policy_loss        | 3.27e+08  |\n",
      "|    reward             | 2762949.8 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 7.96e+13  |\n",
      "-------------------------------------\n",
      "Training PPO...\n",
      "{'learning_rate': 0.0003, 'ent_coef': 0.02, 'n_steps': 128, 'batch_size': 64}\n",
      "Using cpu device\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 1507       |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 0          |\n",
      "|    total_timesteps | 128        |\n",
      "| train/             |            |\n",
      "|    reward          | 1038942.56 |\n",
      "-----------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 990       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 256       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.16e+14  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -4.74e-06 |\n",
      "|    reward               | 1142348.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 963       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 384       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -4.08e-06 |\n",
      "|    reward               | 1232779.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 961       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 512       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.66e+14  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -2.8e-06  |\n",
      "|    reward               | 1479566.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 960       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 640       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.02e+14  |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -4.43e-06 |\n",
      "|    reward               | 1514266.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.07e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 961       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 768       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.41e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -4.51e-06 |\n",
      "|    reward               | 1542169.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 909       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 0         |\n",
      "|    total_timesteps      | 896       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.59e+14  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 1748942.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 907       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 1024      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.3e+14   |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -3.37e-06 |\n",
      "|    reward               | 1886288.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 1152      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.69e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -2.61e-06 |\n",
      "|    reward               | 1802049.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 709       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 1280      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.23e+14  |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -2.9e-06  |\n",
      "|    reward               | 2139598.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.54e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 710       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 1         |\n",
      "|    total_timesteps      | 1408      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.68e+14  |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2465086.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.24e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 711       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 1536      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.2e+14   |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 2543879.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.28e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 728       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 1664      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.94e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -2.8e-06  |\n",
      "|    reward               | 2401495.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 744       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.96e+14  |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -1.72e-06 |\n",
      "|    reward               | 2520594.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 757       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 1920      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.11e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 2611312.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.26e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2899387.4760229667\n",
      "Sharpe:  0.8281159699363047\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 737       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 2048      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.05e+14  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 975944.56 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 744       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 2         |\n",
      "|    total_timesteps      | 2176      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.61e+14  |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -2.53e-06 |\n",
      "|    reward               | 1096712.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.08e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 750       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2304      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.25e+14  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -3.81e-06 |\n",
      "|    reward               | 1243052.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.56e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 731       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2432      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.53e+14  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -5.14e-06 |\n",
      "|    reward               | 1334601.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 738       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2560      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.87e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -4.94e-06 |\n",
      "|    reward               | 1522602.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 748       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2688      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.39e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 1636177.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 756       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2816      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -2.99e-06 |\n",
      "|    reward               | 1719512.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.47e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 763       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 2944      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.01e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 1801940.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 769       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 3         |\n",
      "|    total_timesteps      | 3072      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.41e+14  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -2.16e-06 |\n",
      "|    reward               | 1410649.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 776       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3200      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.14e+14  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -1.91e-06 |\n",
      "|    reward               | 1931118.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 780       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3328      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.01e+14  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -2.55e-06 |\n",
      "|    reward               | 2409280.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.89e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 785       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3456      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.39e+14  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -2.29e-06 |\n",
      "|    reward               | 2540555.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.1e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 791       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3584      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.36e+14  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2605899.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 790       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3712      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.58e+14  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2273260.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.55e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 796       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3840      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.01e+14  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 2620713.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 800       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 4         |\n",
      "|    total_timesteps      | 3968      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.34e+14  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -1.3e-06  |\n",
      "|    reward               | 2603416.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2916178.2293115053\n",
      "Sharpe:  0.8336348593796264\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 789       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 5         |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.92e+14  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -2.34e-06 |\n",
      "|    reward               | 1051046.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 772       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 5         |\n",
      "|    total_timesteps      | 4224      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.29e+14  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 1079387.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 776       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 5         |\n",
      "|    total_timesteps      | 4352      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.29e+14  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -3.31e-06 |\n",
      "|    reward               | 1255728.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 781       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 5         |\n",
      "|    total_timesteps      | 4480      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.64e+14  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -2.76e-06 |\n",
      "|    reward               | 1396661.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 785       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 5         |\n",
      "|    total_timesteps      | 4608      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.94e+14  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -5.66e-06 |\n",
      "|    reward               | 1500413.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 784       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 4736      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.65e+14  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -2.29e-06 |\n",
      "|    reward               | 1574629.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 782       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 4864      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.82e+14  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -3.33e-06 |\n",
      "|    reward               | 1711959.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.82e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 787       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 4992      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.06e+14  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -4.11e-06 |\n",
      "|    reward               | 1884072.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.13e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 790       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 5120      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.7e+14   |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -2.1e-06  |\n",
      "|    reward               | 1662679.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.36e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 795       |\n",
      "|    iterations           | 41        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 5248      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.98e+14  |\n",
      "|    n_updates            | 400       |\n",
      "|    policy_gradient_loss | -3.24e-06 |\n",
      "|    reward               | 2040516.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 798       |\n",
      "|    iterations           | 42        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 5376      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.07e+14  |\n",
      "|    n_updates            | 410       |\n",
      "|    policy_gradient_loss | -2.74e-06 |\n",
      "|    reward               | 2396781.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 801       |\n",
      "|    iterations           | 43        |\n",
      "|    time_elapsed         | 6         |\n",
      "|    total_timesteps      | 5504      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.77e+14  |\n",
      "|    n_updates            | 420       |\n",
      "|    policy_gradient_loss | -2.53e-06 |\n",
      "|    reward               | 2537002.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 802       |\n",
      "|    iterations           | 44        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 5632      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.3e+14   |\n",
      "|    n_updates            | 430       |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 2287281.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.41e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 807       |\n",
      "|    iterations           | 45        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 5760      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.12e+14  |\n",
      "|    n_updates            | 440       |\n",
      "|    policy_gradient_loss | -1.42e-06 |\n",
      "|    reward               | 2406212.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 810       |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 5888      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.38e+14  |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | -2.2e-06  |\n",
      "|    reward               | 2319126.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 813       |\n",
      "|    iterations           | 47        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 6016      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.07e+14  |\n",
      "|    n_updates            | 460       |\n",
      "|    policy_gradient_loss | -1.38e-06 |\n",
      "|    reward               | 2535356.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.28e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2637668.671542917\n",
      "Sharpe:  0.7676614551050455\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 807       |\n",
      "|    iterations           | 48        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.56e+14  |\n",
      "|    n_updates            | 470       |\n",
      "|    policy_gradient_loss | -1.54e-06 |\n",
      "|    reward               | 1061320.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.32e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 809       |\n",
      "|    iterations           | 49        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 6272      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.43e+14  |\n",
      "|    n_updates            | 480       |\n",
      "|    policy_gradient_loss | -3.9e-06  |\n",
      "|    reward               | 1147921.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 812       |\n",
      "|    iterations           | 50        |\n",
      "|    time_elapsed         | 7         |\n",
      "|    total_timesteps      | 6400      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.98e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.4e+14   |\n",
      "|    n_updates            | 490       |\n",
      "|    policy_gradient_loss | -3.94e-06 |\n",
      "|    reward               | 1273688.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.75e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 815       |\n",
      "|    iterations           | 51        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 6528      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.65e+14  |\n",
      "|    n_updates            | 500       |\n",
      "|    policy_gradient_loss | -4.08e-06 |\n",
      "|    reward               | 1507216.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 819       |\n",
      "|    iterations           | 52        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 6656      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.18e+14  |\n",
      "|    n_updates            | 510       |\n",
      "|    policy_gradient_loss | -3.04e-06 |\n",
      "|    reward               | 1557395.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 821       |\n",
      "|    iterations           | 53        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 6784      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.6e+14   |\n",
      "|    n_updates            | 520       |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 1503622.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 823       |\n",
      "|    iterations           | 54        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 6912      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.16e+14  |\n",
      "|    n_updates            | 530       |\n",
      "|    policy_gradient_loss | -3.07e-06 |\n",
      "|    reward               | 1781278.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 826       |\n",
      "|    iterations           | 55        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 7040      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.36e+14  |\n",
      "|    n_updates            | 540       |\n",
      "|    policy_gradient_loss | -2.85e-06 |\n",
      "|    reward               | 1951953.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.71e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 828       |\n",
      "|    iterations           | 56        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 7168      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.83e+14  |\n",
      "|    n_updates            | 550       |\n",
      "|    policy_gradient_loss | -2.48e-06 |\n",
      "|    reward               | 1874073.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 57        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 7296      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.79e+14  |\n",
      "|    n_updates            | 560       |\n",
      "|    policy_gradient_loss | -3.22e-06 |\n",
      "|    reward               | 2185529.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.39e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 831       |\n",
      "|    iterations           | 58        |\n",
      "|    time_elapsed         | 8         |\n",
      "|    total_timesteps      | 7424      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.88e+14  |\n",
      "|    n_updates            | 570       |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2581254.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 832       |\n",
      "|    iterations           | 59        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 7552      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.73e+14  |\n",
      "|    n_updates            | 580       |\n",
      "|    policy_gradient_loss | -1.89e-06 |\n",
      "|    reward               | 2734033.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 834       |\n",
      "|    iterations           | 60        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 7680      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.95e+14  |\n",
      "|    n_updates            | 590       |\n",
      "|    policy_gradient_loss | -1.56e-06 |\n",
      "|    reward               | 2390197.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 61        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 7808      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.3e+14   |\n",
      "|    n_updates            | 600       |\n",
      "|    policy_gradient_loss | -1.72e-06 |\n",
      "|    reward               | 2561036.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 62        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 7936      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.85e+14  |\n",
      "|    n_updates            | 610       |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 2784779.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.37e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2976065.820501569\n",
      "Sharpe:  0.8529936176175879\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 833       |\n",
      "|    iterations           | 63        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 8064      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.19e+14  |\n",
      "|    n_updates            | 620       |\n",
      "|    policy_gradient_loss | -1.84e-06 |\n",
      "|    reward               | 941252.94 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 834       |\n",
      "|    iterations           | 64        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.09e+14  |\n",
      "|    n_updates            | 630       |\n",
      "|    policy_gradient_loss | -1.83e-06 |\n",
      "|    reward               | 1112851.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 65        |\n",
      "|    time_elapsed         | 9         |\n",
      "|    total_timesteps      | 8320      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.29e+14  |\n",
      "|    n_updates            | 640       |\n",
      "|    policy_gradient_loss | -3.65e-06 |\n",
      "|    reward               | 1194730.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.53e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 66        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 8448      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.47e+14  |\n",
      "|    n_updates            | 650       |\n",
      "|    policy_gradient_loss | -3.71e-06 |\n",
      "|    reward               | 1349087.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 67        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 8576      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.88e+14  |\n",
      "|    n_updates            | 660       |\n",
      "|    policy_gradient_loss | -3.62e-06 |\n",
      "|    reward               | 1512385.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 68        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 8704      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.45e+14  |\n",
      "|    n_updates            | 670       |\n",
      "|    policy_gradient_loss | -2.79e-06 |\n",
      "|    reward               | 1597608.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.82e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 69        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 8832      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.65e+14  |\n",
      "|    n_updates            | 680       |\n",
      "|    policy_gradient_loss | -2.71e-06 |\n",
      "|    reward               | 1643882.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.38e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 70        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 8960      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.11e+14  |\n",
      "|    n_updates            | 690       |\n",
      "|    policy_gradient_loss | -2.81e-06 |\n",
      "|    reward               | 1729672.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 71        |\n",
      "|    time_elapsed         | 10        |\n",
      "|    total_timesteps      | 9088      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.34e+14  |\n",
      "|    n_updates            | 700       |\n",
      "|    policy_gradient_loss | -2.38e-06 |\n",
      "|    reward               | 1952372.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 834       |\n",
      "|    iterations           | 72        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9216      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.07e+14  |\n",
      "|    n_updates            | 710       |\n",
      "|    policy_gradient_loss | -2.39e-06 |\n",
      "|    reward               | 1892177.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.94e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 73        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9344      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.36e+14  |\n",
      "|    n_updates            | 720       |\n",
      "|    policy_gradient_loss | -2.28e-06 |\n",
      "|    reward               | 2171450.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 74        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9472      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.73e+14  |\n",
      "|    n_updates            | 730       |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2486664.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 75        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9600      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.17e+14  |\n",
      "|    n_updates            | 740       |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 2468388.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 76        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9728      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.35e+14  |\n",
      "|    n_updates            | 750       |\n",
      "|    policy_gradient_loss | -2.13e-06 |\n",
      "|    reward               | 2255287.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 77        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9856      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.55e+14  |\n",
      "|    n_updates            | 760       |\n",
      "|    policy_gradient_loss | -1.36e-06 |\n",
      "|    reward               | 2390879.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.29e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 11        |\n",
      "|    total_timesteps      | 9984      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.83e+14  |\n",
      "|    n_updates            | 770       |\n",
      "|    policy_gradient_loss | -2.01e-06 |\n",
      "|    reward               | 2573334.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2837113.243425189\n",
      "Sharpe:  0.8160063204910994\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 79        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.4e+14   |\n",
      "|    n_updates            | 780       |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 1034505.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.52e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 80        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.95e+14  |\n",
      "|    n_updates            | 790       |\n",
      "|    policy_gradient_loss | -2.76e-06 |\n",
      "|    reward               | 1083059.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.46e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.24e+14  |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | -3.81e-06 |\n",
      "|    reward               | 1212590.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.61e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 82        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.45e+14  |\n",
      "|    n_updates            | 810       |\n",
      "|    policy_gradient_loss | -4.8e-06  |\n",
      "|    reward               | 1324125.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 83        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.85e+14  |\n",
      "|    n_updates            | 820       |\n",
      "|    policy_gradient_loss | -3.05e-06 |\n",
      "|    reward               | 1422742.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.69e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 84        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.45e+14  |\n",
      "|    n_updates            | 830       |\n",
      "|    policy_gradient_loss | -3.45e-06 |\n",
      "|    reward               | 1655995.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.84e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 85        |\n",
      "|    time_elapsed         | 12        |\n",
      "|    total_timesteps      | 10880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.78e+14  |\n",
      "|    n_updates            | 840       |\n",
      "|    policy_gradient_loss | -3.87e-06 |\n",
      "|    reward               | 1679206.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 86        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.94e+14  |\n",
      "|    n_updates            | 850       |\n",
      "|    policy_gradient_loss | -2.25e-06 |\n",
      "|    reward               | 1714820.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 87        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.35e+14  |\n",
      "|    n_updates            | 860       |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 1656732.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.69e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 88        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.64e+14  |\n",
      "|    n_updates            | 870       |\n",
      "|    policy_gradient_loss | -2.07e-06 |\n",
      "|    reward               | 1926514.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.36e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 89        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.77e+14  |\n",
      "|    n_updates            | 880       |\n",
      "|    policy_gradient_loss | -2.22e-06 |\n",
      "|    reward               | 2330962.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 90        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.36e+14  |\n",
      "|    n_updates            | 890       |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 2424895.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.06e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 91        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.59e+14  |\n",
      "|    n_updates            | 900       |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2352230.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.31e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 92        |\n",
      "|    time_elapsed         | 13        |\n",
      "|    total_timesteps      | 11776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.77e+14  |\n",
      "|    n_updates            | 910       |\n",
      "|    policy_gradient_loss | -1.21e-06 |\n",
      "|    reward               | 2133936.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 93        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 11904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.4e+14   |\n",
      "|    n_updates            | 920       |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 2333615.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.08e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 94        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 12032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.91e+14  |\n",
      "|    n_updates            | 930       |\n",
      "|    policy_gradient_loss | -2.16e-06 |\n",
      "|    reward               | 2336569.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2636508.0128355515\n",
      "Sharpe:  0.7641217953796946\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 95        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 12160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.54e+14  |\n",
      "|    n_updates            | 940       |\n",
      "|    policy_gradient_loss | -2.72e-06 |\n",
      "|    reward               | 1033510.7 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 96        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.74e+14  |\n",
      "|    n_updates            | 950       |\n",
      "|    policy_gradient_loss | -5.11e-06 |\n",
      "|    reward               | 1096403.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4e+14     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 97        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 12416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 960       |\n",
      "|    policy_gradient_loss | -3.9e-06  |\n",
      "|    reward               | 1234506.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 98        |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 12544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.77e+14  |\n",
      "|    n_updates            | 970       |\n",
      "|    policy_gradient_loss | -4.07e-06 |\n",
      "|    reward               | 1370506.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 99        |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 12672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 980       |\n",
      "|    policy_gradient_loss | -2.5e-06  |\n",
      "|    reward               | 1512106.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.9e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 100       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 12800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.56e+14  |\n",
      "|    n_updates            | 990       |\n",
      "|    policy_gradient_loss | -3.54e-06 |\n",
      "|    reward               | 1569009.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 101       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 12928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.02e+14  |\n",
      "|    n_updates            | 1000      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 1669081.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.84e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 102       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 13056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.07e+14  |\n",
      "|    n_updates            | 1010      |\n",
      "|    policy_gradient_loss | -2.77e-06 |\n",
      "|    reward               | 1914647.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 103       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 13184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.88e+14  |\n",
      "|    n_updates            | 1020      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 1842371.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 104       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 13312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.52e+14  |\n",
      "|    n_updates            | 1030      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 2166914.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 105       |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 13440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.3e+14   |\n",
      "|    n_updates            | 1040      |\n",
      "|    policy_gradient_loss | -3.09e-06 |\n",
      "|    reward               | 2521784.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 106       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 13568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.47e+14  |\n",
      "|    n_updates            | 1050      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2637225.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.28e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 107       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 13696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.44e+14  |\n",
      "|    n_updates            | 1060      |\n",
      "|    policy_gradient_loss | -1.58e-06 |\n",
      "|    reward               | 2305970.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 108       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 13824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.12e+14  |\n",
      "|    n_updates            | 1070      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2428700.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.5e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 109       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 13952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.18e+14  |\n",
      "|    n_updates            | 1080      |\n",
      "|    policy_gradient_loss | -1.64e-06 |\n",
      "|    reward               | 2549214.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.26e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 110       |\n",
      "|    time_elapsed         | 16        |\n",
      "|    total_timesteps      | 14080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.55e+14  |\n",
      "|    n_updates            | 1090      |\n",
      "|    policy_gradient_loss | -1.74e-06 |\n",
      "|    reward               | 2915485.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2921383.50288915\n",
      "Sharpe:  0.8332802352380755\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 833       |\n",
      "|    iterations           | 111       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.74e+14  |\n",
      "|    n_updates            | 1100      |\n",
      "|    policy_gradient_loss | -1.77e-06 |\n",
      "|    reward               | 1042593.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 830       |\n",
      "|    iterations           | 112       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.14e+14  |\n",
      "|    n_updates            | 1110      |\n",
      "|    policy_gradient_loss | -5.14e-06 |\n",
      "|    reward               | 1148972.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.26e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 830       |\n",
      "|    iterations           | 113       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.35e+14  |\n",
      "|    n_updates            | 1120      |\n",
      "|    policy_gradient_loss | -3.27e-06 |\n",
      "|    reward               | 1255261.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 828       |\n",
      "|    iterations           | 114       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.72e+14  |\n",
      "|    n_updates            | 1130      |\n",
      "|    policy_gradient_loss | -4.98e-06 |\n",
      "|    reward               | 1507815.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 828       |\n",
      "|    iterations           | 115       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.12e+14  |\n",
      "|    n_updates            | 1140      |\n",
      "|    policy_gradient_loss | -2.19e-06 |\n",
      "|    reward               | 1554241.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.27e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 116       |\n",
      "|    time_elapsed         | 17        |\n",
      "|    total_timesteps      | 14848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.5e+14   |\n",
      "|    n_updates            | 1150      |\n",
      "|    policy_gradient_loss | -3.54e-06 |\n",
      "|    reward               | 1585644.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 828       |\n",
      "|    iterations           | 117       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 14976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 1160      |\n",
      "|    policy_gradient_loss | -3.11e-06 |\n",
      "|    reward               | 1827282.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 118       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.6e+14   |\n",
      "|    n_updates            | 1170      |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 2054153.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 119       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.39e+14  |\n",
      "|    n_updates            | 1180      |\n",
      "|    policy_gradient_loss | -2.61e-06 |\n",
      "|    reward               | 1938214.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 830       |\n",
      "|    iterations           | 120       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.86e+14  |\n",
      "|    n_updates            | 1190      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 2316753.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 830       |\n",
      "|    iterations           | 121       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.13e+14  |\n",
      "|    n_updates            | 1200      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2623924.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.04e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 831       |\n",
      "|    iterations           | 122       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.34e+14  |\n",
      "|    n_updates            | 1210      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 2698310.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 832       |\n",
      "|    iterations           | 123       |\n",
      "|    time_elapsed         | 18        |\n",
      "|    total_timesteps      | 15744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.7e+14   |\n",
      "|    n_updates            | 1220      |\n",
      "|    policy_gradient_loss | -1.57e-06 |\n",
      "|    reward               | 2494853.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 832       |\n",
      "|    iterations           | 124       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 15872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.26e+14  |\n",
      "|    n_updates            | 1230      |\n",
      "|    policy_gradient_loss | -1.28e-06 |\n",
      "|    reward               | 2612062.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 832       |\n",
      "|    iterations           | 125       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 16000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.88e+14  |\n",
      "|    n_updates            | 1240      |\n",
      "|    policy_gradient_loss | -2.04e-06 |\n",
      "|    reward               | 2723841.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2960715.2332456238\n",
      "Sharpe:  0.849045226728578\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 126       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 16128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.63e+14  |\n",
      "|    n_updates            | 1250      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 965222.2  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.61e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 829       |\n",
      "|    iterations           | 127       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 16256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.3e+14   |\n",
      "|    n_updates            | 1260      |\n",
      "|    policy_gradient_loss | -1.26e-06 |\n",
      "|    reward               | 1093440.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.2e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 830       |\n",
      "|    iterations           | 128       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.26e+14  |\n",
      "|    n_updates            | 1270      |\n",
      "|    policy_gradient_loss | -3.13e-06 |\n",
      "|    reward               | 1229768.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.54e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 831       |\n",
      "|    iterations           | 129       |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 16512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.46e+14  |\n",
      "|    n_updates            | 1280      |\n",
      "|    policy_gradient_loss | -3.63e-06 |\n",
      "|    reward               | 1295747.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.89e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 831       |\n",
      "|    iterations           | 130       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 16640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.89e+14  |\n",
      "|    n_updates            | 1290      |\n",
      "|    policy_gradient_loss | -4.79e-06 |\n",
      "|    reward               | 1468915.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 832       |\n",
      "|    iterations           | 131       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 16768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.35e+14  |\n",
      "|    n_updates            | 1300      |\n",
      "|    policy_gradient_loss | -3.94e-06 |\n",
      "|    reward               | 1625489.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 833       |\n",
      "|    iterations           | 132       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 16896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.75e+14  |\n",
      "|    n_updates            | 1310      |\n",
      "|    policy_gradient_loss | -3.63e-06 |\n",
      "|    reward               | 1678501.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 833       |\n",
      "|    iterations           | 133       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 17024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.93e+14  |\n",
      "|    n_updates            | 1320      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 1835633.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.03e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 134       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 17152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.29e+14  |\n",
      "|    n_updates            | 1330      |\n",
      "|    policy_gradient_loss | -3.49e-06 |\n",
      "|    reward               | 1461093.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.01e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 135       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 17280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.96e+14  |\n",
      "|    n_updates            | 1340      |\n",
      "|    policy_gradient_loss | -2.93e-06 |\n",
      "|    reward               | 2101697.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 136       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 17408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.23e+14  |\n",
      "|    n_updates            | 1350      |\n",
      "|    policy_gradient_loss | -2.7e-06  |\n",
      "|    reward               | 2509327.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.58e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 137       |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 17536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.91e+14  |\n",
      "|    n_updates            | 1360      |\n",
      "|    policy_gradient_loss | -2.03e-06 |\n",
      "|    reward               | 2583283.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 138       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 17664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.12e+14  |\n",
      "|    n_updates            | 1370      |\n",
      "|    policy_gradient_loss | -1.52e-06 |\n",
      "|    reward               | 2726416.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.57e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 139       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 17792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.13e+14  |\n",
      "|    n_updates            | 1380      |\n",
      "|    policy_gradient_loss | -1.74e-06 |\n",
      "|    reward               | 2328068.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.64e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 140       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 17920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.17e+14  |\n",
      "|    n_updates            | 1390      |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    reward               | 2712925.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 141       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 18048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.04e+14  |\n",
      "|    n_updates            | 1400      |\n",
      "|    policy_gradient_loss | -2.04e-06 |\n",
      "|    reward               | 2620441.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3024295.7340173936\n",
      "Sharpe:  0.8632173417299328\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 142       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 18176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.64e+14  |\n",
      "|    n_updates            | 1410      |\n",
      "|    policy_gradient_loss | -2.69e-06 |\n",
      "|    reward               | 1042539.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.73e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 143       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 18304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.29e+14  |\n",
      "|    n_updates            | 1420      |\n",
      "|    policy_gradient_loss | -2.9e-06  |\n",
      "|    reward               | 1072178.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.42e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 144       |\n",
      "|    time_elapsed         | 21        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.32e+14  |\n",
      "|    n_updates            | 1430      |\n",
      "|    policy_gradient_loss | -3.71e-06 |\n",
      "|    reward               | 1220933.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 145       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 18560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.53e+14  |\n",
      "|    n_updates            | 1440      |\n",
      "|    policy_gradient_loss | -3.69e-06 |\n",
      "|    reward               | 1378531.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.15e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 146       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 18688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.88e+14  |\n",
      "|    n_updates            | 1450      |\n",
      "|    policy_gradient_loss | -3.2e-06  |\n",
      "|    reward               | 1459202.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 147       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 18816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.45e+14  |\n",
      "|    n_updates            | 1460      |\n",
      "|    policy_gradient_loss | -3.01e-06 |\n",
      "|    reward               | 1540851.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 148       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 18944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.87e+14  |\n",
      "|    n_updates            | 1470      |\n",
      "|    policy_gradient_loss | -4.01e-06 |\n",
      "|    reward               | 1716642.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 149       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 19072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.13e+14  |\n",
      "|    n_updates            | 1480      |\n",
      "|    policy_gradient_loss | -2.46e-06 |\n",
      "|    reward               | 1789998.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 150       |\n",
      "|    time_elapsed         | 22        |\n",
      "|    total_timesteps      | 19200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.46e+14  |\n",
      "|    n_updates            | 1490      |\n",
      "|    policy_gradient_loss | -2.33e-06 |\n",
      "|    reward               | 1654701.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.9e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 151       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.76e+14  |\n",
      "|    n_updates            | 1500      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 2026687.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.36e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 152       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.24e+14  |\n",
      "|    n_updates            | 1510      |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2418320.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 153       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.13e+14  |\n",
      "|    n_updates            | 1520      |\n",
      "|    policy_gradient_loss | -2.3e-06  |\n",
      "|    reward               | 2584848.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.23e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 154       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.52e+14  |\n",
      "|    n_updates            | 1530      |\n",
      "|    policy_gradient_loss | -2.19e-06 |\n",
      "|    reward               | 2375420.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 155       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.02e+14  |\n",
      "|    n_updates            | 1540      |\n",
      "|    policy_gradient_loss | -9.99e-07 |\n",
      "|    reward               | 2449312.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.44e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 156       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 19968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.9e+14   |\n",
      "|    n_updates            | 1550      |\n",
      "|    policy_gradient_loss | -1.81e-06 |\n",
      "|    reward               | 2493221.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.19e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 157       |\n",
      "|    time_elapsed         | 23        |\n",
      "|    total_timesteps      | 20096     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.96e+14  |\n",
      "|    n_updates            | 1560      |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    reward               | 2682632.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2895598.687159441\n",
      "Sharpe:  0.8280843689792998\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 835       |\n",
      "|    iterations           | 158       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.74e+14  |\n",
      "|    n_updates            | 1570      |\n",
      "|    policy_gradient_loss | -1.64e-06 |\n",
      "|    reward               | 1055005.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.55e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 836       |\n",
      "|    iterations           | 159       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.47e+14  |\n",
      "|    n_updates            | 1580      |\n",
      "|    policy_gradient_loss | -5.74e-06 |\n",
      "|    reward               | 1126719.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 837       |\n",
      "|    iterations           | 160       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.41e+14  |\n",
      "|    n_updates            | 1590      |\n",
      "|    policy_gradient_loss | -4.1e-06  |\n",
      "|    reward               | 1269099.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 838       |\n",
      "|    iterations           | 161       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.65e+14  |\n",
      "|    n_updates            | 1600      |\n",
      "|    policy_gradient_loss | -3.16e-06 |\n",
      "|    reward               | 1476661.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.45e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 162       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.1e+14   |\n",
      "|    n_updates            | 1610      |\n",
      "|    policy_gradient_loss | -3.32e-06 |\n",
      "|    reward               | 1564448.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.23e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 163       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.73e+14  |\n",
      "|    n_updates            | 1620      |\n",
      "|    policy_gradient_loss | -2.26e-06 |\n",
      "|    reward               | 1550643.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 839       |\n",
      "|    iterations           | 164       |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 20992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.19e+14  |\n",
      "|    n_updates            | 1630      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 1810909.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 840       |\n",
      "|    iterations           | 165       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.24e+14  |\n",
      "|    n_updates            | 1640      |\n",
      "|    policy_gradient_loss | -3.11e-06 |\n",
      "|    reward               | 2004870.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 166       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.04e+14  |\n",
      "|    n_updates            | 1650      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 1849160.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.98e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 167       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.71e+14  |\n",
      "|    n_updates            | 1660      |\n",
      "|    policy_gradient_loss | -3.04e-06 |\n",
      "|    reward               | 2285192.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 168       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.87e+14  |\n",
      "|    n_updates            | 1670      |\n",
      "|    policy_gradient_loss | -2.33e-06 |\n",
      "|    reward               | 2637160.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 169       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.06e+14  |\n",
      "|    n_updates            | 1680      |\n",
      "|    policy_gradient_loss | -2.49e-06 |\n",
      "|    reward               | 2771093.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 170       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.39e+14  |\n",
      "|    n_updates            | 1690      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2413268.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.61e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 171       |\n",
      "|    time_elapsed         | 25        |\n",
      "|    total_timesteps      | 21888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.25e+14  |\n",
      "|    n_updates            | 1700      |\n",
      "|    policy_gradient_loss | -1.52e-06 |\n",
      "|    reward               | 2558756.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.52e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 172       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.57e+14  |\n",
      "|    n_updates            | 1710      |\n",
      "|    policy_gradient_loss | -1.81e-06 |\n",
      "|    reward               | 2612303.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.37e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2857612.926775693\n",
      "Sharpe:  0.8215220168186476\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 173       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.71e+14  |\n",
      "|    n_updates            | 1720      |\n",
      "|    policy_gradient_loss | -1.54e-06 |\n",
      "|    reward               | 935365.2  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 174       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.38e+14  |\n",
      "|    n_updates            | 1730      |\n",
      "|    policy_gradient_loss | -2.19e-06 |\n",
      "|    reward               | 1099753.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.39e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 175       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.24e+14  |\n",
      "|    n_updates            | 1740      |\n",
      "|    policy_gradient_loss | -6.43e-06 |\n",
      "|    reward               | 1200998.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.45e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 176       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.4e+14   |\n",
      "|    n_updates            | 1750      |\n",
      "|    policy_gradient_loss | -4.13e-06 |\n",
      "|    reward               | 1347625.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 177       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.89e+14  |\n",
      "|    n_updates            | 1760      |\n",
      "|    policy_gradient_loss | -2.66e-06 |\n",
      "|    reward               | 1601838.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 178       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.32e+14  |\n",
      "|    n_updates            | 1770      |\n",
      "|    policy_gradient_loss | -2.88e-06 |\n",
      "|    reward               | 1620961.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.82e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 179       |\n",
      "|    time_elapsed         | 26        |\n",
      "|    total_timesteps      | 22912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.65e+14  |\n",
      "|    n_updates            | 1780      |\n",
      "|    policy_gradient_loss | -3.33e-06 |\n",
      "|    reward               | 1672545.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.46e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 180       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.06e+14  |\n",
      "|    n_updates            | 1790      |\n",
      "|    policy_gradient_loss | -3.52e-06 |\n",
      "|    reward               | 1810051.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 181       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.67e+14  |\n",
      "|    n_updates            | 1800      |\n",
      "|    policy_gradient_loss | -2.76e-06 |\n",
      "|    reward               | 2039045.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 182       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.26e+14  |\n",
      "|    n_updates            | 1810      |\n",
      "|    policy_gradient_loss | -1.7e-06  |\n",
      "|    reward               | 1968779.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 183       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.93e+14  |\n",
      "|    n_updates            | 1820      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 2320795.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.46e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 184       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.12e+14  |\n",
      "|    n_updates            | 1830      |\n",
      "|    policy_gradient_loss | -2.85e-06 |\n",
      "|    reward               | 2616341.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.04e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 185       |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 23680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.19e+14  |\n",
      "|    n_updates            | 1840      |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 2591886.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 186       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 23808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.14e+14  |\n",
      "|    n_updates            | 1850      |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 2415283.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 187       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 23936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.8e+14   |\n",
      "|    n_updates            | 1860      |\n",
      "|    policy_gradient_loss | -1.75e-06 |\n",
      "|    reward               | 2593615.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 188       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 24064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.07e+14  |\n",
      "|    n_updates            | 1870      |\n",
      "|    policy_gradient_loss | -2.03e-06 |\n",
      "|    reward               | 2662312.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2913205.082506648\n",
      "Sharpe:  0.8337211057080942\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 189       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 24192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.83e+14  |\n",
      "|    n_updates            | 1880      |\n",
      "|    policy_gradient_loss | -1.48e-06 |\n",
      "|    reward               | 1035040.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 190       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 24320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.78e+14  |\n",
      "|    n_updates            | 1890      |\n",
      "|    policy_gradient_loss | -2.95e-06 |\n",
      "|    reward               | 1122848.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 191       |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 24448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.41e+14  |\n",
      "|    n_updates            | 1900      |\n",
      "|    policy_gradient_loss | -3.27e-06 |\n",
      "|    reward               | 1295176.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 192       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.68e+14  |\n",
      "|    n_updates            | 1910      |\n",
      "|    policy_gradient_loss | -3.22e-06 |\n",
      "|    reward               | 1396797.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 193       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 24704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.08e+14  |\n",
      "|    n_updates            | 1920      |\n",
      "|    policy_gradient_loss | -2.77e-06 |\n",
      "|    reward               | 1540433.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 194       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 24832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.61e+14  |\n",
      "|    n_updates            | 1930      |\n",
      "|    policy_gradient_loss | -3.42e-06 |\n",
      "|    reward               | 1729024.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.34e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 195       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 24960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.92e+14  |\n",
      "|    n_updates            | 1940      |\n",
      "|    policy_gradient_loss | -3.44e-06 |\n",
      "|    reward               | 1786202.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 196       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 25088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.18e+14  |\n",
      "|    n_updates            | 1950      |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 1855900.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 197       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 25216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.88e+14  |\n",
      "|    n_updates            | 1960      |\n",
      "|    policy_gradient_loss | -3.01e-06 |\n",
      "|    reward               | 1711726.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.81e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 198       |\n",
      "|    time_elapsed         | 29        |\n",
      "|    total_timesteps      | 25344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.33e+14  |\n",
      "|    n_updates            | 1970      |\n",
      "|    policy_gradient_loss | -2.52e-06 |\n",
      "|    reward               | 2143324.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.89e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 199       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 25472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.5e+14   |\n",
      "|    n_updates            | 1980      |\n",
      "|    policy_gradient_loss | -2.99e-06 |\n",
      "|    reward               | 2631969.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.08e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 200       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 25600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.45e+14  |\n",
      "|    n_updates            | 1990      |\n",
      "|    policy_gradient_loss | -1.83e-06 |\n",
      "|    reward               | 2748200.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.31e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 201       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 25728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.29e+14  |\n",
      "|    n_updates            | 2000      |\n",
      "|    policy_gradient_loss | -1.22e-06 |\n",
      "|    reward               | 2833728.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.69e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 202       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 25856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.35e+14  |\n",
      "|    n_updates            | 2010      |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 2437401.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.79e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 203       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 25984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.33e+14  |\n",
      "|    n_updates            | 2020      |\n",
      "|    policy_gradient_loss | -1.85e-06 |\n",
      "|    reward               | 2740072.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.52e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 204       |\n",
      "|    time_elapsed         | 30        |\n",
      "|    total_timesteps      | 26112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.61e+14  |\n",
      "|    n_updates            | 2030      |\n",
      "|    policy_gradient_loss | -2.17e-06 |\n",
      "|    reward               | 2596734.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.7e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3057272.33379414\n",
      "Sharpe:  0.8653724733728025\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 843        |\n",
      "|    iterations           | 205        |\n",
      "|    time_elapsed         | 31         |\n",
      "|    total_timesteps      | 26240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | -1.19e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.37e+14   |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | -1.24e-06  |\n",
      "|    reward               | 1028067.94 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.76e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 206       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 26368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.48e+14  |\n",
      "|    n_updates            | 2050      |\n",
      "|    policy_gradient_loss | -4.39e-06 |\n",
      "|    reward               | 1079244.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 207       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 26496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 2060      |\n",
      "|    policy_gradient_loss | -3.51e-06 |\n",
      "|    reward               | 1250633.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.69e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 208       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.6e+14   |\n",
      "|    n_updates            | 2070      |\n",
      "|    policy_gradient_loss | -4.52e-06 |\n",
      "|    reward               | 1405377.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 209       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 26752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.88e+14  |\n",
      "|    n_updates            | 2080      |\n",
      "|    policy_gradient_loss | -3.69e-06 |\n",
      "|    reward               | 1522091.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 210       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 26880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.54e+14  |\n",
      "|    n_updates            | 2090      |\n",
      "|    policy_gradient_loss | -2.95e-06 |\n",
      "|    reward               | 1625416.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.23e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 211       |\n",
      "|    time_elapsed         | 31        |\n",
      "|    total_timesteps      | 27008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.73e+14  |\n",
      "|    n_updates            | 2100      |\n",
      "|    policy_gradient_loss | -2.4e-06  |\n",
      "|    reward               | 1688860.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.8e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 212       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.97e+14  |\n",
      "|    n_updates            | 2110      |\n",
      "|    policy_gradient_loss | -4.19e-06 |\n",
      "|    reward               | 1868230.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.31e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 213       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.86e+14  |\n",
      "|    n_updates            | 2120      |\n",
      "|    policy_gradient_loss | -3.71e-06 |\n",
      "|    reward               | 1759741.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.23e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 214       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.53e+14  |\n",
      "|    n_updates            | 2130      |\n",
      "|    policy_gradient_loss | -1.46e-06 |\n",
      "|    reward               | 2050878.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 215       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.09e+14  |\n",
      "|    n_updates            | 2140      |\n",
      "|    policy_gradient_loss | -2.77e-06 |\n",
      "|    reward               | 2419241.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.23e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 216       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.95e+14  |\n",
      "|    n_updates            | 2150      |\n",
      "|    policy_gradient_loss | -2.66e-06 |\n",
      "|    reward               | 2464894.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.16e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 217       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.97e+14  |\n",
      "|    n_updates            | 2160      |\n",
      "|    policy_gradient_loss | -2.56e-06 |\n",
      "|    reward               | 2308985.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.37e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 218       |\n",
      "|    time_elapsed         | 32        |\n",
      "|    total_timesteps      | 27904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.82e+14  |\n",
      "|    n_updates            | 2170      |\n",
      "|    policy_gradient_loss | -1.98e-06 |\n",
      "|    reward               | 2425092.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.38e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 219       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.81e+14  |\n",
      "|    n_updates            | 2180      |\n",
      "|    policy_gradient_loss | -1.44e-06 |\n",
      "|    reward               | 2510681.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.17e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 220       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.84e+14  |\n",
      "|    n_updates            | 2190      |\n",
      "|    policy_gradient_loss | -1.22e-06 |\n",
      "|    reward               | 2665591.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2671115.6785741663\n",
      "Sharpe:  0.7693626718439273\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 221       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.08e+14  |\n",
      "|    n_updates            | 2200      |\n",
      "|    policy_gradient_loss | -1.94e-06 |\n",
      "|    reward               | 1011515.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 222       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.07e+14  |\n",
      "|    n_updates            | 2210      |\n",
      "|    policy_gradient_loss | -4.54e-06 |\n",
      "|    reward               | 1154333.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 223       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 2220      |\n",
      "|    policy_gradient_loss | -4.5e-06  |\n",
      "|    reward               | 1243730.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.7e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 224       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.67e+14  |\n",
      "|    n_updates            | 2230      |\n",
      "|    policy_gradient_loss | -3.49e-06 |\n",
      "|    reward               | 1445520.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.4e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 225       |\n",
      "|    time_elapsed         | 33        |\n",
      "|    total_timesteps      | 28800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.11e+14  |\n",
      "|    n_updates            | 2240      |\n",
      "|    policy_gradient_loss | -4.17e-06 |\n",
      "|    reward               | 1499314.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.07e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 226       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 28928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.49e+14  |\n",
      "|    n_updates            | 2250      |\n",
      "|    policy_gradient_loss | -2.4e-06  |\n",
      "|    reward               | 1499088.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.9e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 227       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.83e+14  |\n",
      "|    n_updates            | 2260      |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 1734180.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 228       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.9e+14   |\n",
      "|    n_updates            | 2270      |\n",
      "|    policy_gradient_loss | -2.76e-06 |\n",
      "|    reward               | 1887902.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 229       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.73e+14  |\n",
      "|    n_updates            | 2280      |\n",
      "|    policy_gradient_loss | -3.38e-06 |\n",
      "|    reward               | 1830978.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 230       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.21e+14  |\n",
      "|    n_updates            | 2290      |\n",
      "|    policy_gradient_loss | -2.56e-06 |\n",
      "|    reward               | 2110137.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.47e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 231       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.38e+14  |\n",
      "|    n_updates            | 2300      |\n",
      "|    policy_gradient_loss | -3.32e-06 |\n",
      "|    reward               | 2390797.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 232       |\n",
      "|    time_elapsed         | 34        |\n",
      "|    total_timesteps      | 29696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.66e+14  |\n",
      "|    n_updates            | 2310      |\n",
      "|    policy_gradient_loss | -2.99e-06 |\n",
      "|    reward               | 2331476.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.2e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 233       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 29824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.66e+14  |\n",
      "|    n_updates            | 2320      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 2155375.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.32e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 234       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 29952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.76e+14  |\n",
      "|    n_updates            | 2330      |\n",
      "|    policy_gradient_loss | -1.52e-06 |\n",
      "|    reward               | 2304065.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 235       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 30080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.09e+14  |\n",
      "|    n_updates            | 2340      |\n",
      "|    policy_gradient_loss | -1.63e-06 |\n",
      "|    reward               | 2365012.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.06e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2553088.5317619178\n",
      "Sharpe:  0.7373166413485702\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 236       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 30208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.76e+14  |\n",
      "|    n_updates            | 2350      |\n",
      "|    policy_gradient_loss | -1.73e-06 |\n",
      "|    reward               | 944503.94 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 237       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 30336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.63e+14  |\n",
      "|    n_updates            | 2360      |\n",
      "|    policy_gradient_loss | -2.18e-06 |\n",
      "|    reward               | 1113664.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 238       |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 30464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.35e+14  |\n",
      "|    n_updates            | 2370      |\n",
      "|    policy_gradient_loss | -4.73e-06 |\n",
      "|    reward               | 1259516.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 239       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 30592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.5e+14   |\n",
      "|    n_updates            | 2380      |\n",
      "|    policy_gradient_loss | -4.18e-06 |\n",
      "|    reward               | 1357886.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 240       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.99e+14  |\n",
      "|    n_updates            | 2390      |\n",
      "|    policy_gradient_loss | -3.32e-06 |\n",
      "|    reward               | 1578782.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.87e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 241       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 30848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.48e+14  |\n",
      "|    n_updates            | 2400      |\n",
      "|    policy_gradient_loss | -4.06e-06 |\n",
      "|    reward               | 1662430.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 242       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 30976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.72e+14  |\n",
      "|    n_updates            | 2410      |\n",
      "|    policy_gradient_loss | -3.84e-06 |\n",
      "|    reward               | 1734169.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.53e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 243       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 31104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.05e+14  |\n",
      "|    n_updates            | 2420      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 1857408.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.27e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 244       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 31232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.71e+14  |\n",
      "|    n_updates            | 2430      |\n",
      "|    policy_gradient_loss | -2.64e-06 |\n",
      "|    reward               | 1769585.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.42e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 245       |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 31360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.1e+14   |\n",
      "|    n_updates            | 2440      |\n",
      "|    policy_gradient_loss | -2.28e-06 |\n",
      "|    reward               | 2047759.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 246       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 31488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.07e+14  |\n",
      "|    n_updates            | 2450      |\n",
      "|    policy_gradient_loss | -2.35e-06 |\n",
      "|    reward               | 2528454.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.31e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 247       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 31616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.09e+14  |\n",
      "|    n_updates            | 2460      |\n",
      "|    policy_gradient_loss | -3e-06    |\n",
      "|    reward               | 2706392.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.17e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 248       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 31744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.05e+14  |\n",
      "|    n_updates            | 2470      |\n",
      "|    policy_gradient_loss | -1.64e-06 |\n",
      "|    reward               | 2760794.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 249       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 31872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.42e+14  |\n",
      "|    n_updates            | 2480      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 2445367.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.73e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 250       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 32000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.92e+14  |\n",
      "|    n_updates            | 2490      |\n",
      "|    policy_gradient_loss | -1.33e-06 |\n",
      "|    reward               | 2700187.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 251       |\n",
      "|    time_elapsed         | 37        |\n",
      "|    total_timesteps      | 32128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.18e+14  |\n",
      "|    n_updates            | 2500      |\n",
      "|    policy_gradient_loss | -1.94e-06 |\n",
      "|    reward               | 2788223.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.67e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3164192.36884428\n",
      "Sharpe:  0.8962843303104763\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 252       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 32256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.19e+14  |\n",
      "|    n_updates            | 2510      |\n",
      "|    policy_gradient_loss | -2.69e-06 |\n",
      "|    reward               | 1060633.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.86e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 253       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 32384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.44e+14  |\n",
      "|    n_updates            | 2520      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 1099068.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.59e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 254       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 32512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 2530      |\n",
      "|    policy_gradient_loss | -4.87e-06 |\n",
      "|    reward               | 1242934.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 255       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 32640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.58e+14  |\n",
      "|    n_updates            | 2540      |\n",
      "|    policy_gradient_loss | -3.29e-06 |\n",
      "|    reward               | 1376117.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.19e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 841       |\n",
      "|    iterations           | 256       |\n",
      "|    time_elapsed         | 38        |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 2550      |\n",
      "|    policy_gradient_loss | -3.1e-06  |\n",
      "|    reward               | 1540574.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.92e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 257       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 32896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.55e+14  |\n",
      "|    n_updates            | 2560      |\n",
      "|    policy_gradient_loss | -3.9e-06  |\n",
      "|    reward               | 1673402.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 842       |\n",
      "|    iterations           | 258       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.02e+14  |\n",
      "|    n_updates            | 2570      |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 1824988.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.11e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 259       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.39e+14  |\n",
      "|    n_updates            | 2580      |\n",
      "|    policy_gradient_loss | -2.25e-06 |\n",
      "|    reward               | 1889586.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 260       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.95e+14  |\n",
      "|    n_updates            | 2590      |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 1818232.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.77e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 261       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.19e+14  |\n",
      "|    n_updates            | 2600      |\n",
      "|    policy_gradient_loss | -2.81e-06 |\n",
      "|    reward               | 1976718.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 843       |\n",
      "|    iterations           | 262       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.73e+14  |\n",
      "|    n_updates            | 2610      |\n",
      "|    policy_gradient_loss | -2.89e-06 |\n",
      "|    reward               | 2657397.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.31e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 263       |\n",
      "|    time_elapsed         | 39        |\n",
      "|    total_timesteps      | 33664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.86e+14  |\n",
      "|    n_updates            | 2620      |\n",
      "|    policy_gradient_loss | -1.65e-06 |\n",
      "|    reward               | 2803213.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 264       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 33792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.88e+14  |\n",
      "|    n_updates            | 2630      |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 2541610.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.68e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 265       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 33920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.23e+14  |\n",
      "|    n_updates            | 2640      |\n",
      "|    policy_gradient_loss | -1.35e-06 |\n",
      "|    reward               | 2619667.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.69e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 266       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 34048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.06e+14  |\n",
      "|    n_updates            | 2650      |\n",
      "|    policy_gradient_loss | -2.2e-06  |\n",
      "|    reward               | 2692555.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.41e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 267       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 34176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.94e+14  |\n",
      "|    n_updates            | 2660      |\n",
      "|    policy_gradient_loss | -1.4e-06  |\n",
      "|    reward               | 2806449.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3016333.6063046777\n",
      "Sharpe:  0.8538441124380881\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 844        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 34304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | 1.79e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.26e+14   |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -1.88e-06  |\n",
      "|    reward               | 1038054.56 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.73e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 269       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 34432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.65e+14  |\n",
      "|    n_updates            | 2680      |\n",
      "|    policy_gradient_loss | -3.1e-06  |\n",
      "|    reward               | 1124549.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.47e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 270       |\n",
      "|    time_elapsed         | 40        |\n",
      "|    total_timesteps      | 34560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 2690      |\n",
      "|    policy_gradient_loss | -5.64e-06 |\n",
      "|    reward               | 1279072.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 271       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 34688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.68e+14  |\n",
      "|    n_updates            | 2700      |\n",
      "|    policy_gradient_loss | -4.78e-06 |\n",
      "|    reward               | 1476035.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.41e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 844       |\n",
      "|    iterations           | 272       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.12e+14  |\n",
      "|    n_updates            | 2710      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 1577690.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.23e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 273       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 34944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.59e+14  |\n",
      "|    n_updates            | 2720      |\n",
      "|    policy_gradient_loss | -2.4e-06  |\n",
      "|    reward               | 1640738.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 845       |\n",
      "|    iterations           | 274       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 35072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.21e+14  |\n",
      "|    n_updates            | 2730      |\n",
      "|    policy_gradient_loss | -2.97e-06 |\n",
      "|    reward               | 1783946.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.24e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 275       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 35200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.53e+14  |\n",
      "|    n_updates            | 2740      |\n",
      "|    policy_gradient_loss | -4.2e-06  |\n",
      "|    reward               | 1971027.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 846       |\n",
      "|    iterations           | 276       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 35328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.85e+14  |\n",
      "|    n_updates            | 2750      |\n",
      "|    policy_gradient_loss | -2.04e-06 |\n",
      "|    reward               | 1876164.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 277       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 35456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.43e+14  |\n",
      "|    n_updates            | 2760      |\n",
      "|    policy_gradient_loss | -2.72e-06 |\n",
      "|    reward               | 2188784.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 847       |\n",
      "|    iterations           | 278       |\n",
      "|    time_elapsed         | 41        |\n",
      "|    total_timesteps      | 35584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.74e+14  |\n",
      "|    n_updates            | 2770      |\n",
      "|    policy_gradient_loss | -1.47e-06 |\n",
      "|    reward               | 2512227.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.39e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 279       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 35712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.75e+14  |\n",
      "|    n_updates            | 2780      |\n",
      "|    policy_gradient_loss | -1.86e-06 |\n",
      "|    reward               | 2598385.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.35e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 280       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 35840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.76e+14  |\n",
      "|    n_updates            | 2790      |\n",
      "|    policy_gradient_loss | -2.14e-06 |\n",
      "|    reward               | 2268122.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 281       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 35968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.1e+14   |\n",
      "|    n_updates            | 2800      |\n",
      "|    policy_gradient_loss | -1.03e-06 |\n",
      "|    reward               | 2483979.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 282       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 36096     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.86e+14  |\n",
      "|    n_updates            | 2810      |\n",
      "|    policy_gradient_loss | -1.65e-06 |\n",
      "|    reward               | 2610846.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.29e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2816290.8618611186\n",
      "Sharpe:  0.8029994996852426\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 283       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 36224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.33e+14  |\n",
      "|    n_updates            | 2820      |\n",
      "|    policy_gradient_loss | -1.14e-06 |\n",
      "|    reward               | 961106.5  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 848       |\n",
      "|    iterations           | 284       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 36352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.53e+14  |\n",
      "|    n_updates            | 2830      |\n",
      "|    policy_gradient_loss | -2.12e-06 |\n",
      "|    reward               | 1110731.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 285       |\n",
      "|    time_elapsed         | 42        |\n",
      "|    total_timesteps      | 36480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.24e+14  |\n",
      "|    n_updates            | 2840      |\n",
      "|    policy_gradient_loss | -4.56e-06 |\n",
      "|    reward               | 1183820.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.49e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 286       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 36608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.54e+14  |\n",
      "|    n_updates            | 2850      |\n",
      "|    policy_gradient_loss | -3.91e-06 |\n",
      "|    reward               | 1301587.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.9e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 849       |\n",
      "|    iterations           | 287       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 36736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.86e+14  |\n",
      "|    n_updates            | 2860      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 1607633.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.59e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 288       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.24e+14  |\n",
      "|    n_updates            | 2870      |\n",
      "|    policy_gradient_loss | -2.57e-06 |\n",
      "|    reward               | 1601116.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.56e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 850       |\n",
      "|    iterations           | 289       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 36992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.67e+14  |\n",
      "|    n_updates            | 2880      |\n",
      "|    policy_gradient_loss | -2.49e-06 |\n",
      "|    reward               | 1647375.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 290       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 37120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.9e+14   |\n",
      "|    n_updates            | 2890      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 1758229.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 291       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 37248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.38e+14  |\n",
      "|    n_updates            | 2900      |\n",
      "|    policy_gradient_loss | -2.34e-06 |\n",
      "|    reward               | 2008577.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 292       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 37376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.19e+14  |\n",
      "|    n_updates            | 2910      |\n",
      "|    policy_gradient_loss | -3.05e-06 |\n",
      "|    reward               | 1957729.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 293       |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 37504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.55e+14  |\n",
      "|    n_updates            | 2920      |\n",
      "|    policy_gradient_loss | -2.87e-06 |\n",
      "|    reward               | 2278443.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.08e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 294       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 37632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.73e+14  |\n",
      "|    n_updates            | 2930      |\n",
      "|    policy_gradient_loss | -2.31e-06 |\n",
      "|    reward               | 2513525.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 295       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 37760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.49e+14  |\n",
      "|    n_updates            | 2940      |\n",
      "|    policy_gradient_loss | -2.17e-06 |\n",
      "|    reward               | 2501758.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.39e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 296       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 37888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.96e+14  |\n",
      "|    n_updates            | 2950      |\n",
      "|    policy_gradient_loss | -2.57e-06 |\n",
      "|    reward               | 2476938.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 297       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 38016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.52e+14  |\n",
      "|    n_updates            | 2960      |\n",
      "|    policy_gradient_loss | -2.45e-06 |\n",
      "|    reward               | 2577772.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 298       |\n",
      "|    time_elapsed         | 44        |\n",
      "|    total_timesteps      | 38144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.82e+14  |\n",
      "|    n_updates            | 2970      |\n",
      "|    policy_gradient_loss | -1.69e-06 |\n",
      "|    reward               | 2735199.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.44e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2951978.7798045273\n",
      "Sharpe:  0.8458857490425513\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 851        |\n",
      "|    iterations           | 299        |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 38272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | 1.19e-07   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.22e+14   |\n",
      "|    n_updates            | 2980       |\n",
      "|    policy_gradient_loss | -1.48e-06  |\n",
      "|    reward               | 1017088.44 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.66e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 851       |\n",
      "|    iterations           | 300       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 38400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.84e+14  |\n",
      "|    n_updates            | 2990      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 1141080.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.03e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 301       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 38528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.44e+14  |\n",
      "|    n_updates            | 3000      |\n",
      "|    policy_gradient_loss | -3.28e-06 |\n",
      "|    reward               | 1278044.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 302       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 38656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.59e+14  |\n",
      "|    n_updates            | 3010      |\n",
      "|    policy_gradient_loss | -3.34e-06 |\n",
      "|    reward               | 1378409.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 303       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 38784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.95e+14  |\n",
      "|    n_updates            | 3020      |\n",
      "|    policy_gradient_loss | -3.09e-06 |\n",
      "|    reward               | 1548258.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 304       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.66e+14  |\n",
      "|    n_updates            | 3030      |\n",
      "|    policy_gradient_loss | -2.99e-06 |\n",
      "|    reward               | 1735060.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 305       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 39040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.87e+14  |\n",
      "|    n_updates            | 3040      |\n",
      "|    policy_gradient_loss | -2.53e-06 |\n",
      "|    reward               | 1769153.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 306       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 39168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.37e+14  |\n",
      "|    n_updates            | 3050      |\n",
      "|    policy_gradient_loss | -2.17e-06 |\n",
      "|    reward               | 1879411.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 307       |\n",
      "|    time_elapsed         | 45        |\n",
      "|    total_timesteps      | 39296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.94e+14  |\n",
      "|    n_updates            | 3060      |\n",
      "|    policy_gradient_loss | -2.53e-06 |\n",
      "|    reward               | 1552389.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.71e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 308       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 39424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.21e+14  |\n",
      "|    n_updates            | 3070      |\n",
      "|    policy_gradient_loss | -2.91e-06 |\n",
      "|    reward               | 1948409.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 309       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 39552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.12e+14  |\n",
      "|    n_updates            | 3080      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 2419236.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.03e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 310       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 39680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.65e+14  |\n",
      "|    n_updates            | 3090      |\n",
      "|    policy_gradient_loss | -1.96e-06 |\n",
      "|    reward               | 2510820.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.1e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 311       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 39808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.14e+14  |\n",
      "|    n_updates            | 3100      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2502846.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 312       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 39936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.87e+14  |\n",
      "|    n_updates            | 3110      |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 2159674.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 313       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 40064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.01e+14  |\n",
      "|    n_updates            | 3120      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 2590520.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.24e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 314       |\n",
      "|    time_elapsed         | 46        |\n",
      "|    total_timesteps      | 40192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.43e+14  |\n",
      "|    n_updates            | 3130      |\n",
      "|    policy_gradient_loss | -2.61e-06 |\n",
      "|    reward               | 2515333.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2945490.0622198335\n",
      "Sharpe:  0.8423502374228474\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 315       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.92e+14  |\n",
      "|    n_updates            | 3140      |\n",
      "|    policy_gradient_loss | -1.43e-06 |\n",
      "|    reward               | 1046000.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 316       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.02e+14  |\n",
      "|    n_updates            | 3150      |\n",
      "|    policy_gradient_loss | -3.35e-06 |\n",
      "|    reward               | 1092800.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.59e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 317       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.35e+14  |\n",
      "|    n_updates            | 3160      |\n",
      "|    policy_gradient_loss | -6.33e-06 |\n",
      "|    reward               | 1259541.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 318       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.62e+14  |\n",
      "|    n_updates            | 3170      |\n",
      "|    policy_gradient_loss | -2.72e-06 |\n",
      "|    reward               | 1428873.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.34e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 319       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.91e+14  |\n",
      "|    n_updates            | 3180      |\n",
      "|    policy_gradient_loss | -4.18e-06 |\n",
      "|    reward               | 1540507.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 320       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.68e+14  |\n",
      "|    n_updates            | 3190      |\n",
      "|    policy_gradient_loss | -1.83e-06 |\n",
      "|    reward               | 1671945.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 321       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 41088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.98e+14  |\n",
      "|    n_updates            | 3200      |\n",
      "|    policy_gradient_loss | -2.04e-06 |\n",
      "|    reward               | 1711070.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.08e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 322       |\n",
      "|    time_elapsed         | 47        |\n",
      "|    total_timesteps      | 41216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.36e+14  |\n",
      "|    n_updates            | 3210      |\n",
      "|    policy_gradient_loss | -2.69e-06 |\n",
      "|    reward               | 1912884.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 323       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.64e+14  |\n",
      "|    n_updates            | 3220      |\n",
      "|    policy_gradient_loss | -2.9e-06  |\n",
      "|    reward               | 1763890.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.48e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 860       |\n",
      "|    iterations           | 324       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.74e+14  |\n",
      "|    n_updates            | 3230      |\n",
      "|    policy_gradient_loss | -2.46e-06 |\n",
      "|    reward               | 2109554.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 860       |\n",
      "|    iterations           | 325       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.2e+14   |\n",
      "|    n_updates            | 3240      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 2510230.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.71e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 326       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.38e+14  |\n",
      "|    n_updates            | 3250      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 2482354.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.26e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 327       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.31e+14  |\n",
      "|    n_updates            | 3260      |\n",
      "|    policy_gradient_loss | -1.81e-06 |\n",
      "|    reward               | 2493063.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 328       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 41984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.52e+14  |\n",
      "|    n_updates            | 3270      |\n",
      "|    policy_gradient_loss | -1.53e-06 |\n",
      "|    reward               | 2513445.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.5e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 329       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 42112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.39e+14  |\n",
      "|    n_updates            | 3280      |\n",
      "|    policy_gradient_loss | -2.22e-06 |\n",
      "|    reward               | 2618357.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.31e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 330       |\n",
      "|    time_elapsed         | 48        |\n",
      "|    total_timesteps      | 42240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.42e+14  |\n",
      "|    n_updates            | 3290      |\n",
      "|    policy_gradient_loss | -1.81e-06 |\n",
      "|    reward               | 2860951.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2901559.3090679795\n",
      "Sharpe:  0.827569439900144\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 331       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 42368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.06e+14  |\n",
      "|    n_updates            | 3300      |\n",
      "|    policy_gradient_loss | -1.88e-06 |\n",
      "|    reward               | 1053362.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.6e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 332       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 42496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.11e+14  |\n",
      "|    n_updates            | 3310      |\n",
      "|    policy_gradient_loss | -3.9e-06  |\n",
      "|    reward               | 1185535.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 333       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 42624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.27e+14  |\n",
      "|    n_updates            | 3320      |\n",
      "|    policy_gradient_loss | -4.05e-06 |\n",
      "|    reward               | 1279360.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.78e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 334       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 42752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.84e+14  |\n",
      "|    n_updates            | 3330      |\n",
      "|    policy_gradient_loss | -4.67e-06 |\n",
      "|    reward               | 1503698.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.54e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 335       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 42880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.19e+14  |\n",
      "|    n_updates            | 3340      |\n",
      "|    policy_gradient_loss | -2.35e-06 |\n",
      "|    reward               | 1528234.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.31e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 336       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.69e+14  |\n",
      "|    n_updates            | 3350      |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 1562194.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.34e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 337       |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 43136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.94e+14  |\n",
      "|    n_updates            | 3360      |\n",
      "|    policy_gradient_loss | -3.52e-06 |\n",
      "|    reward               | 1807274.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.12e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 338       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.56e+14  |\n",
      "|    n_updates            | 3370      |\n",
      "|    policy_gradient_loss | -3.01e-06 |\n",
      "|    reward               | 1994974.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.8e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 864       |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.13e+14  |\n",
      "|    n_updates            | 3380      |\n",
      "|    policy_gradient_loss | -2.3e-06  |\n",
      "|    reward               | 1897884.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.88e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 864       |\n",
      "|    iterations           | 340       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.78e+14  |\n",
      "|    n_updates            | 3390      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2193597.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.28e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 864       |\n",
      "|    iterations           | 341       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.59e+14  |\n",
      "|    n_updates            | 3400      |\n",
      "|    policy_gradient_loss | -2.07e-06 |\n",
      "|    reward               | 2495916.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 864       |\n",
      "|    iterations           | 342       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.77e+14  |\n",
      "|    n_updates            | 3410      |\n",
      "|    policy_gradient_loss | -2.03e-06 |\n",
      "|    reward               | 2483188.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 343       |\n",
      "|    time_elapsed         | 50        |\n",
      "|    total_timesteps      | 43904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.44e+14  |\n",
      "|    n_updates            | 3420      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 2328658.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 344       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.54e+14  |\n",
      "|    n_updates            | 3430      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 2449191.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.31e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 345       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.23e+14  |\n",
      "|    n_updates            | 3440      |\n",
      "|    policy_gradient_loss | -3.43e-06 |\n",
      "|    reward               | 2581024.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.25e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2768754.2269599508\n",
      "Sharpe:  0.7974358834828859\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 346       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.19e+14  |\n",
      "|    n_updates            | 3450      |\n",
      "|    policy_gradient_loss | -1.38e-06 |\n",
      "|    reward               | 916791.06 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 347       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.79e+14  |\n",
      "|    n_updates            | 3460      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 1081416.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 348       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.24e+14  |\n",
      "|    n_updates            | 3470      |\n",
      "|    policy_gradient_loss | -5.21e-06 |\n",
      "|    reward               | 1184837.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 349       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.49e+14  |\n",
      "|    n_updates            | 3480      |\n",
      "|    policy_gradient_loss | -4.23e-06 |\n",
      "|    reward               | 1316563.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 350       |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 44800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.71e+14  |\n",
      "|    n_updates            | 3490      |\n",
      "|    policy_gradient_loss | -2.64e-06 |\n",
      "|    reward               | 1482476.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 351       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 44928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.41e+14  |\n",
      "|    n_updates            | 3500      |\n",
      "|    policy_gradient_loss | -3.46e-06 |\n",
      "|    reward               | 1608772.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 352       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.51e+14  |\n",
      "|    n_updates            | 3510      |\n",
      "|    policy_gradient_loss | -2.05e-06 |\n",
      "|    reward               | 1686387.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 353       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.87e+14  |\n",
      "|    n_updates            | 3520      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 1762647.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.92e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 354       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.41e+14  |\n",
      "|    n_updates            | 3530      |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 1888129.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.88e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 355       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.41e+14  |\n",
      "|    n_updates            | 3540      |\n",
      "|    policy_gradient_loss | -2.44e-06 |\n",
      "|    reward               | 1991948.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.34e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 356       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.7e+14   |\n",
      "|    n_updates            | 3550      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 2355118.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.48e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 357       |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 45696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.33e+14  |\n",
      "|    n_updates            | 3560      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2518055.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.05e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 863       |\n",
      "|    iterations           | 358       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 45824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.36e+14  |\n",
      "|    n_updates            | 3570      |\n",
      "|    policy_gradient_loss | -2.3e-06  |\n",
      "|    reward               | 2564385.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 864       |\n",
      "|    iterations           | 359       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 45952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.94e+14  |\n",
      "|    n_updates            | 3580      |\n",
      "|    policy_gradient_loss | -2.35e-06 |\n",
      "|    reward               | 2359732.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.53e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 360       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 46080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.19e+14  |\n",
      "|    n_updates            | 3590      |\n",
      "|    policy_gradient_loss | -2.04e-06 |\n",
      "|    reward               | 2500637.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 361       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 46208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.34e+14  |\n",
      "|    n_updates            | 3600      |\n",
      "|    policy_gradient_loss | -2.23e-06 |\n",
      "|    reward               | 2621315.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2968951.7589135193\n",
      "Sharpe:  0.8469520342278026\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 861        |\n",
      "|    iterations           | 362        |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 46336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.47e+14   |\n",
      "|    n_updates            | 3610       |\n",
      "|    policy_gradient_loss | -1.92e-06  |\n",
      "|    reward               | 1032073.56 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.63e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 363       |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 46464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.36e+14  |\n",
      "|    n_updates            | 3620      |\n",
      "|    policy_gradient_loss | -3.02e-06 |\n",
      "|    reward               | 1089981.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.15e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 364       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 46592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.29e+14  |\n",
      "|    n_updates            | 3630      |\n",
      "|    policy_gradient_loss | -3.85e-06 |\n",
      "|    reward               | 1207369.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 365       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 46720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.56e+14  |\n",
      "|    n_updates            | 3640      |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 1336076.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 366       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 46848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.76e+14  |\n",
      "|    n_updates            | 3650      |\n",
      "|    policy_gradient_loss | -3.84e-06 |\n",
      "|    reward               | 1487853.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 367       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 46976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.49e+14  |\n",
      "|    n_updates            | 3660      |\n",
      "|    policy_gradient_loss | -3.7e-06  |\n",
      "|    reward               | 1580349.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.98e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 368       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.76e+14  |\n",
      "|    n_updates            | 3670      |\n",
      "|    policy_gradient_loss | -3.41e-06 |\n",
      "|    reward               | 1727935.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 369       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 47232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.07e+14  |\n",
      "|    n_updates            | 3680      |\n",
      "|    policy_gradient_loss | -3.29e-06 |\n",
      "|    reward               | 1805563.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 370       |\n",
      "|    time_elapsed         | 54        |\n",
      "|    total_timesteps      | 47360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.69e+14  |\n",
      "|    n_updates            | 3690      |\n",
      "|    policy_gradient_loss | -3.38e-06 |\n",
      "|    reward               | 1710533.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.12e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 371       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 47488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.01e+14  |\n",
      "|    n_updates            | 3700      |\n",
      "|    policy_gradient_loss | -2.81e-06 |\n",
      "|    reward               | 1971976.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 372       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 47616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.24e+14  |\n",
      "|    n_updates            | 3710      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2432318.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.37e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 373       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 47744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.99e+14  |\n",
      "|    n_updates            | 3720      |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 2623099.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 374       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 47872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.23e+14  |\n",
      "|    n_updates            | 3730      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 2538166.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 375       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 48000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.43e+14  |\n",
      "|    n_updates            | 3740      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2522658.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.59e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 862       |\n",
      "|    iterations           | 376       |\n",
      "|    time_elapsed         | 55        |\n",
      "|    total_timesteps      | 48128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.71e+14  |\n",
      "|    n_updates            | 3750      |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 2675480.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 861       |\n",
      "|    iterations           | 377       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.38e+14  |\n",
      "|    n_updates            | 3760      |\n",
      "|    policy_gradient_loss | -1.84e-06 |\n",
      "|    reward               | 2821025.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.61e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3084130.81807568\n",
      "Sharpe:  0.8730480473593332\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 860       |\n",
      "|    iterations           | 378       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.08e+14  |\n",
      "|    n_updates            | 3770      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 1017670.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.74e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 860       |\n",
      "|    iterations           | 379       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.18e+14  |\n",
      "|    n_updates            | 3780      |\n",
      "|    policy_gradient_loss | -3.41e-06 |\n",
      "|    reward               | 1108838.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.03e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 380       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.38e+14  |\n",
      "|    n_updates            | 3790      |\n",
      "|    policy_gradient_loss | -4.45e-06 |\n",
      "|    reward               | 1248540.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.66e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 860       |\n",
      "|    iterations           | 381       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.6e+14   |\n",
      "|    n_updates            | 3800      |\n",
      "|    policy_gradient_loss | -4.33e-06 |\n",
      "|    reward               | 1435910.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 382       |\n",
      "|    time_elapsed         | 56        |\n",
      "|    total_timesteps      | 48896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.02e+14  |\n",
      "|    n_updates            | 3810      |\n",
      "|    policy_gradient_loss | -3.38e-06 |\n",
      "|    reward               | 1509345.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 383       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.58e+14  |\n",
      "|    n_updates            | 3820      |\n",
      "|    policy_gradient_loss | -2.96e-06 |\n",
      "|    reward               | 1607002.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.11e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 384       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 3830      |\n",
      "|    policy_gradient_loss | -3.43e-06 |\n",
      "|    reward               | 1711834.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.83e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 385       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.08e+14  |\n",
      "|    n_updates            | 3840      |\n",
      "|    policy_gradient_loss | -3.44e-06 |\n",
      "|    reward               | 1883524.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 386       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.55e+14  |\n",
      "|    n_updates            | 3850      |\n",
      "|    policy_gradient_loss | -1.35e-06 |\n",
      "|    reward               | 1885859.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.39e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 387       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.71e+14  |\n",
      "|    n_updates            | 3860      |\n",
      "|    policy_gradient_loss | -2.2e-06  |\n",
      "|    reward               | 2187194.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.27e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 388       |\n",
      "|    time_elapsed         | 57        |\n",
      "|    total_timesteps      | 49664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.46e+14  |\n",
      "|    n_updates            | 3870      |\n",
      "|    policy_gradient_loss | -1.72e-06 |\n",
      "|    reward               | 2497136.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.13e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 389       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 49792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.12e+14  |\n",
      "|    n_updates            | 3880      |\n",
      "|    policy_gradient_loss | -1.58e-06 |\n",
      "|    reward               | 2637051.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 390       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 49920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.76e+14  |\n",
      "|    n_updates            | 3890      |\n",
      "|    policy_gradient_loss | -2.21e-06 |\n",
      "|    reward               | 2314440.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.55e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 391       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 50048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.45e+14  |\n",
      "|    n_updates            | 3900      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2538974.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 392       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 50176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.74e+14  |\n",
      "|    n_updates            | 3910      |\n",
      "|    policy_gradient_loss | -2.89e-06 |\n",
      "|    reward               | 2679681.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3014408.707345824\n",
      "Sharpe:  0.856359943246566\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 393       |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 50304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.2e+14   |\n",
      "|    n_updates            | 3920      |\n",
      "|    policy_gradient_loss | -1.67e-06 |\n",
      "|    reward               | 953900.25 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.57e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 394       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 50432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.61e+14  |\n",
      "|    n_updates            | 3930      |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 1097945.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.69e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 395       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 50560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.25e+14  |\n",
      "|    n_updates            | 3940      |\n",
      "|    policy_gradient_loss | -5.58e-06 |\n",
      "|    reward               | 1180825.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 396       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 50688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.49e+14  |\n",
      "|    n_updates            | 3950      |\n",
      "|    policy_gradient_loss | -3.7e-06  |\n",
      "|    reward               | 1284855.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.87e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 397       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 50816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.78e+14  |\n",
      "|    n_updates            | 3960      |\n",
      "|    policy_gradient_loss | -2.26e-06 |\n",
      "|    reward               | 1571560.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.52e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 398       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 50944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.14e+14  |\n",
      "|    n_updates            | 3970      |\n",
      "|    policy_gradient_loss | -4.16e-06 |\n",
      "|    reward               | 1561490.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.42e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 399       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 51072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.7e+14   |\n",
      "|    n_updates            | 3980      |\n",
      "|    policy_gradient_loss | -2.17e-06 |\n",
      "|    reward               | 1564238.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 400       |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.99e+14  |\n",
      "|    n_updates            | 3990      |\n",
      "|    policy_gradient_loss | -2.68e-06 |\n",
      "|    reward               | 1728866.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.79e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 401       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.22e+14  |\n",
      "|    n_updates            | 4000      |\n",
      "|    policy_gradient_loss | -3.05e-06 |\n",
      "|    reward               | 1867468.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 402       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.65e+14  |\n",
      "|    n_updates            | 4010      |\n",
      "|    policy_gradient_loss | -3.42e-06 |\n",
      "|    reward               | 1779888.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 403       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.22e+14  |\n",
      "|    n_updates            | 4020      |\n",
      "|    policy_gradient_loss | -2.82e-06 |\n",
      "|    reward               | 2048714.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.36e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 404       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.01e+14  |\n",
      "|    n_updates            | 4030      |\n",
      "|    policy_gradient_loss | -4.23e-06 |\n",
      "|    reward               | 2308210.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.31e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 405       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.97e+14  |\n",
      "|    n_updates            | 4040      |\n",
      "|    policy_gradient_loss | -2.86e-06 |\n",
      "|    reward               | 2312218.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.12e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 406       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 51968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.93e+14  |\n",
      "|    n_updates            | 4050      |\n",
      "|    policy_gradient_loss | -2.01e-06 |\n",
      "|    reward               | 2269112.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.22e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 407       |\n",
      "|    time_elapsed         | 60        |\n",
      "|    total_timesteps      | 52096     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.33e+14  |\n",
      "|    n_updates            | 4060      |\n",
      "|    policy_gradient_loss | -2.52e-06 |\n",
      "|    reward               | 2210620.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.11e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 408       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.54e+14  |\n",
      "|    n_updates            | 4070      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2295029.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.08e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2550963.7767665894\n",
      "Sharpe:  0.7452388420214676\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 409       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.91e+14  |\n",
      "|    n_updates            | 4080      |\n",
      "|    policy_gradient_loss | -2.43e-06 |\n",
      "|    reward               | 991648.9  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.19e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 410       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.78e+14  |\n",
      "|    n_updates            | 4090      |\n",
      "|    policy_gradient_loss | -2.71e-06 |\n",
      "|    reward               | 1090754.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.92e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 411       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.27e+14  |\n",
      "|    n_updates            | 4100      |\n",
      "|    policy_gradient_loss | -3.76e-06 |\n",
      "|    reward               | 1247496.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.54e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 412       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.47e+14  |\n",
      "|    n_updates            | 4110      |\n",
      "|    policy_gradient_loss | -4.37e-06 |\n",
      "|    reward               | 1309379.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 413       |\n",
      "|    time_elapsed         | 61        |\n",
      "|    total_timesteps      | 52864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.74e+14  |\n",
      "|    n_updates            | 4120      |\n",
      "|    policy_gradient_loss | -2.75e-06 |\n",
      "|    reward               | 1514040.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 414       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 52992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.45e+14  |\n",
      "|    n_updates            | 4130      |\n",
      "|    policy_gradient_loss | -3.69e-06 |\n",
      "|    reward               | 1660302.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.84e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 415       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.89e+14  |\n",
      "|    n_updates            | 4140      |\n",
      "|    policy_gradient_loss | -2.94e-06 |\n",
      "|    reward               | 1721533.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 416       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.2e+14   |\n",
      "|    n_updates            | 4150      |\n",
      "|    policy_gradient_loss | -3.32e-06 |\n",
      "|    reward               | 1847752.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 417       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.57e+14  |\n",
      "|    n_updates            | 4160      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 1661765.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.21e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 418       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.47e+14  |\n",
      "|    n_updates            | 4170      |\n",
      "|    policy_gradient_loss | -2.71e-06 |\n",
      "|    reward               | 2016508.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 419       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.11e+14  |\n",
      "|    n_updates            | 4180      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 2492214.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 420       |\n",
      "|    time_elapsed         | 62        |\n",
      "|    total_timesteps      | 53760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.96e+14  |\n",
      "|    n_updates            | 4190      |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 2572018.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 421       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 53888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.72e+14  |\n",
      "|    n_updates            | 4200      |\n",
      "|    policy_gradient_loss | -1.86e-06 |\n",
      "|    reward               | 2694381.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.56e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 422       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 54016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.39e+14  |\n",
      "|    n_updates            | 4210      |\n",
      "|    policy_gradient_loss | -2.23e-06 |\n",
      "|    reward               | 2239868.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.66e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 423       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 54144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.42e+14  |\n",
      "|    n_updates            | 4220      |\n",
      "|    policy_gradient_loss | -1.48e-06 |\n",
      "|    reward               | 2612664.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 424       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 54272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.09e+14  |\n",
      "|    n_updates            | 4230      |\n",
      "|    policy_gradient_loss | -1.85e-06 |\n",
      "|    reward               | 2658709.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.5e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2959383.766383803\n",
      "Sharpe:  0.8419166287258678\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 425       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 54400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.96e+14  |\n",
      "|    n_updates            | 4240      |\n",
      "|    policy_gradient_loss | -1.52e-06 |\n",
      "|    reward               | 1056909.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.66e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 426       |\n",
      "|    time_elapsed         | 63        |\n",
      "|    total_timesteps      | 54528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.54e+14  |\n",
      "|    n_updates            | 4250      |\n",
      "|    policy_gradient_loss | -2.55e-06 |\n",
      "|    reward               | 1087580.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 427       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 54656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.28e+14  |\n",
      "|    n_updates            | 4260      |\n",
      "|    policy_gradient_loss | -4.32e-06 |\n",
      "|    reward               | 1244956.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.65e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 428       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 54784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.64e+14  |\n",
      "|    n_updates            | 4270      |\n",
      "|    policy_gradient_loss | -5.31e-06 |\n",
      "|    reward               | 1386865.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.24e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 429       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 54912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.89e+14  |\n",
      "|    n_updates            | 4280      |\n",
      "|    policy_gradient_loss | -3.99e-06 |\n",
      "|    reward               | 1494626.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 430       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 55040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.6e+14   |\n",
      "|    n_updates            | 4290      |\n",
      "|    policy_gradient_loss | -3.5e-06  |\n",
      "|    reward               | 1632095.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 431       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 55168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.9e+14   |\n",
      "|    n_updates            | 4300      |\n",
      "|    policy_gradient_loss | -3.5e-06  |\n",
      "|    reward               | 1670208.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 432       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.21e+14  |\n",
      "|    n_updates            | 4310      |\n",
      "|    policy_gradient_loss | -1.32e-06 |\n",
      "|    reward               | 1854285.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 433       |\n",
      "|    time_elapsed         | 64        |\n",
      "|    total_timesteps      | 55424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.48e+14  |\n",
      "|    n_updates            | 4320      |\n",
      "|    policy_gradient_loss | -2.43e-06 |\n",
      "|    reward               | 1727063.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 434       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 55552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.61e+14  |\n",
      "|    n_updates            | 4330      |\n",
      "|    policy_gradient_loss | -2.43e-06 |\n",
      "|    reward               | 2123580.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 435       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 55680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.31e+14  |\n",
      "|    n_updates            | 4340      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 2403318.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.52e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 436       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 55808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.93e+14  |\n",
      "|    n_updates            | 4350      |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 2482025.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 437       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 55936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.06e+14  |\n",
      "|    n_updates            | 4360      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 2358819.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 438       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 56064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.52e+14  |\n",
      "|    n_updates            | 4370      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2429093.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.35e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 439       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 56192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.95e+14  |\n",
      "|    n_updates            | 4380      |\n",
      "|    policy_gradient_loss | -1.59e-06 |\n",
      "|    reward               | 2410998.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 440       |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 56320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.46e+14  |\n",
      "|    n_updates            | 4390      |\n",
      "|    policy_gradient_loss | -1.6e-06  |\n",
      "|    reward               | 2595170.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2712606.928351066\n",
      "Sharpe:  0.7852048921927254\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 852        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 56448      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.84e+14   |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | -1.16e-06  |\n",
      "|    reward               | 1044389.75 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.39e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 442       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 56576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.19e+14  |\n",
      "|    n_updates            | 4410      |\n",
      "|    policy_gradient_loss | -3.93e-06 |\n",
      "|    reward               | 1164294.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.45e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 443       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 56704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.34e+14  |\n",
      "|    n_updates            | 4420      |\n",
      "|    policy_gradient_loss | -4.59e-06 |\n",
      "|    reward               | 1286511.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.77e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 852       |\n",
      "|    iterations           | 444       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 56832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.76e+14  |\n",
      "|    n_updates            | 4430      |\n",
      "|    policy_gradient_loss | -5.04e-06 |\n",
      "|    reward               | 1503232.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.49e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 445       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 56960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.18e+14  |\n",
      "|    n_updates            | 4440      |\n",
      "|    policy_gradient_loss | -2.45e-06 |\n",
      "|    reward               | 1525380.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.37e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 446       |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 57088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.6e+14   |\n",
      "|    n_updates            | 4450      |\n",
      "|    policy_gradient_loss | -3.12e-06 |\n",
      "|    reward               | 1561787.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 447       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.06e+14  |\n",
      "|    n_updates            | 4460      |\n",
      "|    policy_gradient_loss | -3.09e-06 |\n",
      "|    reward               | 1841216.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.15e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 448       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.56e+14  |\n",
      "|    n_updates            | 4470      |\n",
      "|    policy_gradient_loss | -1.83e-06 |\n",
      "|    reward               | 1958398.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 449       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.99e+14  |\n",
      "|    n_updates            | 4480      |\n",
      "|    policy_gradient_loss | -2.7e-06  |\n",
      "|    reward               | 1720238.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 853       |\n",
      "|    iterations           | 450       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.25e+14  |\n",
      "|    n_updates            | 4490      |\n",
      "|    policy_gradient_loss | -2.46e-06 |\n",
      "|    reward               | 2123165.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 451       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.41e+14  |\n",
      "|    n_updates            | 4500      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 2407925.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 452       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.14e+14  |\n",
      "|    n_updates            | 4510      |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 2468976.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 453       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 57984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.07e+14  |\n",
      "|    n_updates            | 4520      |\n",
      "|    policy_gradient_loss | -1.34e-06 |\n",
      "|    reward               | 2203871.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.35e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 454       |\n",
      "|    time_elapsed         | 67        |\n",
      "|    total_timesteps      | 58112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.05e+14  |\n",
      "|    n_updates            | 4530      |\n",
      "|    policy_gradient_loss | -1.91e-06 |\n",
      "|    reward               | 2388591.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.19e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 455       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.8e+14   |\n",
      "|    n_updates            | 4540      |\n",
      "|    policy_gradient_loss | -1.4e-06  |\n",
      "|    reward               | 2558316.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2734705.7096260954\n",
      "Sharpe:  0.7911182371962275\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 456       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.76e+14  |\n",
      "|    n_updates            | 4550      |\n",
      "|    policy_gradient_loss | -2.18e-06 |\n",
      "|    reward               | 949651.8  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.35e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 457       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.85e+14  |\n",
      "|    n_updates            | 4560      |\n",
      "|    policy_gradient_loss | -1.87e-06 |\n",
      "|    reward               | 1096071.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 458       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e+14  |\n",
      "|    n_updates            | 4570      |\n",
      "|    policy_gradient_loss | -4.82e-06 |\n",
      "|    reward               | 1210109.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 459       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.55e+14  |\n",
      "|    n_updates            | 4580      |\n",
      "|    policy_gradient_loss | -4.03e-06 |\n",
      "|    reward               | 1329845.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 460       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 58880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.9e+14   |\n",
      "|    n_updates            | 4590      |\n",
      "|    policy_gradient_loss | -3.82e-06 |\n",
      "|    reward               | 1499121.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.75e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 461       |\n",
      "|    time_elapsed         | 68        |\n",
      "|    total_timesteps      | 59008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.46e+14  |\n",
      "|    n_updates            | 4600      |\n",
      "|    policy_gradient_loss | -1.9e-06  |\n",
      "|    reward               | 1618528.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.83e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 462       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.62e+14  |\n",
      "|    n_updates            | 4610      |\n",
      "|    policy_gradient_loss | -3.39e-06 |\n",
      "|    reward               | 1657079.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 463       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3e+14     |\n",
      "|    n_updates            | 4620      |\n",
      "|    policy_gradient_loss | -2.92e-06 |\n",
      "|    reward               | 1696978.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 464       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.39e+14  |\n",
      "|    n_updates            | 4630      |\n",
      "|    policy_gradient_loss | -2.71e-06 |\n",
      "|    reward               | 1718235.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 465       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.06e+14  |\n",
      "|    n_updates            | 4640      |\n",
      "|    policy_gradient_loss | -1.45e-06 |\n",
      "|    reward               | 1919171.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.82e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 466       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.36e+14  |\n",
      "|    n_updates            | 4650      |\n",
      "|    policy_gradient_loss | -3.18e-06 |\n",
      "|    reward               | 2144609.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 467       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.74e+14  |\n",
      "|    n_updates            | 4660      |\n",
      "|    policy_gradient_loss | -1.53e-06 |\n",
      "|    reward               | 2425245.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.38e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 468       |\n",
      "|    time_elapsed         | 69        |\n",
      "|    total_timesteps      | 59904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.44e+14  |\n",
      "|    n_updates            | 4670      |\n",
      "|    policy_gradient_loss | -1.89e-06 |\n",
      "|    reward               | 2318586.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.28e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 469       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.08e+14  |\n",
      "|    n_updates            | 4680      |\n",
      "|    policy_gradient_loss | -1.93e-06 |\n",
      "|    reward               | 2212641.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 470       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.65e+14  |\n",
      "|    n_updates            | 4690      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 2250380.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 471       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.09e+14  |\n",
      "|    n_updates            | 4700      |\n",
      "|    policy_gradient_loss | -1.87e-06 |\n",
      "|    reward               | 2400972.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.16e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2653003.938916292\n",
      "Sharpe:  0.7701162017145476\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 472       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.46e+14  |\n",
      "|    n_updates            | 4710      |\n",
      "|    policy_gradient_loss | -3.04e-06 |\n",
      "|    reward               | 1019641.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.28e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 473       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.44e+14  |\n",
      "|    n_updates            | 4720      |\n",
      "|    policy_gradient_loss | -2.82e-06 |\n",
      "|    reward               | 1099389.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 474       |\n",
      "|    time_elapsed         | 70        |\n",
      "|    total_timesteps      | 60672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e+14  |\n",
      "|    n_updates            | 4730      |\n",
      "|    policy_gradient_loss | -4.76e-06 |\n",
      "|    reward               | 1258845.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.62e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 475       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 60800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.6e+14   |\n",
      "|    n_updates            | 4740      |\n",
      "|    policy_gradient_loss | -4.41e-06 |\n",
      "|    reward               | 1374432.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 476       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 60928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.05e+14  |\n",
      "|    n_updates            | 4750      |\n",
      "|    policy_gradient_loss | -2.48e-06 |\n",
      "|    reward               | 1499551.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 477       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.63e+14  |\n",
      "|    n_updates            | 4760      |\n",
      "|    policy_gradient_loss | -2.51e-06 |\n",
      "|    reward               | 1739191.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.26e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 478       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.08e+14  |\n",
      "|    n_updates            | 4770      |\n",
      "|    policy_gradient_loss | -2.67e-06 |\n",
      "|    reward               | 1785004.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.1e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 479       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.24e+14  |\n",
      "|    n_updates            | 4780      |\n",
      "|    policy_gradient_loss | -2.51e-06 |\n",
      "|    reward               | 1841591.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.49e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 480       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.81e+14  |\n",
      "|    n_updates            | 4790      |\n",
      "|    policy_gradient_loss | -2.91e-06 |\n",
      "|    reward               | 1695443.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.42e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 481       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.98e+14  |\n",
      "|    n_updates            | 4800      |\n",
      "|    policy_gradient_loss | -1.9e-06  |\n",
      "|    reward               | 1967559.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.94e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 482       |\n",
      "|    time_elapsed         | 71        |\n",
      "|    total_timesteps      | 61696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.14e+14  |\n",
      "|    n_updates            | 4810      |\n",
      "|    policy_gradient_loss | -1.64e-06 |\n",
      "|    reward               | 2459386.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.09e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 483       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 61824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.57e+14  |\n",
      "|    n_updates            | 4820      |\n",
      "|    policy_gradient_loss | -2.01e-06 |\n",
      "|    reward               | 2580144.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 484       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 61952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.31e+14  |\n",
      "|    n_updates            | 4830      |\n",
      "|    policy_gradient_loss | -1.23e-06 |\n",
      "|    reward               | 2450144.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 485       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 62080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.24e+14  |\n",
      "|    n_updates            | 4840      |\n",
      "|    policy_gradient_loss | -1.83e-06 |\n",
      "|    reward               | 2398617.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 486       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 62208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.11e+14  |\n",
      "|    n_updates            | 4850      |\n",
      "|    policy_gradient_loss | -1.86e-06 |\n",
      "|    reward               | 2578135.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.24e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 487       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 62336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.79e+14  |\n",
      "|    n_updates            | 4860      |\n",
      "|    policy_gradient_loss | -1.89e-06 |\n",
      "|    reward               | 2576724.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2891517.062871281\n",
      "Sharpe:  0.8274492779039148\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 488       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 62464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.73e+14  |\n",
      "|    n_updates            | 4870      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 1042491.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 489       |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 62592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.41e+14  |\n",
      "|    n_updates            | 4880      |\n",
      "|    policy_gradient_loss | -2.87e-06 |\n",
      "|    reward               | 1118008.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.17e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 490       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 62720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.32e+14  |\n",
      "|    n_updates            | 4890      |\n",
      "|    policy_gradient_loss | -4.94e-06 |\n",
      "|    reward               | 1260414.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 491       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 62848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.78e+14  |\n",
      "|    n_updates            | 4900      |\n",
      "|    policy_gradient_loss | -4.2e-06  |\n",
      "|    reward               | 1407969.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.39e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 492       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 62976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 4910      |\n",
      "|    policy_gradient_loss | -2.56e-06 |\n",
      "|    reward               | 1497568.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.07e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 493       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 63104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.45e+14  |\n",
      "|    n_updates            | 4920      |\n",
      "|    policy_gradient_loss | -2.05e-06 |\n",
      "|    reward               | 1651525.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.11e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 494       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 63232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.91e+14  |\n",
      "|    n_updates            | 4930      |\n",
      "|    policy_gradient_loss | -2.12e-06 |\n",
      "|    reward               | 1672460.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.89e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 495       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 63360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.22e+14  |\n",
      "|    n_updates            | 4940      |\n",
      "|    policy_gradient_loss | -2.42e-06 |\n",
      "|    reward               | 1838408.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.26e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 496       |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.53e+14  |\n",
      "|    n_updates            | 4950      |\n",
      "|    policy_gradient_loss | -2.18e-06 |\n",
      "|    reward               | 1864942.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 497       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 63616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.74e+14  |\n",
      "|    n_updates            | 4960      |\n",
      "|    policy_gradient_loss | -2.48e-06 |\n",
      "|    reward               | 2092855.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.03e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 498       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 63744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.14e+14  |\n",
      "|    n_updates            | 4970      |\n",
      "|    policy_gradient_loss | -2.29e-06 |\n",
      "|    reward               | 2374468.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 499       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 63872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.79e+14  |\n",
      "|    n_updates            | 4980      |\n",
      "|    policy_gradient_loss | -9.81e-07 |\n",
      "|    reward               | 2478521.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 500       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 64000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.01e+14  |\n",
      "|    n_updates            | 4990      |\n",
      "|    policy_gradient_loss | -1.33e-06 |\n",
      "|    reward               | 2127432.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 501       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 64128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.17e+14  |\n",
      "|    n_updates            | 5000      |\n",
      "|    policy_gradient_loss | -1.69e-06 |\n",
      "|    reward               | 2234924.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 502       |\n",
      "|    time_elapsed         | 74        |\n",
      "|    total_timesteps      | 64256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.35e+14  |\n",
      "|    n_updates            | 5010      |\n",
      "|    policy_gradient_loss | -1.84e-06 |\n",
      "|    reward               | 2347713.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.1e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2641193.586694776\n",
      "Sharpe:  0.7682554776249864\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 503       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 64384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.82e+14  |\n",
      "|    n_updates            | 5020      |\n",
      "|    policy_gradient_loss | -2.79e-06 |\n",
      "|    reward               | 2641193.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 504       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 64512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.39e+14  |\n",
      "|    n_updates            | 5030      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 1042881.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.31e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 854       |\n",
      "|    iterations           | 505       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 64640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.14e+14  |\n",
      "|    n_updates            | 5040      |\n",
      "|    policy_gradient_loss | -4.6e-06  |\n",
      "|    reward               | 1153903.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 506       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 64768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e+14  |\n",
      "|    n_updates            | 5050      |\n",
      "|    policy_gradient_loss | -4.18e-06 |\n",
      "|    reward               | 1269337.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 507       |\n",
      "|    time_elapsed         | 75        |\n",
      "|    total_timesteps      | 64896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.69e+14  |\n",
      "|    n_updates            | 5060      |\n",
      "|    policy_gradient_loss | -3.39e-06 |\n",
      "|    reward               | 1551419.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.46e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 508       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.27e+14  |\n",
      "|    n_updates            | 5070      |\n",
      "|    policy_gradient_loss | -2.69e-06 |\n",
      "|    reward               | 1558483.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.43e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 509       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.76e+14  |\n",
      "|    n_updates            | 5080      |\n",
      "|    policy_gradient_loss | -3.82e-06 |\n",
      "|    reward               | 1588223.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.28e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 510       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.02e+14  |\n",
      "|    n_updates            | 5090      |\n",
      "|    policy_gradient_loss | -3.19e-06 |\n",
      "|    reward               | 1792032.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 511       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.35e+14  |\n",
      "|    n_updates            | 5100      |\n",
      "|    policy_gradient_loss | -2.56e-06 |\n",
      "|    reward               | 1933726.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 512       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.95e+14  |\n",
      "|    n_updates            | 5110      |\n",
      "|    policy_gradient_loss | -2.28e-06 |\n",
      "|    reward               | 1814719.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 513       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.49e+14  |\n",
      "|    n_updates            | 5120      |\n",
      "|    policy_gradient_loss | -2.13e-06 |\n",
      "|    reward               | 2152976.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 514       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.61e+14  |\n",
      "|    n_updates            | 5130      |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2542734.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 515       |\n",
      "|    time_elapsed         | 76        |\n",
      "|    total_timesteps      | 65920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7e+14     |\n",
      "|    n_updates            | 5140      |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2599677.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 516       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.93e+14  |\n",
      "|    n_updates            | 5150      |\n",
      "|    policy_gradient_loss | -2.29e-06 |\n",
      "|    reward               | 2581683.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 517       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.65e+14  |\n",
      "|    n_updates            | 5160      |\n",
      "|    policy_gradient_loss | -2.43e-06 |\n",
      "|    reward               | 2648001.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.41e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 518       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.27e+14  |\n",
      "|    n_updates            | 5170      |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 2720554.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2992985.852527056\n",
      "Sharpe:  0.8560208622123309\n",
      "=================================\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 856      |\n",
      "|    iterations           | 519      |\n",
      "|    time_elapsed         | 77       |\n",
      "|    total_timesteps      | 66432    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.0      |\n",
      "|    clip_fraction        | 0        |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -41.1    |\n",
      "|    explained_variance   | 0        |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 8.03e+14 |\n",
      "|    n_updates            | 5180     |\n",
      "|    policy_gradient_loss | -1.9e-06 |\n",
      "|    reward               | 978436.7 |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 1.61e+15 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 520       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.11e+14  |\n",
      "|    n_updates            | 5190      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 1098287.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.15e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 521       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.28e+14  |\n",
      "|    n_updates            | 5200      |\n",
      "|    policy_gradient_loss | -4.4e-06  |\n",
      "|    reward               | 1248223.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 522       |\n",
      "|    time_elapsed         | 77        |\n",
      "|    total_timesteps      | 66816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.43e+14  |\n",
      "|    n_updates            | 5210      |\n",
      "|    policy_gradient_loss | -3.84e-06 |\n",
      "|    reward               | 1332711.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 523       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 66944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.84e+14  |\n",
      "|    n_updates            | 5220      |\n",
      "|    policy_gradient_loss | -2.34e-06 |\n",
      "|    reward               | 1512023.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.7e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 524       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.43e+14  |\n",
      "|    n_updates            | 5230      |\n",
      "|    policy_gradient_loss | -3.34e-06 |\n",
      "|    reward               | 1663375.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.9e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 525       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.65e+14  |\n",
      "|    n_updates            | 5240      |\n",
      "|    policy_gradient_loss | -3.84e-06 |\n",
      "|    reward               | 1745688.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.59e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 526       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.13e+14  |\n",
      "|    n_updates            | 5250      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 1878401.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 527       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.75e+14  |\n",
      "|    n_updates            | 5260      |\n",
      "|    policy_gradient_loss | -3.1e-06  |\n",
      "|    reward               | 1397797.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.48e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 528       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.1e+14   |\n",
      "|    n_updates            | 5270      |\n",
      "|    policy_gradient_loss | -3.39e-06 |\n",
      "|    reward               | 1954757.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.56e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 529       |\n",
      "|    time_elapsed         | 78        |\n",
      "|    total_timesteps      | 67712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.99e+14  |\n",
      "|    n_updates            | 5280      |\n",
      "|    policy_gradient_loss | -2.09e-06 |\n",
      "|    reward               | 2480278.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 530       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 67840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.59e+14  |\n",
      "|    n_updates            | 5290      |\n",
      "|    policy_gradient_loss | -2.07e-06 |\n",
      "|    reward               | 2541890.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 531       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 67968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.91e+14  |\n",
      "|    n_updates            | 5300      |\n",
      "|    policy_gradient_loss | -1.41e-06 |\n",
      "|    reward               | 2673661.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 532       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 68096     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.36e+14  |\n",
      "|    n_updates            | 5310      |\n",
      "|    policy_gradient_loss | -9.17e-07 |\n",
      "|    reward               | 2367204.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 533       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 68224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.97e+14  |\n",
      "|    n_updates            | 5320      |\n",
      "|    policy_gradient_loss | -1.62e-06 |\n",
      "|    reward               | 2689773.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.44e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 534       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 68352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.22e+14  |\n",
      "|    n_updates            | 5330      |\n",
      "|    policy_gradient_loss | -1.71e-06 |\n",
      "|    reward               | 2686730.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3048059.121898484\n",
      "Sharpe:  0.8681418356912414\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 535       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 68480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.08e+14  |\n",
      "|    n_updates            | 5340      |\n",
      "|    policy_gradient_loss | -1.27e-06 |\n",
      "|    reward               | 1060269.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.75e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 536       |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 68608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.4e+14   |\n",
      "|    n_updates            | 5350      |\n",
      "|    policy_gradient_loss | -3.22e-06 |\n",
      "|    reward               | 1079298.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 537       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 68736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 5360      |\n",
      "|    policy_gradient_loss | -3.38e-06 |\n",
      "|    reward               | 1244869.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 538       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 68864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.6e+14   |\n",
      "|    n_updates            | 5370      |\n",
      "|    policy_gradient_loss | -3.49e-06 |\n",
      "|    reward               | 1413124.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.21e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 539       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 68992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.1e+14   |\n",
      "|    n_updates            | 5380      |\n",
      "|    policy_gradient_loss | -4.2e-06  |\n",
      "|    reward               | 1496079.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 540       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 69120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.59e+14  |\n",
      "|    n_updates            | 5390      |\n",
      "|    policy_gradient_loss | -2.98e-06 |\n",
      "|    reward               | 1602724.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.2e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 541       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 69248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.9e+14   |\n",
      "|    n_updates            | 5400      |\n",
      "|    policy_gradient_loss | -2.92e-06 |\n",
      "|    reward               | 1699199.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.84e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 542       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 69376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.12e+14  |\n",
      "|    n_updates            | 5410      |\n",
      "|    policy_gradient_loss | -2.61e-06 |\n",
      "|    reward               | 1840400.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.34e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 543       |\n",
      "|    time_elapsed         | 80        |\n",
      "|    total_timesteps      | 69504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.57e+14  |\n",
      "|    n_updates            | 5420      |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 1715345.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.2e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 544       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.43e+14  |\n",
      "|    n_updates            | 5430      |\n",
      "|    policy_gradient_loss | -2.62e-06 |\n",
      "|    reward               | 2097500.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.5e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 545       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 69760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.49e+14  |\n",
      "|    n_updates            | 5440      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 2441303.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 546       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 69888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.84e+14  |\n",
      "|    n_updates            | 5450      |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 2613685.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.2e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 547       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 70016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.32e+14  |\n",
      "|    n_updates            | 5460      |\n",
      "|    policy_gradient_loss | -2.13e-06 |\n",
      "|    reward               | 2353927.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 548       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 70144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.09e+14  |\n",
      "|    n_updates            | 5470      |\n",
      "|    policy_gradient_loss | -1.8e-06  |\n",
      "|    reward               | 2551100.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 549       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 70272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.37e+14  |\n",
      "|    n_updates            | 5480      |\n",
      "|    policy_gradient_loss | -2.58e-06 |\n",
      "|    reward               | 2482230.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.26e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 550       |\n",
      "|    time_elapsed         | 81        |\n",
      "|    total_timesteps      | 70400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.38e+14  |\n",
      "|    n_updates            | 5490      |\n",
      "|    policy_gradient_loss | -1.16e-06 |\n",
      "|    reward               | 2707419.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.47e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2844802.0791415754\n",
      "Sharpe:  0.8167934549984688\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 551       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 70528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.63e+14  |\n",
      "|    n_updates            | 5500      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 1061852.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.53e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 552       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 70656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.29e+14  |\n",
      "|    n_updates            | 5510      |\n",
      "|    policy_gradient_loss | -3.11e-06 |\n",
      "|    reward               | 1147642.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.71e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 553       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 70784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.4e+14   |\n",
      "|    n_updates            | 5520      |\n",
      "|    policy_gradient_loss | -3.98e-06 |\n",
      "|    reward               | 1259654.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 554       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 70912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.71e+14  |\n",
      "|    n_updates            | 5530      |\n",
      "|    policy_gradient_loss | -5.17e-06 |\n",
      "|    reward               | 1454464.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.37e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 555       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 71040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.05e+14  |\n",
      "|    n_updates            | 5540      |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 1496806.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.12e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 556       |\n",
      "|    time_elapsed         | 82        |\n",
      "|    total_timesteps      | 71168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.42e+14  |\n",
      "|    n_updates            | 5550      |\n",
      "|    policy_gradient_loss | -3.58e-06 |\n",
      "|    reward               | 1443410.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 557       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.74e+14  |\n",
      "|    n_updates            | 5560      |\n",
      "|    policy_gradient_loss | -2.88e-06 |\n",
      "|    reward               | 1738987.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.74e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 558       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.16e+14  |\n",
      "|    n_updates            | 5570      |\n",
      "|    policy_gradient_loss | -3.27e-06 |\n",
      "|    reward               | 1932077.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 559       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.87e+14  |\n",
      "|    n_updates            | 5580      |\n",
      "|    policy_gradient_loss | -2.6e-06  |\n",
      "|    reward               | 1875918.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 560       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.4e+14   |\n",
      "|    n_updates            | 5590      |\n",
      "|    policy_gradient_loss | -2.6e-06  |\n",
      "|    reward               | 2303062.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.25e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 561       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.06e+14  |\n",
      "|    n_updates            | 5600      |\n",
      "|    policy_gradient_loss | -1.36e-06 |\n",
      "|    reward               | 2713274.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 562       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 71936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.51e+14  |\n",
      "|    n_updates            | 5610      |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 2876193.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.5e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 563       |\n",
      "|    time_elapsed         | 83        |\n",
      "|    total_timesteps      | 72064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.68e+14  |\n",
      "|    n_updates            | 5620      |\n",
      "|    policy_gradient_loss | -1.45e-06 |\n",
      "|    reward               | 2546935.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.74e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 564       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.48e+14  |\n",
      "|    n_updates            | 5630      |\n",
      "|    policy_gradient_loss | -1.57e-06 |\n",
      "|    reward               | 2741217.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.66e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 565       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.39e+14  |\n",
      "|    n_updates            | 5640      |\n",
      "|    policy_gradient_loss | -2.12e-06 |\n",
      "|    reward               | 2922374.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.56e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3127408.1668220134\n",
      "Sharpe:  0.8772435974637901\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 566       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.89e+14  |\n",
      "|    n_updates            | 5650      |\n",
      "|    policy_gradient_loss | -6.45e-07 |\n",
      "|    reward               | 927509.44 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.77e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 567       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.52e+14  |\n",
      "|    n_updates            | 5660      |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 1076240.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 568       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.21e+14  |\n",
      "|    n_updates            | 5670      |\n",
      "|    policy_gradient_loss | -5.06e-06 |\n",
      "|    reward               | 1155347.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.41e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 569       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 5680      |\n",
      "|    policy_gradient_loss | -3.96e-06 |\n",
      "|    reward               | 1281830.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.78e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 570       |\n",
      "|    time_elapsed         | 84        |\n",
      "|    total_timesteps      | 72960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.73e+14  |\n",
      "|    n_updates            | 5690      |\n",
      "|    policy_gradient_loss | -5.97e-06 |\n",
      "|    reward               | 1447374.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.42e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 571       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.18e+14  |\n",
      "|    n_updates            | 5700      |\n",
      "|    policy_gradient_loss | -2.38e-06 |\n",
      "|    reward               | 1544662.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 572       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.43e+14  |\n",
      "|    n_updates            | 5710      |\n",
      "|    policy_gradient_loss | -3.58e-06 |\n",
      "|    reward               | 1633978.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 573       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.75e+14  |\n",
      "|    n_updates            | 5720      |\n",
      "|    policy_gradient_loss | -3.5e-06  |\n",
      "|    reward               | 1764671.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 574       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.21e+14  |\n",
      "|    n_updates            | 5730      |\n",
      "|    policy_gradient_loss | -3.28e-06 |\n",
      "|    reward               | 2017688.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.78e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 575       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4e+14     |\n",
      "|    n_updates            | 5740      |\n",
      "|    policy_gradient_loss | -2.24e-06 |\n",
      "|    reward               | 2010027.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.38e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 576       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.71e+14  |\n",
      "|    n_updates            | 5750      |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 2334089.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 577       |\n",
      "|    time_elapsed         | 85        |\n",
      "|    total_timesteps      | 73856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.41e+14  |\n",
      "|    n_updates            | 5760      |\n",
      "|    policy_gradient_loss | -2.83e-06 |\n",
      "|    reward               | 2640716.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.08e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 578       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 73984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.04e+14  |\n",
      "|    n_updates            | 5770      |\n",
      "|    policy_gradient_loss | -1.66e-06 |\n",
      "|    reward               | 2607496.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 579       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.97e+14  |\n",
      "|    n_updates            | 5780      |\n",
      "|    policy_gradient_loss | -1.36e-06 |\n",
      "|    reward               | 2362767.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.61e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 580       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.05e+14  |\n",
      "|    n_updates            | 5790      |\n",
      "|    policy_gradient_loss | -2.64e-06 |\n",
      "|    reward               | 2454604.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 581       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.17e+14  |\n",
      "|    n_updates            | 5800      |\n",
      "|    policy_gradient_loss | -1.93e-06 |\n",
      "|    reward               | 2652026.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2888895.082879384\n",
      "Sharpe:  0.8289487697031963\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 582       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.78e+14  |\n",
      "|    n_updates            | 5810      |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 1045404.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.58e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 583       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.08e+14  |\n",
      "|    n_updates            | 5820      |\n",
      "|    policy_gradient_loss | -2.77e-06 |\n",
      "|    reward               | 1093233.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 584       |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 74752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 5830      |\n",
      "|    policy_gradient_loss | -4.5e-06  |\n",
      "|    reward               | 1238507.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.65e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 585       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 74880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.57e+14  |\n",
      "|    n_updates            | 5840      |\n",
      "|    policy_gradient_loss | -4.3e-06  |\n",
      "|    reward               | 1355289.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.13e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 586       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 75008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.88e+14  |\n",
      "|    n_updates            | 5850      |\n",
      "|    policy_gradient_loss | -3e-06    |\n",
      "|    reward               | 1436451.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.84e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 587       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 75136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.5e+14   |\n",
      "|    n_updates            | 5860      |\n",
      "|    policy_gradient_loss | -2.75e-06 |\n",
      "|    reward               | 1674383.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 588       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 75264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.86e+14  |\n",
      "|    n_updates            | 5870      |\n",
      "|    policy_gradient_loss | -2.52e-06 |\n",
      "|    reward               | 1717708.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.56e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 589       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 75392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.92e+14  |\n",
      "|    n_updates            | 5880      |\n",
      "|    policy_gradient_loss | -2.58e-06 |\n",
      "|    reward               | 1757633.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.03e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 590       |\n",
      "|    time_elapsed         | 87        |\n",
      "|    total_timesteps      | 75520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.58e+14  |\n",
      "|    n_updates            | 5890      |\n",
      "|    policy_gradient_loss | -2.6e-06  |\n",
      "|    reward               | 1718191.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 591       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 75648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4e+14     |\n",
      "|    n_updates            | 5900      |\n",
      "|    policy_gradient_loss | -1.51e-06 |\n",
      "|    reward               | 1999134.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 592       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.89e+14  |\n",
      "|    n_updates            | 5910      |\n",
      "|    policy_gradient_loss | -3.93e-06 |\n",
      "|    reward               | 2413544.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.09e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 593       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 75904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.4e+14   |\n",
      "|    n_updates            | 5920      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 2546746.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.12e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 594       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 76032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.11e+14  |\n",
      "|    n_updates            | 5930      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 2517366.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 595       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 76160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.56e+14  |\n",
      "|    n_updates            | 5940      |\n",
      "|    policy_gradient_loss | -2.11e-06 |\n",
      "|    reward               | 2308849.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.48e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 596       |\n",
      "|    time_elapsed         | 88        |\n",
      "|    total_timesteps      | 76288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.2e+14   |\n",
      "|    n_updates            | 5950      |\n",
      "|    policy_gradient_loss | -2.09e-06 |\n",
      "|    reward               | 2551266.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.25e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 597       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 76416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.96e+14  |\n",
      "|    n_updates            | 5960      |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 2584939.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.41e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2916171.654790629\n",
      "Sharpe:  0.8354499832559718\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 598       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 76544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.5e+14   |\n",
      "|    n_updates            | 5970      |\n",
      "|    policy_gradient_loss | -1.73e-06 |\n",
      "|    reward               | 1053076.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.53e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 599       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 76672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2e+14     |\n",
      "|    n_updates            | 5980      |\n",
      "|    policy_gradient_loss | -3.81e-06 |\n",
      "|    reward               | 1106876.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.63e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 600       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 76800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.34e+14  |\n",
      "|    n_updates            | 5990      |\n",
      "|    policy_gradient_loss | -3.42e-06 |\n",
      "|    reward               | 1244813.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 601       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 76928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.7e+14   |\n",
      "|    n_updates            | 6000      |\n",
      "|    policy_gradient_loss | -3.51e-06 |\n",
      "|    reward               | 1392172.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 602       |\n",
      "|    time_elapsed         | 89        |\n",
      "|    total_timesteps      | 77056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 6010      |\n",
      "|    policy_gradient_loss | -3.99e-06 |\n",
      "|    reward               | 1508559.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 603       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.52e+14  |\n",
      "|    n_updates            | 6020      |\n",
      "|    policy_gradient_loss | -1.61e-06 |\n",
      "|    reward               | 1553421.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.09e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 604       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 6030      |\n",
      "|    policy_gradient_loss | -2.12e-06 |\n",
      "|    reward               | 1645674.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 605       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.08e+14  |\n",
      "|    n_updates            | 6040      |\n",
      "|    policy_gradient_loss | -3.09e-06 |\n",
      "|    reward               | 1879431.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 606       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.61e+14  |\n",
      "|    n_updates            | 6050      |\n",
      "|    policy_gradient_loss | -2.92e-06 |\n",
      "|    reward               | 1846692.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.11e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 607       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.61e+14  |\n",
      "|    n_updates            | 6060      |\n",
      "|    policy_gradient_loss | -2.63e-06 |\n",
      "|    reward               | 2119910.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.24e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 608       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.04e+14  |\n",
      "|    n_updates            | 6070      |\n",
      "|    policy_gradient_loss | -2.71e-06 |\n",
      "|    reward               | 2438884.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 609       |\n",
      "|    time_elapsed         | 90        |\n",
      "|    total_timesteps      | 77952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.38e+14  |\n",
      "|    n_updates            | 6080      |\n",
      "|    policy_gradient_loss | -2.25e-06 |\n",
      "|    reward               | 2566951.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 610       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.31e+14  |\n",
      "|    n_updates            | 6090      |\n",
      "|    policy_gradient_loss | -1.62e-06 |\n",
      "|    reward               | 2276086.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.42e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 611       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.57e+14  |\n",
      "|    n_updates            | 6100      |\n",
      "|    policy_gradient_loss | -2.28e-06 |\n",
      "|    reward               | 2447127.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 612       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.38e+14  |\n",
      "|    n_updates            | 6110      |\n",
      "|    policy_gradient_loss | -1.6e-06  |\n",
      "|    reward               | 2591642.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.27e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 613       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.43e+14  |\n",
      "|    n_updates            | 6120      |\n",
      "|    policy_gradient_loss | -8.48e-07 |\n",
      "|    reward               | 2931508.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2937978.288448705\n",
      "Sharpe:  0.8428449704965824\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 614       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.17e+14  |\n",
      "|    n_updates            | 6130      |\n",
      "|    policy_gradient_loss | -1.19e-06 |\n",
      "|    reward               | 1059534.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.62e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 615       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.14e+14  |\n",
      "|    n_updates            | 6140      |\n",
      "|    policy_gradient_loss | -3.95e-06 |\n",
      "|    reward               | 1166356.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.3e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 616       |\n",
      "|    time_elapsed         | 91        |\n",
      "|    total_timesteps      | 78848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.37e+14  |\n",
      "|    n_updates            | 6150      |\n",
      "|    policy_gradient_loss | -4.3e-06  |\n",
      "|    reward               | 1278723.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.79e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 617       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 78976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.82e+14  |\n",
      "|    n_updates            | 6160      |\n",
      "|    policy_gradient_loss | -4e-06    |\n",
      "|    reward               | 1543195.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.53e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 618       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.19e+14  |\n",
      "|    n_updates            | 6170      |\n",
      "|    policy_gradient_loss | -1.73e-06 |\n",
      "|    reward               | 1576891.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.47e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 619       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.71e+14  |\n",
      "|    n_updates            | 6180      |\n",
      "|    policy_gradient_loss | -3.7e-06  |\n",
      "|    reward               | 1602607.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.39e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 620       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.1e+14   |\n",
      "|    n_updates            | 6190      |\n",
      "|    policy_gradient_loss | -2.72e-06 |\n",
      "|    reward               | 1819532.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 621       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.45e+14  |\n",
      "|    n_updates            | 6200      |\n",
      "|    policy_gradient_loss | -3.27e-06 |\n",
      "|    reward               | 2010196.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.93e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 622       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.02e+14  |\n",
      "|    n_updates            | 6210      |\n",
      "|    policy_gradient_loss | -1.82e-06 |\n",
      "|    reward               | 1879860.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 623       |\n",
      "|    time_elapsed         | 92        |\n",
      "|    total_timesteps      | 79744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.41e+14  |\n",
      "|    n_updates            | 6220      |\n",
      "|    policy_gradient_loss | -3.23e-06 |\n",
      "|    reward               | 2218841.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.1e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 624       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.88e+14  |\n",
      "|    n_updates            | 6230      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 2560172.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 625       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 80000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.89e+14  |\n",
      "|    n_updates            | 6240      |\n",
      "|    policy_gradient_loss | -2.37e-06 |\n",
      "|    reward               | 2684992.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.39e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 626       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 80128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.57e+14  |\n",
      "|    n_updates            | 6250      |\n",
      "|    policy_gradient_loss | -1.2e-06  |\n",
      "|    reward               | 2492607.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.55e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 627       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 80256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.33e+14  |\n",
      "|    n_updates            | 6260      |\n",
      "|    policy_gradient_loss | -1.68e-06 |\n",
      "|    reward               | 2596926.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 628       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 80384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.14e+14  |\n",
      "|    n_updates            | 6270      |\n",
      "|    policy_gradient_loss | -2e-06    |\n",
      "|    reward               | 2699152.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.41e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2984080.58244214\n",
      "Sharpe:  0.848731616217365\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 629       |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 80512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.79e+14  |\n",
      "|    n_updates            | 6280      |\n",
      "|    policy_gradient_loss | -1.71e-06 |\n",
      "|    reward               | 953251.44 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.59e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 630       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 80640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.54e+14  |\n",
      "|    n_updates            | 6290      |\n",
      "|    policy_gradient_loss | -2.94e-06 |\n",
      "|    reward               | 1100802.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.2e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 631       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 80768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.34e+14  |\n",
      "|    n_updates            | 6300      |\n",
      "|    policy_gradient_loss | -3.94e-06 |\n",
      "|    reward               | 1235044.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 632       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 80896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.43e+14  |\n",
      "|    n_updates            | 6310      |\n",
      "|    policy_gradient_loss | -3.78e-06 |\n",
      "|    reward               | 1322545.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.94e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 633       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 81024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.89e+14  |\n",
      "|    n_updates            | 6320      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 1489480.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.69e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 634       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 81152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.6e+14   |\n",
      "|    n_updates            | 6330      |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 1619908.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.85e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 635       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 81280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.74e+14  |\n",
      "|    n_updates            | 6340      |\n",
      "|    policy_gradient_loss | -1.92e-06 |\n",
      "|    reward               | 1639715.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.35e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 636       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 81408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.93e+14  |\n",
      "|    n_updates            | 6350      |\n",
      "|    policy_gradient_loss | -3.83e-06 |\n",
      "|    reward               | 1765919.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 637       |\n",
      "|    time_elapsed         | 94        |\n",
      "|    total_timesteps      | 81536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.18e+14  |\n",
      "|    n_updates            | 6360      |\n",
      "|    policy_gradient_loss | -2.82e-06 |\n",
      "|    reward               | 1343758.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 638       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 81664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.91e+14  |\n",
      "|    n_updates            | 6370      |\n",
      "|    policy_gradient_loss | -1.74e-06 |\n",
      "|    reward               | 1814296.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 639       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 81792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.22e+14  |\n",
      "|    n_updates            | 6380      |\n",
      "|    policy_gradient_loss | -2.82e-06 |\n",
      "|    reward               | 2212165.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 640       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.54e+14  |\n",
      "|    n_updates            | 6390      |\n",
      "|    policy_gradient_loss | -1.61e-06 |\n",
      "|    reward               | 2343416.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.14e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 641       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 82048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.94e+14  |\n",
      "|    n_updates            | 6400      |\n",
      "|    policy_gradient_loss | -2.26e-06 |\n",
      "|    reward               | 2430700.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.25e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 642       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 82176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.75e+14  |\n",
      "|    n_updates            | 6410      |\n",
      "|    policy_gradient_loss | -1.77e-06 |\n",
      "|    reward               | 2072395.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.33e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 643       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 82304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.54e+14  |\n",
      "|    n_updates            | 6420      |\n",
      "|    policy_gradient_loss | -1.48e-06 |\n",
      "|    reward               | 2424213.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.18e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 644       |\n",
      "|    time_elapsed         | 95        |\n",
      "|    total_timesteps      | 82432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.99e+14  |\n",
      "|    n_updates            | 6430      |\n",
      "|    policy_gradient_loss | -1.85e-06 |\n",
      "|    reward               | 2340054.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.25e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2693126.978213206\n",
      "Sharpe:  0.7764971776594812\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 645       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 82560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.17e+14  |\n",
      "|    n_updates            | 6440      |\n",
      "|    policy_gradient_loss | -1.41e-06 |\n",
      "|    reward               | 1049561.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.36e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 646       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 82688     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.63e+14  |\n",
      "|    n_updates            | 6450      |\n",
      "|    policy_gradient_loss | -3.13e-06 |\n",
      "|    reward               | 1094234.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.08e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 647       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 82816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 6460      |\n",
      "|    policy_gradient_loss | -3.19e-06 |\n",
      "|    reward               | 1238855.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.7e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 648       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 82944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.62e+14  |\n",
      "|    n_updates            | 6470      |\n",
      "|    policy_gradient_loss | -3.02e-06 |\n",
      "|    reward               | 1395340.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 649       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 83072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2e+14     |\n",
      "|    n_updates            | 6480      |\n",
      "|    policy_gradient_loss | -3.11e-06 |\n",
      "|    reward               | 1487582.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 650       |\n",
      "|    time_elapsed         | 96        |\n",
      "|    total_timesteps      | 83200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.71e+14  |\n",
      "|    n_updates            | 6490      |\n",
      "|    policy_gradient_loss | -3.01e-06 |\n",
      "|    reward               | 1555770.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.15e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 858       |\n",
      "|    iterations           | 651       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.84e+14  |\n",
      "|    n_updates            | 6500      |\n",
      "|    policy_gradient_loss | -1.43e-06 |\n",
      "|    reward               | 1742372.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.72e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 652       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.95e+14  |\n",
      "|    n_updates            | 6510      |\n",
      "|    policy_gradient_loss | -3.37e-06 |\n",
      "|    reward               | 1871635.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.19e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 653       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.73e+14  |\n",
      "|    n_updates            | 6520      |\n",
      "|    policy_gradient_loss | -2.28e-06 |\n",
      "|    reward               | 1729848.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.44e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 654       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.17e+14  |\n",
      "|    n_updates            | 6530      |\n",
      "|    policy_gradient_loss | -1.67e-06 |\n",
      "|    reward               | 2068460.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8e+14     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 655       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.47e+14  |\n",
      "|    n_updates            | 6540      |\n",
      "|    policy_gradient_loss | -2.14e-06 |\n",
      "|    reward               | 2520205.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.04e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 656       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 83968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.85e+14  |\n",
      "|    n_updates            | 6550      |\n",
      "|    policy_gradient_loss | -1.39e-06 |\n",
      "|    reward               | 2683631.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.29e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 657       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 84096     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.36e+14  |\n",
      "|    n_updates            | 6560      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 2542774.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.59e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 658       |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 84224     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.36e+14  |\n",
      "|    n_updates            | 6570      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 2533263.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.6e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 659       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 84352     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.99e+14  |\n",
      "|    n_updates            | 6580      |\n",
      "|    policy_gradient_loss | -2.65e-06 |\n",
      "|    reward               | 2520313.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 859       |\n",
      "|    iterations           | 660       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 84480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.29e+14  |\n",
      "|    n_updates            | 6590      |\n",
      "|    policy_gradient_loss | -1.35e-06 |\n",
      "|    reward               | 2698001.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2865555.4114028052\n",
      "Sharpe:  0.8225322390211994\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 661       |\n",
      "|    time_elapsed         | 98        |\n",
      "|    total_timesteps      | 84608     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.83e+14  |\n",
      "|    n_updates            | 6600      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 1076340.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.57e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 662       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 84736     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 6610      |\n",
      "|    policy_gradient_loss | -4.46e-06 |\n",
      "|    reward               | 1136508.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.06e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 663       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 84864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 6620      |\n",
      "|    policy_gradient_loss | -5.84e-06 |\n",
      "|    reward               | 1276254.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.83e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 664       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 84992     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.76e+14  |\n",
      "|    n_updates            | 6630      |\n",
      "|    policy_gradient_loss | -3.54e-06 |\n",
      "|    reward               | 1463553.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.51e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 665       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 85120     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.02e+14  |\n",
      "|    n_updates            | 6640      |\n",
      "|    policy_gradient_loss | -4.54e-06 |\n",
      "|    reward               | 1548962.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 666       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 85248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.55e+14  |\n",
      "|    n_updates            | 6650      |\n",
      "|    policy_gradient_loss | -1.49e-06 |\n",
      "|    reward               | 1558848.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.19e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 667       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 85376     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.16e+14  |\n",
      "|    n_updates            | 6660      |\n",
      "|    policy_gradient_loss | -3.56e-06 |\n",
      "|    reward               | 1822459.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.01e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 668       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 85504     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.45e+14  |\n",
      "|    n_updates            | 6670      |\n",
      "|    policy_gradient_loss | -3.79e-06 |\n",
      "|    reward               | 2020061.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.77e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 669       |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 85632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.97e+14  |\n",
      "|    n_updates            | 6680      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 1795221.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.07e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 670       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 85760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.85e+14  |\n",
      "|    n_updates            | 6690      |\n",
      "|    policy_gradient_loss | -3.44e-06 |\n",
      "|    reward               | 2251901.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 671       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 85888     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.87e+14  |\n",
      "|    n_updates            | 6700      |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 2645657.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 672       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 86016     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.92e+14  |\n",
      "|    n_updates            | 6710      |\n",
      "|    policy_gradient_loss | -1.7e-06  |\n",
      "|    reward               | 2768509.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 673       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 86144     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.88e+14  |\n",
      "|    n_updates            | 6720      |\n",
      "|    policy_gradient_loss | -1.58e-06 |\n",
      "|    reward               | 2376556.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.61e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 674       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 86272     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.7e+14   |\n",
      "|    n_updates            | 6730      |\n",
      "|    policy_gradient_loss | -1.34e-06 |\n",
      "|    reward               | 2638253.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.51e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 675       |\n",
      "|    time_elapsed         | 100       |\n",
      "|    total_timesteps      | 86400     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.07e+14  |\n",
      "|    n_updates            | 6740      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 2749723.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.38e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2988630.850345112\n",
      "Sharpe:  0.8509885960743567\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 676       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 86528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.42e+14  |\n",
      "|    n_updates            | 6750      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 932025.7  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.59e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 677       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 86656     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.63e+14  |\n",
      "|    n_updates            | 6760      |\n",
      "|    policy_gradient_loss | -1.87e-06 |\n",
      "|    reward               | 1086924.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.54e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 678       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 86784     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.18e+14  |\n",
      "|    n_updates            | 6770      |\n",
      "|    policy_gradient_loss | -3.69e-06 |\n",
      "|    reward               | 1185398.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.4e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 679       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 86912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+14  |\n",
      "|    n_updates            | 6780      |\n",
      "|    policy_gradient_loss | -3.24e-06 |\n",
      "|    reward               | 1315522.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.85e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 680       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 87040     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.81e+14  |\n",
      "|    n_updates            | 6790      |\n",
      "|    policy_gradient_loss | -2.38e-06 |\n",
      "|    reward               | 1558775.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 681       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 87168     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.33e+14  |\n",
      "|    n_updates            | 6800      |\n",
      "|    policy_gradient_loss | -3.06e-06 |\n",
      "|    reward               | 1582116.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 682       |\n",
      "|    time_elapsed         | 101       |\n",
      "|    total_timesteps      | 87296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.61e+14  |\n",
      "|    n_updates            | 6810      |\n",
      "|    policy_gradient_loss | -1.99e-06 |\n",
      "|    reward               | 1626570.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.21e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 683       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 87424     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.88e+14  |\n",
      "|    n_updates            | 6820      |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 1745409.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 684       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 87552     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.58e+14  |\n",
      "|    n_updates            | 6830      |\n",
      "|    policy_gradient_loss | -2.79e-06 |\n",
      "|    reward               | 1974747.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.79e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 685       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 87680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.99e+14  |\n",
      "|    n_updates            | 6840      |\n",
      "|    policy_gradient_loss | -2.36e-06 |\n",
      "|    reward               | 1922256.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.96e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 686       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 87808     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.62e+14  |\n",
      "|    n_updates            | 6850      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 2277002.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.09e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 687       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 87936     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.94e+14  |\n",
      "|    n_updates            | 6860      |\n",
      "|    policy_gradient_loss | -2.47e-06 |\n",
      "|    reward               | 2564713.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.95e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 688       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 88064     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.08e+14  |\n",
      "|    n_updates            | 6870      |\n",
      "|    policy_gradient_loss | -8.67e-07 |\n",
      "|    reward               | 2560063.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 689       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 88192     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.79e+14  |\n",
      "|    n_updates            | 6880      |\n",
      "|    policy_gradient_loss | -2.13e-06 |\n",
      "|    reward               | 2400341.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.53e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 690       |\n",
      "|    time_elapsed         | 102       |\n",
      "|    total_timesteps      | 88320     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.7e+14   |\n",
      "|    n_updates            | 6890      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 2646144.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 691       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 88448     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.07e+14  |\n",
      "|    n_updates            | 6900      |\n",
      "|    policy_gradient_loss | -1.85e-06 |\n",
      "|    reward               | 2759039.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2998317.88426711\n",
      "Sharpe:  0.8526376727134596\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 692       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 88576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.32e+14  |\n",
      "|    n_updates            | 6910      |\n",
      "|    policy_gradient_loss | -1.97e-06 |\n",
      "|    reward               | 1016767.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.7e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 693       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 88704     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.03e+14  |\n",
      "|    n_updates            | 6920      |\n",
      "|    policy_gradient_loss | -2.49e-06 |\n",
      "|    reward               | 1101572.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.01e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 694       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 88832     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 6930      |\n",
      "|    policy_gradient_loss | -3.55e-06 |\n",
      "|    reward               | 1275739.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 695       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 88960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.59e+14  |\n",
      "|    n_updates            | 6940      |\n",
      "|    policy_gradient_loss | -4.45e-06 |\n",
      "|    reward               | 1392776.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 696       |\n",
      "|    time_elapsed         | 103       |\n",
      "|    total_timesteps      | 89088     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.98e+14  |\n",
      "|    n_updates            | 6950      |\n",
      "|    policy_gradient_loss | -2.73e-06 |\n",
      "|    reward               | 1504269.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 697       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89216     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.55e+14  |\n",
      "|    n_updates            | 6960      |\n",
      "|    policy_gradient_loss | -2.78e-06 |\n",
      "|    reward               | 1663560.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.18e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 698       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.85e+14  |\n",
      "|    n_updates            | 6970      |\n",
      "|    policy_gradient_loss | -4.22e-06 |\n",
      "|    reward               | 1690718.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 699       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89472     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.06e+14  |\n",
      "|    n_updates            | 6980      |\n",
      "|    policy_gradient_loss | -1.78e-06 |\n",
      "|    reward               | 1750027.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.92e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 700       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89600     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.31e+14  |\n",
      "|    n_updates            | 6990      |\n",
      "|    policy_gradient_loss | -2.72e-06 |\n",
      "|    reward               | 1654577.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.02e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 701       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.83e+14  |\n",
      "|    n_updates            | 7000      |\n",
      "|    policy_gradient_loss | -2.22e-06 |\n",
      "|    reward               | 2040119.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.85e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 702       |\n",
      "|    time_elapsed         | 104       |\n",
      "|    total_timesteps      | 89856     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.2e+14   |\n",
      "|    n_updates            | 7010      |\n",
      "|    policy_gradient_loss | -1.93e-06 |\n",
      "|    reward               | 2457027.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.38e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 703       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 89984     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.97e+14  |\n",
      "|    n_updates            | 7020      |\n",
      "|    policy_gradient_loss | -2.48e-06 |\n",
      "|    reward               | 2519549.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.14e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 704       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 90112     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.32e+14  |\n",
      "|    n_updates            | 7030      |\n",
      "|    policy_gradient_loss | -2.08e-06 |\n",
      "|    reward               | 2516928.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.44e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 705       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 90240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.8e+14   |\n",
      "|    n_updates            | 7040      |\n",
      "|    policy_gradient_loss | -1.94e-06 |\n",
      "|    reward               | 2195682.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 706       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 90368     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.09e+14  |\n",
      "|    n_updates            | 7050      |\n",
      "|    policy_gradient_loss | -2.45e-06 |\n",
      "|    reward               | 2506041.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.21e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 707       |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 90496     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.03e+14  |\n",
      "|    n_updates            | 7060      |\n",
      "|    policy_gradient_loss | -1.53e-06 |\n",
      "|    reward               | 2443887.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.4e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2848911.5488143307\n",
      "Sharpe:  0.817524142563569\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 855        |\n",
      "|    iterations           | 708        |\n",
      "|    time_elapsed         | 105        |\n",
      "|    total_timesteps      | 90624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.77e+14   |\n",
      "|    n_updates            | 7070       |\n",
      "|    policy_gradient_loss | -1.63e-06  |\n",
      "|    reward               | 1035953.94 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.54e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 709       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 90752     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.52e+14  |\n",
      "|    n_updates            | 7080      |\n",
      "|    policy_gradient_loss | -3.17e-06 |\n",
      "|    reward               | 1058203.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.94e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 710       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 90880     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 7090      |\n",
      "|    policy_gradient_loss | -3.79e-06 |\n",
      "|    reward               | 1245424.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.69e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 711       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 91008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.65e+14  |\n",
      "|    n_updates            | 7100      |\n",
      "|    policy_gradient_loss | -4.05e-06 |\n",
      "|    reward               | 1400443.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.26e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 712       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 91136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.01e+14  |\n",
      "|    n_updates            | 7110      |\n",
      "|    policy_gradient_loss | -3.77e-06 |\n",
      "|    reward               | 1497825.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.98e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 713       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 91264     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.53e+14  |\n",
      "|    n_updates            | 7120      |\n",
      "|    policy_gradient_loss | -2.99e-06 |\n",
      "|    reward               | 1600207.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.13e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 714       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 91392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.78e+14  |\n",
      "|    n_updates            | 7130      |\n",
      "|    policy_gradient_loss | -2.94e-06 |\n",
      "|    reward               | 1675548.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 715       |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 91520     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.2e+14   |\n",
      "|    n_updates            | 7140      |\n",
      "|    policy_gradient_loss | -3.88e-06 |\n",
      "|    reward               | 1867254.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.1e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 716       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 91648     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.55e+14  |\n",
      "|    n_updates            | 7150      |\n",
      "|    policy_gradient_loss | -1.77e-06 |\n",
      "|    reward               | 1768750.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.27e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 717       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 91776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.24e+14  |\n",
      "|    n_updates            | 7160      |\n",
      "|    policy_gradient_loss | -2.18e-06 |\n",
      "|    reward               | 2119783.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.26e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 718       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 91904     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.28e+14  |\n",
      "|    n_updates            | 7170      |\n",
      "|    policy_gradient_loss | -2.63e-06 |\n",
      "|    reward               | 2476718.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.54e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 719       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 92032     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.8e+14   |\n",
      "|    n_updates            | 7180      |\n",
      "|    policy_gradient_loss | -2.3e-06  |\n",
      "|    reward               | 2541516.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.22e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 720       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 92160     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.18e+14  |\n",
      "|    n_updates            | 7190      |\n",
      "|    policy_gradient_loss | -1.08e-06 |\n",
      "|    reward               | 2434136.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 721       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 92288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.44e+14  |\n",
      "|    n_updates            | 7200      |\n",
      "|    policy_gradient_loss | -1.5e-06  |\n",
      "|    reward               | 2538729.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.5e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 722       |\n",
      "|    time_elapsed         | 107       |\n",
      "|    total_timesteps      | 92416     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7e+14     |\n",
      "|    n_updates            | 7210      |\n",
      "|    policy_gradient_loss | -1.96e-06 |\n",
      "|    reward               | 2649253.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 723       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 92544     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.39e+14  |\n",
      "|    n_updates            | 7220      |\n",
      "|    policy_gradient_loss | -1.6e-06  |\n",
      "|    reward               | 2881472.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.49e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2905382.7772479686\n",
      "Sharpe:  0.8294157442182528\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 724       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 92672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.67e+14  |\n",
      "|    n_updates            | 7230      |\n",
      "|    policy_gradient_loss | -2.06e-06 |\n",
      "|    reward               | 1024187.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.57e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 725       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 92800     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.16e+14  |\n",
      "|    n_updates            | 7240      |\n",
      "|    policy_gradient_loss | -4.7e-06  |\n",
      "|    reward               | 1172468.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.29e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 726       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 92928     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.33e+14  |\n",
      "|    n_updates            | 7250      |\n",
      "|    policy_gradient_loss | -5.22e-06 |\n",
      "|    reward               | 1281760.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.8e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 727       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 93056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.7e+14   |\n",
      "|    n_updates            | 7260      |\n",
      "|    policy_gradient_loss | -2.51e-06 |\n",
      "|    reward               | 1479472.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.56e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 728       |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 93184     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.2e+14   |\n",
      "|    n_updates            | 7270      |\n",
      "|    policy_gradient_loss | -2.68e-06 |\n",
      "|    reward               | 1538276.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.33e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 855       |\n",
      "|    iterations           | 729       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93312     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.62e+14  |\n",
      "|    n_updates            | 7280      |\n",
      "|    policy_gradient_loss | -2.75e-06 |\n",
      "|    reward               | 1563102.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 730       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.84e+14  |\n",
      "|    n_updates            | 7290      |\n",
      "|    policy_gradient_loss | -3.25e-06 |\n",
      "|    reward               | 1801352.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.85e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 731       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93568     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.25e+14  |\n",
      "|    n_updates            | 7300      |\n",
      "|    policy_gradient_loss | -2.94e-06 |\n",
      "|    reward               | 1993670.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.57e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 732       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93696     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.07e+14  |\n",
      "|    n_updates            | 7310      |\n",
      "|    policy_gradient_loss | -3.35e-06 |\n",
      "|    reward               | 1914274.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.67e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 733       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.69e+14  |\n",
      "|    n_updates            | 7320      |\n",
      "|    policy_gradient_loss | -3.05e-06 |\n",
      "|    reward               | 2233132.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.16e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 734       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 93952     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.68e+14  |\n",
      "|    n_updates            | 7330      |\n",
      "|    policy_gradient_loss | -2.27e-06 |\n",
      "|    reward               | 2560145.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.6e+14   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 735       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 94080     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.83e+14  |\n",
      "|    n_updates            | 7340      |\n",
      "|    policy_gradient_loss | -2.5e-06  |\n",
      "|    reward               | 2577259.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.37e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 736       |\n",
      "|    time_elapsed         | 109       |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8e+14     |\n",
      "|    n_updates            | 7350      |\n",
      "|    policy_gradient_loss | -1.07e-06 |\n",
      "|    reward               | 2469404.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.54e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 737       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.21e+14  |\n",
      "|    n_updates            | 7360      |\n",
      "|    policy_gradient_loss | -2.07e-06 |\n",
      "|    reward               | 2604056.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 738       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94464     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.94e+14  |\n",
      "|    n_updates            | 7370      |\n",
      "|    policy_gradient_loss | -2.23e-06 |\n",
      "|    reward               | 2735707.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.38e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2948786.869404159\n",
      "Sharpe:  0.8445677503789945\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 739       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94592     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.86e+14  |\n",
      "|    n_updates            | 7380      |\n",
      "|    policy_gradient_loss | -1.55e-06 |\n",
      "|    reward               | 943158.6  |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.56e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 740       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.89e+14  |\n",
      "|    n_updates            | 7390      |\n",
      "|    policy_gradient_loss | -1.95e-06 |\n",
      "|    reward               | 1100588.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.23e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 741       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.25e+14  |\n",
      "|    n_updates            | 7400      |\n",
      "|    policy_gradient_loss | -3.99e-06 |\n",
      "|    reward               | 1224683.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.55e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 742       |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 94976     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.48e+14  |\n",
      "|    n_updates            | 7410      |\n",
      "|    policy_gradient_loss | -3.2e-06  |\n",
      "|    reward               | 1325746.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 743       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.83e+14  |\n",
      "|    n_updates            | 7420      |\n",
      "|    policy_gradient_loss | -4.24e-06 |\n",
      "|    reward               | 1556739.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.65e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 744       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95232     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.27e+14  |\n",
      "|    n_updates            | 7430      |\n",
      "|    policy_gradient_loss | -3.72e-06 |\n",
      "|    reward               | 1622977.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 4.81e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 745       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95360     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.63e+14  |\n",
      "|    n_updates            | 7440      |\n",
      "|    policy_gradient_loss | -4.25e-06 |\n",
      "|    reward               | 1614264.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.32e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 746       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.86e+14  |\n",
      "|    n_updates            | 7450      |\n",
      "|    policy_gradient_loss | -3.67e-06 |\n",
      "|    reward               | 1745378.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.71e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 747       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95616     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.37e+14  |\n",
      "|    n_updates            | 7460      |\n",
      "|    policy_gradient_loss | -2.53e-06 |\n",
      "|    reward               | 1679665.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.48e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 748       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95744     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.72e+14  |\n",
      "|    n_updates            | 7470      |\n",
      "|    policy_gradient_loss | -2.1e-06  |\n",
      "|    reward               | 1907336.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.73e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 749       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 95872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.57e+14  |\n",
      "|    n_updates            | 7480      |\n",
      "|    policy_gradient_loss | -2.68e-06 |\n",
      "|    reward               | 2274942.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.11e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 750       |\n",
      "|    time_elapsed         | 111       |\n",
      "|    total_timesteps      | 96000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.04e+14  |\n",
      "|    n_updates            | 7490      |\n",
      "|    policy_gradient_loss | -2.89e-06 |\n",
      "|    reward               | 2444945.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.85e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 751       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96128     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.7e+14   |\n",
      "|    n_updates            | 7500      |\n",
      "|    policy_gradient_loss | -1.37e-06 |\n",
      "|    reward               | 2480248.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.34e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 752       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96256     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.17e+14  |\n",
      "|    n_updates            | 7510      |\n",
      "|    policy_gradient_loss | -2.24e-06 |\n",
      "|    reward               | 2134998.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.44e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 753       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.58e+14  |\n",
      "|    n_updates            | 7520      |\n",
      "|    policy_gradient_loss | -1.36e-06 |\n",
      "|    reward               | 2392809.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.24e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 754       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96512     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.52e+14  |\n",
      "|    n_updates            | 7530      |\n",
      "|    policy_gradient_loss | -1.87e-06 |\n",
      "|    reward               | 2439421.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.3e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2809781.8084142\n",
      "Sharpe:  0.805950830276032\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 755       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96640     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.44e+14  |\n",
      "|    n_updates            | 7540      |\n",
      "|    policy_gradient_loss | -2.59e-06 |\n",
      "|    reward               | 1054646.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.45e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 756       |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 96768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.26e+14  |\n",
      "|    n_updates            | 7550      |\n",
      "|    policy_gradient_loss | -2.63e-06 |\n",
      "|    reward               | 1100548.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.89e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 757       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 96896     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.36e+14  |\n",
      "|    n_updates            | 7560      |\n",
      "|    policy_gradient_loss | -3.88e-06 |\n",
      "|    reward               | 1233897.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.68e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 758       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97024     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.62e+14  |\n",
      "|    n_updates            | 7570      |\n",
      "|    policy_gradient_loss | -3.83e-06 |\n",
      "|    reward               | 1368881.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.17e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 759       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.88e+14  |\n",
      "|    n_updates            | 7580      |\n",
      "|    policy_gradient_loss | -3.81e-06 |\n",
      "|    reward               | 1537078.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.86e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 760       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97280     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.49e+14  |\n",
      "|    n_updates            | 7590      |\n",
      "|    policy_gradient_loss | -2.8e-06  |\n",
      "|    reward               | 1645124.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.22e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 761       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97408     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.04e+14  |\n",
      "|    n_updates            | 7600      |\n",
      "|    policy_gradient_loss | -2.77e-06 |\n",
      "|    reward               | 1835122.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.91e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 762       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.14e+14  |\n",
      "|    n_updates            | 7610      |\n",
      "|    policy_gradient_loss | -2.66e-06 |\n",
      "|    reward               | 1914083.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.65e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 763       |\n",
      "|    time_elapsed         | 113       |\n",
      "|    total_timesteps      | 97664     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.01e+14  |\n",
      "|    n_updates            | 7620      |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 1896457.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 764       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 97792     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.19e+14  |\n",
      "|    n_updates            | 7630      |\n",
      "|    policy_gradient_loss | -2.22e-06 |\n",
      "|    reward               | 2083082.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.64e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 765       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 97920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.04e+14  |\n",
      "|    n_updates            | 7640      |\n",
      "|    policy_gradient_loss | -2.09e-06 |\n",
      "|    reward               | 2712189.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.01e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 766       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 98048     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.31e+14  |\n",
      "|    n_updates            | 7650      |\n",
      "|    policy_gradient_loss | -2.32e-06 |\n",
      "|    reward               | 2854483.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.43e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 767       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 98176     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.51e+14  |\n",
      "|    n_updates            | 7660      |\n",
      "|    policy_gradient_loss | -2.02e-06 |\n",
      "|    reward               | 2539393.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.74e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 768       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 98304     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.81e+14  |\n",
      "|    n_updates            | 7670      |\n",
      "|    policy_gradient_loss | -1.31e-06 |\n",
      "|    reward               | 2698873.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.77e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 769       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 98432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.56e+14  |\n",
      "|    n_updates            | 7680      |\n",
      "|    policy_gradient_loss | -1.24e-06 |\n",
      "|    reward               | 2770831.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.46e+15  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 770       |\n",
      "|    time_elapsed         | 114       |\n",
      "|    total_timesteps      | 98560     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.13e+14  |\n",
      "|    n_updates            | 7690      |\n",
      "|    policy_gradient_loss | -1.94e-06 |\n",
      "|    reward               | 2926526.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.7e+15   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3149982.9860003088\n",
      "Sharpe:  0.8846901225846362\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 856        |\n",
      "|    iterations           | 771        |\n",
      "|    time_elapsed         | 115        |\n",
      "|    total_timesteps      | 98688      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | 5.96e-08   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.25e+14   |\n",
      "|    n_updates            | 7700       |\n",
      "|    policy_gradient_loss | -1.93e-06  |\n",
      "|    reward               | 1035985.75 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.83e+15   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 772       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 98816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.76e+14  |\n",
      "|    n_updates            | 7710      |\n",
      "|    policy_gradient_loss | -2.78e-06 |\n",
      "|    reward               | 1101029.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.65e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 773       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 98944     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.25e+14  |\n",
      "|    n_updates            | 7720      |\n",
      "|    policy_gradient_loss | -4.28e-06 |\n",
      "|    reward               | 1245235.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 2.62e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 774       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 99072     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.66e+14  |\n",
      "|    n_updates            | 7730      |\n",
      "|    policy_gradient_loss | -3.99e-06 |\n",
      "|    reward               | 1442898.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.24e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 775       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 99200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.96e+14  |\n",
      "|    n_updates            | 7740      |\n",
      "|    policy_gradient_loss | -2.25e-06 |\n",
      "|    reward               | 1533564.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 3.97e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 776       |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 99328     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.56e+14  |\n",
      "|    n_updates            | 7750      |\n",
      "|    policy_gradient_loss | -2.78e-06 |\n",
      "|    reward               | 1560304.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.08e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 777       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 99456     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+14  |\n",
      "|    n_updates            | 7760      |\n",
      "|    policy_gradient_loss | -2.13e-06 |\n",
      "|    reward               | 1676049.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.76e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 778       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 99584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.1e+14   |\n",
      "|    n_updates            | 7770      |\n",
      "|    policy_gradient_loss | -2.88e-06 |\n",
      "|    reward               | 1851665.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 5.99e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 779       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 99712     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.53e+14  |\n",
      "|    n_updates            | 7780      |\n",
      "|    policy_gradient_loss | -2.55e-06 |\n",
      "|    reward               | 1825137.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 7.01e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 856       |\n",
      "|    iterations           | 780       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 99840     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.47e+14  |\n",
      "|    n_updates            | 7790      |\n",
      "|    policy_gradient_loss | -2.56e-06 |\n",
      "|    reward               | 2189588.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 6.88e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 781       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 99968     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.46e+14  |\n",
      "|    n_updates            | 7800      |\n",
      "|    policy_gradient_loss | -2.84e-06 |\n",
      "|    reward               | 2572837.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.05e+14  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 857       |\n",
      "|    iterations           | 782       |\n",
      "|    time_elapsed         | 116       |\n",
      "|    total_timesteps      | 100096    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.08e+14  |\n",
      "|    n_updates            | 7810      |\n",
      "|    policy_gradient_loss | -9.06e-07 |\n",
      "|    reward               | 2748075.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.38e+15  |\n",
      "---------------------------------------\n",
      "Training SAC...\n",
      "{'learning_rate': 0.0003, 'buffer_size': 50000, 'learning_starts': 1000}\n",
      "Using cpu device\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2786959.6223982894\n",
      "Sharpe:  0.7936124522820193\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2927478.9599951236\n",
      "Sharpe:  0.8261008161632722\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2928192.8460976854\n",
      "Sharpe:  0.826265386179066\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2928533.816941963\n",
      "Sharpe:  0.8263566636864672\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 62        |\n",
      "|    time_elapsed    | 128       |\n",
      "|    total_timesteps | 8048      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.07e+07 |\n",
      "|    critic_loss     | 1.83e+11  |\n",
      "|    ent_coef        | 8.65      |\n",
      "|    ent_coef_loss   | -252      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 7047      |\n",
      "|    reward          | 2928533.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2928064.0650989884\n",
      "Sharpe:  0.8262816341760569\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2927548.122851297\n",
      "Sharpe:  0.8261411485604343\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2925648.7944213413\n",
      "Sharpe:  0.8257865664516201\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2925081.5020801723\n",
      "Sharpe:  0.8257211120063216\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 58        |\n",
      "|    time_elapsed    | 274       |\n",
      "|    total_timesteps | 16096     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.84e+07 |\n",
      "|    critic_loss     | 9.35e+11  |\n",
      "|    ent_coef        | 82.3      |\n",
      "|    ent_coef_loss   | -288      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 15095     |\n",
      "|    reward          | 2925081.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2928171.8352743816\n",
      "Sharpe:  0.8265869720350423\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2924129.2312890943\n",
      "Sharpe:  0.8255049697195889\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2914352.369762038\n",
      "Sharpe:  0.823996479780897\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2924007.5146151697\n",
      "Sharpe:  0.8258482935769859\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 56        |\n",
      "|    time_elapsed    | 426       |\n",
      "|    total_timesteps | 24144     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.23e+08 |\n",
      "|    critic_loss     | 1.91e+12  |\n",
      "|    ent_coef        | 598       |\n",
      "|    ent_coef_loss   | -84.9     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 23143     |\n",
      "|    reward          | 2924007.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2932072.4032224515\n",
      "Sharpe:  0.8288890887389657\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2902992.718015057\n",
      "Sharpe:  0.8219495966946593\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2941384.804724259\n",
      "Sharpe:  0.8312172080784643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2898822.875727546\n",
      "Sharpe:  0.8221100179596879\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 56        |\n",
      "|    time_elapsed    | 566       |\n",
      "|    total_timesteps | 32192     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.46e+08 |\n",
      "|    critic_loss     | 3.72e+12  |\n",
      "|    ent_coef        | 1.01e+03  |\n",
      "|    ent_coef_loss   | 3.67      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 31191     |\n",
      "|    reward          | 2898823.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2937862.4391054064\n",
      "Sharpe:  0.8303923843366497\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2949326.0792096015\n",
      "Sharpe:  0.8334771394890891\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2956344.2798411897\n",
      "Sharpe:  0.8349342419284274\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2917268.00138113\n",
      "Sharpe:  0.8249312556525962\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 56        |\n",
      "|    time_elapsed    | 715       |\n",
      "|    total_timesteps | 40240     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.58e+08 |\n",
      "|    critic_loss     | 3.52e+12  |\n",
      "|    ent_coef        | 1.08e+03  |\n",
      "|    ent_coef_loss   | 3.57      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 39239     |\n",
      "|    reward          | 2917268.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2920238.171032051\n",
      "Sharpe:  0.8269367056013154\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2932311.222389981\n",
      "Sharpe:  0.8288313723817883\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2889348.202378563\n",
      "Sharpe:  0.8197219844631789\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2922560.299600546\n",
      "Sharpe:  0.8271267690543124\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 56        |\n",
      "|    time_elapsed    | 850       |\n",
      "|    total_timesteps | 48288     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.69e+08 |\n",
      "|    critic_loss     | 5.68e+12  |\n",
      "|    ent_coef        | 1.07e+03  |\n",
      "|    ent_coef_loss   | 0.788     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 47287     |\n",
      "|    reward          | 2922560.2 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2913482.1748256464\n",
      "Sharpe:  0.824847748112339\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2930331.7812914797\n",
      "Sharpe:  0.8289947925532724\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2966960.779512478\n",
      "Sharpe:  0.8375159584561358\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2899277.650337519\n",
      "Sharpe:  0.821844132800317\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 28        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 981       |\n",
      "|    total_timesteps | 56336     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.73e+08 |\n",
      "|    critic_loss     | 1.16e+14  |\n",
      "|    ent_coef        | 1.07e+03  |\n",
      "|    ent_coef_loss   | -0.915    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 55335     |\n",
      "|    reward          | 2899277.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2933995.0366414757\n",
      "Sharpe:  0.8295725898635502\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2930302.1672283555\n",
      "Sharpe:  0.828671043141779\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2920464.8437142926\n",
      "Sharpe:  0.826374246997475\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2943139.292025309\n",
      "Sharpe:  0.8320727286940495\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 32        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 1112      |\n",
      "|    total_timesteps | 64384     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.75e+08 |\n",
      "|    critic_loss     | 6.36e+12  |\n",
      "|    ent_coef        | 1.07e+03  |\n",
      "|    ent_coef_loss   | 4.74      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 63383     |\n",
      "|    reward          | 2943139.2 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2917252.225357689\n",
      "Sharpe:  0.8255240189740882\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2951119.0035503106\n",
      "Sharpe:  0.8330945533412492\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2909217.524780573\n",
      "Sharpe:  0.8236363364160837\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2929522.857589877\n",
      "Sharpe:  0.8277965776734595\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 36        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 1260      |\n",
      "|    total_timesteps | 72432     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.71e+08 |\n",
      "|    critic_loss     | 8.23e+12  |\n",
      "|    ent_coef        | 1.04e+03  |\n",
      "|    ent_coef_loss   | -1.24     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 71431     |\n",
      "|    reward          | 2929522.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:3049297.946439899\n",
      "Sharpe:  0.8548988212630694\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2934154.8172077476\n",
      "Sharpe:  0.8294806403883636\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2921618.5478741834\n",
      "Sharpe:  0.8250470803982626\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2911933.5938300146\n",
      "Sharpe:  0.8236887784001717\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 40        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 1401      |\n",
      "|    total_timesteps | 80480     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.83e+08 |\n",
      "|    critic_loss     | 8.94e+12  |\n",
      "|    ent_coef        | 1.01e+03  |\n",
      "|    ent_coef_loss   | -4.21     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 79479     |\n",
      "|    reward          | 2911933.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2932497.9141103877\n",
      "Sharpe:  0.8299920080049246\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2911127.5269817435\n",
      "Sharpe:  0.8248020834213514\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2972281.6206255765\n",
      "Sharpe:  0.8384579980965867\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2910093.4527385044\n",
      "Sharpe:  0.8243514410013303\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 44        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 1543      |\n",
      "|    total_timesteps | 88528     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.79e+08 |\n",
      "|    critic_loss     | 7.33e+12  |\n",
      "|    ent_coef        | 929       |\n",
      "|    ent_coef_loss   | 15.1      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 87527     |\n",
      "|    reward          | 2910093.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2977743.0221854947\n",
      "Sharpe:  0.8410562981726538\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2960230.239986556\n",
      "Sharpe:  0.8390343794005785\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2943119.9219201403\n",
      "Sharpe:  0.8337808306842973\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2909400.481246527\n",
      "Sharpe:  0.8258335243266787\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 48        |\n",
      "|    fps             | 57        |\n",
      "|    time_elapsed    | 1691      |\n",
      "|    total_timesteps | 96576     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.81e+08 |\n",
      "|    critic_loss     | 7.98e+12  |\n",
      "|    ent_coef        | 800       |\n",
      "|    ent_coef_loss   | 9.22      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 95575     |\n",
      "|    reward          | 2909400.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:2917950.81459365\n",
      "Sharpe:  0.8295078455266892\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# Flag to use manual parameters\n",
    "use_manual_params = True\n",
    "\n",
    "# Hyperparameters for the different algorithms\n",
    "A2C_PARAMS = {\"learning_rate\": 7e-5, \"ent_coef\": 0.01, \"n_steps\": 5}\n",
    "PPO_PARAMS = {\"learning_rate\": 3e-4, \"ent_coef\": 0.02, \"n_steps\": 128, \"batch_size\": 64}\n",
    "SAC_PARAMS = {\"learning_rate\": 3e-4, \"buffer_size\": 50000, \"learning_starts\": 1000}\n",
    "DDPG_PARAMS = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_starts\": 1000,\n",
    "    \"batch_size\": 64,\n",
    "}\n",
    "\n",
    "algos = [\"a2c\", \"ppo\", \"sac\", \"ddpg\"]\n",
    "trained_models = {}\n",
    "\n",
    "for algo in algos:\n",
    "    print(f\"Training {algo.upper()}...\")\n",
    "    agent = DRLAgent(env=env_train)\n",
    "    if algo == \"a2c\":\n",
    "        model = agent.get_model(\n",
    "            \"a2c\", model_kwargs=A2C_PARAMS if use_manual_params else {}\n",
    "        )\n",
    "    elif algo == \"ppo\":\n",
    "        model = agent.get_model(\n",
    "            \"ppo\", model_kwargs=PPO_PARAMS if use_manual_params else {}\n",
    "        )\n",
    "    elif algo == \"sac\":\n",
    "        model = agent.get_model(\n",
    "            \"sac\", model_kwargs=SAC_PARAMS if use_manual_params else {}\n",
    "        )\n",
    "    elif algo == \"ddpg\":\n",
    "        model = agent.get_model(\n",
    "            \"ddpg\", model_kwargs=DDPG_PARAMS if use_manual_params else {}\n",
    "        )\n",
    "\n",
    "    trained = agent.train_model(model=model, tb_log_name=algo, total_timesteps=100_000)\n",
    "    trained_models[algo] = trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c247b",
   "metadata": {},
   "source": [
    "Save trained models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d7a67d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model a2c saved to results/models/a2c_trained_model\n",
      "Model ppo saved to results/models/ppo_trained_model\n",
      "Model sac saved to results/models/sac_trained_model\n"
     ]
    }
   ],
   "source": [
    "models_dir = \"results/models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "# Save trained models\n",
    "for algo, model in trained_models.items():\n",
    "    model.save(f\"results/models/{algo}_trained_model\")\n",
    "    print(f\"Model {algo} saved to results/models/{algo}_trained_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a19091",
   "metadata": {},
   "source": [
    "Load saved models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b3bdaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models are already set up.\n"
     ]
    }
   ],
   "source": [
    "if \"trained_models\" not in locals() or not trained_models:\n",
    "    # Check if model files exist before loading\n",
    "    model_paths = {\n",
    "        \"a2c\": \"results/models/a2c_trained_model.zip\",\n",
    "        \"ppo\": \"results/models/ppo_trained_model.zip\",\n",
    "        \"sac\": \"results/models/sac_trained_model.zip\",\n",
    "    }\n",
    "\n",
    "    if all(os.path.exists(path) for path in model_paths.values()):\n",
    "        trained_models = {\n",
    "            \"a2c\": A2C.load(model_paths[\"a2c\"]),\n",
    "            \"ppo\": PPO.load(model_paths[\"ppo\"]),\n",
    "            \"sac\": SAC.load(model_paths[\"sac\"]),\n",
    "        }\n",
    "        print(\"Models loaded successfully.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"One or more model files are missing. Please ensure all models are saved correctly.\"\n",
    "        )\n",
    "else:\n",
    "    print(\"Trained models are already set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da5e6c",
   "metadata": {},
   "source": [
    "## Backtest DRL strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca399842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtesting A2C...\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:1055226.115537142\n",
      "Sharpe:  0.34928383378428784\n",
      "=================================\n",
      "hit end!\n",
      "Annual return          0.042164\n",
      "Cumulative returns     0.055226\n",
      "Annual volatility      0.150632\n",
      "Sharpe ratio           0.349816\n",
      "Calmar ratio           0.292723\n",
      "Stability              0.644938\n",
      "Max drawdown          -0.144042\n",
      "Omega ratio            1.067477\n",
      "Sortino ratio          0.507361\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.867501\n",
      "Daily value at risk   -0.018769\n",
      "dtype: float64\n",
      "Backtesting PPO...\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:1078637.1658947\n",
      "Sharpe:  0.46302390918557734\n",
      "=================================\n",
      "hit end!\n",
      "Annual return          0.059883\n",
      "Cumulative returns     0.078637\n",
      "Annual volatility      0.149868\n",
      "Sharpe ratio           0.463730\n",
      "Calmar ratio           0.407215\n",
      "Stability              0.699006\n",
      "Max drawdown          -0.147055\n",
      "Omega ratio            1.092309\n",
      "Sortino ratio          0.671375\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.900832\n",
      "Daily value at risk   -0.018606\n",
      "dtype: float64\n",
      "Backtesting SAC...\n",
      "=================================\n",
      "begin_total_asset:1000000.0\n",
      "end_total_asset:1087207.7709841405\n",
      "Sharpe:  0.5069107550311978\n",
      "=================================\n",
      "hit end!\n",
      "Annual return          0.066347\n",
      "Cumulative returns     0.087208\n",
      "Annual volatility      0.148507\n",
      "Sharpe ratio           0.507684\n",
      "Calmar ratio           0.430724\n",
      "Stability              0.675527\n",
      "Max drawdown          -0.154037\n",
      "Omega ratio            1.103984\n",
      "Sortino ratio          0.729323\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.826058\n",
      "Daily value at risk   -0.018411\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for algo, model in trained_models.items():\n",
    "    print(f\"Backtesting {algo.upper()}...\")\n",
    "    df_ret, _ = DRLAgent.DRL_prediction(model=model, environment=e_trade)\n",
    "    # Reconstruct cumulative account value from daily returns\n",
    "    df_ret[\"account_value\"] = (df_ret[\"daily_return\"] + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats = backtest_stats(df_ret, value_col_name=\"account_value\")\n",
    "    results[algo] = {\"df\": df_ret, \"stats\": stats}\n",
    "\n",
    "    # QuantStats report:\n",
    "    # qs.reports.html(df_ret['daily_return'], output=f'results/{algo}_quantstats.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa5638",
   "metadata": {},
   "source": [
    "## Minimum-Variance Benchmark\n",
    "\n",
    "Construct a rolling min‑variance portfolio for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e55ab70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building min‑variance portfolio...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building min‑variance portfolio...\")\n",
    "\n",
    "dates = trade_data.date.unique()\n",
    "min_var_vals = [env_kwargs[\"initial_amount\"]]\n",
    "for i in range(len(dates) - 1):\n",
    "    df_curr = trade_data[trade_data.date == dates[i]].reset_index(drop=True)\n",
    "    df_next = trade_data[trade_data.date == dates[i + 1]].reset_index(drop=True)\n",
    "    cov_mat = np.array(df_curr.cov_list.values[0])\n",
    "    ef = EfficientFrontier(None, cov_mat, weight_bounds=(0, 1))\n",
    "    ef.min_volatility()\n",
    "    w = ef.clean_weights()\n",
    "    prices = df_curr.close.values\n",
    "    next_prices = df_next.close.values\n",
    "    shares = np.array(list(w.values())) * min_var_vals[-1] / prices\n",
    "    min_var_vals.append(np.dot(shares, next_prices))\n",
    "\n",
    "min_var_df = pd.DataFrame({\"date\": dates, \"account_value\": min_var_vals})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50364f",
   "metadata": {},
   "source": [
    "## DJIA benchmark\n",
    "\n",
    "Fetch DJIA and compute daily returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69a90a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching DJIA benchmark...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (328, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching DJIA benchmark...\")\n",
    "baseline = get_baseline(ticker=\"^DJI\", start=trade_start, end=trade_end)\n",
    "baseline_ret = get_daily_return(baseline, \"close\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3175c4",
   "metadata": {},
   "source": [
    "## Plot cumulative returns\n",
    "\n",
    "Visualize DRL vs. min‑var vs. DJIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d941e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/sAAAIsCAYAAACtNLkZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnQV8JWf1/p/rfpPceLLJulu73bq7Q1tKDWuhFCtQKNACP6zYvzi0uFWA0lJ3963tdt13s7txz3W3/+e878yV5MaTzcr58gkzmTs+k+193nPOczTpdDoNhmEYhmEYhmEYhmEOGbRTfQIMwzAMwzAMwzAMw0wsLPYZhmEYhmEYhmEY5hCDxT7DMAzDMAzDMAzDHGKw2GcYhmEYhmEYhmGYQwwW+wzDMAzDMAzDMAxziMFin2EYhmEYhmEYhmEOMVjsMwzDMAzDMAzDMMwhBot9hmEYhmEYhmEYhjnEYLHPMAzDMAzDMAzDMIcY+qk+AYZhGIYJh8N47LHH8Oyzz6KpqQnRaBTTpk3Deeedh2uuuQYmkwkHKhdffDFKS0tx1113jXrbdDqNtrY21NbWit/XrFmDz372s7j11ltx+eWXY3/wxBNP4Ac/+MGA5VqtFg6HA7NmzcJVV12FM888c8zHaGlpEc/zQGPr1q144IEHsG7dOnR1dcFut+OII47AJz7xCSxZsgSHMjfccAMaGxvx3HPPTfWpMAzDMJMEi32GYRhmSiEh+NWvflUIj3POOUcIfBLB7733Hn7/+9/jjTfeEFOLxYJDiUAggC984QtYuXIlvvjFL4plM2fOxG233TYlQvPSSy/FkUcemfk9mUyKZ/Pggw/illtuwc9+9jOcccYZo94vXRuJ6J/+9Kc4kPjHP/6BP/3pT2IQ4oILLkBFRYUYeKFBp0996lP48Y9/jLPOOguHKp/85CcRDAan+jQYhmGYSYTFPsMwDDNlxGIx3Hzzzejp6RGR8YULF2Y+u/rqq/Gf//wHv/rVr/CLX/wC3/nOd3Ao4fP5sGXLFiH2VShDgITnVLBs2bKCx77oootEZJ+E8VjE/ttvv42zzz4bBxLPPPMM/vCHP+ADH/gAvv3tb0On02U++8hHPoJrr71WvG8LFiw4IDMSJoLjjjtuqk+BYRiGmWS4Zp9hGIaZMh5++GE0NDTgpptuyhP6KpTCP2/ePJFqTOKY2f/U1dVhxYoV2LNnzyERCU4kEmIAiUonvvWtb+UJfaK4uBhf/vKXEY/HRZSfYRiGYQ5WWOwzDMMwUwbV6Fut1iGj2b/85S/x/PPPw+l0ZmqNzz333AHrffOb38yLklMtOv1OddkUvT311FNx2mmn4fvf/z5CoRBWr16Nj3/84zjxxBPxoQ99SJyLCqVz07Z33HFH3jHIS4CW0z6G4tVXX8XnPvc5nH766SKCStdHaeFerzdTm09RZeLuu+8W+6Rj0nKap9R5ynqg7T//+c8P2P/69esz66m89dZbuP7663HSSSeJa/3Sl76E7du3YyJQSyiovCK3DIGezYUXXojjjz8el1xyCf72t78JMZ17D4kXXnhBzNP15V5jLvv27RPL//znP+f5IXzve9/D7bffLp4TPfe9e/eK+0+f7dy5U9wfumbKOiDvAY/HM+S1UHmI2+0WZQt6feEEx1NOOUWcH5VZqKRSKdx333244oorxPVStgJF/9vb2/O2pfP64Q9/iKeeegof/vCHccIJJ4htqBwlEong5z//uSgPoPMlbwY6FxW6droHdC/o2HTN559/Pn7961+LbXNpbW0VJR90/+kdo2dOfg9r167NW099j6kUg86F1qeBs/5/R/TcfvOb34jnSOvRZ9/97nfR0dGRtz+/3y8ybdTjfvCDH8Sdd96Zd37qs3/00UfFO0HZIbRPytZ58cUXh3w+DMMwzMTBafwMwzDMlEDCcdu2bVi+fPmgoouorq4e13G+/vWvY/78+SJaS0LvySefFGZsJIRJ5JMQoXIBEpW0HtXNT4Th3bHHHpsR6u+88w4eeeQRUa5Awo2OQT4FFGE++eSThXAsKSkRIknFaDQKUfj444+jr68PLpcr8xllOtA9U2vKSViSACZzuRtvvFEMZtB2VHtO6ep0j8cK7ev9998XkXCqvVcNFUksUk0/3UP6bNOmTUKs0jMlMUjXQ2KUBOPSpUuF8KXrJrE+Gl5++WXU1NSI+0UCd8aMGWI5CVYaUCFhTp/RAAjdezq3//f//t+g+6PBH2IoXwSK9qvHUaHroAEhEuBknkgi+H//+594tlSCoposqqULr732mhC3ZrNZfE7Cno5J7/1nPvMZkdFCAwr0HH/0ox/lHYueIZUP0IAN3c9///vfYmCDnqVGoxEDBFRqYDAYxP2n8g/yvKBMGfJIoHeNPAhUyISQShK+9rWviXdJHTjLhQYhaDsamJgzZ454F//73/9i48aNmfMkoU/vFB2LBgXmzp0rPqfrI5NDKvWgc1L5+9//Lu7llVdeKQwf6e+MBuXo3tIxGIZhmMmFxT7DMAwzJVAElkzgysrKJvU4s2fPFqKaoCgkiRIS/bmGc/X19UJgvfvuu+MW+/fee68oPaBoKgkcgoTuddddJ4QhiT0SZ5RlQOdFbveDZTZQ9JQE2EsvvST2QdA9o+goiU5KOafUeroWGjRQr5Mg0UZik0Tcv/71rxGJ+tyoOGUWNDc3469//avISKBBExXaH4lVEnOqaCYBTKUYJPQpik0inK6LRHJVVVXmGkcr9km80z6pnCAXum56ZiR6icsuu0wI8FdeeUVEmUlkF6K3t1dMR/Pe0XMjoU8C9//+7/8yy+n9oedKAzh0jio0mEQCWL03JIDpGZFYpnunvhck4GlgoD8khn/3u99l1qP3hTJAaACB3hsa1CDBT+9abvkLDRCQESJF98noUoXeOTpHdbCmEDRgRNF3GhBQqaysFEKfBnXonO655x5RzkGZC5RxoD53+huj953WpXcu9x166KGHMselwTTKPqDBKhb7DMMwkw+n8TMMwzBTgipkSLxOJrmmchRlJEFEUxKjKqoJmyoExwNFLynCqV4fQSLaZrOJOnA1zX0kUESeIsZUxqBC5Qck9FSxRQMUJHzpOuk46g8dh9LbKYOhu7t72GOp6eXqD4lzikDTsUio5opHGnyYPn26uG+5x6QBB4o8k9ifKEhw9hf6KtS9IRcSk/Q+DZXKP5b3jsoyCIpq50JinlLZqYSChG3uOedmDtC9IijVPve9oGdLAyn0XuRCAxi5633sYx8T09dff11MqfyE3olcoZ+7Dxq4yYXWG0roE5QJQCUWVKqg/h1Q1gD9rmY50H2gc859F1RvDXq/aaAlFyp3yD0uZRdM1N8ZwzAMMzwc2WcYhmGmhKKiIpGqTmnFkwlFRXMhoU/Hzi0dUIUV1WWPF9rvrl27RCSYaq8pKportkdzDBLOJOopgk7RYhJkFBUlAaUOVlD0nRjKR4DqysvLy4c8FglKEq4UBaY0bYri0n2hSDal4edCxyT/gsFa0/WvY5/I55dLbmkDQe/TcPdYjejTe0cR6ZFAKe0mk6lgSQkJYYrOU4kGlRsUOi/VBLDQu1jofPufF2VwUOp97n2lbahsgsoSqLyB3jN1IKn//vqfTyHI14JKDciHgTJESJjTO0bZMGpJAN2Ho446SryXuVDmAg0C9H/uVMrRf71C58cwDMNMDiz2GYZhmCmDItdU601Rydxa31zIEZ0iihRlViODhRhMQPR3Wyf6i5WRMhKRQmKJoqGUpkzt7EgQU5SX6p+p5dtoIbFPJmdkckep/BQ9pX32F7ZkwEblCIXoX39eCConIJ8BQjV8+8QnPiF8B0hULlq0KLMuHZOuiWrmC1GoJnw4Bou050a4J+I5kq8BQbXmRx999KDnQtdG69L1q8aENO1/TPWz3Pe30Ds3Ggp5WNA5qfslfwKqzad34JhjjhGRdiodoeeSm4Y/knuoQiKeygPefPNNrFq1SmSM0HOnsgMabKL3ma4116QxF1re/294JMdlGIZhJg8W+wzDMMyUQannlJZOIlh1p+8vIKhmnfrRkwkbQYInN2VaZSJTg1WR0v84wx2DIpsk9Mlw7yc/+UmeMBxrBgOlgC9evFiIfEqbJxd8NYWfUKPNDocjI9ZVaCCFUvwpKj1aqM6eDPaoLp4ivnRdlKqtHpMM8vofj6L9VFdOaeyDoQrW/qnr+yu1mwZgKLpPRo00mFFIWFONPtW90z0gKGJP0Xt6vmr0XoWyN0h0949ijweK0uem6NO7Q89RLWdQy0Tuv//+PO+B3I4So4EyAsg/gAZp1DIOggaYyFCP6u5pMImunbI++g960LOkqH/ugBDDMAwz9fCQK8MwDDNlkOEZRaPJjKxQmziKaG/evFm0AVOFDqVCk9EZpS7niiPVZX0ioLRpEqU7duzIWz6cmFJb61EkPVcM0bWpLdHUCPZoSgeofp6EO7mtk9CmvvcqFIUnMU9mbbmDE3QuJNCoM8BYI80k5smAjYQctVdToah/U1OTEIO5UPYC9a6nARwVus7caLCayt7/3lJ5wv6A7gVF66kUgVz7+99/KpeggRqKUtNggHq9xD/+8Y+8dWkQiiLgVJs+VEeJ0UIDK7lQSQWhinB6tlSKklsWQM+eugOMxQeDBmk+/elPCxO/XFTfAfVdpftA70L/vwN67jQYQZ4NDMMwzIEDR/YZhmGYKYMEFRnDUfSYXM0pIk6RVxIOlEpMApmihSRaVShlmcTGTTfdJBznSfhTazESwRR1nAjIyZ163JPrPfVSpxRnEttkPEciazCo1pqinyS8SXDRPLnWU79xVTCReZrVahUDCrSMrpOi97lGgv2hwQ4SYrQu3afcgQTaD6V0kxs8GbeRgz8JWorGklfAj3/843EJUXo2dN3ktE7nQantdA6UaUD1/GTqRsZ41CKOSi7oeVGveRWKeFPaOQ1UkNs7De7QOuT+TpkClB5OUXPyOdhfad90fnQ8EtV0bvROUV07dQqgloXk5k/PXa2dp/Omd5OeI9Xm0+80KEDvHUXD6V2cSMgAkboQUIr+hg0bxPtO2Rz0HhJkvPjPf/4TN998sxDYJP6ffvrpzABYf4O+4aDnQH9L9N5S1wUaQKLj0/XSQNKll16aMQ6k507+EHTfqPUeDcbRs6RnSgNDDMMwzIEDR/YZhmGYKYUEFfURpygqpRJTC6+//OUvIl2d+oxTdJ9S1FVI6FBqMYlpMhIjoUH11bmp7RMBHYNEITmtk5AmcUc1zLnnUmjw4re//a2IvJM4JoFOUe5PfvKTQnQTFAlWBxQowkzp6zTgQdc+GCToKXpMFLrOq666SuyDBhHoHKldHonX3/zmNwMc60cLCUGK1lN0nlquURSYBC6JTRKBNBBAx6Z2hnQe9Pxy297RQARtS/fw/fffF8vI3Z8GUyiVns6RRD6d91i9FEYLHYeEMj0rKo2gUhE6J8ouoPtMbfMuuuiivG1+9KMfiWuhLBJ6rlTffuaZZ4p3d7BuAWPl9ttvFwKejkODTDTgkmvAeMMNN2T+Xui+0kAKCW+KsNNzp2cxWugYNGhBA2Z0XPq7I9M9+ltU2+TRu0/ZDdTmkDoDkD8FDUZQlwJaT/WRYBiGYQ4MNOnBnFYYhmEYhmGY/YY6UEMDRSMxVWQYhmGYoeDIPsMwDMMwDMMwDMMcYrDYZxiGYRiGYRiGYZhDDBb7DMMwDMMwDMMwDHOIwTX7DMMwDMMwDMMwDHOIwZF9hmEYhmEYhmEYhjnEYLHPMAzDMAzDMAzDMIcYLPYZhmEYhmEYhmEY5hCDxf5hQjKZzJsONj+eZftrm6k89sF2vofrsQ+28z1cj32wne/heuyD7Xz5XvGxD7XzPVyPfbCd7+F67IPtfJOj2M+hAIv9w4Tu7u686WDz41m2v7aZymMfbOd7uB77YDvfw/XYB9v5Hq7HPtjOl+8VH/tQO9/D9dgH2/kersc+2M63exT7ORRgsc8wDMMwDMMwDMMwhxgs9hmGYRiGYRiGYRjmEIPFPsMwDMMwDMMwDMMcYrDYZxiGYRiGYRiGYZhDDBb7DMMwDMMwDMMwDHOIwWKfYRiGYRiGYRiGYQ4x9DjA2LFjBx555BG0trbCZrPhhBNOwIUXXgidTldwfeqF+Morr+DNN99Eb28vnE4nli9fjg984AMwm82Z9Xp6evC///0PO3fuFL8vXboUl19+uVh/f0DnGY/HMVXQsSORSGaau2y4z0e6bH9tM5XHHs/5GgyGSXu+DMMwDMMwDMMwB6zY37t3L373u98JsX7RRRehpaUFjz/+OMLhMK688sqC2zz66KN46aWXcN5552Hu3Lno6OjAE088gT179uAb3/gGtFqt2P5Xv/oVLBYLPv7xjwvhRQMKd9xxB775zW+KdSaLdDotzsnj8WAqocGGQCCQmeYuG+7zkS7bX9tM5bHHe756vR6VlZXQaDST9KQZhmEYhmEYhmEOMLFPwr66uhqf/vSnhRhasmSJEEcPPfQQzj33XBQXF+etH4vFhNA/++yzRSSfWLhwIex2O/72t7+JKP6CBQvw2muvwev14pZbbkFRUZFYr7a2Fj/+8Y+xdu1arFy5ctKuSRX6FRUVsFqtUybyKLpMkWV1mrtsuM9Humx/bTOVxx7r+dJ7HAqF0N7eLt4Jes8ZhmEYhmEYhmEOebFPgojE+QUXXJAniI866iiRfr9lyxaceOKJedsEg0GcdNJJYp1cqqqqxFSNptO2s2fPzgh9or6+XgjwTZs2TZrYp4iuKvRLS0sxlVAZBAlPdZq7bLjPR7psf20zlccez/lSZgm9E1RuQu8EwzAMwzAMwzDMIS/2qaY+kUiIFOdcSkpKhFCiiGh/6LNrrrlmwPL169dnovcEbbtixYoB65HgKrTfiUKt0aeIPsMQqo/EVPo3MAzDMAzDMAxz6HPAuPFTXT2Ra6qnQstU07PhaGhowHPPPScM+Orq6jL7LrRfk8k04v2OB67PZlT4XWAYhmEYhmEYZn+gSZOD3AEAifSf/exn+OIXvyhq9XP52te+hiOPPBIf+chHhnXy/8Mf/iAi/rQN1e4Tn//853HWWWfhsssuy1v/L3/5izABvO2228Z83pSW3d3dXfAzit6SV8D06dMLDjbsT1KplDAiVKe5y4b7fKTL9tc2U3ns8Z4vDTw1NTWJkhJaTgNO0WhUTAl1vtCy4T6fzP0cbMc+2M73cD32wXa+h+uxD7bz5XvFxz7UzvdwPfbBdr6H67EPtvONjmI/BzJlZWXCE2xY0gcIra2t6RtuuCG9Zs2aAZ994QtfSD/44INDbr9q1ar05z//+fQPf/jDtNfrzfvs5ptvTv/73/8esM1vf/vb9E9+8pP0ZBEOh9Nbt24V06kmFovlTQebH8+yH/zgB+mjjjoq/ac//ang54888kj6mmuuSZ988snpCy64IP39738/3dPTM2Cffr8//ec//zl91VVXiXXPPPPM9Kc//en0c889N6HXsL+2yV3m8/ky70R7e7tYpk5z5wstG+7zydzPwXbsg+18D9djH2zne7ge+2A7X75XfOxD7XwP12MfbOd7uB77YDvf9lHs51DggKnZLy8vF9HPrq6uvOVut1tEyIdyLycX/6eeegqLFi3CZz7zmQFRdPIBKBR9p2Vk3MeMH3Kaf/HFF8X9fOyxx/CJT3wir688mSzefvvtooUiZW+QIz11TPjkJz+Je+65J2OeSFFv+pye+dVXX41Zs2YJLwfa97e+9S1s27ZNZGowDMMwDMMwDMMwg3PAiH0ShvPmzcO6detEmz017fn9998X89RCrxDPPvusEPrHH388Pvaxjwnn8/7QIACt5/P54HQ6M6KSBhYuvvjiSb6yw4MXXnhBtEL8+te/js9+9rN44403REtElX/84x/id/qcIDE/Z84cXHvttaJ9IpVYkKi/9dZbxTOkEgsapFHb15166qmi9eK9994rnvUxxxwzhVfLMAzDMAzDMAxzYHPAiH3iwgsvxK9+9Sv8+c9/Fi31WltbRdSehJ7L5RLCr7m5WdTk009nZ6eIIlOrvZNPPhmNjY0DsgUcDofY/pVXXsGvf/1rXHTRRWI/jzzyiDDw69+2jxkb9Jyo48Hy5cvFoA3dX1XskwnimWeeKUR6LjNmzMh0YiDefvtt0X7xpz/9qXje/bnuuuvEgIA6EMQwDMMwDMMwDMMcBGKfROLnPvc5PPHEE/jTn/4khPp5550nBDpBZneUCk6/U0SeWuyRyRmlhJO5X38o0k+DBmTUd/PNN+OBBx7AXXfdJSLFZAJ4+eWXF8wE2B+QL2I0ltxvx4snEkimNJmpuoyMHcbrEE+DLBs2bMgYHdKzoUEbGpihARUqqyDDxP7t5l599VUxpVR94q233hLP48QTTyx4HHofbrnlFm5bxzAMwzAMwzAMczCJfYIiw/QzmOsgRf1VKN2ffkYC1fx/+ctfxoEACf1b7nwT2/b1TfWpYOEMF26/8aRx7ePJJ5+EzWbDGWecIX4///zz8bvf/Q4PP/zwoPecBgJ+85vfiAEeGpAhqKyCUvWtVisLeoZhGIZhGOagYJ+7BfdufhCftn8EVfbyqT4dhsnA+dDMuKC0+meeeQannHKKEOh+v19E56mmnlL7qY6/P7t37xYme5RVQBkZanYFTamVIcMwDMMwDMMcLNy36TFs6t2B53a9NtWnwjAHdmT/cIDS5imavn/T+OMw6A2ZqbrMbjWPK41/1apV6O3tFYKffvpDLvq5Rn20Prnqk1HinXfeiWnTpmWi+OS9QJ+Ts3+uk38u5NNQqJ6fYRiGYRiGYfY3kUQUmzq3i/l2f+dUnw7D5MFif4oggW027b/br9OmYTDoM1N12Xjr9Sl6X1FRkanXp8i8GqH/7ne/iwcffDAj9slM8ec//7lI3acpiftcjj32WNGij2r3yVSxP8FgULj2n3766fjRj340rvNmGIZhGIZhmPGyzb0biVRCzLf781uIM8xUw2KfGTMU0X/zzTdx1VVXYeXKlWKZ2iqPplS7/69//Uuk7VOrQzJXPO6440TqPqXw94fEPrXj+8Mf/iB8G6ibQi7Uji8ajQrTRoZhGIZhGIaZajb2yKg+0RXsQSLFJanMgQOLfWbMPPXUUyKCP5hJInVNILFPRn0vvPCCaJf4iU98Qoh/qvVXBT+l5dfW1orff/CDH+DGG28UbfZoEGH27Nkiov/000/j9ddfx7XXXisGBRiGYRiGYQ4Emvb0Yef2TlSeXznujEnm4CKRTGBL767M78l0Ct3BXvBbwBwosNhnxgy1SKS2eXPnzi34OUXpFy5cKIQ6ReSJz372swPWIwFPAp+YP38+7rnnHtx7771ikIAc+i0WixD9lBlw5plnslM/wzAMwzAHDI/9dz3cvSHMnleLmXPKpvp0mP3Ilu6diCSjKDI7YdOZ0RbsEnX7NVp25GcODFjsM2OG6uuJocQ3ifbc1H7VeK//fP82iV/5ylcKbsMwDMMwDHOgEI8lhdAnWhs9LPYPM1a3bBDTo2uWocffJ8R+m78LNUUs9pkDA269xzAMwzAMwzBjwNMXycy3t3im9FyY/UsqncLqVkXsT1uOCkupmGdHfuZAgsU+wzAMwzAMw4wBd084M9/W7J3Sc2H2L23+TrgjXhi1BiypmJ8j9tmRnzlwYLHPMAzDMAzDMIOQSCTR2RpAOp0e8Jm7NxvZ97rDCAakRxFz6NMXkpkcpeZiGHQGlFvHL/aDsRCe3PEiPFHfhJ0nc3jDYp9hGIZhGIZhBuHVZ3fisf9sx7tv7B3wmbs3G9knOLp/+OAOy2ftNDnEVI3s94bdiCXH5jP10p43cc/6h/B80xsTeKbM4QyLfYZhGIZhGIYZhO2b2sV09Zv7kE7lR/c9SmTf5jCKKdft71/i8ST+d/f7WP+ufEZD4ekLoa3ZP2HHphR+osgoxb7NYIHdaBPz3eG+Me2zI9Ajtw+NbXuG6Q+LfYZhGIZhGIYRwr4Drz6zF9FIQvzu90bR1yPd9sl1f9+e3jyh6fPItP25i11iypH9yYWeQTKRyvy+c0sntm1sx9q32wuWWeTy4L1r8eR/d2Dv7p6Jjewb7Zll1Y4KMe0KZ9+T0dAXloNF7ii/R8zEwGKfYRiGYRiGOexJJFJ44oEN2Lm5F2vfaRTLWvbl106ve6cpM9/bFRBTi9WA+plFYr69mSP7k0XDjm7c8ZOX8frz8tkQO7dK5/tEPAW/L+uf0J9UMoWOFimg16zaNymR/Vyx3x0am9h3h7Jif7jBC4YZCSz2GYZhGIZhmMOevTvcCIdkrfXG91vFtLVRiv362VLMb9vYgUhYRv27O6XYL69yoLTCCo0G8PuiCAZiU3QFhzaqSG/Y1odQIIZUKo2dWzsyn/d2Bwfd1uuJivWJHZs7ERhiYGD0NfvZyH6No3JCIvvxVAK+6MSVHDCHLyz2GYZhGIZhmMOerRu6M/OdbT60t3gzYv+IY6pQVeNEMpnCrq1SyHV3SjFWXmmHwahDeaWM8PZ0yLR/ZuKgQZhd26TLPYn2zetb0dUWQDSczKzT3Tm4g73qraBuv+695nGfkyeTxj8wsj8WsZ9IJeHNEfg9Ife4z5FhWOwzDMMwDMMwhzWd7T7RXk+r1aBqmozUvvDEVkQjSRhNelRU23DkcfVi+faN3SLFukeJ7JcpIr+6Tkb/uzsGjzAzY4Oi+STSKXuC2LimBY0N+XXtbe2Di2O1a4LRpBPTde82jStNnrYtmMZvrxw2jZ8yAqLJgdkfvlh+JL+HTfqYCYDFPsMwDMMwDHNY8/5bsg58/pIqLFspBdu+3VKwzZhTCq1Oi6UrakUE390Twdp3mtDdkY3sEzV1xWLKYn/i2blFPouTzpoLjVYjjBB3bJZGewGHkmnRNXxkf8mKCpgtBnj6wgP8GEZDOBnNtNfLNeircpSLaTARRiA68D3o8Hfhi099B//c+uDAc+yXtt8dZLHPjB/9BOyDOUy54YYbsHbt2rxler0epaWlOPHEE3HjjTfC6XTihz/8IZ5++um89XQ6HYqLi3HMMcfgM5/5DKZNm5b3eWdnJ/7zn/9g1apV6O7uhsPhwJw5c3DZZZfhlFNO2S/XxzAMwzDMoQ857298v0XMrzxhOozWmDDdU+v3Z80tE1MSiWecPx/PPbZVRP3jcekKT+n7wbAH9TOlI39rkx/BgHTpZ8ZPV4cfPZ0hkXVx7Ekz0bS3G427PYiEEkgjjd7KvbD7S+HpGbwO39MnPyurtGLZylq898Y+bNvQjaOPnz+mc1Lr6a0GC4w6Q2a5WW8SNfy+aECk4dtNshWfytr2zWKQYKd7D1KpVP45Rn0DI/syWYRhxgyLfWZczJ07F9/4xjeEyCfC4TB27dqF3//+99i9ezf+/ve/i+UlJSX42c9+llkvEomgtbUVd9xxBzZu3Ij7779fDAAQa9aswde+9jW4XC5ceeWVmD9/Pvx+P1566SV885vfxJlnnikGENR9MQzDMAzDjJXd27oQiyZRVGISUXwKOCw5sgarV8lo/6x55UikZcr+MSfNxIY1TehoDWTSwu1OE4JhoLLGiZq6IhF1Xv9eM2YvykZ8mbGzYbWsr5+7sAJWuxFzF5UKsU8EHX0I2+V82JcUngr9SafSGbFf7DKjprZIiH0aQBgNiUQyk/rvi8nnX2IZqMZLrSVC7PeF3ZhRkh/M2ta9W+4rnURHsDsvxdobKyD2GWacsFpixoXVasWSJUtgMMhRzXg8LqL1gUAAf/3rX7F582axnD7vv97RRx8tfv/e976H1157DWeccYaI4tPgweLFi/HLX/5SDACo21C2wKmnnopbb70V06dPx2c/+9kpvHKGYRiGYQ4F+nplunVlrR0apSh8+dF1WP1WI4qKTSitsKFTqc+nFPJTz5+Bh+7aKlr1lZSaM9sQK0+Ygcfv34D3327CrIULp+iKDi22rGsT0+VHS+E8fXaRyLKIhOPwF3ciYYgiqU1Al9LD740Btfnb+7wR0ZqPMgOcxSbY7RaxPOiXjv4jgUo2/vyr17FoeTku+0g1vEp9fYm5gNi3lGCvu3mAwR4NFGzr3pX5vcXbjnp9VeZ31Zyv2l6B9kAXejiNn5kAuGafmRQWKv+Ba29vH3K9RYsW5a133333IRgMCkFvNpsHrH/WWWeJn3/9618IhdjtlmEYhmGY8eHzyKiv3WHMLKP6++tuPBHnXz4vT8wTRSVmnHmR/J5TXZc1ZyMWH1Ejov2evhCa9469JpyRhINxIdbVDAtCp9fi3EsWw1qThKe8BdAAMbMcsFEj+LmoXRNc5TbhvWB3mIXwpyD9SFvw7dnZjVQyje2bepCIJzNmesUFIvsuq/RuoMh+LuTQTxF/lRZf+4Ca/aruOC79107MbYxwZJ+ZEFjsTxE0upeKRab8ZzxOpEPR2ChT3/rX4g+3HtXoU9p+VVV2pLM/JPapDODdd9+d0HNmGIZhGObww+uRTu12Z1bsE3UzSkQkuBDHnjwTN37zdKw8sSZvORn4zVtSKua3rpet4pix09cjnw09B+qKoLJ85TSkj2pDUh/HzJI6RM1SRHsLiP2eLqVrQoUsqyCh7yiSASWvMtAzHE1t0gyQMgT27u6BVxHtrkJp/JYSMe0NyfICld0e+Z03N7KPfmn8s1uiMIRiOGJnWAwMqCaADDNWOI1/CiCB3XbPtxFt2THVpwLTtAWo+fiPxrWPRCKRGfXu6+vDpk2bcNddd2HZsmWZCH//9bxer6jt//Wvf42amhqcdNJJYnlbW5tI1x8KdWCA1mUYhmEYhhkPPndhsT8crjIbOhRH/lwWHVGBze93oXmPF153GEUlMm2cGT193fLZuMoG3sO2QKeYHlm9BG+aZS28111A7Hfmi33CWWQWz8bnCaO0avjYZ2tbtpXejs2d8JUqkf1CafzWkoKR/QZvk5jOKJ6GfZ4WNBeI7M8JJcV8VU8cxngK7qgX9agb9vwYZjBY7E8Z+SlhBysbNmzAySefnLdMq9Vi5cqV+M53vpMR911dXQPWI6iOn2r0KWWf6vhpIGQ44z3VyG+yshIYhmEYhjkcI/uFo/ijhUzgyOiPWvdt29iO406dNSH7PZwj+z5Tr/jep36vTKSS6AjJaPuR1YvxknnDoGn8mci+0iKRcBbT4IFbEfv5jvmFCHoSme/u27e0w3usatDnzKT5v/TUdnzgSmtG7Pev2W/wysj+OXNOwV/W/Adtvg6k0tJQkK7NG/XBHpa/a9NAbVcc7oh3lHeMYfJhsT8F0D9UFE1Px/dfWxYS0mR0p07VZUZr1oxmLMybN0/U15NAp/2Q0KfIu9FozByHIGf9X/ziFxkhT+vW1taK1nx0HioU5R8uYk8u/kR1dfWYz5thGIZhGCYWTYjWe4Tdkf3eMl5mzi0TYr+1KT+Vmxkdfd3Sn2l9dD3Wtc/GipolmX71yXRStLqb45qBuEWu5+mTgwODp/HLwQA120L6NQwU+8lE1tWfUveT0hIAKU0SIT8Q6ksJFVViLkbAG8PD92wThoEb1rRg2emyVWNfyJMJTHUHe0WUXqfR4sT6o/HPtQ8gnkqgJ+xGDWoQiAWFQ789lD1uXUdMbDMSkuGB180wBIv9KYLErsY40IBustBqdNAaDJmpumw8Qp+wWCwiVT93AEEdVMiFRH6h9fpDbvv33HOPMOyrr68veMyXX34ZJpMJxx577LjOnWEYhmGYw5uALyamFqsBeoPMHJwIyOCPaGtmsT9WqGWeu1eK86glgKd2vpQR+43eFjGtL6qFTquD2SlT8SOhJKKROExm+R0zFIwhFIhlxH6fkubvLFZr9geK5C3r2/DQv9bilHNnCA8pn4eCcxokdXEEnD0oclcDnTbh+l9scuLpp7cLoU94Onrgss6V55yMIRgP5bXcm1VSD50/jGqTC03hLnSEurFMpPx7KLyfieyrYr9nBJH9zhdfwr47/gDDTV9Exemnjfl+M4cmbNDHHFBcddVVcDgcuO2224QJX39effVVPPvss7j66qtht3P/WoZhGIZhxi/2J7quvqZO1nK7e0MZsckMz+pV+9CwXbrQu/tCIqpO0fSoOYhNndvR6JEiv8kjs0Dri6RBYrHNhrhBfm/s7Q4OqNe3OYyIaaLoDst9FxWrkf18sU+R+Ndf2AWkgYatvXnZAnQO/hLpE2DtKxfr7Hy3D21NWd8Gd0cPjDoDbAarPBcllV8V+0sN1Vhz/Wdw2ouyXr8j2C2mJPZNsTT0SZkJQP9f5k0i0Du8yaN3k2xz7du2fRR3mjlcYLHPHFCUlpbiZz/7Gfbs2YNrrrkGDz30ENauXYs33ngDP/3pT3HLLbfgtNNOw2c/+9mpPlWGYRiGYQ4Vsa+Iv4nCYjWiqER6ALS1cHR/JFC7wmce3oyXn9yDgD8qeturUX1opAh+asfLImK+sWOb+L2+uFZMKcKutt/rVdL2ia4O2f6wpNSMX636K36y+veiVl7W7A904+9oDWSO29UeRCqVRneP/J327y/qQhppWMJOLFp7Ll5/rkF8Ntu0U0wDoXTmfHId+bf3SLE/s0+LdDIJp3Je7SFF7Ic8mai+3uFAskaWAuj3yMGNoYh2yX3EerlVHzMQTuNnDjhWrFghUvkffPBBPPDAA+js7ITNZsPcuXPx4x//WKT6D2fixzAMwzAMMxwB/+RE9onyahu87qio259fLMUfMzh9PTLlncrcKZVe9VKIWPxCPHuiPrzR9B52de9Ba7ATOo0Oy6pk1yf6vMPsh81fisY9fVh6lOzcRPshymuteK57p4jcb+3ejeMrjxbLg/5oXn3+1vVSOBPxeApdHX709MrBA609AavViKCzB3ZfObRJPfTaFOYYtmGxYycaovMQihvEAEGJyYnWQIdw5HeZHGjzyYyAEl8cdARdNA5jLIWOoIzc94Y9sCtO/MZSFxIzqoC2HjgapQnhUERUsd/HYp8ZCCsmZsz85S9/EdP+9fn9IVf+QnX8Q1FZWYmbbroJX/jCF4b1A2AYhmEYhhlPZF+N9A6XLt362BNImIyovPkr0GiHTpCtqLZh91ZK8/Zg/jIW+8PhdUuxT2x6vwXFLpkKH7X6scg1B70xD3b0SqHvMNnxyYUfRo2jUqxTZHLCW7oDru7p2LS2FWdfvFDU2jc29AkTfXN9FOkGGXXf52nGmbNOhE6vQTKRRjAQzwj/vTvcmcEfas3Xss+daednLzGg2FmHrbM2wOp3obbSgWu2rYJWq0HFFd+G5g9NSEMLb2dvXmTfFDeIbIASUxGSe7KDCc5gCp2mHqRSKZHGr0b2TaUuaBctRuDVd1HZGkAylRS+BIVIJxIZkR/ry3f/ZxiC0/gZhmEYhmGYw5KRRPbDrW1o/eVvsPn/vgf36jXwv/kWQk3Nw+67Qmnp1tqcdWVnBsfjztbPtzV7sWdnTyayX2R04rLF5wtj6WpbBX569q2YXZQ1ciZxHXT0IWWLIB5LYuOaVuzcLLefNbccHalsT/tGT6vYj81uzHsH1r3XLKLyNfXFWL5SZga07OtDyCtFeEmZFdOdtUgYo/CVtqOoKA2tJg2Nsxz22UfAqpODAn1NjSg2qmLfjSa/4i/gqEG4JZuWXxyGcODvDPbAHfbApjjxG12lcC1YjIQWYgCge58sAShEwu0BUnK7uNeLVEJmQzCMCot9hmEYhmEY5rBkOIO+VDSKbT/+KSI7d0Gj18NQJI33fFu2DLtvV4VVRH3JoE89DjM43r5sZJ9QHe4jVkrjd+DI6iX4w0U/xjeO+gwqbKV564pIugbwV8r2zGve2oedW6TB3hFHT0OjTy4nmjytor+93SnFftAXE87/a99pFL+vPH46ps0oEfM04JCKys5VVVXFmOmsy+zHqZGZpxqzNIy2mmQavrutMxvZD+eIfWsVIu0dme3rknIwaHv3bqVmP5vGbzCZEVRaQfZ1DF63H++V1yhIpxEn8c8wObDYZxiGYRiGYQ47KIobVKK6aiu2/vQ++LCI7OuKi7Dij3eg+uILxXLvpuHFvl6vRWWNFH3dHVmHeGboyP70ObJtIZHSJ5AwRESaPlFqLRG96vujiuv2kj0wGHTo7gyIARaTWY95Syqxz58VzOFERPS9tzuykX3KviDXfYNRh8VH1mDadCn2ySiQIKf/6pJyEZ3XKscvSmvyxL7NJlPtPV2ezPmQiG/yy4GG+phFmPOp1CZkmcIfV9+LZl877Gpkv9QlpgmlfWDEM3h6fqKfKR/X7TP9YbHPMAzDMAzDHHYEfBFhBkfRd7tjoNjvffc9+F5/U8xXXPtxmCsqULRksfjdu2XriFLza+uLM87uzPBu/MTSoypgNOlynPiBYqNjyG2dRrtIzU/oYpi3vDyzfMmRNfAlfPDFAkKkV1rLMqn8NiWyT4MCO7ZIA736WUVisMBsMaCkLPtOkBN/pb1MtNWbWSyj+0Up5fmb7XCvXQc0ytIOnzuUEfvUWq83IqPt5dkOfYLZKMYxlcvFPGUa2JSafaNLEftW2c0h6vMOet2J3Mg+i32mACz2GYZhGIZhmMMOMmBTo/ok+HOJdvdg951/FPM1l3wA1oULxLx9zmxoDAYkfD6Em4ev26+pk2K/m8X+kKSSKfi9sua92GXBgqXVYj5klVFtVTwPBkX7S8yyxKJ+uYy0E8uPrsOu3r1ifnpRLWY4ZC3+Pk9LJrJP2R27FLE/fbbcB1FZk91PlMS+TQ4UXLviwzhz2glYkjJlIvs9b7wJY1Ceqz+QyJwvmesR1fYKaLqkMNdZrZmo/EcXXILbzrgZ80pnoTgs30FTqSxRSCtiP+aTbfoKEefIPjMMLPYZhmEYhmGYww6vRxX7+fX6qVgM237y/4SgN9bVYfpHr8l8pjUYYJ49S26/eeuII/vdnSEk4tkUbiafgD8usiyo9MFi0+PsixbiiJNr0F3dIKLpFn3hMotcSi3yXqedEZxxwQKsOKFa3P9dvfvE8rmlM1Fjr8yIfZsi9inrglrsabQa1M0qLPaTlgiKzFLAzy+bjQ/OPhu6cCAj9skJ35SQmQn+iBGGeBQOo6zJJ2a7piPWIev1i5cvE9Not3TmX1A+B7edehOMkXheGn/aJt/LhK9fSkCByL7WLs+VHfmZ/rDYZxiGYRiGYQ7byH6uOR+l5nfddS+Ce/bCUORE1ec+LQR+LuZ5c+X2m4ev2y+rsMPhNCERT2HPruF7ph+uBHzRzLMQTvkOE+ac4BDO9y5LsVg2HC6rrLN/oeENlC/X4KgTasR2u5XI/pzSGZhmrxLzjTmR/UhYOtjXz3SJGn+VypqsWLcW6wacQyrkyxH7fTAnZPZGKGlDyt2eOR9ilms64u0ye6B4xZFiSmZ6aaWdtBqRp6wRvUOWLGjt8vip4OBZIQllO/PsmWIa7RfpZxgW+wzDMAzDMMxhh0+J7BflRPbbHnsCwffXQqPTYf4tX4dBSanOxaKIfd/mLcPW7VO0eOEymZK+bUO2/RuTjz/TFUGmuBN9YXfGlG8kLCyfI6YbOrbiOy/9Ar9Y+1ds727AHndTJrJfa5ORfTLo01lljbzK/MXyM5UilxkGmwZppFFcObBbQzJP7FNkX4ryiMaKWGdzJtOAmF1ch1injOw7Fy2AxigHGhJueY0xRaQbnHY0/+HzSOxbD50i9tOB/C4FKmT2J1rvkdifJbNNOI2f6Q+LfYZhGIZhGOaww+uJDIjsd774kpjOuO4TKFq8qOB25hnToTUaRV/zeKeM1g6FKvbJBC6ZyBeYjMTvjWbq9VX6wlLIluSI5qE4f+7puOmIT+K0GceL1P/mQDu++/IvEEvGRRlAtaMCVoMlM3jQE+/Ji+TP6yf2KZJfeUYM++a/i6qK4kHFflpnRiIQgDEZhiadpA3Rt35n5jgaaFCbsiEdjYlBJHNVFfSukryaezUirzNpkfB0IblnLfROxZQwKN/T/kR7eqmlhGgJaaqXpoEs9pn+sNhnGIZhGIZhDjt8GYM+KTDTqVSmD7rrmKMH3Y5SrR3z54n58I5dwx6nbqYLFqte9I3fu5tT+QsR8MrIfrErJ7IfkmKf0vhHAonzWUV1+PyxH8cfLvpxxumemO6ozbTMm14sTfpag52ZZ19WaYerLJu2r+Ix9CBY1Cuc+HOhjI5kSNbSJ2Myu4PKPax66cvQu9udEftVtnIk27vEvLm6Glq9HnrVcV8R57E+xbzPJEsF0iE3jA7pEaANDSL2u+Q+TRXl0JfIY7HYZ/rDYp8ZF3v27MH3vvc9nHfeeTjuuONwwQUX4Oabb8aGDRsKrv/UU09h5cqV+PznPz/kfgOBAP72t7/hYx/7GE455RScddZZYpuXXpIj7gzDMAzDHNokkyk88cAG7NzcM6kGfUXF5ow7ejqRkJHS8nxx1x+n0oIvvGPnsMchp/+Z86QY41T+odP4KbXeH5Pp8L1KZN9lyZrmjRSn2SGc7r972pdxzLQjcE79yZnPZhTXimlroCPz7Octyo/qq3QGpYleheLEnyEWBlKy1j+lGOvpipwoLpdGef6wAXNC0n9gael8hFtaxXJrnTy2QTHho3dO7E6ZavUy8yMd9MJUJAc59GF5b/qjGvxRS0h9sbxHyWAIqajMkmAYgsU+M2YaGhpw7bXXore3F1/96lfx+9//XkyDwaAQ5q+99tqAbR577DHMmTMH69atw9690jClP01NTWK/jzzyiBhE+PnPf47vfOc7qKysxC233II777xzP1wdwzAMwzBTSWNDL9a924z3XpdCaSKJx5IIh+J5afwxJSXfUFEBjTb7FZnM3P694zH0BLNRU9VRPbxtu6idHg5V7G/f3CHazDGFDfru3vEf/HLd35BIJjJp/COt2S/EksoF+NqJn8Gc4umZZWpkvy3YheNPn40Zc4tx7CnS4C6XRl8rGj3y3atx5g8GpKOKE7/BjKRSU68vKkJxlRTxUb0NplfW4B+X/AIXzjgdoZYWsdwyTR47G9l3Z1PySZhppLBPh7wwOxWxH0kUfMciXVLsm8rLoTGboTXLgYuk1zvm+8UcemQLVRhmlPz73/+Gw+HAb37zG1gs8j+U8XgcZ599Nq655hoh/k899dTM+i0tLULk//KXv8QPf/hDPPTQQ/ja176Wt89EIoFbb70VWq0W9957r9i/QXHBPeGEE1BWVoZ//etfYr8rVqzYz1fMMAzDMMz+ortDpkmHgnEhzieSgF+KKqNJB5NZfs+Id8q0aENVRd66f11zH3b27kF0TQzfOvWLYplj3lzobFYRSQ3sbgCKhu4DX13ngNVmRCgYQ1tzADUywMtQZDyZQkCJ7Pt0HiQiUaxt35wR+yKNX47LTAjVSvu93ogbM+eUwWKfA4czv7VfOB7BXdseQiqdwpHli1Hj6Cf2lbZ7OqsTUUVc64qLUFQiSwEieht633oXM667jnL+Edi5O1/sK5H9eCaNXxlISitmfKkEzFaTuGxK7E8EB5r0RTuzafyUQWB0lSDS1o6Eh8U+k4Uj+8yYoYg+1SylUvkj1Hq9HjfeeCMuu+yyASn8VqsVxx57rBgQoN8jkfw6pFWrVmHnzp244YYb4FJGPXP51Kc+JfZLgwEMwzAMwxy6dHdKQUV4+go7ko8VVVyq7deIeE5kPze6S0KfWN+xVTi9E2S0Vrxc1oS7160fUSr/gqWy7duOTVy3n4vPGyE9DCqpTxhkhP/lvW/BE/aOqmZ/pJTZZKZAIB5CLFE4Rf7va/8rBgPKrC5cOe8ipGIx7Lv7XkQa5LuQjmTFflIR1/qiYjiVsoC42SY8INqffAruJ55CcO9e4fXgXDAX3U/9EZpwZ8E0fp2Sxk+Yk3FEDbKGP+6TZoC5RDI1+/J9NarZAiz2mRxYMU0RJJIjieiU/wzXMmYoTj75ZHR1deH666/Hf//7X+zevTuzv+OPPx5XXXVVZl0aEHj66adF7b3JZMJFF10Ev9+P5557boDY1+l0IopfCIr0f/3rX8cRRxwx5vNmGIZhGObAp0uJ7BPuyRL7zlyxr0b2s1Hc19veE1OjVkb/713/sIj2EsVHyu8inrXDi31i5Qkylbxhe1/etR3ueBWjRJ0tJcPYANa2bUIynRJO9sXmobMmRovNYIVZbxLzPUp7v1zWtG7A6/veFcf+0nGfhFVvRu8776L14UfR+/CjciVF7GutTiTUyH6RM9PGMWaWRoPtTz0D99PPivnyj16DpKcJ/vUvIr13Vab1HqXoq5F9bfZ1hDESQcQob0jC7x+iZr88T+wnvTIjgmEITuOfAkgQf/elX2CHMlI8lcwvm43bzrh5TNtefvnl6Ovrw913341f/OIXGTFOkftLLrlEGPapvP3222Jg4OKLLxa/z507FwsWLBCp/GTqp9LZ2Yni4mKRAcAwDMMwzOH7XaknJ7Lv7g3BmdOWbaLS+HPFvlqzb1QipRRZXtu1Wcx/avEVuGf7w2jytuLdjg24tLoGJYrY9+/ahdICadb9qaotEtH97Zs68PrzO3HSOZzLT3gUsZ8wDXSddxrt0Gl1E3o8SnknH4BWX4fwYahAvifAqqY1Ynpq7TFYUD4bHR0dCDXLmvt4d09+ZN/mRNIrOziQSZ6tSEb2wxobjC4nYn0yIl998YWwHncMIlueF79rk35K9yAXSuz5y98UY0gddIZsuYoxHETEpEVRMIWozwuUZDMcxACBUudPkf1QIi7S+ImEmyP7TBaO7E8VGmXo8iCH0u2ffPJJ/PSnP8Wll16KkpISvPjiiyKN/7e//W1mvccffxzV1dWYPXu2iOjTD0X5t27dim3btmXWo6h+cgRGNwzDMAzDHLpQnT61qlPx9E5uZD8ZiSDp9uRF9l9oeENEl+eVzsJC1xx8aLEMTjy172VhIEeO/YbqKtHr/PHn/4bm3ia0Pfk0oo1Ngx73tHNly76tG9rR2zWx13SwopZohPQyen1UxdLMZ0Umpdf8BEPp+URPyD1gkGlrt2ynuKR0fmZ5pL09Y36XjEazYt/iRMIj3xtdUVEmsh9JW1B8xCwxb543FzOu/biYj7buzMgAo+Kg3/GsHAAoPmmZKGVQMQR9CJvkgpAnv6WeZ/0Gadqn08GoDAKYSksz58gwKhzZnwJoRJGi6dFk4TqhyYCM88joTp2qy+xmmzif8WC320UNPv3QPltbW3HbbbcJg70LL7wQRUVFeP3118Vnp59++oDtyXV/2TLpaksDAm+++SZCoZDYrhCUIVBby6PhDMMwDHOo4u7Jj/LKNH4pZiaCoD+/Zj/cJsWc3uHAnng33t/egGd3y65CF8yT313OnXMqHtn2HHzRgMjOXFwxD+ZFCxBv74B56z6s+tatqOuIwjitFtOPPabgcSuqnZi1oAR7trvx/qo2LF4mBeHhjJrG79dJ0XzBjNOwoWcbEqkEio0Tm8I/UOz3AdbsM+iJuOEOe6HX6jHDKc30ct8PItrdk1+zr4hrcuO32o3QatJIpTXQVBZh2S9uR8BsglavRzqVRLS9IbMfg9OKmOLGP+3DH4LG6UViE/1G38vTSPvdiJlkVkPY0wdTTgbKvl/+Rsw7Tzxe+EcQmci+MvjAMARH9qcIEthULzTVP2MV+iS4qS0epeH3Z8aMGbjpppvEPLXXe/bZZ4XQ/8lPfoI//elP4oec+mlKtf0vvPACAgH5jyb9TvX977zzTsHjUlu/K664QrTiYxiGYRjm0MTdKwWgyayf1Mi+TYnsR9ra5HGdetyx4W78a8Mj8EcDKDE5ccy0I8VnBp0BR1YtFvPr2reIaV+9FI3zmqJC6Kv7Gqod31En1IjI7r7dHrh7ZU/5wxWKpFOLRSJqCYhIfrnFhZU1MghUMsH1+iplSjs/IfZz2O1pFNM5rukw6gxZn61csd/VhXREqaE3WJEKKZ4DxUXie7VJicaH/UE45s4RxnxiP32tSOcYAppKZMlqxVlnoP4jVyMdVDJLyuvENBnoRcIit1Ud/xOBIDp+/2ckg0E45s9H2RWXZ/bHBn1MIVjsM2OitLRUpNw/8MADAxz1iaYmmcJGafuU5r9o0SIR1V+5cqX4obZ5NCXhTtvTOgTV+c+ZMwd//vOf4SkwMvnHP/4R0WhUZAwwDMMwDHNo4u6RAmrOgopMZH88psK5pFPpbM2+GtlvlWK/2RSGFhocO+1IXLPsEty4/BPQ59SMH1Gtin1Zy7+lKIyE8nHKahbz2lQaDbs2DHr8klILauul2GzeN9Ag7nCivdkv/BjI/9Bf1IUap+xY8LEjLsNZs07CKbXHTmpkv7dfGn+DV4r9RRVzM8uSPh+SYfk+EhHydlAi+6mElFJaoxFapQ21xSxfiIg///txsivfq6t4cRlqbr4Jc77wOTFIkA7KczHXyGMn/H1IWmQ8P6a48e+7517RNcJYWooF3/x6ZiCBMCrt/CjTYKL+VpiDHxb7zJggof/Nb34TjY2NuPbaa4XoX7NmDd577z0Rtf9//+//CQO/cDiMhoYGnH/++QX3Q5F8Gjh4+OGHM237fvCDH4ia/o9+9KO47777sHr1auED8I1vfEO4/n/sYx/LM/9jGIZhGObQwt0rhdKcBdJpPB5LIhxKTMi+g4EoUsm0iK7b7FIshdXIvkOHFRVLcfOJN+CSheeKKHMuy6sWCpf2Zm+biApv9u3B6kU2JOurcNTPb0e0TEaiX31bBjEGo3a6rLNubTy8U663b5SGd+a6GNK6FGoVsV9uK8UNR39kwP0vRNzbhXQsK8ZHQpktJ40/h92efWK6qHxedv9d0vVeJdrVjXREZmSkoqlMCr2aLWu2KgNIofxy3VSX3LexcqaYJn1dsMybC43STlqN7Jtq5bGT/j6krFLsxxU3fu8mmVEy6zOfhrEk31hQ/T0djyOhZMwyDIt9ZsycdNJJuOeeezB//nwx/dKXviQGAN5//33cfPPNuOWWW4QxHw0MUD1/IUjcn3POOdizZw/Wrl0rltH+/v73v4tMAKrn/8pXvoLbb79d1PGT6//nP//5/XylDMMwDMPsLygq6VHS+MnBXjXR83tkmvx48Xrkvh1OM7Q6+VXY2yQjum6nDmfXnzTotg6THdOd0jfo6R0vi17sa5cXYfqtt8A6bRoqZktTt769u9HklwMIhaitV8R+0+Eb2ScDxr275PVHqqSgrnVk2x6OBIp+N//hi4g+e+cY0/jdmSh4d7AXfVEvtBot5pVKQZ7bkjFz3p2dmTT+RCSRl0JPWOzSkT8SSyOVk7af6torpo5lp8n9Ulq/cux0OoV0SIp9syL2UzSgYJH7SvmDSMXjiHRI53/7nNkDromyC3Q2WRoQ98pMAIZhgz5mXMybN09E4nNN/1QjQBrhJPH/ta99LbOsEDRIQIMDuZ+TUR8to88K7ZthGIZhmEOTgD+KaCQpIu+l5TY4ikyixt7njU6oIZyzRKZdk+AKt7aCkq+nzV2CapvMJhiMRa452OdrwTO7XpG/l8+FSScHJEpnzkHwrdUo8SXx1N5XcMzcFQX3MW26FJsdbT4k4odnF6JNa1uRTKRRUeXAVkMrkABqndWj2ke0Yw/l0iPV1zKq1HWXpVjY4MWTcQTi0g9ia5d04Z9dUg+zQYpsIt4lxb7WCKRiVPLRCmOFFPHJoMxAMeRE2S02uW0sZURSidYng16k/TKLwb74ZPS+eBfSsQgQJlFeLT5HKgmy4zeU1gB6I0ADBWb5HTgVCCLe0Sk6P2itlowZX3/0djuSwZCo6WcYgiP7DMMwDMMwzAFDd4dMQXaV2aA36OAsNk1wZF8KNLVNWnvbXuiiCZBUPO+4Dw67/SKXrKmmtnzEipolmc8s02TU3+VLYpt7N3b25NdpqxSVWGCx6kU5QXvr4RmFXf9es5guP6YW3RFp0lfrHGVk3y0j3UgmkFLq6EcCmS06jHYx745KQzu15d7CimwKf25k36Q0iYpSzT6h1SPmDw6M7Ctp/LG0CcmAFPsRpeWeoWwadLYiaOyys0TKK/eV8Mnr19mKodHpobFJMa81KTX5oTBiSvs/Y03NoAbbJPZz0/4ZhsU+wzAMwzAMc8DQ3SmFSlmlFC6OIimeJiqy71Mi+yS4ia2b3xXTkMOE2ZVzht1+mr06r//7ippsX3hK5SfK/SlKGcDGzm0F90Firbzadtim8ne1+9De4oVWq0HlfLMYOKHsiFIlvX6kxPuyLvnJwOjuY4mi3vuLfcrUyDuGUrNvUhoDJMPk+SDb7sXd8pi5kXazVQr0WNqYOaeoIvbVFH1NkRzUSHvlQEJSEft6pxwE0FjluemMigFgKIqYYiJprBk8+0EV++TazzAEi32GYRiGYRjmgKFHEfvlVVJQO4uUyL53Ymv21ch+sFl2EEoq5nrDodVosLx6kZivsJSiyp5N+zdXVwFaLXSxJGzhFBo9rYPup0IV+4ehSV9Xhz9zD3qTUujWOCpFvfxoiKuRfSFwRyn2zYrYj3hFvX5noFuYLy4oy9bDp1MpxLul2DfYAI3SeSEZJbHvQKxvoNi3qO3yCkT2TbXS00FbVJEf2VdS/DNi3yY9HfR6GcHXJFOI7FUM/qqHEvvynZpKg76414utP/opguvzO1J0vfwqIg2FM12YyYPFPsMwDMMwDHPA0KWk8VdUSrHvUNL4fZ58d/Ox4lPEvrNY1lYnmmV0WFMlBdhIOHv2ybDozTi1X2s4rcEAQ3lZJpW/aQixX1ljP2wj++TLQFgdBrT6pGBXnfjHKvZHG9l35UT217RuFPOziuphNcpBICLW2yvc7anAX2eSP1mx70Ssr69AGn82sp8IeoT5XrS9QSwz1czJi+ynlMh+Jo3fWZYn9o3pRKa1Y3SPNPgz1tYMek16u2PKxX7nCy/BvXoN3M++kFkWamrGrt/egY6//n3KzutwhcU+wzAMwzAMc0BAJmudbbKGvaI6P7If9MeEmd3qN/dh52YZCR2PQZ+axm9sl4LNVF834n3ML5uNuz/0a5xce/SAzwxVUrSWeBPoCHQjkiickVBeRaFiwNMXRjh4eJkPB3yK2LdlxX7NKMV+OpVEwptti6dG0Uedxh/xYXWrjEIvLZWRd5WwkjpPIp/K5PWK0z6JfS2JfTWNP8egz6xE9mMpGdlP+3pka0CdAcbyurzIvprGn/ApkX2HmsYvxb4pGkFYSeUXgw4A3k23CGPBQhgc9ikX+x4lop/olQMYBJkaEkm3h/0E9jMs9hmGYRiGYZgDAp8nilg0AZ1ei7IKKVzMVj0MRhnevP+uNXjmkc149Zl9mejwaIjHkwgGYhmxn0om4eiVbuzOGQPbmY0FY5WM2lYFNEgjjRavzBxwr1uP9z7xqUx6s9GkQ7lyjV3th1eNdVCN7NsMGRPDGcXS3HCkpAN90sF+nGn8rcGOTL3+0rJ+Yl8xxdObAY3RkhnIIbGvMdiE8/3gNfsmJINupHpkmYjWVQuNVpdfs+/vQTqZQNLf169mX4p9czSMiCkr12IWAx7ufANvN8t21f3R2ZQ0fv/UiP1ULAbftu1iPunzIRmVzzmS075QHUBh9g8s9hmGYRiGYZgDgp5OKZ5Kyy3Q6rQZM7uSUtk/vGF7NpLbtCcbORxtCr/eoBURWH9HCwyJNOI6oKxuYsS+ger2KTMhIOutGz0t8nz/81/EPR74Vr2dWbe2vuSwFPvqQE3KmEB7oAtaaLCoPN8FfzjSvuy7MJY0/mLFca873IdUOoW6ohqUW7Lp+ES4NSv2SYgbaqeL36krXiIiW/1pDAborPL9zHfjJ4M+D1K9suuAtjSbOUIGfBpq75dOIe7pzEb2+9Xsm8IBRExZ5313keyavk95pwaN7AenRuxHdu1GOpHI/B5V/A4iagcDuqctg5e2MBMPi32GYRiGYRjmgBL7ZZVZ8USUuOTvOp0WNXUyItvYIKOho8Hrlm337E6jGETo2yMjut4SE0wGpSB7nBiV6K9TaRXY6G1FtLkFgZ3yWGS0pvaEr50uRV3jbg9SqZH3iT9UxH5vSorBekdtXq18Lq2PPYHu++5HOpmN4hMpVewrpn5jdeNXObp2+YB1IkpkX6eIfeMMpe1iFOhds1vMWxcvymuFpxr0iZp9f05kv6w+sw6tb3BJo72ep/6YqdnXKzX72ozYDyKcE9nvUJpAtHjbhnbjn6LIfkiJ6qtElYh+pl1hTko/s39gsc8wDMMwDMMcEPR0BguK/RXH1wvn9quvPxonnD573JF9u0NGX0NNjWIarswXfuPBoKTxG4JRGGMpYdLne+PNzOcpvz+T1rxgaRVMZj36esJY964UhYeT2G+JS+E3v2TmoOtSRoTv1dfh2769YGTfVDVrTGLfbrDCoDMMEPs0EON+f60YYPBu3pKN7DtKYaiQAzmJMODbtlcU8pd84KK8/app/GloEQ4Es5H9snxPCGOlzBKING8TEX6YbNDZlXIAs0MMYphTKUSUmn2it1iWATQrpSGEO+zFc42vwxPx5bTemxqxH1bEvtYo/77U9zw/jZ/F/v5E5oIwDMMwDMMwzBRCImuwyP7chZVwlKRRVVWeqffu7PAjHIqNyZyPIvtEUknTxjQp0CcCncUi3NnJqZ0c+VtNzfC/K8VOTK+BMZHGqjcew5KTPwCb3YTTzp2H5x7bipef3o4rPrUYhzqUwRAKyGe4J0KCGZhXIgV7fyian4rIbAz3mrUoWpy9P1TvTpjrFyLavlvU7Gel+/BQdL3MWoJ2fxdclmLMKqlHZ2cnOp59Hnv+9JfMelqTAQZrXDjl68tkmj2UJIzy006FqZ87vsGgg06nQTKZRiyhgzEdAHR6aIrzW+a5TvsIouYSOItd0Jpt8Jtc2Zp+at9oL4Y56M5L4+9V0vh7w26EyPQPwCNbn8Wz+16F2WrBRY6lYlkiMLllIVSL3z/TIubxIEYp+hoNSo8/Dt2vvY5oVxdM6TSiXd15afxZhwNmsuHIPsMwDMMwDDPlkBCPRpLQ6qhGv3BKN2FzmFDsonpniu6PLpXf55UCyaZE9g2dcnvL9JE78Y8EyzRpNnfSugAWbuhBOhKBx67D9pnSzX3HmjfR7JcDDStPnIGSUjPCoTjWrDr0zcsioQSoioEy371ww6QzYoZzWsF1U5GsCaN77br8z5TIvrluoZimYxHxMxrKrK5MVF9NxQ/ulS3uzPPmYsG3bkXlubOh1cvIPkWsDUUyC0Sj16P+6isL7peyNdRUfvF7xXRodPkxVr3DBcPSs1B09AVwLD0VWqccyHrpqW2i3ERnscOcSuel8fcpYp9o8cn3Z5tiLuilyL4tG9lXS0UmmrjPj7WfuxGtt/8i7xie9bJ9oW3WTNjnzM5E9Mmoj4z7VCIdnQMGCpjJg8U+M2ZuuOEGrFy5Ep/85CcHXeeb3/wmjj/+eHznO98Rv3//+9/HBRdckPn8iSeeEJ/ffvvtBbf/29/+Jo6RyDH7GIpIJIKzzz4bN95446DrBINBnHTSSfjxj3+cWRYOh3Hqqafi6KOPRltb4f/QXnzxxeJc6HzV6THHHCO2o3vw7LPPjugcGYZhGIYZSEerV0wrqhzCjX8oqqZJUdM4arGv1Ow7jIh7vTAqEeaS2bIWe6KY9qFLoTEaUdsdx7GbZbbCpjlmlC6UkemKnhj+tOnf+P27d+PZ3a9g/onSLG7rui50dRzarclCSptBqoOnqP6C8jkwkJouQCqaFe+hfY2IKu3cqO0etbQjjJUzAcVvIR2W79BIOXPWSZhmr8L5807PLIv1yP06jj0GpcceDU3Ul2eeZ1Y8GarOOwfmStlCrz8ms4zQR9PyvIxKqcFwrHuvGatebsDG1Z3Qmu0iBTtukvuKWA15zvxN3jaEExExJQLxEPSKQR+Z5KUUJ/yJpuPZ5xDr7UO0sUlMVbwbZJeJ4uXLYFLuC0X2Ez3ymZnKy6AxGYXQjyvGfczkw2KfGRc0Crpt27aCApkE9BtvvDGi/Tz44INYu7ZwG5HRYDabhdhfvXo1enP6e+by0ksviUGBSy65JLPs5ZdfhlarRUVFBR599NFB908C/69//Sv++c9/iulf/vIXMaBB/N///R/eeuutcV8DwzAMwxyOtLdKUVVVO3z9fE2dY0x1+36PFI82hwHBvfvEPEXcK0pH1/ZtOIqPWI66734L/joZOU5ogW2zLFh+3Fni9wp3AsFoAK/tewd3r38Qf+v4JxIVXhHxXvWSNH47VKEMBiJplNHepZULBl03Fc6P1HuU6L5oVZdKgELuJMI1FvnOpEPyHSqE5+1HEXnmDqSiMruDOKH+KHzjqM+gxpEt44gq4lSvtNNLBz15Yr/+o1fDedopqL/6qkGPZewf2R+h2Pcrg1E0IEKp/WJZqVlUDTRXyH26FGNBMunb52sV7R3FNrEwtCYTuVhOmklfOh5H+1PPZH4PNMi2iRTh92zYlBH75oqKTGQ/rgyemCorYaiU9znekTXsYyYXFvvMuJg3bx4sFgtefPHFAZ+9/vrr4rPy8vJh92O32/GTn/xEiPDxQhH4ZDKJ5557ruDnzzzzDObOnYvFOXVfTz75JI477jiceeaZYj4el/8h6k9xcTGWLFmCpUuXiukRRxyB8847D7/73e9gMBjw1FNPjfv8GYZhGOZwpKNFRmWrRyD2q6ZJsd/e4kUslhx1ZJ/S+P1KunZ3iR6VdumCPpEYyssR+dyH8OTJRXj4zBKUV9Zh7oIV0Fot0CfTuN51Bj68+EIcUbUIWo0WjWVSLG1a15LxFjiUI/sBjRTmy4YS+/1ayJFxHhF3d4ipobhC1LlrrDIzIh0qHNkXYvTtR5Bq247QnvxygP5EFXGqLylBisoCYjIzg9L4ieJlS1F+9ZXQ26UYJzY19ODe5/eiqy+UF9mPpUyjEvuhoBwAiYQTIrIv5l0W/P2SUjx7nPx9WZksW2j2tWOvL2vqGIyHRBBOZ7NOWvs9/+o1on1k5pgNDfJYvX2IUZBNq4Vj4YJMZD/h9yPWKgOC5spKGBXzyhiL/f0Gi31m3JH0E088saDYf+GFF3DGGWdAp4wwDsWXv/xlkR1wxx13jPucFi5cKMR8obT6lpYWbNiwIS+q39TUhPXr1+OUU07BhRdeCLfbLaL/o8FkMsFolG18GIZhGIYZPe1KGn/VtOHFPhnsFbusIhLe2ToyUROPJREJxzNiv2/XTjHf5zKi2CzF4kRTXzINDXUmtJcbcPrM46HV6WCaMUN8VucBPrzkInzr1C/iR8ffjEuOPw1BRy+Q1uDxZ97DoUpYEfsxfRg2gxX1xYNnVSS9Spq48vWKosciDbxP1qvrS2RKfSayHy4c2adBgFRYvifRdilQC5EKh5EMKuK+pBgJv4zya4yWTKQ9l2g8iftfbsS3/rAKr2/owtNv7R1Ys6/VwVghnfeHI6iUlZDY1ynHs0CDoFWHlFYD+t/SsvliebO3DXu80umfUA37tFbrpET2acDE++LLYt5cI80GA3tkZD+iiH5TfR10JhP0Viu0Nnn+4R3y74xKHgxKCQRH9vcfLPanCPqDSUYiU/4zEeYdFA3funVrXio/1cVTSvu55547on0cddRRuOyyy/DAAw9g3bqhR1xHwgc/+EFxTo2NsqWOCkXeKQKf6xvw+OOPw2q14vTTT8f8+fPFQMFDDz1UcL90v8g/QP2hTIS9e/fihz/8obhmivIzDMMwDDM6/L4IAr6oMG2rrFaaiQ/D9NkyRb69eWQ17kF/LCPEjEYdQkoaf6KmbNIG62eW1ImovU6jw8nTjxHLzDOl2I/u3YdUPI7ed9+DORDDpYvOQ/USKRIb1rvR5pER5kONUECK/YQhihmOWnF/BiPllWLbYBMZ+0iGQojsbkCgYReiXiCtcwjxP2xk3539jhrrkAK1EAm3bN+ns9mgNZuR9PXmpfDnkkymcOvv38SL78ssA6Kp058f2U+boCmpgUY/sj4BwYB8R6M5kX1zOvtuUveAOrsU2tRqb483P7KvnvtEt9+j+v/uV14TUXq6LzM/dZ08ZoMc3Igo6fzm2dKYj9CXyr9Pqu0nKNpvVCL+HNnff3DrvSmABOOmW78N//YdU30qItVm6U9/NK59UB27zWYT0f2rr75aLHv11VdFyvuRRx454v184QtfwDvvvIPbbrsN99xzjxDlY+X8888XqfWUyj9nzpzMfX/66aeFqHc45BcJSvenAYCzzjpLZCmoZQC/+tWvsGfPHiH+c6Fsgf4ZA1TrP3v2bGEySMZ/DMMwDMOMjMf/uwFbNrRmxDa57BtNI/t6Om16CTasbkFvlxQ5wxHwS5HpLDIjnUoh2dktAsaGafkt0SaSEksRvnHS5xD0BeCk3ukkehSxH9qyDeu+9BVE2tpFar/lpi/h8uNPxd83vQttwISHXnkLR85ffMim8ZPYr7YN7ZWQ8knxTR3p9EVAuBdo+80d1L9PLO/b8Rr23f8W7Eumw24YXOyncsR+tH3PoMGuRJ87YyYnfldMANUU/lz2tvuwu9kDo16LD5wyGw++vAstXYH8yD4s0M9cgZGitiSMRhKAUUbozcq1EjXOSpj1JpRbXegO9SGRToq/HbqeYCwkppnI/jjEfiIUgv+9NQi0tMC3ZSvClIqv3LPKM89A0ZLFop0CtZeMud1ZsT8nW65gKCtFrKk5sx2l8YftcgAj3tkhzpUzYicfjuxPFYfQy00p7JQCn5vKT/NklDeaP2Kq7yeTO0q1/9Of/jSucyoqKhIu+c8//3xmGWUMtLa24gMf+EBmGQ0udHd347TTToPf7xc/J5xwAvR6PR5++OEB+6XP/vGPf4jBCHLzr6urw4wZM8Q8ZTgwDMMwDDMy6Mv+hjXNiMdSiEVl3X3drOFT+FXKK6V4dvdGRhU1dRRZkPB4oEmmkNQCxVUTa87XnxU1SzC3WAp8wjxDpnRTSzIS+lTnnAqFsf0nt8Pz8GM48ywp8DVNxdjcNfWBoclK448boqiyDe3rlPRL8a7RAWYZKBZCn5IB9GZAY9AL07jA5n1CUw6Wxp/qy4r9VCSAhLer4HoJt6xHN5UpYp+MAAeJ7PuU+vryYhMuOmmmmO/sDSKeSGYi+/p5J8Ow/ByM9O9Brdmna4nrZITelMyK/Wq7rHmfVlSTWTavVArsZDqFaDIGrVKzHx9HGv/W236Mrr//E53PvYBwS6s4IUNJCazLl2Lahy+DzmyGQam/927akq3Ln50V+/rS/HtmqqiAoaJcaCB63+Pewc0UmYmDI/tTAAlgiqZPVkuMQpDhHEXK1am6zGS3T8ioGkXGb775ZrS3t8PpdAo3/M997nOj3g+1vqN0/v/9739isGC8qfzkG7Bx40ZRx09t/urr67FiRXaElZYRX/3qVwdsTxH8m266SQxC5A4i0L7oHlK6//Lly3HNNdfgS1/6Ev71r3+JDAeGYRiGYYYnlUyrQT9cf9NJMFsMiMZHLgDKq2SUMOCLyUjoCNP4ncXmTDswv1WHSmfh9mmThc7hgGPBfAR2N6D2kg+g5oMfwI677xH10PQz+8iVeBlpGGNWPL7hJXxq2YdwyEb2rUPf+1RQpsXrilwwFfehdLEeGpsd+rQH+plHoPZDX8e7V30U6XhCmvOPILKvRvdRIgV6oTR+U1lpXmRfVyCy71eEud2ih8tphsWoQziWRFtPECYlO4Vq70cKpe7nJhzEoET2qf20NPVHtUPer7qiGqxr3yzml1ctxK7evUilU6JuX2eV30WTweCYhB7pE79SZ1998YXCkDBUXIxp8+aio6MDxhLZpcBUV4d4ewc6nnlWDAZQmr6+KDtYZ8gR+xqDAcaSYmjjMZgqyhHt7EK4tQXG4pEP7jFjg8X+FCHcMpW08f1BSqeDzmDITNVlE5U+Q6n85KhPLexIEFdVVeW53Y8GEs6rVq0S6fyUMTBWjjnmGHEe5L4/c+ZMcW7XXSdrjAgy4qPjkFkfDSyoRoKU2t/Q0CBS+UnwX3rppYMeg/ZPgxzf+9738POf/xzf//73x3y+DMMwDHM4EY9nXfQrqh3Q63XoGEWPeYvVCLvDhIA/ip4uP3SKIBqMYE4af7xHph377FrMsw/fNWiiWfKjH6CjpQU1M6XgLPvwh2CCBl0vvoRow04UlVbD2xvB7n0daJvdhSpIY7NDSewnDTFUWofugpAKKXXorkoYSvTQaCgi74HOWQrjSddAbzbD6CoR/d6TUUBXoPVeOpVE2iPr6rXV85Bq34lYR0Nhsd8nI/lGNbKfqdkfeJ7+kBT7NgudlwZVpWbsbQ+ipTMAk0V+p1QNIUdCOJQ/MBClen8S1fGs2Kc0fqLOmS09mV82Gxa9WdTs0w+VhKiRfdkLYHREm1tE9oSuqAizrv+kWBbryPoSqJAZX+C91fBt3SZ+dy7M76qgVwZMCHNFOTRamVBunVYrxH6osRlFY9QKzMjhNH5mQiAnekqbp1p9NYV/rFB0nHrXk0v+UD3vh4Nq6S+66CJxTiTqo9GoqMdXoVp9MtmjyDxF+1euXCl+aP6KK65AaWnpoEZ9uZCDPxkMkj/A2rWyJQzDMAzDMEOTSGTTk3W6sX0lLauU0f3ujsCYIvtemw4VtoFR28lGazBAm5M5KM5rwTwxDezajdppMnpqCTnxSsvbOFSgjghUtkG4Suww6ob2Z0qFpdjX2p2wLTheWapBxQe/DI3JlqkFJ0jsU5u8VDw/c1a06UvGoTGYoJt5ZDayP4Ka/aS/Z9g0frtFXkOVSz7Pli5/JrIfDo1C7PfLAogk5H5Nsez1VDsUsa+k8ZM7/xzXDFippoHe8Vgox6Bv5ANnuUSbFEO96fVDrtf/c8eCfLFvUAZMxLrKMxLrKX5YbY89juR+zHI+XGGxz0wYJPC3bNmCNWvWiLT+8UBReYq4B8bpJEpCvLe3F3/5y19w8sknCwGf68JPqfizZg3sfUo1++eccw62b9+OzZtlmtRQUBkAZQb88pe/FAMIDMMwDMMMTUKJ7Ov02jFnGqp1+92KC/pIxD7V7Ku91H12HUrMB0YqsV0xFA407Ml0JDAHnVjTuRHucOH09IMNysIgUpokalxZAThYDXsqItfXOorgPOpc0cLOcOyHYJmejQibldrxZEzKmmQw2weeiHVJ8Wosq4O2TPolRDsaCpr05dbsp3qaEetpFb/riyuHTOMnqlxScJNJn1qzXyiy37zPjYDyLuYS6TcwEE3o8sS+XqNDmaUk0+Xh/Lmn45LZZ8NiMIvIPhGMhzM1+4lAEGMh455fXzfkesa6aXm/D4jsK278ats9leqLL4KupBiRjk60PPDgmM6RGTks9pkJ47jjjhOp/NOnTxfu9OOF6uUrc0YCxwKl2dPAAWUJUA2/Cgl4ctsnQT/UQAExkug+DRhcddVVYp/UPpBhGIZhmJGl8ev1Yy8pLK9Sxf7wwYGA0vKNIvuxnm4x77frYTXmR9inCmt9nahtpvZyJWYZOCiKlgnjtTcbV+NQEvtUr19fNHQXhFQ0hHRcZgFoi1wwFFdi2qd/BcOS0/PWU6PGqaTMdU8GZHReJdYl2zAbK+qhddWIHn6pcADpgEzZz2uvrNTsG4odiL52F+0UuunLYXANPFefmsavOO9Xl2Yj+0ZlGYn9VCo7qNDa5MY/71yF5x7ePWwaf1gZvLAo25dbXCJrlaDBsetWXIHTp8lsB4suG9kfixt/7sBHRuwPE9nXWSwwV8vyEmrHR+9vLlqjEYbiYrmviqzY11stKL/qCjHf+shjiOW07mYmHq7ZZ8YMRctVoz81Gk7u96oRoMojjzySWabWtKufU1o99abvvw1BAweUxp9rKDgW7rzzzjxjQmLJkiUiA2GofdKABa2jHls18xtsm6985Su48cYbx9UykGEYhmEOFxKKkKPI/lgpV9L4e4aJ7NPAAhmgqTX7iR4p9OLFtiH7vO9PNDqdiJZG9+yFLSjd4jUhIzRJLTyRQyOyH/TLzgkJYxR1RQNr5nNJeLuRVio91NT0QqhRYzWyn+gv9ruleDWU1yOpM8BYXodY516kepqAudkMgYTPJ5z9icCmZ0Wdv85WLLwBCmWe+AZE9lWxH4DRlH2n1E4TxOZ11MIOol2k1x3O21//lH+R1q83Yk44hpUVC7CkdPD6doruE6F4OCeNf3ixn04msfGWbyMWCaPy179AOpFAvKNzRGKfsM2ahUh7B0yzZmZq8vPOq7YGcY8Hltr8jhe2I5bDdezR6Ht3Nbr//V/U55hnMxPLgfGvG8OMADLOoxT5oX5oHYZhGIZhDp40fv24xL6M7Hv6wqIefDD8XikyDUYdjHog7ZNGbuliJw4k1LZ8qea9sFjpRDWwBB0IJw6N2ma/L5ppu1c3TGSfnPBTyiOlyPFgmKtkdDkRlisnlXZ5KnFF7FNknzBVy+zTVK9crhJVfBz0DjsCa58T8+UXfQEas73wtYTyxT614NNpNYjEkvCFEuJdI2JKpwiKnu/YnDW627tLlpKoRJTIvlYnBxbCwRg0JivMqTS+PP9CrKhYMug9yK3ZH01kn645sGsXYs0t6HtvDYJ79wlnfaPLleesPxjlJ58kpo7jjy34+awbPoXSD38IrpUDxfysT18v2k5Gdjcg5skvvWAmDo7sMwcNl19+uWj5MRTV1dV4+OGH99s5MQzDMAwzPoM+3TjS+K12I8xWvRBKnr4I6gYJRvo84UxUP9bTA43oYw4YnAeW2FejqcGG3SitnY2WfT6c+6YWUWsTsBIHPT19MkMhaYiixlGJ3ogU2IVI+nqQHoHYV1PEE6GYyATwrXsBzqPOE8vIrC/eJ787GsunA4EITFWzQHkgVJOfi+rjoDPL91E39zhY56yAb5Dvnmpkn9z4Cb1Oi6pSG1q7A+joi8BiMYgBqKgS2e/tCotBqVyxX1VfPSCNv7Tcju4OP0K0f6MVCHqQjATpZR/0HuSm8evsUuwngyGkU1kTzEJE2tsz810vvYTiI44Q8/Y5IyvHLT3+WJzw8APo7JZlMf2xzZiBYrNZZK30h0wQDQ4H4l6viP4blZR/ZmJhsc8cNFBrO1FPlUiIkgGi/7xVGc1kGIZhGOZgqdkfX6JpSakF7SE/3D35adG5+JTIvqPIjEhnV8acz24cXEBNBabpMrIf3LMXrqVGtOwDQgYX7HulUdzBTlefjOCabXoYhnHiT+SIfc0QYj9ltQuvA0rBT8KCeHczfGtfAKYdIeZF3rzZjvanX0TX6jWYf/2VYju1HZ8KDQIRWo0U8fqZQ6eWqwZ9DsWNn6irtAux394XhsVqEO+dWj6yb5csL3A4TSLDgcT+cWdkWyqqZn5lFYrYD8WhsVjp7JGKBADr4D5WZqXvpDDoy/kurLYuHIxwe/YeuNdtQDKqDGDMHmhencu69s0I+0LCG6uQkB8phuIiRewfGmUqByIs9pmDhjlz5mRq+3Pr+PvPj7W2n2EYhmGYqXHjHw8lpWa0N/vh7pWCvhA+j/zMWWwRPb7FMhuJ/QMrSGCorBBR7FQkAsOu9QCmwW9ywREq3CruYMPjlQ7xxcWD1+CrJLw5afyWwmLfG4jiMz99Edca7XDE3dDUHQO0vgb36/+F8QP18GyW6fiwV6L5/v+JmvTe1bLLUjroQTqZ/c4Y7ZZiX6OJAhottJWDC954IiXS9XMj+8S0Cior6UBHbxhlVvn9VI3s79slBzpOPXcennlkizArpHe2ujo/sk8+FNvUNP4i+X6SoeBgBLaugv79p4AyG4LxkBDfZJ6XDIdFdH8oIrlZC6kUfJu3yNs1ZzYG9guQUGeI29/4I7TQYFH9fBRbxt7NwqCUCsRY7E8aXLPPMAzDMAzDTF0av278kX3C3Tt4ZN/vzabxRzqlAZmXIvuGA0vsk8mZmkJt2PyumAaMLmjCg0mvgwu1/WG5a6BApOzNnuf+jvi6Z8TvcU+3CMoTWlNhsb+jyY1gJIFuyMGDlKUKhvI6pMJ+RP73AwS3vCn3pakRQp/oevkNQGQVpJHw9Q5M4zcCxsqZ0AzRpSGgROu1Wg0spmxke1qFzBShNH6zEvGPRhLo6wmirycMjVaDhcuqUT1NrtfaKL0jcmv2yxTTSZHGb1JS8imNfxBCu9bAolxbKBbO+A6MJLKvpvGbZs7IW24fIrLf5u9EKp1CIp3Es7tfxXigyD4R93LN/mET2d+xY4dwb29tbYXNZsMJJ5wgWqBRD/PhcLvduO2223DDDTdg4cKFeZ/df//9ePnllwdsc+mllwo3eIZhGIZhGGYKDPoM4xT7ZVIIuntGEtk3I7qlOxPZrzIMH2He35DYpwirNe6HNhVHSmtAImwa075SqVTBfvJTRTyYBlXE15SVDfyspxm+NU+L+eiK0xHry9aBa82Fr7+1S0a83XrFgb7PjdJzr0PHfbcBqQT0RRUov/gL2PHPRzLbxHp7EY+4YDD0Ie7pBCyVeQZ9JPYt0xdhqDzRoCL2HVYDtDlO/XWKYWR7bxiWKtlnPhpJYvsmGUGfMbsUFqsRtdOdwo9BFfvUni+i7LMvIo8cJgNAZTBKpPEPdk/72jPt+SiyT+htdkTRjVRw8EECcYw2KfaLzz0bPXf/S2QD6IqLYSwpAQbxKugKZI0Fn9v9Oi5ZOHYdZSiSdfqcxn+YiP29e/fid7/7HZYvX46LLroILS0tePzxxxEOh3HllbK+ZjD6+vrEtqFBRrBoX4sWLRKt3nJxueQfIsMwDMMwDDMFrfcU9/HxRvb93qgwRFNd0AvX7Ftyava1sB+QYn+OmGqQhtMQhSdpQCwpReRoiCSi+Obz/w86aPGzqm9PeYvBaDQOTVRGu+fVTxvwebw322/d+96TiHv6Mv3aB6sLp/p4wmOQ9yfe3QPrrOVIFx2DkMeNRdd/V3Q0CCnp6dYli8V8oDWGkhlAwtOVEftqzb7OBJjrhhb7AUWQO6yyVl6ltlxG1L3BOPTKe9iyz4ttHrnvBUtkjT6JfaK9yY9kMoVITtu9Xzy4ASuhI1N8xHU2kYadGiKyH3d3wKz0KCSDvtzIfnKIyD6Z90XUNnvTpqHslJPQ+dwLw7bc6wxmxT4d79W9b+MIxwKMBaMa2Wexf3iIfRL25Kb+6U9/WvSzpF7oZL720EMP4dxzz0VxAZdGGrF855138OCDDw65bxL755xzDmbNGtpwgmEYhmEYhjl4DPrIjd9qM4q05zVvN+L4U2cNKvYpjd/b1Zmt2T/A0vgJ56KF0JpM0BUVoWxGKTwNUSTSoxf7bzauRqtfRmd7gn2osA+Mpu9P9nXIQZaEPoqZFfl914l4X1bsBza9hnRSRqt11sHT6amnPeHRS3Gb6OmBf9dudLzwnvi965XXRccFMu+jFn1lH7kKTd/+HiJdAcQrFbFfLfvNR3v7MpF9c/1C+BV/gaHS+J22fLFvsxhgNesRiiSQUsaw2pvlORa5zFiyokbMl1ZYhIFfOBRHa5MHZrOUZBq9FulEksYnRMeIiMYC6xCR/XQ0JEoWLAZdxqCP0NuUsoYhavaTHq+4LzSQoneVoPLqK5FOpmA87uhBt8mN7JdbXOgO9+GpHS9h2VHzML40fhb7h3zNPpmq7dy5E0ceeaQQ+ipHHXWUEPRbtsgRuf5Quv+///1vHHfccbjuuusKrtPT0yMi/nV1dZN2/gzDMAzDMMxYWu+N7+sofW884XRZ5/7C41uxaW2+c30ykULQL/u7280kLHzZmn3j8JH9ZNCL+JZXRRu3/YGp1IUj7/wNam+5GTanMhiR0o0qHZ/WfW73a5nfG71T7+bf1CHT8jW2BLTagc88lhPZpx56qhO/bohOSwMi+z29aHkw24J53z/uRtvjT4r50hOOg8HlgusYKWZDnfQudGVT+KlNnQYw19ZBZxl6cEUV+/0j+0SRTZYcaPRSgJOsOe7UWfjQxxeKFH65TIOZc+XgC7nyBwPSyyCl1eRNYylLXs0+mfFFnv4tEgHp7J/yyXtqVtL4Q/EwUun0iCL7caVdnqmyQgh+St2f+8XPwzSMXlIj++fWnwKH0SZ+f3D3M2jxZdv4jRQ26DuMxD4JcmqdVlmZ31aipKREOKy35/SB7J+G/6Mf/QhXXHEFjMaBf3BqVJ9Yt24dbr31Vnzuc58T22zeLN04GYZhGIZhmKly4x9fGj9x/GmzsHiF7Lf+2H3r0bI3Kx66OvyZQQVNQBqBRQwaxIwjS+Pvee6viL/zP/S98i/sL8wVFdDZ7bA61PPTIzJEKnd/9via0eiR33+JJs/Ui/2ubvkcLEWF5Yeaxq+tWyKmqhM/OcsXgqLnHmUQx2tQDOmCQfS9I40NjfV1SMVi8G/fIX4vPeF4Ma0692wxjXiUyD5FxPftE1O9her15fExgpr9/pF9scwulzlr7DjjggX44EcW4JwPLILeIAdsnn+3EY0dwTyxH1LEflwZ0FGn0bQpz43f8/ZjSLXvRGDzG+L3tCL2LTRQoQzyRJMx6O3q/RhC7Hcp21Zn2/+NhK6g9DaotlXgovlnifk329bgq8/cht+s+yf6QiM32zMoWdsc2T8MxD7V5RPmAn00aVkkUth0hUz8aEBgKJqbmzPH+MQnPiHEvt1ux5133smCfxyQEeLKlStx/PHHi+nRRx+NM888Ex/72MfwwAMPiMGboUo2aJu2NvkPO01pP48++mjB9emZ0edPPPHEpF0PwzAMwxwuBPfuQ8ef/5Zxpp/Kmv3xpvFnovtn1GHJkTXC7Oz15xvFlNi8TgrduplOxLrUen2dqGG36Afv366mSQd3rhbz/vUvIzlEC7TJwKaI/aTWgIBXRnNHwhut8pxNSv/1Jm9O1HyK8LtjeR4Lg6XxG448HzpbUTayP4jYJ8d7lZjWgKQ5mwHgOvYYVH/+M9Ap6eyUpq52OXAsWCDC7akYEO3qyPw9iGNbKYV/0bDXMlgaf25kPxhN4qQz56CiWgpvYvs+N+54YD3+/nQDZs2TYr9lnxvuPinKQ0q2S1R5dyNJuX+q2acaezIxFJ93NOSJfUMa0CvbhBORrNgPBYcV++YqpfffCKCBBG9EZsaUWkpwycJz8ZUTrseS0nnQabTY42vCt1/62Yij/IYi6V0Q93gOKCPJQ4kDpmZ/uAecm9o/Wkgkzpw5U3gAqCxevBg//OEP8dhjj+UtHy3JZBLdShpModIE+pymI+kmMJlQKQSdhzrNXTbc54Mto2c2Z84cfP3rXxfpWHStPp8P7777Ln77299i/fr1IoOCKLQfggYEaF4dGFDvV+5xGhsbsWbNGsyePVt4M5D3wkRcw/7aJncZ3TP1naHlHR0diEajYkqo84WWDff5ZO7nYDv2wXa+h+uxD7bzPVyPfbCdL9+rkW3T+sc/I7JjJ3bf/yDKrvjQlFy3z6cK59SEHDsWi+GYU6uwa1snAr4YVr+1AxW1ZmxYIwXSjHlOdO3ekhH7VK8fj8WGPE5k57tUByDm0/EI2l5/GKkFp+63exWJSUGb1OjRum8PSqpnDLvNjsZdWN+zVfx+dt1JeHLfy9jT25i37v5+3vT9J+7XgGRwhcsx4POIr0/UnhNxqwu6RacjvVcGgBI6bcF9tnTJ9VVCFiccESmaLaefiqTVirKPXYOuv98F28knobOzU2zb4/PCUF4mxG6k2wdt0A/3ls0Zse83lyEwzL3yBZWSjmR0wHoGnRylaO3oRUeHOe/ztVvlfjr6wgiEvbA7DQj44tj4fpPcv2K0Fxc9BzUIRaX+SYT9SPW2IZ2QAyahll1inwlP1jHfnEohoNXBG/JCr3zPjvv8gz+nTvl7zG6FboTPscMnB8tokEyX1Ih7OtNQi0/MvQyBVAh/2PgvdIf68H8v/AzXL5Dm6kO9I5R5If62Egm07duHhFZ7QP2beyBTVlYmvO0OGrFvUUbt6Ab3h6L6hSL+o7kZ9JMLiW9qz/fqq+PrD0n7qaoqnP5C5x0IBEQZAv1MJSQ26RzUae6y4T4fbBkNwFBmxbJly/I+P+OMMzB9+nT86le/Eu0OzzrrrAH7UWu16CWlefVlpfuZuy5Nn3nmGVGuQZkEt9xyC3bt2pUZoBnPNeyvbXKX0TtB11heXg6PxyPeHfoHRX2H1PlCy4b7fDL3c7Ad+2A738P12Afb+R6uxz7Yzpfv1fDbNG/disjOXWIe3d1Tcr40NRhkBNRkNk7osVcc58Hbr+7B7q1ekbofCsRFz/PZ88oQbZBi0GvTothSBJPJNORx9j2xVsgubVk9Uj1NSG1/A8YlZ+y3e1VeTtmrjUhq9TBrNcOeL82v6d0i+qDPL52Fk2tPxrM730K3pg+u8lL0dfdOyfPuDvZCH5aR9zl1tQM+b+3cA1IAOmcZTDYnKs/+KNLdgHffo7AVlxS87l6/HMQx6LWIJ1IIWYvhcHegaNlSzDj+OLHe9PPPw+xzzkZnv/fcu2A+erq6QZ3qjPEgEkrJr6G8BNUz5w17PeGYLA2orSrNnJv6WVUZpbl3I6WR73XufvqUQDvFONN6O6bNKML2jT3o6ZTvpZoTm5mmlcyBWBj6QBekNAbS3i5UlBShKdAr3k+C2u/R8FlCm0LZjOmgUGTK7x/0GpoVQ8KKefMQG8F7RfObeuR1VznKBzyT6VXT8VX9p/DPHQ9hZ+8evNT2Fk5aLJ/DkH9jZjPSkQhcRhO8Ou0B9W/uocABk8ZP4odEX5eSXqXidruFWCKX/rFCEWb66Q/tl9L5mYnnQx/6ECoqKkQnhfFA0e8nn3wSJ598Mk444QRRsvHII9leqQzDMAzDjI7Au6ul2hC1yo1Tlj47kTX7uaw8YbqYNuzoxtq3ZWr44iNqpPBvkgKxr0gPp2no74DUvzzVtQfQaGE843robMVIBvqQ3LsW+wuDUQZDEloDov6R1UJv79kNfcyE2n3LcO9v1mDu5pNFSUOrb+qildtbGqFL6ZFGGi7XQMO9tFeWkxhd1dmMXq1xSDd+io4T86fLct4dlUtgWTAfM6//ZN56hdr22WfLlP54EEh2tyLWJ2vGTbPnFjxWMpXGq2tb0OuVQclAWGm9VyiN3y4HsbxKHX4uje0yBV7tJKC24FOJ9xP7kXj2byPVuSdnzTSinXszBn2q2FfT+E1KkDPhLlz6ITItMjX7AzXWc7tew11bH0Iknl9G3RuR+6u0lRfcr81gxeWLLxTznmj2WodC71TMFblu/9AW+xT5nDdvnjDRU1O8iffff18MAiyg+pox8t577+Gee+7J+AKoGQSbNm3C/PnzMRXQH1ksmth/P7F+U2V+sv4DT8+MavjJE2Go2v2RPDsaYbvoootE9P+8887D888/LzImGIZhGIYZHfTffb9iYEYkfD7E3SM31DpQa/ZzKSm1oX6WdPnuaJHfF5YeJVu9qWK/dwRi379JutlbZi6H1lEK58rzxe/xTS/ttwESo0kK1ZRGj6g/P219MHqbIpi78TR0bYuTJoQuYYQxaplSk77dTXLQRWdPQacb+LxTiiu+oTTbkk91kh+sZr9TqdlfMksK2936MtR85UuwDdMnnrDPlu0ZE0Egopjzkb2BYUbhev11O7rwy3+/j7uf2zO8G79i0OdVU/3Va0yn0diRL/Zr6vNd/xNKnF795hwNJ6ExyOzmVKes01eJNG4GlJZ8GmsRzMlURuwbS0vlNv5AJlU+F/qbT9NyrRamioHC/YEtT2Jt92Y83yCNAPuL/Qq73H8hnCbpkxCgtIkRoHPIexDzTM2/Q4c6B0waP3HhhReK1O8///nPOOmkk0RbPTJyO/XUU0UaN0XiyWyPorvDmfLlcv7552Pjxo244447cO6554qa6eeee04I/g9+8IPY39B/IP5551vCkGOqqZtRgmtvPGFS9l1aWiqEPtXxq2Uao4Wi+vX19TjiiCPE86fndd999+Hpp58WHRgYhmEYZjyQ+Ot59HGUffITGVOrQ5nA7gbEOzrR55yB9qI5mNn+rnQirxl7BuVYiWci+xMfe1p0ZAWa9shIYUmpVXzfaWtoEEZgRF+RDkeaB2+vRm32Apul2HcsO1WkRztXnAv3m/9Duq8FCXc7DC7ZM31/RfZjvuHFUDKVhG5fmYiil9fYEA0l4fNEYIzY0eRtxXzLDEwF7e2UMu6Cw1W4rDWt1IIbSmuyKewhGaRrcsfR8G4brv1AZcbDiyLtnW5F7M8uBV4APL7IiAdhbLNmyv3EkClp0VsBbdWcguuTMCcaWgNIJFP5bvxpNR4vcSoGfb5+kf0eD3kwJPPaBp6yxImqGic62nz90vgVg75IAlqzDcl4BKleOVClrZglMk4C294SvwszQ6sLlpR0yQ+RQZ/DDq3RKIR+lNL1+yXPhJUuZ6byMmj7lRrT9v6ovN6nd76MC+aenvmsl1oYkNi3lQ16r50mR0bsj+R5qGI/7vH2P03mUIrsExTZJ9f13t5e/OlPfxL19BTJVUWd1+vF7bffjjfffHNU+62rq8PNN98sWvPddddduPvuu+FwOISxHJUPTAX8Mg8PPe833nhDOPz7/X7xQ60ZyRRwvOUBDMMwDEM03Xc/vC+9jOb7/zepxwns2QvPy68IR+39Te/b7wjn/a5XX0fbcy9gZ9kxWFdxOjpMdWgrmi9S+aeChOI8XijSO17IeZ9EPrF0Ra0QibE2KXBiRVbEDdqMKMklGfQivv5ZNN35WdmWzWCGdd4x8jytDphrZJp3uFEa4O2vyD4Z9CVGkNXYF/XCEJUBlrMuXITaehkcM0VsQuxPFZ5eKcwrKmTGRX9SHpnGnzuAklQycl/f1oOHX2/G5j1SzBLd7hASybSo15+nXGMskcoT00Oht9mgL5aDe8Edsl7f5LJBayscTOz1hjPH2NPqRSiaHNyNf5DIfmtPfqRbNRicqbjyEzRsUFZsyabxhxPQWZT2i4pw1s2V72O8W4p/fUkVYLIKgz41sk/vu7FMRt9jvdn7phJp7xg0hb8nLGv5ib6wB6ua1mTvQ1gGKnWvP4ToM79FWu2PmINDyZhJppOIJAZ6sfVHx2n8h09kn1i+fLn4KQSZ7FHUfzAoJX+wz8mN/6abbsKBAP0BUjQ9PsJ/kCaCeCIOg96QmarLrFbzuDodDAU5zpN5R1FR4X/Yh4OM+chZ95///Kf46Q/5MFBXBYZhGIYZK6FGKXR73nwLM679+KQdZ+evfoNwcwt6aqeh/NSTMZnkRtMoTX/vb+5AKhLB9nUbsbb2PPiKs//tDBmcCO1rhPOE4zBVNft6w8R/D6HvNh+86gi8++YuHHeqTNmOtcpU8kCZHARQ0/jTyQS8a55BZOPraOzaK+qhxXkVVUB37IegVYwECXP9YkSatyHStAXOI2WP8cnEaFTEvlaPZGDwNmoqXaFekbJPuEptKK2QQtEUtqHJI8Xh/oaixCm/vI7p0yoGfE6CMe1XWsiV1gCRdJ7YD6Xktm9taMPS2WV5kfaaMhssJj3MRi0isRS8wfwo+1AYayqR8ASQjMrj2WbKaH8hejzZUuDVW+XABH19tlsM6N+NUW29RzX7uX+LLd1S7M+ZVoTdLV5xDfT5zLllwlCSIJG/cIYLa9a3ZsS+1pzNONKarNDXL0N81X8zywyuaiSCQVjC2Zp9gur2I23tiPb0AIrwV4kokX1zddWQYp94YseLmLf8U+Jc1ci+o6cdqXgS/o2vwnnEmXnrm/RGGHUGxJLxTIbAyCL7HgwcOmEOObF/uCBG3Ez77/ZrtGkYDPrMVF02WUKfSiXWrl0rBm527NghsjSuv/76jCs9fU7QYMBgUAkHdUz48pe/nNmGnOzJ0Z6yMqgNH4t9hmEYZqyk43GElQhXrK8Pvq3bgPL87j0qqUQCLQ88CPrKX3qxNKAaKfHubiH0ib7VqydV7O/81W/h2bEDJT/4LsxVVXA/8ZQQ+vqyMvQZquAzV0CfimPlqXPxzhv7hNgP7luLfJuwgz+yT9TPcsFonS6c+IlYmxT7nmKSFAkUKWn8wZ3voe/FuzLbacumo+zES2FbdAI6FRMzFfP0RcAqINy0db/U7RuVNP4U9ZEPDl8D3el2Q5uibdJwOo1IbqaobLFI42+LeBEcYR31eKF787+730cwEMIRHyyFKSIFa3U1Rc7zvZwSvh7R3lCjM0DvLAMi3XliP6qVz++tTW349CVLMynwRG2FPRNhpzaFvlB8yHOKKgNMhGn6dIS2ZuvgnUuP6Hdmg4j9bfLfDJvZUPDddSqRfUr3D0eze2ztlvs4fmkNGig7IJKALxjHrFkVKCqxoMsdFsdfMKME7yhiPxpOQKPUwBPGiumiPl9nL0EyIKPshpJqRBJtsCTzxb5atx/r6R0g+CIdcsCC/o3oT7ci9peUzscu7z6REbLd3QBLiQ2xVFxkJxcr99H9+v2wLzm5YHS/N+SGLxqAHeaRiX2O7B/6afzMocNjjz0mem9efvnl2Lt3L+69917hwaBCnw0V9acBgp07dwofh5UrV4qfFStWiOmxxx4r3Plfeukl0b6OYRiGYcZCrLOL2r5kfu9+Y/AywZ7X3xCp/j33/w+rr/s0Ov95t4imjYTgJtnDm3CvXS8GDiYDEvXdr70uavK3fP+H8GzcBN8bq8RnFdd+DImTpU/R/GVlOPpkGe0OGxwItVD/7sk5pxFF9iehZr8Qahp/l1ObF9kn131CW7MA9V/8C8wf/IYQMBrtQBd3c+184c6f9PUgoZjKTSYGJbJPJIcQsipdfbL2W2tJofv5FxBfLQ3WrIrYbgtO/jkT4WAc2zd1oHmvD688sTuTbVBWPtAXI94rB2H0rqq8e64a9Kliv88XxbZ9Uoi2KpH9WmV/Tqtch8TzYNx+7xrc/Pu1mZR88xzZYo/QaAHn8sGzW3q8WVf6hhbvoE78Yr9GPYwG7QBHfjWNf05dMcqKZLCroy8invFHP38cNkP+PSyY7soMOtB4UkKfHYozlNeJqalqVnZZgTR+sU6pS96/Amn80W45oFLInK9HMeGb7qjBmbNOFPNP7XsFbUo3hxKdOTN4kPT3wrfm2QH7UP+2SOyPNI0/5mGxPxmw2GfGRSgUEo771Nlgw4YNosaefBXIaJGMEc844wwhzq1WK37xi1/gnXfeERF7qrmnz8hhvxC0DkXxqV6/EBdffLEw7CMDP4ZhGIYZCzEllVVjkl/ae1e9Pajo7XtP1q1qrVaRERB45z3su+ueER0ntGlLZj4ZDMK/XfaqnmiiSq9wtSZ3y3d/INRC6fHHwjRrFnZtk1/wZy2tEpFErU6DlFaPsMaMWEcnYn1u7Lrj94g05Lb4OjgN+gp2QVLEfptdqbdWavaTPimGtBUzoXcO7jIu1jGaoS2Xrf0ijdnnOlkYDCR+lbT20PADMl63FLLki9z4r//AGlfEf9wEbVKPtoCM6E424XBW5AYadNBAC60esDsHZnTG+6TY7294qEb2Y4rYJ1ZtbEM8kcKmhh7x+zQlsl9kk+sMlsZPrQfXbOtENJ7C9kYpZk0zZfs9cWyHXormQbbt8+W3oBusXl/FYdHn1e1TRoFqKDij2okqlyWvfaA3nABJ9WK7CdVlNvHEk8pzj2mzAyTGctlpwNhP7GuM1kzrPTLYE+so7fcost+fiJKxYiovxzvNa7G+e+uANP4yiwsXzz8LVoMFTf42/HnNv8XyUo2SIaw48nveegjpWLig2B9VGj9H9icFFvvMuNi1axc+/elP47rrrhNp+j/4wQ9ERJ7S7G+77baM1wKJf+p+QMvvvPNOnH322bj11lsL7pPWe+GFF3DcccehuLi44DrHH3+8cPt/9NFHp6w/MMMwDHNwE1fEn/2oFTCUFAsDtBCl8veDBgDc69aL+eovfQELv/MtMd/5wkvw79o95DFIsIQVt2/TDCkS+1ZnDa8mkliTFPvGujronU4ZFtTpMP0TH0N7SwCRcBxWuxGVNXZotRo4i6XwolT+WEsLdv/+j+h68WV033f/pJzf4K33Jt+2mFqNpShSrNWgzSpFc5Ei9kUaOX0pthX+ztEfbZVi0tckBVIqFkbKL/cx0Wi0Gmi1yvecEXg9BX1K/3d3t8j0MKRiMCSkEDNGrOgI5ZclTBahAqLbVWotWD6qRvaNVK8/iNivcslU8FUb2vDflxpFvbvdoseK+ZViudM2dGS/2xtFVLl/7T0yI0dns0JvlcLVUlMxaGkrlQaQ4Ke/mcqSbEp6obZ7KnY100CJ7Dd3+MWfIw0QlDhMmeuhyD7R2Sej/uUlFuEDoNdpMtH9mEZ6TOSKfVN1dqBC76qGhiL7/dL4TUqdfv/IPg1Wxt1KR7ASJ3779t/xz60Pwhfx56Xxl1tcKLWW4MZjr5X3zS+zQlwJxdNiyRkwlE1DKhxA9NW7kIpmS0QcRkXsx0YS2Xdm3PiZiYdr9pkx85e//EVMKcKu1uKr8zTN/UeT0u//9re/DVhPpaamBm+//XZm2fPPP5/ZTyEoI4DaJ/Y/DsMwDMOMFDXSa6ythb20FO1PPIUARfDPOTtvvfCu3VI4FRfDNL0erpoa2I89GoF3V2PPn/+Giq9+adBjUCo9EgmYKitQfPaZ6PzrP+Be8z4s55874dcTVXrI25YtQd3pp2HXb++A5eiVwnF730vys/mLKoVoIYpKzMIlPWR0wvPCS4i1yHK7WHMLAhTdt2VFxmSm8e+PyH6oqUlMjZUVSOrS0EIDq9GCAPxIKJF9zSBO7P3RVc9BYuPzIrJvWHoeWv/+I8TdnYh9+pcZMTaRUEQ8RZpRMZIbjFQqhURQPltLTzs0ej0qzjgNti1eePQWmMJ2eKJS0E024ZAUuRGrD0ltAraAC8WlA2u3KWAT3rdJzBvK6vKWJ0NZsX/60go8/W6biLC/vpHc5oFPXTgbxQ7TiMR+S1dWiKpin7DNqIJ3awuKjzhy0Gvp88lrcTnNmFNrz0ToRxTZD0SBUhP2tfsyUX363to/st/lludX4ZIDIiV2IxLeOOjqImmLmBLi/fIFYa6dB43eCNiKoTPbAJMNlv5p/JnIfv5AVEIR+hqDAR5DAsm03G5H7x4srVwAnyLQy8zy72Fl7TKcU38ynm+SJSGuiMxW0DrL4TrnU+i4/ydINW9G613fhO70TwFVVRlH/uHS+F/d+zbcoXZUKGUbqUG+9zNjhyP7DMMwDMMclsQUcz5jTTXKT5EmU4F169Gz6u289UJKzX3JyhXQaOVXp9IPXQqdxYLArl3wv/XOoMcgYU+4Vh4Fy+JF0Oh0CLe0It418bXT0WYp6E31dXDMnYMVd/4WJeeeLYTTvt3yC/78pdlU5aISNbJflBH6WrM5k7UwmdA5ZQz69oPYDzZKsa+tkZFgm8EKLRVqk/jxq2J/hJH9itmiyJtq9iPP/E7W/KdT8G96bVLOXadkPlA796GyGaktml6pjbck/Kj54MUoP+0UWGPeTPs9b2z/iP2I4i+Q0EehXdmJE8+cjaNOyI/cE6n2XYj3tgIGE2zzjs6LPqcVM2eq2a8sMeGYxdl398qz5mPJzOzzytTsD+JrkNv2Llfsz7/lu6i67sOouUJGrwvh9kuxX15swayabEr9kGJfOR9vUG6riv3p1TKK3T+ynxH7JdZM+z41sh9Ny79TYcxnldkoOlsRpn3mNzBfdLP8zGjJpPH3N+iLe315IjreKyP3+lKXaK2nsqOnAZ0BmfnhMNpE+r7KBTNOw5HV0hR7mpJur3GUwjJzGao/9kNxbvGeFkQe/wWiHXtGVLO/vXs3/vDePfhv0wvi30Ui6d8/7+fhBIt9hmEYhmEOO+jLL7nkE8bqatjnzoHruGNFFH7Hz36B5gceFMKKfoIUnReCfWVme31REequvlLM9z36eMGIFG3rfn+tmC9ZeZQYHHAuXiR+D+bU8U/U9WQyFeqzEVKivcWLoD8ujMCozZcKRfaJsMGZMeua91XZprj79deRimXrrieapJJyvL8M+kJK1kOqSgogu1E6nKcTMaTC/lFF9jVGc8YgLd3XKt3d6JlueXNSSgt1Rrn/dFovRPBgdAS6YYxKsWiOB1B8xHLYZs7K1O1bgjb49pPY9wdkxDqhj+HDR52HMy9YmHnfcklskwMk+tnHiLZymeVKVJ+IaQwocZpwzjGyDGbJzCJcdc78vP0MV7Ovtr0j2nuyAtRQXArbcadBqwziFcKtpOKXFpnzxP5Qafx5kX0AjTmRfUKN7PdSeUE8iS4ljb+yRC4vthuQUGr244YSQKuDtnZh3jEMxZXQKG35ZBq/HDyLJKMiy0PvsIvoPZHMMbRO9Cli3+VCbyi7fHt3g3iHxHnY8437aGDslpM+j+8uvx6z/XKwRGOXBoDm2rkwf/AWmKrnANEg2v/zA1ii0SFr9lPpNO5e96CYT2sAXZG8L0kfi/2JhsU+wzAMwzCHHWHquZ5KibpdXXGRSJ1d8I2bUXTm6eLzpn/fh65/3C160Ce6e0RKdNHyZXn7qL7wfBhdLhGNUg38cgnu3YdYbx80RiOKlizOiH4ipAwgTBQhilwrX/D1JfmidftmmcEwZ0G5YvjWL7JvlF+0Z17/KbiOPgr60lLR5i2o+BRMBkklqr+/avbVNP5ouYyMOgyK2A96MgIexmwkczhECz5Cq0PVFd8UkWmq/Y+27pw0R/6kVo/UEO332r1dMESloLbE/bBOmwa91QKnVd5fa8gGfywohOBk0+dVRJshiSOrlxRch8onko0bxbx+4Sl5nyXDihM/mcFpNHA5jFg6pwz/+L9z8MXL5kOnlKKoqGn8/kHEfmuO2Cdn/dwWfMPh9knhWlZsQU2pBRaTbtjIfqZmPxgTA0B72rx5Yt9h1cNmMQg5T5kG1HZPTeMninMi+1SzP/2mf8B48kcGPR615zMrkX0iFA+Lf9PUfwsS7hyxr0T2DaUk9uU8scfdhGavHDCs6if2CRoQKYnLs9LZimUZgXp8axGqr/muMK+kGv7Eu0/mif1YIobvvPhz/GPr/+CJ+LCmayMa3I0DHPk5sj/xsNhnGIZhGOawQ430WuvqMt4vlEpadsXlmP25z4j5wHursenb3xGfkVgn4ZSLVqmJJjpfHJj23vfeajG1LJgPrVF+MS45StYGR3Y3TGjkPLBnr5juqj0VTz2wE4lEVszs3SVrductkinsKkVKKnHE6ITrIx9B6bFHizIFxwmyBZmvXznDZIh9uvVkQjeZkNhSn3egTIp8u0GKqnRQljfoHaWj8gByrjgX5hlLYTztOljnrICuXg4EBbYO3r5x3GJfo8+0oytES2e3dL1PJWA2pITpJFFcraR+x23iXnj3Q92+xydFnsGsHdz4bt0LovzBXL8I2iGc+I0GnTDjUw3sVM+JXDI1+6H4gOyKSDSBbo8U7GR8R3T2jqxtZn5kXx576WwphMk1fzBIzKuRfSoDINFPAxSq2Kd7onYS+OcTW9DWHchL46fIvjpsEQ7FobPYoVEySApitAojNqMykBOIKSaEyjuQ6HMXjuznpPEnUgm81SQHLascA8U+kQ7Ikhd9cf6/JYTWbIPp3BthrJoNayiYl8a/u2+f8AQg1/+vP/sjPNbwQv62TnkvOLI/8bDYZxiGYRjmsCPUnBX7/ak67xws+v53oLVaRIQ7NyLfn4qzzhBTz7r1iHbnG2H1vfuemNqOyGYEWGprhdEfOfz7d0mX/okguGcP4loT9iQq0NbkR1uTjCSS8Ontkl+8q2qL8rax2gxCSJI20ixZkVkuxL5Gg8iOnYh0Tk6rtoTq6G3QTbrRbqSjQxgsUmcCt13XT+xLsaN3ZssbRgK1O6v5yPehnykHb/SzZIlHcOtbSE9w5Dwb2TcgFRxcpHb1yFRxcyIIU1Vl5r66ZlRBI0zYDNDHzXDnCLzJTuO3mAtHv9PJBPwk9kmoH3XegM9Vc76o1ihq5Yd7R9Sa/UQyjWA4P7rf1OkXEXQy86stsw6o2x8OtWa/rFgOjn3pyiPw1SsWYNmcwd8ZhyVbs9/UKY9VXWoRAxcq86fLqPvaHV2IxJLQKIMZ/SP7IaXufyg0eoOItNuU8hhVZGci+zlp/Lk1+70hOQig+le0+NTIPlnmDSSt+FvoiwsPBlA5gevUK2FT/gbUyH5HIPtvIw02+eNBlNtKhTeA2M4hpxzZn3hY7DMMwzAMc9gRVsV+v/p2leJlS1F769dhqa2BxmRE6fEy2t0fcro3z50j2tx1vfJqZnm8txdBirZrtbAtW5pZTqJFrdv3bc72th4vdCy3JRtt61UihZFwQrTcI1z9IpF0LqXKMq/iME4YXC7Y58jWXoHdezCZkf39Ua/v3SBLJswzZ6BXMasrMjnzIvs6h6zlHyva2gXQmu1IBj1IdQzdjnG0mIz6jNhPDJHG71Hqvs1xPwxV2XfBMqNepPWLfYVt6AtPfouzkOLGbxukrp0c+OleweKAbf4xAz5XMxhiWn1GAA+FQa8VafGE2y+j+Cp727L18hVK6Up771jEvjyPIrsJC6fL0p/BsCuRfV8gisZOeS3TK/P//q69cDG+cOk8fPT8BTj1yGm48szpsJoNYxL7BL1/NqVu36dkb+jVyL67QGSfDPoUsb+gRHpQqBRK4yfSAaUEoKhi8POwFsGqnEcgFkIqncoY/x1bdQQunHcmik1O3LDyGpgNio+DKvY5sj/hsNjfD3AfeEaF3wWGYZgDLI1/ELFPGCsrceQdv8H023+S6VldCOeJJ2RS+dWobnC9rEV2LlwAnUOmUauo9fveLRMj9sm1nPwB3JbqzLKeLin2vYrbt91pzESIc3GV2/LWUzFXy31NXmRf3qdcD4HJwrNBPgvLwgWZSGaJqSg/jd85PrGv0elhWyAHhBINsnxjojAaFZM1jR6xgBSuBVvYeWXphiUREO+uiqluGqxxKfDtASs8kckX+9GwlKpOe+H2jeTYTuhq5kOjy7ZiVkmGI5k0forsj4RiuxTynn5iv7EjK/bLleh82wgj+8lUGp6AHCwrKxq5p0NeZF/JrKmvtA4YoDhiTonoLPC1jx6FM1fkdMrIMegL54j91av24b9/3YS+AuevtdhyxH6goNinfyvUlH6DqxQ9YTl/ZLn8N0nFtOE1RB7/GZKh/Pct5ZcRen3x4GJfZ3XCqmQYpJFGMB7OiP1qazk+ceTluO24r2B51SIYqK8krae8JxzZn3hY7E8ias/40BD1VczhRYTSCHPeDYZhGGb/Q871YaXtnqVu2pDrUu0+uegPhe2oI6GzWhHt7EJ4hzRoC67fIKauYwdGLdXIvn/7jkx7sfGaDVL9v8daQOy7o3lmfIOKfWU9FXOl/DIfnSSxn4nsGyb3qygNvngVM0TrwgXoUcW+WYr91BjT+AthX3ySmCZ3vyfb8U14ZF+PeCBfDL3V9D7+tOnf+N07/4AuIp8xRfENVVnhqKUuEEb5nhV5rfslsp+ISLFXbM+61+cS65QeE9rSwoNtiUxkf+Rinxz7Cbc/f+BqX25kXxH7HSMU+1RzT4KfbAJKHIX/hoaq2Y/GkmholX+L9f0i+0ORG9kPKp4BxKb3W+HzRNGwXYrnXHR5kf1+afyKQV+M0vlpQFKrRcxmQjgu79XS0vkwKIMuZp0JyfdfQKq7Ed41zxSM7A8t9h2gITyLci7BeAidShp/mUU6+KuoYj+lDEQO1W2CGRvyDjOTgk6nQ3FxMbqUXrpWq3XS69IGIx6PI5lMZqa5y4b7fKTL9tc2U3nssZ5vIpEQgz70LpSWlop3g2EYhpkawq2t4gsviSBy08c4BS2Z75WfchI6nn0ePffdj+oF8xHZJVO5S487Bp5+WV3WumnQ2myi/jq6rxGorR3X8QN79iCmNSFgzLrw9ypi36NE7Au1PRPnV24fkMZPmJU08EjH5NfsTybRpmYkAgExGGOYXo/eNjWy75zQyD5hnr4EllnLEd6zAT3P/R047VOYCAxK6z0S+7Fgvtj/98ZH0B3sBfqAWZETMmn8xpw0fqKEyjW8gDlsgWc/iP10TCtq0Ev7ZbWoxDr3ianWNS0vO2HzHX9CuLMTdpMilrUG1I0gjT83st/ni+TtM7fHvUETGVUaf49HegeUOM3Q6UY+MGU26qDXaZFIphCMJIQRZV25dVTbG8j1P0oGfdLRn/Ar1+ZVzqt/Gr89JAW2N1I4jT/aJQcJKFPJm5D3wGawwGqwYI5rBrZ170KZ0QHEZeaT7/1nUXz8JWJetCJVavZFGv8g1QUag1nxD0ghrNMKsd8RlMctNed3CtHr1IEsqY/Iy4SZWFjsTzJVysiqKvinChKdJDDVae6y4T4f6bL9tc1UHnu852symTLvBMMwDDM1BElgU3o01eNP0CB83dVXwv3+WhHd33TLt0QNv23mDJgpnbpDZhGokOO9Ze4cEf0P06CAUgYwViiF32OR/22xOUwI+qNw94aEI78q4osV5/3+lGYi+xHxZV69H+K8SexP0veXbGR/csV+eNt2MS1auhjBVEQ4jtM1FpGgyTPoKwXGmWRB+y0793o0//krCO9ZB+PMDYBSDkEkAm54Vj2E1Kzj6QviiPerljokNQYkcwz6osmYFPoALl98IXZtSIlLsCSDMJTnZyq4qkuE2NclrOib5DT+eDwBbVJKjIoiKTZzScciiPfJvwmtKzvQ1bNtF3wvvSjm1QpzGdknkTz8w5lZU4Q3N7SJn0tOnZMR/v5QTIjt+koHEhEp/KmvPQnx4ej1hvPq9UeKeMfsRvR65d8fOe+bCpTRDIWNBi+iUWGgGY0kxN9nRuwrrfoGpvGrBn2q2JfiOuUPiOyfaLci9svL0ROV98JlciAV6MOCstlS7CObfZoK+RDY/AZQvQTJoBdIUuRdA31RGdDdO+i1a0Uqv3xmXeE+BGMyU6PMUlIwsp9UxlEmItOJyYfF/iRDL3x1dTUqKipEhHeq6O7uRnl5eWaau2y4z0e6bH9tM5XHHs/5Uuo+zU9VdgfDMAyTFceEcdrQKfyjwVhcjIX/901s+MY3Eff6Bk3hVzErYj8yAY78oX2NcCtif9GyKqxf3YJ4LAl3Tygj9tU2e/1RTfuC/jhu//ZzcJVZseKEKiydXZmJBE7GF/Bkcv8Y9Kliv3j5MjQpItdlLoZOq0MqHgWiwUzrPXjGXy9scNVAv+wsJNY/i/g7DyK14jRojfLee958UERKdX3dwNzFI9+nIRvZT+SI/a6QFFs2gxWXzjsfP43KlOtilxWafuWCrqoSYHsASVjhD8uo7WTR5c86v7sc+R0giJS7VVRz6xwuaCzZyH/zhm1i6tHbYaupFKU2O231uJwi+0mZqTIUZx9bj/ue344djW5sb+xDsQmZqH5liVk44RfZZCu/WDyJXl8M04ZJqulWIuijqddXKbKZMmJ/du3AQY/hcNpMSPZGoINGmPRFQgmkFDFfUOwXSOOnDCLKPBJCv7cvG9kvL4cnKv8ebD0diGy/HRfc8Eshypc2KyUoRisQC8H73hPQf2AREl458CeeWwGfhVx0ZLyYkin/jf4WeT/MTph0+YaNaulAUpMWteUs9icertnfT1Bk12w2T9kPCc3c6WDz41m2v7aZymOP53w5dZ9hGGbkhNvasOX7P0REEeYTiXDJV4zLJhLbjBmo/NQnZfN4ipoff+yg61rmzRXT8O494/6CG2wksS8jyDPmlKG4VIrL7k4/fJma/cJi32ozYsFSOVAQiybQ0erD5vc7ZXmDTifSamOKe/dEkohPvkFfMhpFuEEawRUtXw63Im5KrUods0/WEWuMFtEjfKIwLD8X+qJyUSLg3/ByZnloz3p5Xm3bkRat8EaG6mtAbvzpHB+ojpAUblXWsoxhmy4Zg7NmYD21q06WKaQ0Jnj9I3eiHwvdPin2U/qESGXvT6pXij9T5cy85d5d8lnttNXh7vIz8YfpH0KjtRqlI63Zd5hxzEJ5nY+/vgepdFpMc+vlKeBSowxwdfUrXSlEr0euU6rU+o8Gpz0rbGdPGzjoMRwOW74jf1AxChwsjZ9q9u393Pjpeo2KuWikvT0b2a8gsS8HQpzRKBAJwNDZhOtXXo1Kt1zHcOT54m8j3tOCVMs2JDxS7BuGqNfPnIvNmRl4aPTR4A5QZRvoi5GN7CuBME7jn3BY7DMMwzAMc8DR8cxzond93+NPTuh+KRVWjexPtNgnbMuXigh/xXUfF+J/MIzTaqGzWZGORDLnMxbIvTroDSNokgJ2+qzSTMp+w45uJJNpUWtMbvyDccW1K/HJr6zAJVcfIX73+6LCmNBQ6pq0un06r8mO7Pu2bhPiwVhaKlooqmK/TBH7SV/vhNXr50L1ys6VF4j54M73Mi7mCbdSzhEJINYpS0lGgtpFgdz406GsQO0MycGKCksZnn10i5h3RntgnVYzYB/2ynLok3LbkC+G5CgGG0ZLn9I+TWss3IFIFfvGyvy/j2RLk5h2mlzoUSLiZHRnGsWA0FlHyYGrVRvb8N+XGkUPe4rkX3Bs9p5UK2K/WxHyQ9HjHV9kX2UskX2HlRz5s2I/lGPUR+n8anaMCg1YZSL7kWwmhHPhQjFtfeSxvDR+tyL2ixJysDG8b6P49zHVKzM/dFVz4TziTDEfW3UfAptfH9acT0VnyYr9tqAcJKgs0M4vW7OvuPdzZH/CYbHPMAzDMMwB2xqP3O1VZ+6JIOnxIEHtnbRaGGqy9dQTiWvlUXAcN3hUX63bV7+Ee7dIoTYWoq1tmRR+V5kFVrsxI/Z3bpVfsik1X6tGzgaBRHftdClI/F5pCKYvk5G4SGfXpLXem6yafRIN3a++lknhpwinW0njL7O58iL7Ey32Cdu8o8U00rgFyXAAqVZZTqAS3iu7NYwusq8HlJZ0uWLf0FCJxoZe6JHE/O63YS2Qm24qdcESlxF9S9CMQGzyovuegFIaYS78zqX7VLE/M69rgqFXpo8Hc8SkaxQO+ERdhQ3L5pQhlUrjlXVykOozly5FbY45XlWpEtn35HegGMqgb7Q1+wTV7KvMrB1fZD/cL7JPXfl8/QYrtJbcNH5/xtSv7soP0x+46Erh3ST/rTHnRPaLlL/F8N6NSHi7gVgY0OqhKalG0XEfFJ0qKEsltPt9sZ6ezPmGQduv/R5RCh1SAdWNIT+yn9Ao63Jkf8Jhsc8wDMMwzAEr9pFMwrNu5MJoOKLNLVlH/Clug+pcuEBM/Uq7vrEQa22D3ywjZlXTpLO+KvbJqI8orSjc/qw/RYqgoRT7cCgOg5r+Ownt91SDvslI4/dt246WH/8/dL/6el45hRrJLFVMwhJ+pY2YY/xt9/pjcFVDU1xNKhahhrVIKmJfZ3dlhNWI96WKfY0BmnA0L42/trkEfVvk50tC62GL+2Ap4EVBddsWjdzWHjDDG5u8fub+oBTIJstAa7B0KomUu01+nhPZT/T0QJ+II67R4ZQzl0CnDE65hshIGYwPnDwrM3/aimk4+5j6vM+rR5jGH0+k0K6UR4wlsq+m8ZcXm2C3jP7fGqeVxL4UwaFQPK8FX6FU/tw0/ngqgUgimmmjWXTaKWKeavezNfv5kf1YVyPCDevEvLG8DhqdHnqHC9M+8xvojzhfZKyIzyry72chdNZsZF/FuPo5RJ/6tXgHVLQxeY4JZVyII/sTD4t9hmEYhmEOKJLBUF6deN97qyds3zFF7JNT/lRjV+r2AzvHbtIXa21FWG/Pq8vv77yvmvANB0XZ7Uok1dMXykb2JyGNPxvZ1054p4XN3/6uGATRO+wo//hH4DpGRtkzafz9Ivu6SYjsi/1OXyamoR3vItm2Q8yXnHqlmEaatyGdGJlxs5r9QJF9bSQqouCJVBK9wV5Ma5wnPqsLNaC0TQ4gWAZp5WgzyHtuDpvhVWq6J4NgSAo4m3VgVD7e20ojPaIWXF+SbQ8YUQb3uo3FmD+9GCctl9dQMYjXxFAcvagKRy+qxLw6Bz73IZnVkUt1qXVEafz/e7UJbn8UVrMO06sLtxAcilqlreXcaaPftlDNfig3sk+DWv1M+iiyT5UTBiWir9btEyUXnAedLfvvgKm8bEBkn/C+J8umTFXZrAut0QLjUReh7nN3wHjWDbDNHzpraTCx74rFkQ70IrRLZggk/G7Ed60R83H1SlnsTzgs9hmGYRiGOaCItcvIH6XaE+7335+wiE+0RRX7+eZgU4F9zhxh5hft7hFO2SOBInOx9mwrPxK1EYMUFWpdvrPYBE1O2n7ZCCP7RJHLknH7ViP71E5wokkmlJr9CY7s977zrnhXzLNnYcUf7oAzp61hJo3fOvlp/LliP7j9XeFqrjVZ4Vh2OjTWIqQTMaQ6G0a0H4Mxm8ZP2c5UhtIZ6Mb0ljCiOvlsa3qk0Nfa7TA4C4tLh03uxxizwhcb3t1+rETCUpQ6HAOj4dFOxS+jcgY0mqwM8e6WHgbd5lKUFpnwmcuW4uMXLMQ5K0dfakMlK9/91HH4+lWLYDUPjKhXuKTY7/Nl+9f359X3mzNlANdfOKfgfobj+KU1uO2G43Hl6dMxFhwisp+Txu+XUXmtTv5texSxHw7FsG1DN2KQgytq+z1vJCv2SehPu/wyOV9UhIgmiUgymhX7iit+vK9tQImFCqXz66cvh0arG5vYj8t/w33rXpDnt/pJ6JR/12Mp+c5wGv/Ew2KfYRiGYZgDilibrN0tXrYUWqsVCX8AEcVBf6LS+A+EyL7eaoGxtmZU0f199/wbzd//IbrfWCVErRD7ehmxcxTJL/s6vRYliqAhXOUjd5ovLrFmhITaq30y0/iHM+jrCfYhnBjeSE3Fu0GKXvJMMDidmeXxZBx+pWZddeNP+nuzbfcmAW1ZPXR2OpYUX+bpS4RQ0tbK8g01tX80afy0p7Ynn0arrwOLd0WR0MnI98JPXiPS950nZQc3+uN0Ku9H3JJJ4+8vdilj4Fer/orH98h+96MllU4hHpX7LHYOHGSKde4taM4XbpSR/YirSqTwk9D98Jnz4LRNfKlNuVKuEkuk4O2XGk80dfhw54OydOjKs+dh6azRm+sRdB1Hzq+A1Ty2TucyjX9gZL+sQv6N+pQ0/jdf2o03nm/EuvUyUm9X0vLV9nsqNRddgJoPXISyD38IfSHZMcGS1sCUTmcGplRM1dlSiLGgtTpgTWXfLRO0sCuDEFQqkOprg2/t89Ar7188La80rZw7M3Gw2GcYhmEY5oAi1tqeEeTWpbIfeVARceOBjP4S3T0HjNgnTIpjv3/nyOr2A8p6bY8+JkQ4pcPH9PLLv6PIWDCaXzoKsV9Uokb2Q9CXSrEf93iQovZc+9mgr83fiS8//T38dfP9I9onnaNfGTSxLJyf91lvWIobo84Ah1Hej4RPqdl3TnzNPkGRa6ti1CfOaeZyMdXVKGK/bWRiX6+48VMWSEqjQ9vjT6Jz4zpU9UghrNNpUHfeGVjx+9+i9NIPDrqfkjLlnUhRZN+PRk8LPvno1/Bow/OZdbZ378Y7LWvxUvMq0XN9tHjCPmgTUtyWFg3MMIgpkf3+Yj/dLtuz6WqHrwcfLwa9Di5l4KPLPfAaH3hxF6KxJBZOd+Lqc+SzmgoGa71XUWPLZN8QZM5IBMLybypr0hcY4Nsw81PXwX70UegJSaO8YiX4rpt5lDDlk2hgrBhbNoKKzlqUF9kvhR7ZXKM0oi/8EeloCDplPCABuS7X7E88LPYZhmEYhjmgiLVLsW+tr4Nt2VIxH9q4adz7De2TqcLUii036juVmGepYn9kkf1ojxysCOxuQOcLLyGi1OsbTXoYTVnhXFohBYHJrIPVNnKTs2Iljd/TFxatAdU630SvFBQTLfbVqHUh3mtZL4zGGrz7EIoP7Cven8juBpEGTPXIqt9AboaAmsJPNdxUL59S2pPJ6PvkYJt3TGbeOktGT3VKZD/d2wz/xldEdJ3q8AOb30B87VMDavlzsx/cFUVIRSJw3v0cosogD3Vg6F+XXoiSKhmhTmms8IaD+N/mp4Sgf6djnYjIEzt6ZGkBabCdvbJH/WjoDvVCl5CDENac1nMqZAJHmCqyYj/mdkMXDiIFDRyzxycyR0rF/2fvPMAbO8vsf9R7seTe7fH0nmmZZNI7KYQAIbSwLIS2dNj9s+zSFnaBBXZZlmWXuhBaQllCEtLLpE8mmd7tce+2LKt3Xf2fr1x12ZItz9jj+5tnHsmyLF1JV9I933nf8/IKlsmsvnd/MIaXj7FS9jsub0oGBZ4PWBk/U8M+TwihIJP+NfXGZEBfNBLH6DBz9MOhOGQafUYifyGcQSb2zVF2m3JLNbSNLP9BZqmmffrzQaEzQSskIOfOvZ2/3+miAtm/fHyhTXT2wUS+VMZffiSxLyEhISEhIbGoiPIyfl1TE3Tr10GmVCI6PgH3iZPzul1/LyshNnCBvRjQ8uwAX9fZpKsV9abGZqVDy/anmUNNIA5vSGVIivR0wVdVY0qG9hUjBEUsXASJrqG2loWoRSenFqZnX1nY2T8yxl5vcs1u5+xz6YOnWdWDZVNuKJsjkBL79DaDTCARN5PMJ18odK0boGvdCEXbRVBWsP5zGZlBvmY3PT/50Pcxdt/XEPq/r2Liz99F9NAj8Bx8PKcHXTRdz2xhSfvKUBRhBXutDMbiSt0tdXbIBSamhh0O7B8+TM8HYiEMuJjAPT3RjbZTF6P19E4cPFZcpkA6k34i9tnikk6fuV2JkA9xP8tNUFWmJgb4eYuOU2VGXR17fc6V2M929l856aAp/O31FrTULNx+UQwmgwriso9zKpBs0amsSb1HJ8f8SPBy+XA4RkW2mMjvSevZz0Z09i1h1sZAciR07VvpeXnaQsxcIWGBMsiSCw+2EGvFUa6/EnId+2xSmOxQa9hzHOE1DPN19uPBIDr/7T/gL8Pi8IWCJPYlJCQkJCQkFg1Rtxtxr5eWLJPxeAqdDtVXXUl/d/b7/434PMrJ/b39iyacT0RVWwOFXk9L0CMjIxh/8insf/d74XosVVotEnO5ACFVGktcsKBSFPWZTtzaTbXYvL0R2y9lmQDZxIU4Br2jENJuL9PZZ+JCW81makd5RUHZe/YLOPvheASnuctM6JqaPbMheIYl3lt4NUg6U1zciP36CS6EZDpTSYshpSJTqFD3zi9Dc/X7Mu6n+k2fgmr7G+liQ7DnMBLuCZK8Rn/nPfJ0zmKP+DxN2LWwbGYVAh49E0r6IsW+prIS2hirZuDxBUlOTnZCSCQwMOCAwWuH0VOF4ccVePj+M8kRjsUw6XcmnX2dPrOiRHCxYEmZ0Ybw1DTO/td/Y+KXv8Hoo4/Ry8c1NtQXOTlivlTx90u62CfP+QtHWRjl9Re3LOh+UQxatRIyHsbHDX6YzFoYTOx5Ja7+QDdbPCGEQzEejCem8RcOYXTy94M5Fmcj9dQ6WHfdCvv174Oa7JfzhIb4aQ3Q822pCLDnWW6tgWXHG9hll70VKh4MGOHOPknjLxSaWAyOl17B5HPPY+pPf573Y7hQkMS+hISEhISExKIhwEdwkdnQCi0LH2v9q7tZgvTICAbv+11Rt+N48SW4n3sh4zJvFyuVN/A++cWATC6HiY/g876yHz0/+ilRHQh155ZQx6bZAbqy0g7DChagJYbzicF6IhqtCm98+xY0tllybicYC+Ore/8D3zr4IzzT+1LG7yw8vIwIB/JfdPbJHPSFEfu5zn7/r3+LgS9+Bdq08LTOWcR+zOdDmO87lo0bCjqZlaLYDzBnX6Yvrp0jlpUsXg4xpNp8PRr++pswrN0N1fbb0Pw3P6Cp6JGJAURGM111Fe/bj0UFVLz7LRiuUqGn3lqS2CftK9qoLzl+j3Bx40X09MREJ8b8ExB87LZiiggSMgEjA14890RxeRKEMd9kYWffNUZ2bfgmVTj88U9j/Imn4H3xJUy/diAp9sVxdQuNmMg/4UyV8Z/pn8aIIwi1SoErL0pVHpxPSBtOOiaLlrZ1GPiIzO4zqSkeDmcgIwV/pjJ+V4jt/+a4QNtYyMKGTKmiQpy4/OVApjGgJRSFHDK0haKQqbWAWg/rnrdAe+c/wbz1Oqh4yUokwcU+2UGyFiBLITDIPgOio2OI82qC5Y4k9iUkJCQkJCQWndgnJfwiSqMBVe+8i54ffuBBhHjvfSEiLhfOfOe7cPzmPtrbLjrTtGdfJoOFh/4tFoxc7LuffoaO1iPE3bzMPI2Yk5XwK2021L3hRnpeHLsnOvKz4Q378F9H78XJSbbwccaRuahAev+1enYA7vNEoKnhZfyOc9OzT1y9sUcfg9zhwuq+ENoq2H5wdqp3RsfPffwEFQokkV5jzy0Fzy7jBy/jJyX1s/Hwiz34yL+/hpeO8pGQZYSMoKu547NQbb6BBgUqWlmIn+fI03nFPnFzHSYZ/nBdBWJG9lgMRnXR0x90CSaADH4tNteuxa1rrqU/n5o8i273ADQhtngUrJzEQMdBer7r1ERRbivJV3ht8CgUAtt/srMiiLPv7gE8x8bpfk4qMKw33Qj9lovQq6tDp60DNjNbhDgfZfyP72OfK3s218OgK/8UgLlg0KsRF219Is4t7PmxWNmp3xvNGHlIUvALBfSlI47lM8aY2F8IZFoj3jTpxZdlraiJxKG0VLNFBZkccj4BQ6lQZvTsE4R59O0H+bQV8lng72VhkMsdSexLSEhISEhILBoCAwP01NCSmcpt2LwJlZfvoa6Pc5YSTceLLyfdockXXqSn/sMszV+7smPRhPOJmFazYCyKnB2axTyews5+hRWVl+2hfxex1OQt489HJB7FPz37XQx4R2g/LYGMcMvZHjMTaV53ONWzP87Km8tFnJf3Zjv7MccUHbVIaB2J4Pa1N0AhU1DhMhViix0TPkfyPIEI0emDrP/csinX1U8X+8ky/iB3PWcR++S2H3iumxqOP3vwOKILPBpMuYqNzvOdeBGJWCRjEYYQjQj49ZE/sU2PlVbGT6+rZtuvDenwprU3oa2iGWq5Cr6IHy+PHoCai31zhQY+swMyeYL2hjsmCgtHkaOO0wgG+TbLWHVJOrGJYQT5mtGKD38Q6//pS7Dffivid70f9zdcB2ttFc0nOBdU8/fLJBf7oUgMLxxhEwFuuPjchAQWg0GnTCbyi85+ofe7QIS73pzs2XfP5OyH+Zi+uAClaeHEPnk1NVNMgKssVTnXEZ39cJrYT/DQwLkQGOJin+egSEhiX0JCQkJCQmKRO/siTW+7k54Gz3bP2Lvv4AJfPE+Szv2HmBg0bGXO6WKClvHz/uDWu99FT+MeD93udGJOnmBdUQGFRoNN//p1hLl4tfKy5Jk4PHoC/e5hGFR6fPKS99HLhr1jOa6tkY8lI86+mG8QJWP+fFmN3uUYvZeWNE8I9aXcuPrJKDaa2tBorKU/93mG4Ay68LeP/zO++fr/YPj1V3H8i19B36f+FuOPs4wD66bMeeEE8vjEnv1KQ2ZA32zOfs+oD+M8v2BiOognuPu7UMjrVlIHlIwli/exfZagUTNRlIjL0OcagkVjgkEwlxTQR6+rY4sr1bI6rKteiYQ/gBUm9l4b9o8nnf3aKisSijgSFeyxd5+epKfjox781zeexeljuW0d+0YPQclL+LVaVY5wD/YyMa2qtqP2xuuTPfHDk2whob6EEZHlcvb9oRgCoRi6Bl103J7VqMLa1nMTElgMRm2W2OfvTTFIkxAW2/rjCci16WX8vvxBn4lEMryPiH0FrxBZCLFP72+aBa4q84p9VdmcfVItEp5g+ylBrOpa7khiX0JCQkJCQmJRQA5CxZ5LMnYvG11DPdQ2G1GK8J5mYWzZRKem2O9IuahGg8iUE1Ov7Ev2wBu3bMFig1QarPzkx1D5zrtQd+vN7EJBQIwEFeZz9m1M4MdicQT47O1inP3Xho/Q0x3Vm7C9fhN194PREKZDqZAvgskiOvsRqK2WpLsvZh4sZM9+OK1Fg8zgDp04g1Yz65/u8w7hjyceQTwQwCWvTKLvq/8K95GjEIJBOrFBt3YNrBflvr7EtQ7F2OJQpa6iJLH/2ilmRRt1TGzf/1QnwtGFc/dJibNp81X0fKzzleTloksuFxQwqg34wpWfQNgvJEfvFYvRxCsEwgo67vG1v3o/Ln6ZV20kkBT7K+rZ5IApE2tdeObVw/iX136AH/7yMUxN+nHyeGZFCKm2OOPqSYp9vSFzAUIIBxEeZ4tF+qwAxREu9s9Vvz5Bq1EmX9MpTxin+9hC2or6hQ1sLJuzz8v4CS4+NpFstaAmZfx8nF08ioiQOcaREIqHacsFvT3q7C/Q4oaWhYeCb18+sa9UcrGfIEGBfEFrjmI/OjbOev45vrOSs0+QxL6EhISEhITEoiDidLISbpLE39iQ83tyEC6WabuPHc97Gz4e9mVevw7G7Sx8rOeHP6EHgcaOFUmhvNiovvIKWC6/DHKlEkreZpA+Zi+7Z5/gcYWS/dzZ/dHZkDnqB0fYOKqNlatpCrYofEeySvlFZ9/rYQLZtHo1+/lM8UFtsxETR+8VEPteHTtEnT5wMCn2jzvOYO/ZF/HWJ6ex8Sx77NZrrkDjP/49Lr7vV6j/5McQVQD3HvoDTjpTB/qvDbMWjmqdHWqSPJ4e0MfHgOUjHhfw2mkmAu++oY2Guk17w9h7aBwLiXETmz4hjHYh5mMLPBoNE0Va6PCPV3wctboa2r9fahm/mVeABKJyDP7fn6mwMneO0PeHMqqBXFBCJpeho64eaoUKUybmxkcmFHBPRIFxPp/ek7lvPtP7Mj1tN7JKEG1WEn94chDimpJhc+aCTOcAe4yN1edO7BNsvF1lyhOh4XyEdj7DfrFAFiRiaT37MZkMLx2bhMmSWtzzIEH/0d8rjVAnElAlUgtd2Xj5ZZoE6PUURhb0WAqT416cOe7Ay8924/knOxH05y4qyLJGWiqtbLJHOmQfyxH78bmJ/cgoH9nKvzuCwyN0IXC5I4l9CQkJCQkJiUWBWHapbqiHXJ1fvIpJ64XF/uv0tOryPTDu2J4c50ewXbwLSwF1BTv4jpJRe3l79isyxuNZK3SzupG97kF6kG9Q69FuYXkINfpKejqUJfZFZ5+U8dOfV68su9iP5wnoIzO2xUT919cxUTl98CBaDMxldobdqHSEUemOI6pW4A/XWPHyJZXQNDVCrmKi4YFTj+Hhzqdx76k/IhBlB/pP97C2jl21KZGZdPZnSOM/etYBTyAKk16Nje1WvP06tujx2P7RBe3dV1mqoaknz3kCgTOv0ss0vGf/mvo9aLc1w+thix1qjQJqHt5XDMZKM2QJAQnI0H2EV1EEQ6gOKqAJMaFbYdNBrVJhpb0NEa0fEXUA8oQCa/v3JG8nntZFQ8Y37u1lVQhrLew50mcl8buPHEQiBshVcmj5JAnCxHQIZ4fctIvlotWsguRcYeeLWsTZX6xi35BVxv/gK734+WM96J5IVf2Qughxb4wpDNThN/AOIF80FUAo4o2wSgojv46yxDJ+EgT44397Ac892oenHj6FvY91Yt9zqV757DJ+EaU5Txm/gn3WxAQBMgXbj4U59uxHRseTC71KHtIZ5p8nyxlJ7EtISEhISEgsCsRAJU1WOF86lo0bk9cVskYrBQaHEBkapgeN9t27oVu9CipryrWyLxmxz8R8hIt7AskoEHy+LLEfLLqE/9gUa3u4qG4DFDJ2+FejY2J/xDNeMKAv29nPzhGYdxm/UpHx+iVI361ShlMdesi1WkSnXTBO+miPOqF5lC1AKNd0YLhGjWd6XsJUcDoZOvbwGZZiH4iF8HjXcxjxT6Brqpc+5rxif4Yy/ucPDSfT2ZUKOa7a1giLUQ1fMIazg5mtD+XGsOZieuo/vS8jjT8Rk2VWXZSYXq+yWWEJsbL9Q/U34GT1HkTkGmyPViXD+Wy8nJ60ehDlqK1nUjLiTznMsqgS/ggTkl3OXpqloFfqUKthgl2X5ey7DrMWEkNzdVLUEV4/w9ok1jSbYeXj5M612O8c8MDlC0OpkKGl5tzlBhTv7Kc4O8b22wFXAK0ddmirdfT3otiPgO0PBr4Y5Y3mOvsefpmRX0dRYhk/CWwkmRsKpQxrNrI8jZ4z0wiHojOKfVUeZ1/FK21iiTitappfGT9btNQ3NSa/Q8L9LPB1OSOJfQkJCQkJCYlFJvYLp2Fra6qhtNupCxzKCmCaepm5i9atW6Aym+gM+8pLWbq5qraGHgQuBcQFivQy/ggffUcEsFyvSx50FxPOR7IQRLG/oyEVUFhjqEyG9OUr4w+H4giHYtC3tkCmUiHu9yM6wYSi+8QJhHp65/T4EkIiLY0/dSjq45kAE3YlKs3VsG5h2xo4cRIrK5kbvN7JxEH15u10dFw8IeDnp/5Iw8ge7dtLJw6QnnbCw2eewt4htk9sa9gEs5qJDyESBHjSPSnjJz34v/jLSfzf8wN4fF8f9p+awq8eO5UctXcFn7muUMiT4W2n+lKjCCecAXQO5k5PKIfYD/afQCLkg5oH9EV5XoDPzRa6jCWKfaXVig1jz6LOw57rUfNKnKi5HBfHa7HLuINeZudBeW9YdTW+vOsTeMtVLEOA0NDC9k0yXq/PyZ6fbierECAVI+EQW8TRZTn73rPM+TWvT5s8QcU+a5PYsYaNYjuX2C1sPz/aw95n7Q0WqLICIxdTzz6p4pj2sf327JALd394N0I29n4Qxb4vyvYTAxfMvjxiXyztN0aZOFeWOHrP72MLTWarFm99zzZUVhvp4t2Jw6yMPp/YlynVkOepolEle/aFeffsp8r4G5PfIWFJ7EtiX0JCQkJColwQAdr/y1/Df5T1RksUDxGkvu7uWZ19go6XlQezysrFucrWzalE9vrbb6Wl/7bbb8NSIV8Zf9jB0s+DVa145dlB+DwhuPjYsNmcfSLmJ4NOKOVKbK5dl7xcdPazx+8RUSGKNfd0gDpu4msS6u6Fr6cXx//hSxj57n/OOBVhtiR+giqtZ9/bxV7/cZsKTcY6VGxjmQuBw0dx14ZbcYV9C0zc2dStW4O7t7yFCvt+7zD+4clvYt8YS6//uz0fQpXORtsWxMuubU8rQfex51Wm0tL/Lx8dwR+e6cKjr47i+78/gh8/fBb3kz7kcAxVFk1GOvu6NiZKT/Y6k/vtl3+yD9+67xQVYOVCVVELma2BhpvF+4/S14Q+d1H23Ill/GI6e7GQsY2aeAjrJl7ETvfz9DKnvgHu7mHIg+y27NzZJ60hNq0V7Ssrk1MTrnnDGpbkRwITJ1jlQ880E1RNxloE/ZEcZz/inEaEt5zYdu5MXk5S+AcnAlDIZdi68txnadh5BUuMLzytaVk8Kfz50vhV2tR7pW/Ug0g0jvHpUIbY9wQTgEyeTOT38eqLdLxRXsYfJwJbDZlm9kke6fj5goNOr6T7yJadLEz18P7B/AF9NJyvMm+rkUrJ9rlYQoBcpZxzGr8QjSLKk/j1TU2pz6v+hZ2esRSQxL6EhISEhESZIOnWQ3/4Pzju+9353pQlhzhfnbg7mjzhfOnoeFl5ttgPjjCnUcuTxOn56mps+NpXYNy6+FL4C6GqyHX2RbHfrV+L4wcm8Jsf74djnB20W9PGcOXjdR5Qt6F6FXSqlBMs9uyTEmwxrV7EzsPS+ruZqNW2M2c93NuL/l/8kga6JcLh5KjEUiBTBETSR++Jzv64XYkGYy1sO3fQ/SE8MADrqBc3xlrplAJtfT1UNhuaLPX4p2s+gwqNGeN+Bw0p29W4FWuqOnB982XJ263U27CpZm3y57ifleCLwWTiaL1amxbb1lSjo8GI63e14J43bsCn37Y2Y4TcujZbUuwLQgIjjiAGx1n/9NGu3HF080HZupU9X32HkmX80YiQWcbP09mLRW4wJPMw1l19EerqDDQQs88BuJ1MOCpGejLeW2qNEne+dzuuurkNrR2VkPP1haFJ1v7R6+Ri31SPSb5PkgUo0vYx+Zv7cPTvPkcvUxkAfStZLGC8cJgtFmxeVQWjrviQwXKX8Yusbll84Z3E2ScBfCEZoKtOLeqRBYreETfNPMhw9okQ1xph5AsY+Zx9MaCPXIeU8Jc6fSDAnX2tnonzTdsaaObCUP80XFPBvAF9ZJxkPtSi2CcpEvNw9kOjY/SzQaHTQW23QdPMxH5s0oFo1lST5YYk9iUkJCQkJMpEmJdax6acc3I8lzNiCruhrTV50FcI0otP/2ZgMDn7nfSS0wM+8vs0sb8UUVuZ6Iim9eyHJ5mQDMiZsB8b8WB0iIlWi21mZ//o2Cl6ur0hcwa9XqWDRctKa8cDmUJ13Wb2HB49yMqvNe2tyWkHYv81wd/DRhqWgliKTkS0XCFPzsgO8JLbcTtz9snYv+qrWTL90B//hMDJ0/S8dUvqcTSa6/DJre9Dm7UJRpUe79h0O3usNZtQY2SBYFe3XwK5PHXIG/Oz51VhYGJ/ipfEb19tx5fv2Y3/9471+NidW3Db5StQyUu9RdobrFAr5fAGItSZPnQ29Rqd7mcLI+VC0cbEvjByBko5e85i/Lnz8m0utWefCLuKHduhqLCi9sYbsGE7E0Vj+lZ4XOwzy/mbn2Hsv39EK5VEOtZUY+U6VtWg4Q7z2PQUbZsY4m0g9doajAyyBaq6Wj2O/+OX4HnuBbbvygBDgyoj+V0U+5dtnnlx71yJ/UXp7PMy/mOJOHy6zCDG106NIxQRqNAWgy693ggtn086+3kD+thnpikmlFzCn+7s84EatJWkqd1Cz585nmpvoVUDfHEx39g9gkpVHrEfGBpKJvGTfVxh0ENby/IE/Hzs6nJFEvsSEhISEhJlIupKHfiHeP+gRHGI5ZZkPF4xpcjE3SXusufkSXpZ3O2mghFyOTTV+V2kpezsiz37AYE5oOlmHEnjn4lRL+uzb6vIbY9oMLFAtfFgptjfsKWe3sdwvwtOhx/adjZSTQxFJNkBBF936X37Yil6er8+acEg4tKvlcOrl1Nnn1D/xtvog51+7XX4XmdjFa1bMqs0iLP/jev/Hl/e9UnUmdhrTwL5PrX7/bi26VLcsvrajOuLZfwKAxMoDhdzIytMs8+rJz3dbcQNp+7+FA6nif1TfU5a1l8u5NZaqCobASGOxBRrUYnmlPGXJvYJa/7uM2j5l69CbavAus319DK3roaOKFcgDk08QEeWBQt8hhmMTKA5XG4M+8boY7ZqzYi6FbR3W6tTQj09TN+PCrMJbXffjpqLAMOqxqSLTKohBsa8NBTv4o3nZ3FOr1VAx6ccVJg0qCoi6PJco9eQUnl2vmuIOdRVVvb8P3+QLZZUWXVQ8sqPQICJfTMX+0P89UnHw8v4yYJAqeF8BCdvH3q1awpTbvbeWb2BVQl1npiCwO+boNCbZnT2Vcq0/VdM45+D2A8OMrGfnssijuAL8ZyR5cq8xH44HMb4+DhGRkby/peQkJCQkFhOkN5UkeCwJPbzQQ48Y85pBAYGaNuDKB7FICVjR0dRt2New9x90j9OEPs1VZWVyVTnpYramr9nPyZXIRpnR/53vPMiKgJ0BlVSfOUjKsRomX56IF86DWYmqkkZfDrErWtoYa7/sQPDUFosyUUUUirbevc76Xn/HEL6RHdamdav7zpyNFnCX2uqho6X9+obG2DgGQyC308Xcywb1+fcJhGR4sxuETKi7rb2a6HltyUS97PnQ3Q1ndwlL0bsEzoaTUlnun/MT18H0nfu8oaTLQHlQtfCRk3KA1MZZfwks4FgzKo8KBYSXimW29u0kdT9hV10dNtMr63FZEgGOJ6aPptcSBofZiKypsEIH28D0K5ciYT7GOQKQG5nvd3pmQcdDabzUsIv7jPVXOCvaS29nP1cQKpfxOdnjLdZXLqBueSjU8yhr6s0JBfOgoEoLZ9f7Q9DKZNjxD9Op1HkC+gzEbE/B2d/mgeDhgXQbAtC8woL9AY1gv4o+rpT7r5YPaOy5nf21dzZJ4hTGubn7KfEvsrKFvOiroWdnLHYmdO3ocvlwle+8hU8+eSTiKeV+GRz6hQrG5OQkJCQkFgOpIsz0j+uWsHcUIkUnf/2XTiefxFibJK6vh7V3/lmSuyv7EAxHZaGNvLc7k2G8kXGWf+wqjr/QeVSdPZjPh8SPDGbiP2QkvXRE+d0/dZ62GuMcLudkKX1lGfjDLloL7tGoYZJYyws9rOcfQIp2x7q8+DYwSGs2rSWBh+OP/kUGt78pqS7Hujvzyj3LgbRnRbD+cgC0OTzL9Dz3Y2anAoE643Xwc9bB0yrV0Gp1wOeuaffp5x9Ky2RdnB3ssJYpNhvYGL/CO/RX91cgWg0iu4RH3X31zaUT7zKed+zQiBCz0AXSsjzlT56LxLLHHlWKq2tejhPM4Glj3hY2UgiQcW+dhULw0zHYGACTRlTY/84W6Rpr2jG2Eku9usN8B5jIlClDiI82k0fh3Lz9cnb6BthAqy5urRwuHJTazegf8yLNYuwX1/EpFfDG2CvMXmrX7y+Eg+8mJprX19pxLQnRPv2Q6EoZNVGGIQEtmuqsC80jie6n8dbWm5MXl8cx0cC+uZSxu/j+14UCTzxaj/uuKqDTqogY/gO7hvAqaOjaF/FPoetl9wBx8Gnoe/Ynve2lKq0agqe35Eok7Ofb9F0OTInsf/Nb34Tjz76KHbs2IF169ZBzYM+JCQkJCQkljPpZdchIvbP69YsPoiLP/UymxuuNJkghMOIjIzg5Je/SsPe5BoNdXK9k8ylnwnS20/w92Y5+0u8hJ+gNBpJch1JskPM66XijvQ9h5TMmTfyFPHaejOxfGe8LXEGvV1bkde5TIr9rJ59QutKKw2GczoCmBz1Y91774Z83Ro0XnUlXM4AwnorNAEXgsPDQAnHgmJAnxjOFxkeoQfrgkKOs00avKUi5QATtG1tMK9fB8+Jk6i4iPWxzwfR2Sf949GYAA9PkLeainvHttcbRT1MuXhDHUbGnWlin7VGlAO5mokhRSKUXCgh4xCjkXhS7E855xdA1rG9BQdPs0kI+qgHdbe8AaMP/YVWzeRrEtAZ2GutiKngCLHnstXaiOdHWLl0Tb0R3j+wsEWF5zRZo0DlDffAZ0gJy95RtljTeJ7F/l3XrYZenaCBjItZ7ANMoNfYDTRroNqmpyMfCfVVBviHp0GWrMi+AR1b1LtcYcE+jOOVgQO4sf5yelk4FkE4zvZ3Y0zIyFAolhBfeCCSPC4k8NsnzuDtV9Unxf7pY2O46Y6N9DqG1TvhtTRDrsnfIqFQqaFIJBCXyZCYRxl/aHwiJ5xVdPYjktgvnWeeeQa33347vvGNb5R/iyQkJCQkJC4EZ394FKnBQxKEYGcXdW2UlZXY9dMfwnPqNI79wxdpajfBuKI9WcpZrNgPj0/QkD5x/ruqZumLfSLKlWYTbXeIuz2I+wN0oSRkZi6vschyc4IjxMR+pS6/g9dgYmKfjOYjYWvppfBE6K/ZUItjB4fRddKJTRd1QL9uLRWaP/nuixDq34Dd3ffDRwKw1qZS1ovv2WevtW//a/R0pMmIiFqOtiyxT1j1qU+g5+G/oP62WzBf0p19Fw8bI6F7Bq2y6D7q1jozekeYYN21oRZHlVHg9TGc7nMCl5ZP7MtEsR8PJp87sV+fjOMTU/rng7WuAhXxaUwrKlDTVIGqKy6nYp84+/Y8GQTiWEZFLLUfVspqEPQPQ66QwaoMYIRUXsgBlS4Bw9pLYFi/Bz5efUMWr0Rnv7Hq/Ir9jiYr3nFtK4xpowIXGya+uEJoqWXfKiubrEmxX2c3YFCroGI/FolDxit4GkMxNBrrMOQbxatjh9DR1A53iO2zygSgSSSSZfalEI0wMd7RbMbhAQ/2HhjElZsqsGlNCw1vJAF+g71OaFJh/AWRKVVQcrEPxdycfXL9eIA9FyoLE/jsvOjsL+8y/jn17EciEWzbtq38WyMhISEhIXGh9OxL2TU5BE+xNHX9OiYMzWvXoPJtb03+3rBi9nC+dPdbaWfhUv7+PkS5s7PUy/gj4Rj2Pd+DiJk9jrjHkxy7F9ZXZDj7xTAlin1tfrFv01th01khJAQ8ePrJnN9vuIgFuPV3pxayxoY9tDc4DA2d0V5q336yZ18pp1MUxOC9I7wClyTrZ6OpqkTFTTdAwYMBy+LsG6yY5mLfbtGV1LO9rs2eHNfXWG2ibj+hf9SDYLiwWAmFYyWF+Mk1PM2ci32y0CIm8euNs1ciFHtf1243YJ3nAHbffSMMZEa5XE6rSuJp1UoiOn3K2SeQ9hDfGHtN6xotiPGwTVKhLVPIUHnjBzKeW6c3An8oRnMO6uyLLxRvsWHiiyuE5lqWo7GqKfV+rq8yQsf7+sl7iwT0EYSQF5fVs/L5F0cO0Pe4i4t9UzxBsxlKFfuxmADwsX5b19hw8YZaCAngfx/thpBIoGUFuz1Syl8McqWGLjwQEuJkjmhpYj/uY+0jZJ9VGgx5evZdWM7MSexv3rwZhw8fLv/WSEhISEhILFFI33I0rY+YHiiLByESlAAX+7q1qZnn5sv3oO7mm+iBmn33rpJuT83Tln1nexDlafWLsYyfCK7xUQ9GB2cvtz68fxBP/PkkzmpX059jbndyln1YZy1d7PNwPlLGnw+5TI53bb6Dnv/TyUcx5stsoWhqZQsqPk8EAV7uPsZdWcKEsTUZkjgXZ59UdZBRldBq0FuvgVVjhllrWtiAyGRAnxXTXi72raUtIly7o5kmuN+wk5UNW41q1Nj0VPj0jubONie8cmwEb/38X/DisdnbVLLL+OVxPmIyAex9nFXCGAwzi30hFsHQjz+F0IPfQiKRSkjPx9p33YE9X/0gzB3tkKvVUNexio/wINv3ZnL2Sb/+UJ8rub+EeGuN2gjIdOZkIrvI0ARzYZtqTFBygSdRorPfzD4LiGCvteuh5zPvhZiQFPvxgAfbqjfSEZtk0e/kRCc8YfYZZODuealiPxRgfycggWq7Du+7bQMMOhXd53/85+NoW80+Z04dy50CUMjZJ2X8BLGMv9QMkDgfv6owGJLBk+k9+xHJ2S+dz33uc3j66afx05/+lKbuk1R+4vZn/5eQkJCQkFguUGFPDlrkcih4KaHoNkuQgLkpREfH6POj40n6BOL4tX/g/Wj73r/Bsn5dSbep4cnLZCwb6W8nc5qVtsUTtJUQEnjpmbP4/c9O4Ifffh4P3XcGPZ25vfHpTIyxg3G/jDlUpIx/+sBBej4yB2ffEWKp5/YCZfyES5u3Y5W1jSb3/+zAfRkH6VqdChV2Vmo9NswOmsd5+TphUt8Eb+9ASW612LNPZoNPPseC+c42qRFXytBqTgVsLQRCyA/EmWCRGyxweVn/sd2sK7n8+94v34g9G1OLS2v5wkj3SP5FnVeOMbdz38mZ94G8Pfux1ALCUB+r1qjn0xIKETx7CNHJQQiTfYi5SvssUjex6oowX2hKR6djwlLJnX3SdjFE2heo2K9AuIeFZqqI2NenyqqT2z/JxH4ryZyQmBVzWouB6OyvabHhojXVuHJrDVRKBYx84SdBHHvR2Q94aVvO9gY2zeLo+Gm4Qt5kOB8JnsheiJkNH6+EIe+gKquWBhx+9p3b6KLDoy/3YdAXgVqjpNUnEyP5F71yy/jZ+QQPGi21jD/uZY9JbszsG1BxsR/3+yHwoNPlyJzE/kc+8hHEYjF8+9vfxjXXXIMtW7ZQtz/9P7lMQkJCQkJiuUBEGUFlMUNdy3p2I8t8vm86Lp6mbuxYAQVJU89Crio9zlDNk5fdJ07SU21tbYazc745sK8fT//lNFx8ZBbhNBd8hZiaZNUgAYEd4MfdbkwfPETPh+S6knr2iQB3BGcu4xcXXO5ceTOUciUOj53EEUfmNCVSmk0YHcoV+3GFGpMJC2JTqXFbxabxK5RyjL3IxP6xRjkazXW4vT2V2L4QiCX8UOsgV6qTZfyVJTr7+SDj2whdBSo4SOo7oXfUhyhf8Ci2Z18WCWD3le2obTTiqptW44OfuRxbL555Pr3v5IvJ85FxJsCLRdPMxT5POSeEenpx6l++ic4vfoH+rBbYc9ZiaMY4f2z19QaE+Rg06uzrc53jQS722+oksV+Ks0+0cEMVE7QqpRxfuWc3zRug1+GTJGSktCTN2ScVHRuqWZXQ8fEzyZ59Es5HricjMxFLYNLB2knikMHMFxi2r63BLZewKqtfP92Hykb2uvZ2ptraCiFTqmnPfnoZf8lin1fQKUyZCxdKIv7l7DaXc9/+nAL6du7cuShnUUpISEhISJwvYryEX11RAUVNNYJnOiVnPw0Xb/+zbtlcttvUiGOWBCYedQ0zi59zDSnJJ2zcVoOONfX4068PoevUxIwu+NQkc8NCcQXiMgX8x0/Qvn2Z3oBAKFGSs09KdiNCFDLIUKHNdVjTqdbbccvqa/DAqcexb+wwbtx4dfJ3tQ0WnDwySnv129YYMDHKhF1TmxmDvR5ayk8d4A1sJnyxPftyIQZ4/YjLANumzfjkng/A48w8KA8NnoYQigO1rKy8XGKflJcTXLyM32aZv9jfwseNnR7wYHDcmzGNg6SWk8sI0VgCZwfd4CPeZ0RMMRciIVx36zqMjdlQy5+LsbHCkxgS0RCCXa8nfw6P98Gw5uKS31uRwUHqip759r/Due9VepmKj4BUxTW4pfVq1CeagMQI2y/Hh+j7UWnQQq4OQZanTFws42+tJ/vkzO0FEoCFjzqsrtBSFz8fJp7fQKRtQs0XU0nrRiSEDTVM7HdP96PexBaiTXEBMt4WVAoOvnApV8sztCAR+w6vQKtXXu5xoBVyTI4X4+yroSQLFGRPUMjmlMYviGKfTDFJv21SZWc2Ie5ys0R+U+7o0eXAnMT+Bz7wAbS3t5d/ayQkJCQkJJYoxIElqCuskNewAypJ7DNICJvryLGk2Gfe0PxR2u20SkBMYtbWLR6xPz0VxMigG3K5DFt21aKxqRYKpQzu6SAmiQuaxzOJROLJGdaEkNIIBQ9I0268CIkp0LRz3Sy92iLjPkcyhE8ln/2Qb0vteir2xwKZPeW1DeZkGb97uoKGdJEU+M07a6nYnzQ0Y+I3v0Pk4GEo2ttQ8/a3zWgK0ZAvsl8E2UH6tEWBT+y5B3q1Dh6kxH5ouAsj9/4j5JXNwMp/QzkQk/hlevaYxJ79Ssv8g+Iaqow0sGzf8TH84ZkuOo5MZNIVomP+RE70TmHPOlPRZfxCJFhSq0R84DgSsVRLbWSiRGefi30yEeL01/+VtZLI5bDt2IaJ/azSJB5L4Or6SzA5wt7RVpuWjkekf19lgkwWyinjD0VimJhmgrGt3oywWGkhUZDNq6qwY10NNrcVFqsWS2oBMBAClGodEmSfCXlRqW9Hlc5GJ268NsIrrIjYN5ZeWeFys88ntTbzM0guk+Hv3r0d//Kzl3DmNGvpcLkjxYl9fl7gRVmJEkvu415R7OfG/ytMZir2o+T7eZmK/TnVut199934zne+U/6tkZCQkJCQWOpl/NaK5Pg3cRzccsff10crH2QaDUyrU/3684UISnEEH0GXNmP5fNN1gpW1r1hTRcU5Ecf1TUzcEXc/Hx4ugkRCpOmZo1i5np5arMWnxk/4mdivNRY3oaDRwp4/Z8iFUCy16FDXYElWHYwNsQPrmjozahtN0GvliCk0cMSNNDvBcf/vk4GChYhyZz/uY063w6KETpXrrPtOkBL/BATnEBJCaaFdszr7Wu7sJ9P45+/sE956Ddu/9x4cgoMLI8IwL10XOdFTXNuDXM23S4gjES9eBMV7mKuvbVo7pzJ+uU5H22IIROiTPIy6j/8N1vy/vwUxl2U88C8UisPpYA6uxjWGgd/ez+7XxsRgttgfGPOCLFlYjRpUmMrznF/oGHUqfPF9F2PXusqC1yEheSQ0j+DxRaDgi1kJklFB0vutbfQ0GA2lxD6vbikFH18c0+dZcCRhi++/uQNb17LFbr8/WlxAn+jsy/hpyWX8/rxl/HSbLOyy5ZzIPyex7/P50MSDOyQkJCQkJCTYiDTR2RcT4YmzT1zt5Y772HF6qlu1EnLlnIoKC5Iu9s+Hs09GoQn8YDU9mI/MpSds3p4KnGtqt84o9l3OlDgkBHm5NL3N2hZ6arYW70CLzn61IVckxHwuRI8/wwLrOGaNERYNOzge8YwlLzeYNDCY2MF953F2mzX1Zlq1sHYrOx50brsFugbmZIdGRosq4xd8zMV327R0KkA6pNfYf/oV9oMQR9w3e/9vMcT47RBnn5TWi2K/soTndSZWNVdgbYuZ7hNPvJZ6HoYmmfvdyvvUT/U56aiy2ZCJYp88J+HiamLiQR/iQ8xht131Tnoac08invZaF4OhnQlEEuS26lMfh37tGsgUCujr66CKM9EYDsbg5DkT8q5jtITftHsX9NXs9cwu4+/leQ9SOF95Ic66wMuFPN50sc8W1FZV8NeSw8R+4cqSY2cdeOrAGH2PpBPkafzmApUw5DPh0q38M4+P6CsEqVT59U8PQtd9BVnTQ5yL/dLT+PMH9InO/nLv2Z+T2L/jjjvwq1/9CoN5xnFISEhISEgs5559kgCsqrTTg2JSjhghY8WWOd4zXfRU27Gi7Led4exzsXmu8LiC+M+vP4MHf8NGCor09UzB741Ao1Vi1TrmchGa25nLOdg3jXAoRsP4juwfQyjIHDB3jrPPDsYNK1bAH2WHbJZiGr2zxH6NMVPskwWo8d9/A9FX/wj3gcfyuvtDaWKfUFnDDqTHecK2WNq/49IWogUxMBpFsIG5yKFZKlrExwsPE94+e+5BujDRh7g39d6JTo+jHMQ9U0kR6vaF6ag8EnxGnOZycfPFLKzshaMTmPaw13TEwZz9q7Y1QaOSwx+MYoQvAMwEDVBTqpOl/MUQ6NxPF0hUVc3U2ZcZKuZUyl91xWWQGwxY8eEPoHLPpcnLdU2NUApskYTsx5ND7DnVI4iVn/oEqv/qbggBcVElU+z38bGN4qKHRBnhafZefzQp9sEXeDosqc9JMaCvkLNPRPi3f30A9z/Tj6f2D2T8LhJiYt9mK/w5JP5OnlbFk4/pqQB6u6YgD9roGEexMiExV2ffmLt4oTCzy2jP/jJlTsvrgUCACv3rr78edXV1sJOeOT4bMZ377ruvHNsoISEhISGxZMr41bYKxBQKaGpqEBoZQXBkBJqqwuWXywFfFxf7acK8XBh4hhBpEVDbbMB4eURhMTzx4EnaY0/++31hGLhgPPo6SyNfv6WezpIXMVs1qKwxwjHuw769Q+jtPI5IOAaNRocrb1gNNw+/Ik663xtGiIfq2bZfhJHpYLKMv1jG/fmd/diJZxAdYa9JZKI/43cN5lqcmOjEoHsEq7SsmoBgr9ah/2zqgJk4+0AY1XVmbNnRhEP7B3E0VI+N5NJZxL64qKGeZtcLVuWKjnjvocxtdo0DNXbMl6ib5RHIjDY4XOw5rTBroSjjvPdVTSasaanA6f5pPLG/H2+7djWGeIp5e4MZ7fVGnOr3oGvIg+1sKtrMqDRALEJD+oDZS98D3WxUo3Htbnoqtzci7p9GZLwfaCr+ObRfvAutLc2ozaqY0Tc2QtXH3PxQMAaXmyzeyGBf2YjqKy/H6NBAsmIkx9kfZZ+TbTScT6KsKGVAJIGALwo5H6mXCLHXyaQ2oMXaiH7XUI6z3z/mgWMykMzAdHoicPJFqt88fhpXXMQWrwhxPkmjqjJ3gU7EXqFDAgkaDBrglTP5GO5PVevIBTlisgQNtRSiJQb0zdSzbxad/eUr9uf0ybZ//35UVFRQoU+YmprCxMREzn8JCQkJCYnlVsYvzvYVk+GJ2F/uFQ/hiUlaCiyO8yq3s9/8jrtQ9a53nNNJQUO9bppQL0JD97grdvoYc8U3bcudGb9yLWvxOHPMQYU+ofv0ZIYIXrGKifOI3kZD0ey7L4abC1NLRfF9zhN5nP3I1DCiBx5K/hydytw/yfg7+vg8o3mdfYoMqK5NuWhX3rgaSpUckwElJgwt7PWeAfc0D1SMehFSyUjceE4Jf7yPiX2FiYnTaIlz4gsR87DnhLjdU+5QWfv1Rch+eMPFbGHruYNDCEfjmOSvbUudGav4aLKuYW9xt8fzDEjgWjFEHMP0VFPXwf7expP1x3vn9Fiy0RGxH2cibnoqhJggo8nvtg4mChMBnotAFinSshjIe0N09kk4n0R5IaMsCf5gLK2MnwlhgjiCT54AdEKCtrKQEZCf+/6L+MZvTtBqE0LvWOpviOh/8PmeZLiinJf116e9/7OxGDUQ5brTVXhixPBASoDLEkTsC/McvWcs6OxHpTL+0njmmWeK+i8hISEhIbFciInOfoUo9tmBb3B45v7lC51wL3OO9U2NNPSr3BAx0vS2t8K0czvOFbFYHC89zctbuRaa4GLfPR2mpc3kwLuxNXe2/cq0sv6tO9nix8igC8FAhP4toX01C9QL6axo/MfP0QUND3f2i+3Zj8SjcAbZwXQNd/aJiJ58+L9IjDpUVey+o87RjJT3lNjPLuPn47yIOK40QK1JFYeaLFps2s4eV7d9OwIziH1yX+LChTbqh6OChPNlPqbwyFkk/NO0X9205Rp6Wcw9f7FPQv7E1gC50YYpN9sOexmS+LPZvbEOSoUMg+M+KvjJM2w2qGm7wMpGHtQ45C0uYZ8LZqGInn3SohFzss8clZ21tcht7LMoTJz9MkDeyyqBLV5MjDChpY35YehgfeEJPxNWSpMtY7GAOMZ+8t6Qy9BYPfskAonSEKuISF+9gpfoJ8JpYp+P4CNj94gAJGX8ZMHLF4wiFBFwvJsthPXy19TOR3z+8dkueANRTDgDyZLwmZx9Mh5Q4K/7lLPwPjuULvYFBeJFlPGT/fvYP3wRYz/8Mfs5kUiJ/azRe+mhfRHJ2ZeQkJCQkJCYK/FgEIlwOJnGn54MT0r5lzOhXtYnbFy5EhcKLz59lgpzo0mD7btbMpx9xzhzsuxVOhpWlU1Luw033bEBN755JW5922ZUVGpB9N6JwyOIhON08aB9ZWXyoF1exWpr3a5QST37Dv8ULaXVKNQwadhBsO/Y8wgPnaFl4bVv/RxpCKfz2NN745t4zz6pCiALBiIGowp6ozqthD8TMoZPq1EgqDZj0hktKGJJoFuMlwITgThlUUKryHTW/adepqf6lduhrmwsW89+IuBms8fJGEKdacGcfTEdffMK9lnw2yfO0NOWWjMVv211RroQ4PJFcYwLLMLPHz6Bz/3wEEZ44J0IdciL7NlP+J0stV+hhNLCFo3kdib2o5MDZZlqoCUBfbxnf2KYLXLq436o+Wee6OwrTLaMvxviEwlqbWRevCRByo2KL8DRxUYj2/cEZ+r7Z2vtety26hrcMsk+q0SxL3LkLBf7Y6wF45ZLGtBeb0EgFMOfXhjE8LgXCr66KbYsFUTBrjfNq3iyiccEjPN9h26LIEecO/szpfGTEXqe4yfgP3gYUa8XcX+AhkIWFPtmKaBvTj373//+92e9Dvkw+5u/+Zu53LyEhISEhMSSIsIPJOQaDRQ6LeBxQ1fPXLXlXsYf7mNi37TqwhD7pG/9+SfP0vPX37aOelGvv9yPiVFR7PtznPDs46Mdl7ZibIw55w0tZkw7Qnjtxb5kT77RrIVao6Di3+uOIByKJkPtyO+d07Onqo94mRNu11bQ+0zEoph+7rf0MtXmG6GqqIXMVImEZwJRIgi0TBiaNSYYlDr4Y0FMBKfQDFYBQG6DjODrPjOZV+yT0YLVdSYM9LngF9SIcbet0OguDSKQQ6DOfoUyUzgEutjYOOOa3VCY2cJHzDWB3HSo0kj42KKG0myHTCaHYwGdfcLOtXYc6HQmswFa6pjLqFbJcc2OZjy+rx///ttD+M/PXIkXj03gj8+yMvsHnuvGR96yOdfZL0bsu9miiMxUxcL96PlKWiWRiISQIBUS9ake7Lmg0Gig0bLbDvOWbItBTkNJ6Tbw8YZKkx3ps0gGudhvqs7/3pCYH6Tahkj3SCQO/YrtdMEnMTWI0HAXWXmBXC7HXSuuwsAjvwXIvqHRwzmeEvtHuyYRjwvo559hK+pN6GipxRd++ApeODqJgWE/aBOSjL3fZ0JO5jPGYnB7MieMiExNBOh9Ja+fXsYfn8HZT1sICI2NQ2lg+5JCp4NMlWccoJm952Jeb8kp/xcKZRf75MuA7EyS2JeQkJCQWC5Ep1nQkLqCCSuClov90PgEhGjx87GXOuSxBrvOIsHHD4b7WOmwcVUH8su/pcPEqAfPPNxDx0St3VyF9VvrkyKflPETN3uKO/uFxH42ja0WHD8wgclxXjpbxcpjTRYNPSD2esJJV58IrPTy+Zl4tpe5461mJuxip56j/eqkB165/kp6mcxSzcQ+6dtvYGKf7L+1hip0uwcw5s8sx7/qptVQqARsvyQV3JdORZWRiv2gysT69vmBeDpk8YKgjbLH67AoUa9M6+sOuGlrAVEU2taNNFWeEPc56YLFfCCtAQSlhS0gOLmrWbkAzj5hY7sVBq2Slq6Lzr7IX9+6HgdPj2HSFcQ//3w/Tvelqiv2HhzEX92yLsfZJ2J9NgSebSC3ptpFyMKGurqFVnUITtLPv3Xej01n0gFpL4e9xpRZQcGdfSGPs99YJYn9hUCrU4J45dFwHAqDBcZ1e+A7thceMnFj51vpdeJ8IUaht9D9wulJLRz2j3lxpMuBSFSAXqtEjU2L+rpqfOhNG/E/fzoGx1QA1VBAoVbMmo+i1CiAUAxeb36xPzGauWBJnP0Y31sSMwT0pbv+ZMSnpqY6Q9RnIzcYaO4Jcf/jHi8wv3WuJcmcamgeeeSRnP8PP/ww/vd//5eO5WtsbJR69iUkJCQklg2RaXYApeL9+mIqv0yjpgcZRPAvF/p/+WuMfPvf0ffzexEcGYUQDEKuVkPf3IylDBkTdd/PXkc0KqBlhR2XXtNED3jt1QY6eo6UznpcITgmShP7dY3GjCT4lNhnJfNedziZWk0WAIphPODA68NH6fkrGy5GPOhF9DAbsWe74i7I+Cg3uYUdKEfSSn0JtXom/McCmfttfZMVV97UBp2e/X02FXb2mJnYZ39L5s1HI/FcZz/EBOGUVQFdmrMfH2NVEzJ7IxRaA+QkMVwUu9yZnysJHxf7Zvb4RMd9oZx9Uqp+yabUOMj0cXN6rQr33NJB+9ePd08hFk9g57paWuIeDMfx/KHhufXsi84+f21FNNUsMFCYYmns80VXkVkyXd3Oo9wznP2sMn7+3pDE/sKg1zNnm3xGEczbbqSnvpMvIhFki5JxHxf7RmvGgpfIH55hUzpWNlkh54L+5j3tePf1bTQpn6DR5Tro2ZCxo4SAr0ixn1Aknf2ZyvjTFwKCo6OI8qwclTn/dAeZXA6Vhb3v4t5U28ByYk5iv729Ped/R0cHdu/ejX/+53/G6tWr8Y1vfKP8WyshISEhIbEIibq4s8+T+AlECKqqa5ZV3z4psZx4Zi89P/Lgw/Q/wbCiHXLlnIoJFwV9XdP48b+/AJczQEX4W+/eBjkX6EqlAlYbE2NnT08gHIpDrpChwl6cgCTlsE1tqSA/W5UxQ9gTJ/zgqywMsH11buBfPp4efJn262+v30RdetcrDwCRIJ27btx4RfJ6cktN3kT+pNjno/uKpcKWEvviAtfTfzmFX/znYYwOMXHv83BnP+ZHyKJFVCWHLs3ZF0aZ2FDU8iR5mQwyI0vkT3hL257CZfzc2fcsXM++yJVpExmasxLMSe/+O25YQ89XWzX41DsuwmWbmEh/9JW+ZO5BKT37Ahf74msrIob1JXxTKAf6qsyRenXrV+Q6+8aU2CdJ7hN8IkFTdeFwN4m5Y9Dz/STGMzEaVkJe2UIDOWOdr9DLYry6hTj/6e8B0lpCEDMkVjVnftZcvrkat17SNms4n4iWLwgEeftRIbEvFgiQ0XtR0dmfQewLadU9odExxLiAVxVw9tO/l2PE2V+GLEg6xmWXXYYXXnhhIW5aQkJCQkJiSTj7BDUvMSQO93IgcOIU7Y2kJBIYf/yJJd+v/8pzPXjigW7aM9/QbMWtd61OBtWJVFQyYX/kdeaakrF04hisYljB0/cJtspMZ3+gx43hfhcN+1u1ITVCrxAkgf+1cebqv3Ht9fQ02H2Ybeelb072cae7v7RnPw2yQEAYC8w8Qi+bCr7tQWXK2SdjCIm733lyPEvs++DhlQDpAX2isy/nYp+eN7HHLXjnJ1SFZBl/FUKROP1PsJqKq5iYCxvaK3HbZe24fU8jdfOzees1K/EvH74U//DuDTDqVLhkQyWtCOgZdqOPB6WV1rPPnndZltgXw/JEIT5fDHVsAUakui11f2JAX7qzP0DaXMhzbdTAbJjdGZYoHaOJfWYI8VQ4pnLd5fQ0dup5No2CT0pQGCoyxP7Wjkxxny32CQ0V7P1qLWIiiN7AtiXCW1gIHn+EjqEM+CLwuJjj7xMXtEgZv6yINP40Z5+I/aSzz937fKgslozxuMuNBRH7Z86cKW6UiISEhISExAVAJK1nPx1VUuwvD2fft/81emrafTHUttSB/lJO4n/52W56SkL1/upvLoHRnCsMbVzsD/Wx/YAE2ZVC+6qU2E/v2Se4nexgfPWGWuiLEEmPdD6DeCKONZUrsLpyBT0ei3IBqK5hpdwiMnN1MvwuPRRLdPYng05E0xL5i3X2w0oD/OOTtHx/2slKt8eSzn446ew7bUwQiGX88YAHCRdbGFPUpJximYk7+z7mOgYHTiQXBebk7Fsq4fFHk46mrsgchLlAFmnuuX0jbt6dv1mYVC5s7KikPdIEIvgv3cxc+OeOTJTUs08WA0Shne3sK3k6e7nEvrExdft6RRQqPvaNjHcU7yNd7PeOsMta84Q7SpQHs7holSb2FW3baCsMyasIdB9KlvErjewzSkzj37HGTltKZhL7fh9bqMte7MyHiW9LNMw+V1zeMD77lSfwnz8+igOvshwXuVaZjH2QJxRJZ3+mMv6Mnv2xUUS5gFfy1P18qLizT3v2lyFz+nS7//77814eiURw8uRJ/PnPf8Z11103322TkJCQkJBYEkRFZz+tjJ/+zEPqgsMjyB0KdGERCwTgP8IcZctVV8B0zVU49bWvL2lnnzjSft5zevl1Kwu69aKzL1JbotivrTdj5bpqhIKhpGA2ZS0qbNtNMg9mTpMmo/Ke6n6Rnn/j2hvYhWE/EmEmuMVRbCIyEtIlprTTEnlWcm5WG2FQ6eCPBjHiHUeLNVWKPhNEBNAQ7rgMrkkfElNBGmZIGB3OKuOP+jBYS94VoWQZf2jgFD1VVTZCRnr1s8W+dwpR1zhGf/VlWv8bW7EeSlNxrQ3ZZfyefuaSm/WqWcPGzjU3XtyKvQeGcOAM6eUXICuyZz86xRZK5HozZJrMvnhxFBsR4uUw5PTWVCm3xZRahBICXh6qKGP3GWQLNH0jnpzcAonyYjGz/URGZs8LCSreZUoVTJuuhPvVh+A7+iwdt0lQGNh31bSXiX0SxkcE/qk+J2wmNWxmLcbSpubR8FE+EnLWsXvkfcW3Jc7zAw4fG0Ej2S38cTz7CBtF6QinFhKJsx9VimX8hT/n0l1/4uoTd5+gmlHsW9i2SGK/eL70pS/N+PuNGzfi7//+7+e6TRISEhISEkuKiIuJfXVWGX/S2R++8J39qVf2IRGNQtdQD3VzE2x1dVjxkQ/C7ZyGlj8PS40gcX8T5PhYlixLzYetKkvsN5KDy/zBVPkgt//29+2k4/jI+fQyfjH4rq2jEuMTM8+aPzZ1GoFoEDaNBVvr1meUvhNhL+cOcUauhK0ekbGeZK+3eHmjpR5nHN0YcI0ULfbJ35lMKky7onC5w4hPpsQpCS90TwcRDLCDda0yhgGiP+PE2dcmHXuCrnk90r09MjpOfCye1x8FEgJ9XXwnX4B1121FbZsQ8gPRUErs+3uSYn+xsbbVRh1+XzCKs0MuGNPK+GcqyY3SpH1Abc+tIhDFPuJRCHzxZz4oVQooZAnEEzJUt6Zc/hjf30hPuEyRkhm9o0zst9WXthAmUTxWHjRJaiwCoShMPEjTtOkqKvb9na9DZa9j1zFYaRtLgJfZW41qbF1VRcX+igYjzhwfw5EDfWhbEYKtyoCn/nIG48NM7JMRm7NRYeWtOXy83vAwe/1jNE0EUEEGR0KAnczxg4yJfXH03kxl/Fm/83Z2Jnv2E7P07MeXaUDfnMT+vffem/dyMnKvqqoKLS35R7JISEhISEhciESmmGOottvyOvtkNJ8Qmn1s1lJm8jmW1VN15RVJp7T2husBPk9+KRLgpd56vTIpwvNBSu6VSjliMYEGTtXUmeCcLl7sFwruIwsMAX8EF13cPOP9i7w6doSe7qzdDDl38MRQO9Edz7kfOxP7Yq+3SIu1gYr9fvcQLsPOorfbbNNRse9PaBDuzwzUO3OC7QsKIQrzyjb4BfazVsEWIUIDJ9nPzesyxjTKRWffMwnv4aeTl/uOPle02CdjB+lt6UyQq7XJMv7F2D9OSv9Jaf8rx0ZxtMuBS3mVR2KWnv0ID1okCzjZ3ihZ6JFrjRBCPsTpVIL5ty7ozTp43SFUNqSqK+Le6czFBe4K9/Ey/jZaxj979oBE6Rj4giQR+25fOCn2ydhFeWUzBMcAopOD7DpGK9z8PaDTKKBVK3D7lR30c2ZDsxaP/u44XaA7fdSR8Zm0Y099RsZIIWy8QonrdzgmWf6EBwl0I0ElPhHn4l4iT8hLLuNPr6pTmi3pkyAzUC1zZ39OPfvkS5yk7+/cuTPj//bt26nQJyvTDz74YPm3VkJCQkJCYpFBnIao6OzbMgWVwqBPBgdFeWDZhUjYMQX30WP0fNXle3ChEPDxg+FZBCERZ1U8aZ0k86vL1AO+87I21DUZqdifjanANM5M83yBms3Jy0npe7o7ng0RhgQhS+y3cje/31XaqDYi9gkhpQkTXbysXGAH6KePMOdZE/NDvXZlspycOPvxkB+R8b6k2E9HTOMnzjxxpZUkWFCuRGSiD2H+N7MRczsykvg9geiidfYJmzvYdh7pmiw6oC86NZyRvJ+NOG4t7p3fCMNscSnmTKQ7++n9+pPTQfhDMVpW3lg9uyssMTfEcXdyyOB0ZS4uK1buyvzZYIWL9+CTkn0Cya6467rVsOpVVOgT2lZWwmjSoHWlFR/5uyuxYVtNUW0vlXZDcuEhFI7B62b7bnWVnu4H5J1fV2mAjodWUmdfXkRAX4HfzRjQZ13ePftzEvt33303Xn755YK/f/755/GFL3xhPtslISEhISGxJIi5eeCVUpl3/I+2nh14R/gospJvPxCE7/UDiAcXrxs29uhjNH1fu7ID2trUvO2lTtLZN84uCEkCP8FeXb4Z4iQn4Na71hSca5/OC/376QH02qqVqNKlhFbK2c8v9tXiSLa0Mn6CWLrf50qb914EZh4sGFCZ4A6z560qyBYM+numk/36WMXGeCnkCqjkSgR7yMSABGTmqpz57CSgThwVRrDsuhWK5g30vO/Yc0VtV8wzmQznIyxmZ5+waSVzT0lZdVzOU9bDM1cHiSMUVXnK+Ani8xrj2QXz5fLrV2HVBjs61qTadGJ8IUGRVkkihvPV2rR00oDEwqBJW2R08GBMEWX7drpAll/sZ7YheXmIJnHy3/XBXfj0l6/D9bd3wFJR3DhRepsWLS/YB114CPH7aqg34u3Xr6bnydhJBR9hKksoECkijV9IS+NPZ8bRexV89J7LtSwD5Itaeh4cHMR3v/vd5M/kifrVr36FZ599Nue6giDgwIEDMM8QlCAhISEhIXGhEBPLCC0WyOS5B7K6+np4T51GdA5inwj8E9/+d/i6zkLt86P5rjux2BAiEYw9/iQ9b7n6SlxIJMV+EYJw665mDA+4sG7L7CWu5YYcl+3tZXO0r2y9OON3Ys++WApfrLPfbGkgnbRwhzxwBYtPcDdZmdj3aKsQVeroIlDH+koQA54V7wJGTQIRK1sUIUGACPkw9eT/0p8VLamqhHSIm0/GhpHgOdKD7BUUiPcdhu/481Cvu7boMn6luSrT2V+kYr+x2giLQUVLrQecMdTP4uzTqQvO0ZSzn6emWZx7T0vty7CbrtlYC2sV69/PWVThCwuTrhB+8mAXPd9KAxklFgra6qOQ0TR+p9Of+TutEYZV2+E/vY+KfrnWADevXBKdfRGvm4l9s1U95/BKuUIOgYQ0kiR+VwTxMGssqarS4Q3XrcaOVQa0tzTiyYdOJp19UewLc3H2zRbAl9+519XXQ6ZUQggEEBodJaVYWE4UJfabmprgcrnw0ksv0Z/JC3/48GH6P1/fvs1mw2c/+9nyb62EhISEhMQiI85L+JVZ4XwiunoWiFSq2I+HQhj7zx8g1M2CxPy9xZUrn2t8rx1AzOuFpqoShs2bcCEhlvEXI/ab2234yP+7krYynmu6pnppar5arsLFTRfBPcX2yWKcfVHsI+Slo+8UembWaJRqWiEwEZyi7n6tLNNtL4SZi/2Ikk8V0CbQdvVWvPQzJvgIFbUVCMaYS61X6RB+4VcQfNM0hV950c35t7OyEeGRLpg2Xw25RgdF43rafx/3uyCMnAHqG5Kj3zwHnoCgswNpVSbJMv5sZ3+RlvGTY+01zWa8emoKneMRKvbp1IQ8ziS5LDR4EgkSQCiTQ2WtASYz8xII4uSCcjn7+bYj2MvaeTR17dTR/+ZvTtIFixqbHrdckr/iQKJ8KDRKxANROJ25C0OmTVdTsS8z2uj+lXT2LZli3+OKZIz/nCsJoqkFYNwRhIrutzLUVbPyfj2vQhAnnMhLLONXVlQgxkfeEvFOWuYKiX25Wg3jyg666O45eQrYwMJLlwtFN5X99Kc/TZ5fs2YNvvWtb+HWW29dqO2SkJCQkJBYWs5+1tg9EZJOX2rPPjloPv31f2VCnzgr5CB6uLRy6nMB2U73M6zKr/YNN0GmSDl8y83ZP58cGGECa1PlGuhUWog+fEKIJ8fNFRL7RDgTIR11DNE0fOOa3cnfNRhrqdgnffu1FcWJfZM5s+WgtsUOvd0CgyICf5z9rqqjISn2NZEIhMEuctSP6ts/helE/paFisvvRFhjge2Kt7LHo1DCuH4PTeePnd0PbL+aXu4/8RKmHv8xZBX1wPodeZz9pVHGT1jTwsT+yaEwWM1MAohlBj/6u15H6MlfYHSalfDLrLUZKfh5nX0a0Fd+Es5hxEkliUIFVeM6fOVfn6dCn4zb+8oHdiMSSC1CSSwMGp0KgUCUBidmo+u4CJVv+DC8claO7xIzSRKAYzyQXBvzurizP0+xLyNCPiJgZNQHJa/qsVdmLiyIYl+WkCOclsZfqNxedP1VdbVJsa8wGmetQDCvW8vF/mmYlpnYn1Mdw9NPP41rr529ZEpCQkJCQuJCh/QBEhQFnH2xZz86Nl50v2BwcBCuw0do6eGqT3+SXkbmCSfiM89ZP9d4Tp5EZGiYOic1112DC41SevbPJ5P+qaQ4TyfmmaJj6mQKFWTcsc+Hro1VZAR7j2Zc3mCoKTmkjxy8m0wpwV7bwsR1XUOq5752QwcCXOyrPGwxwn7N3dDUtBa8XZWlGqpN19EkfRHj+svoaXzgKIQoEyi+k6wKNTE9ghhPhidE3WLP/tIo4yesaWbP2dnxMFv0I/DHKeJ8+l76WMlrbFi7G5rL313w9sSE/PTnpZzEB4+z+2lYA2cggSl3CEqFDF//mz05peISC4PexDMzvLnTQIggNm+9FoqaFfRnty9CJXjPS/148LenEQkzIe3hZfxiS85ckauYzJziIzgTMuSElybFvqBAJF2VCjzGv4CzrzCboDSZkmJ/Nszr1ia/s5YbcxL7DQ0N0Ol02Lt3L774xS/i/e9/P06ePIne3l789re/RTg8v3EzEhISEhISF4yzX1fL+gVDIYRGWE/tbARHWSm4qr4OlZfupn9PDnLCjtzS3PPJ6F8epadVV10BFT/wWq5l/OcTR4AJ5gpN5gzzmIuF7imtVZDxUXz50LUWEPvG0sU+wVadOvgmYwgJTetTEwVsNRaEuEOtibHn2LSx9LwHTcNKKIhTHw0j2H2YjqZjQX+MYN/RZIWDmEBPnH2SDh6OMjFB+uIXK5UWDS1/J6PKBT6ekJbqcxKCgCh/jRvu+Q5q7vgsHbFWCLGMP75AZfzxAS72mzbA4WICr8KohlG3eJ/jCw0zL8kPBwsNoktByvjJteMxAbGogLERT1bP/vzEvlLNPnOifNFUnmdKiVKpSJbxp4v9QqX84uWkekVbxxY35aYixP6aNXTBjCyaJ0N1lwlzEvuxWAwf/ehH8eEPfxi///3vaS+/2+3GqVOn8JWvfAXvfve74fGwHUZCQkJCQmI59+wT19u0hqUPu45miqlChHjft6qqkpbGK6uZGxkcZqW6iwEhHMb0awfo+dobrseFBu0/XiLOviPAnNoKbabYF4WgkvRwz4CuZT3t9Y5NjyHqSrWb1PNKgWHvOKJ8fF4xVNhSo9iqa1lFQV1jattMFi2CcSZatQKrdpGlOfbFQhYwjGsvoed9p15CfOAYEvGUyAn2sfaGqGOYVjiQYDKS6u/yMTGjVimg4e7jYmV9OwtWjMo0Oc5+IuAmSo316VfMPgUjPaCv3KnkJDxRmGS5IvKm9ZgUxX5WW4fEwlLBR1/GuEtfCPL6u/xRpMv5sSE3vVws459vz744HYC0CdBTY+6+oEwr488U+/EZy/hlSgV0dXVFO/tKowFq3lIXOstGlC4X5vQJ96Mf/YiW8v/DP/wDnnjiieQHBint/8xnPoPjx4/jv//7v8u9rRISEhISEou2jL+Qs0+wbtpIT91HmfM1G6FRJtJUVUzkq6urF53YD5w4SZP4lZV2GNrZGLULiWAgCoELUd0iDXEjCAkBziDbB23Zzv40349mEftyjR7yqtYMN5xgVZtgVBvofYz6i8+cqKhk4XwKhQw2fr6ptYKK/IYWMx23Jfbs68hzrFRDJp9b3oOBi/1A1wHWu09ERv1K/liOMfFybC/bnsa19H5cvMTZatLMOW38XFHBy7JjclWusy+GL5LAtSKePyUv46cLIjMk+8+FQPchmimgrmmD3FCBKS72bWktHRILT1UVX2iLCjMu6ARCMUSiArS8l54wNuxBwB9BlFS9yHLzN0pFo2P7pNivb7bmju5TpZXxx9LFPlnEykMiGk06+/oWVsWisuefNJKNtoO1L0hivwgeeOAB3H777XjXu94FY9pqilqtxj333IO3vOUteOqpp8q5nRISEhISEosOUkYbc7ln7NknWESxf+w4/ZtSnH16WsPF/sjiEfv+g6xc2rB1y6IXTHPB5+FiVK9K9pUuRtwRHxXjCpkcJnXKUSdE+Ti92Zx9grxhdU4pP3ldW6wsQX3YxxYOisFmZ9tRUamjI7gIGq0KH/+Hq/GGtzIhLpbxa+MCZOri53dno6nvgMxopyJYGD5FL7Nf/9fUxY97HEi4x+E79hy9XLGShQ9Oe9lrW2Gcn3N5LtBrmciPgAmvRLqzP8ukhWxkShWgYa9NYoawPPf+hxHrPVjSdgbOvs62t2MbPU2W8Uti/5xSU8PaZsheE5zB3Xfyzzcjf38SRofdmJ4K0PNms3ben3v6rEVSu7gQkYZKnSrjp7kUvKwfRTj7dW+4ESs/8VFYb7yuJLEflMT+7IyOjmLLli0Ff79hwwaMjxf/pSAhISEhIbEUiZKWNRKaJ5NBacl0VdMhY39kGg0dUefv6ytB7DNnX1XDxFqxPf8LjRCNwn+MVSkYtxY+HljKeD1MVBnnESwWi8fw8JmnMFKCUC6V6RBbbLLpKyDP6ssv1tknKOrXpLnhqQWpFmsjPR3xFz9ScNX6Guy4tBW7rmjMvA+FPLkwFBTFPnH2VXN/jsntKdouyhglSJx9eTWrNom8+kc6no+U7yuaN9DL0p39xY5ey0qhI1S+kQ+dlLMvkOR7cjDPJwwUg0xvSbUA5CE83oepJ/8Xked+kQw9nA1SKRDoOcK2dyUT+8ky/iXwHF9IVFYyQa2CLLngkg8nT+vXp7j42mcAAQAASURBVM2cnxzzwjHuo+etdlaRMx+MWe1P9XW5IaEqlSJZxk9P+SSJQmG0iShfwFAoodDpUH31VVAYchcR8qHr6KCnkcEhxAJsUWM5MCexb7fbMTg4WPD3JKzPZituRIuEhISEhMRSJTLFgq5UVsuMY+fkSiV0KzuKKuUnBznhCZ4cvkidfdeRo0iEQlDbbNC0FU5QX8r4uCA0zkOsPN+/H/ce/iO+c+gn2D+UCo4rJ9NhJtoq9bnHXamefbb/zAQp45eptBACHiScqf2slYv9Upx94tbddMcGWrJfCLGMn4h9mSr/cxwXEvjFX07iYOfMgXLK9pTYJ4n0dAGgnlUqCEMsfdu48YpkqftSEvs63vccTsxUxl+4jNnjj9CS7aLF/uhZdiYeQ3i4s6htDI/2IBEOAFojNHXMPXW4pTL+84HeoCYDGiljY0y452OKO/vqtFJ/0rbUeZK9zyvKIvYzX/uGtIkc2c6+jDj7BF5pUKiMP93ZLxVlhRUa8l1KWntOn8FyYU5i/7rrrqOp+6Q3X0RcqX300Ufxhz/8AVdfzeadSkhISEhIXKiEHcxZU9tm7xnU8ZA+9ywhfWR2MBH8JIFfzAFQc7EfnnTQPvnzzdTL++ip7eKdkKU5QxdiGb/JPHdBeGKCHVCScLvvvPQjPDP4MhbK2a/Us35sESESpMKdoCpC7NN06+Z19Hx85HTy8lZrEz0d8o3RdoFykQroEwo6+0c6J/GHZ7rw26dnroaR2Zugrm4F5IrkOD45F/sips2p0ZDTvqXn7Ae52M8I6OPOvqyAs0/KuD/27WfwtV8eR5xE+hch9iNjvam/7y8uYyQyyQxAub0puaAy5eKtEpLYP6cQPSYomCabnPTNWMZPPrllMSb27dVM3J89NVE2sW/N6vm35blNtVqZKuMn8EXzQgF9yTR+ZW6yfzGY17IRfL4uvqi1DJjTN/QnPvEJNDY24q677sLdd99Nd6zvfve7uOmmm/DpT38a9fX1+NjHPlb+rZWQkJCQkFhERJzsYFtTOXs1m27NKnrqPnGq4FghQnSSuXXamuqkkJYbjaxUMZFAdJK5/ucLshDh3M+C0Oy7L8aFiujsG+YhCE9PsgPKFZYWJJDAAz1P4ugY6ytfaGc/JqbqawyQa4ssc21l2RLCeE/ysiZLHVQKFULxMMa8xYf0zYbYs08C+gr17J8ZYFMGXL4oQpHC7xlyHFr3ji9C+6bPQ13FFifkVS3JhH9Nw2qoK1MtBaKzvyR69jVM5AfjXARF0sv4Z3b2j3RNwukJY9IVxojDz66rNyfFPglwI8GGgp89z4TwaKqfOdR/oqhtjE6x0YxyK5sIEI0JyYkHktg/94jz7Z3OwIxiX9z7tToVGlpYr38sxhaFrLb5i31LWpp/QgYY8qTxazS8Zz+hyBL7s43em1ugp4ZPtonwYN3lwJzEPgnlu++++/ChD32IfsBqNBqcOHGCfmj89V//NXX2KyoyV5glJCQkJCQuNCIlOPvqhgYozWYIoRBCff0FrxcTxX5tapQW+a7V1bOxQdHx8gmuuUBCBmNeH+QGAyzrmRN8IeLjPfumOfbsE8d9MuCkffQf2vgOXNnGwuGe62NVEQst9iNTrBRfbiouqZogCmXBk1pQUsgVaOPu/lln4f22VNLL+As5+51c7BPGZxAudDsNlqTYJBCHWQyLM2/LHA2ZKuOfe1bAuULHnX1/nDuZvIyf9tMHPTP27B84nfqs6B1x5zj7vqPPYux3/4LI3p+zy4Q4IhOp1zg00oVEbPZKoshkptif9rK/USvlMOrm5sBKzB2llglhz0w9+2lin0zMqKrNXBCsKIPYNxpSPfsKjTJvkKu6QBk/zcLJgxCLzrmMn6DkwfIkP2e5MOfaO51Oh49+9KN48MEHcfjwYRw7dgyPPfYY/vZv/xZmsxmRRVBmKCEhISEhsZCEec++pnJ2QUVcesvG9fR8cIZ+wWgesU/QNdQtCrE/sfd5emq8aMuc3ZXFREJI0DF72WOqvGJa9RzL+LvdA/SUCGWNQo1r2/fQn/cPH0G4CAFVchm/IdNk8Z9iLQPy6vaib0tVwYL8Ep7JjOdjha2Fnnanif29va/g4ERxZd4ziv14/p59cv8ZYp+nhJdC5Y0fgOamT8C44YqMy5diz34gxh1PXsYvVm6QsYlQ6/M+fwdPp3IWekfYwoBMb02G+00/fz87P9aNuN+NhGucintSaUGvF49BmEhVeRQi6mBl/DJR7PvY/l1p1V2QkzoWO1o9XyDi+3k+pj2h5Ng9W6UBlTWZ+1A5yvjVfKGKoMvj6hM0vIxfDOhLyGXFOftkssQcUJl4BYM31eIQnpzE8S98GZ4Xy99mtSTFfiAQgM9XuAeEcODAATqaT0JCQkJC4kImMiU6+8WF0lo2sjTwYGdXwetEHcxV1dZlJqjrGhrOu9gnVQlTL79Cz5sukBL+F585i1/+1xF875+fweMPnMC0I5jh7M81jb/bzYTxmioWzLjS3gab1opwLIwDIzPnNszX2SdhaYHO1+h55criXyelpYqsSgHxKOK+6Ryx38PF/ohnDD/Yfy9+ceqPcIWYiCyFOHGQhWiqZ5+X26fjcIdpuJzI6BQrQy8Fhc4IRf2qHMHp8on95EunZ98bVWQ4+6nwxZq8gnrMGcLEdMrZ7cl29qcGEfOwhUUggUDPIQhTbIFKU9sGeR0bkRgfZZ9V8aAXgj+39JkEBoq3k3T2PSmxL3Hu0XNHPeRn77F8THvDEN91ROybrRqo+cISGbk3n/YlEblcBq7hYanIvy9o+X3KBL6YxfMGCqbxi4sAc3X2zUzsR9PE/tSrr8F99Bgmf/lrDP3xT1i2Yv+pp57Crbfeim3btmHHjh244YYb8Mgjj+QsBHz1q1/Fu9/9bvT2pgI+JCQkJCQkLmixX4SzT7CsZ85+uKeXjq8rydmv587+xPkT+74DByGEw9A11EPTzkabLXVOHWXjDN3TQbz6Qi8e+NUpGs7n47PY55rG38Od/bVc7BNBtr2aLfa82M+E+HwJRUMIcIfcnhbQF+s5QMehqatbILNnjr+bCZlCBaWFlYRHp1Oj9jq42O91DSKeEGh1AoF4/4dHi+vrTicQTYlQlsafKwR6RzPF/dgcxH4+SO9/MBxfMs6+XsuFm8BHknGxLzr7hSYtHOthwtzKcwn6ssS+CFksIATOHoTAHXpNbTsUdSxjRBjtRMQxhMH//hhC938BnkNPZvy9wBcdFAYrZFpWIu3kjrIk9s8PZt4rHwsXzrlweUkZP3f2qwz086m2geU5mK3qslVkGPn+19GW/ztSwxezZGRbEmRxYGaxL/DRe+KIvnKU8UfdqbDK/nt/BeefH8KyE/tPPPEELdkfGBjApZdeStP43W43PvOZz9BFAALp2b/tttvw61//GrW1tfjRj340pw06c+YMvvGNb9CAv8997nO0TSBe4AXPZnp6Gp/61Kdw6lRu+A2pRvj5z3+Oz372s/j4xz+O//qv/8LkeQ45kpCQkJBYupAyWbGMv1hnX9fUSPv2E9EofGe7895mIbGv5T37kbGFm9k+G16ewk9mG5+L8txQsLAzVQ6ikTjGR9lB3613bkJVrQnRqIDnnuhEhAvCuaTxe8M+jAbYMcaaSjaKjLCtmgXgHRo7AX+a4J0rjiBz3w0qHfRpgjnexV4n46YrS36dVBVsUSmWJvZrTdXQKjSIxKMY80/gtbQxggdHjs9Z7KshA/Xn8vTs9476MsrYx+ZQxp8PsYRfpZQlb3sxo1UrqCQLZaXxi86+2HqRzfFeJvZvuayN/j0J6iOPXaZLjUNUmitRdctH6Plgz2EIk2zqgbq2HXJR7E/2Y+y+r0EIeknPCxyP/A8cj/+E9vcTEi62n6gqWeVRes++JPbPD5YK9pmViObXT6FInC54pTv7hDo+Gs+UFqw3X8y8MipfEn+6sy8m8hdfxq+YXxm/L+Xsxzx8akktey9NP/IYAkPDWFZi/95776WBew899BB+8pOf4Hvf+x6efvpp6vCT80ePHsW73vUuDA8P4x3veAe93mWXsdEnpUCqAcjt2Ww2fPCDH8SVV15JcwBI4N9sOJ1O/Md//AetLshGEAT6O7KQcOedd+I973kPFfrf+c53EAzO/8tWQkJCQmL5EQ8EaFk7QWMvTuwT4WVZz0b/eE6w+d/pkIMOMr9eTONPR1fHxL/g9yPKD07OJcHRUYTIAoVcjqqrMnugF4ITh0bwr//4OE4cXLhKhsnxAO3ZNxhV2LqrGdfewl6bA/uYK69UyZOlraVwxsEWcupNNTBr2cEloc5QjRZLAy1jP+LIff2LodPRg/s6H4In7IODp6jb00r4iQtLRZtMDuP6y0u+fSUXj+nOPgkZbDKxRYCjjjPocqZG4R0ZO4lYgZnYhQhwd1pHIrrJ+yJPz34fnxG+e2NdWZ19MSXerFctiX5yso1E8IeR7ezzMn5LTd6Re11DbBHr0k31qKrQJkP6iCNKXHiC9bK3Qtu0lk5sEEL+pNjX1K2AzGSHggT/CXHE3JNQ2eqg3HIj/b3n9UcR3c/KnQUXq4xRV7IQR4Ik9s8vlTb2vCuEBNVA2Xj8USoAyWJbuthft6Welu+3rypfyPqOS1tR12hEx5r8FSjatL5+WZrYR4HRe0Jsns6+yZT6/ua3FXWz71PLlVdg1ac/CfOVV+R8/17wYr+rqwtvf/vb0dzcnLzMYDBQ972zs5O66eTnn/3sZ/jiF79Iz88F4uLX1dXhnnvuwYYNG3DjjTfijjvuwN69e+EqMCKB7MQvv/wyvva1r8FT4OCHZAiQqoSPfOQj2LlzJ21FINtM3P7nn2dBQxISEhISEqUQ4a6+XK+DQlf8Qa2Zl/K784j9EHft1XYb5OrMQCNyH7pGVpLtOly+nu9imXhmLz21bt4Ejb34hPe5cvo4E5vjIzPnBM2HCX7b1fWstLNjTRWqavWsPp33vs5FEJ7mYl/s109nT8tOevr6+NzC7X5/4mG8PHoQ/3fyUTgCbB+sTCvh9x1jr5N+xVYojUzUzcXZTxf7hGYTqyzZO8QyGzpsrTCpDDRo77SjtJnV/ggzZrRiBmBWz34sLqB/nIn7y7c2JNP4hawQxbkwzbMYzGlJ4YsdrUaR4+zHZnD2j3U7EIsnUGPTo6HKiKYqfUZIHwkuVG19A0ybrqJTCxSNbJGLIFNpqbCnE0BaWNsJWRyoffsXoN52K6pu+zi7/659SMSiac5+ql3EycV+lST2zwvVVex5l0MGN89PSMftj2aM3dPp2b7V1FqBz3z5OqzakH+6w1zYsrMJt759DfQFAvqIsy/wD1xZQpHs8U/EF8bZVxr0ZAUtw90XF88VJiOqrrgMVW+/E3LV0vl8KIvY93q9GUJfRLyMlB0S9333bjZWZi5Eo1G6cLB169aML1YizImgJ20C+SDVBKR14OKLL8Z73/vevNchf1tZWYmmptSqo8ViQUdHB61KkJCQkJCQKJUw79dXWEsTVGY+rs5z8lROX2JwdCxvCb+Ibed2eup8rTw936XgeP5Felp9zdXn5P6G+plrHQqW5hqXwvgIE5Q19cykIMcfW3czUZsedFUqpyaZ+F1bmSv2dzdvSwb4+SKlu9VDHraPPNf7Cg3KSw/nI6XV3qPP0fPGzVfNadtF8Zhexp8u9oNxJjZ3NW7FOhsLcTtQYim/WMZPx+5RgZkpCvtHPYjGEjDoVNi8sgoKuYzPbo+Uz9lfSmJfLUeYi33i7NN2n+nCPfuH+Mi9i9ZU0326qVoU+6w32bBmF1QX3UyFPkHRxEQ9QV3TmrzceukdUKzajbp3fAkq3ttv3HAZFCYbEAki0H0QAhf76jSxLzr7dsviH214IaLXqSB+ak7wwNF0SPBlqoRff14rXNRKhbi2Ssv4Bb4piQLOfkrsz83ZlykUkPPF+ZjHm+Hsy3k//4VGUWKfiG1FnvE6au46vO9976N9+vPB4XAgFouhpiZzhZK0D6hUKoyOsjKhbEjJP3H1SXm+uD3ZkL/Nt33V1dUYG8v8MpOQkJCQkCiGQD8v9S5R7BtamunBBmkBCA+y+dQiobHZxP4OejpNgvIK9DQuBGRRIjTOnETLBrZYsZD4fREamLeQYp8IJtHZr+HOPqFlhQU19ayvWTcHQUicbjG1fm01E8PpVBvsaDDXIoEEjo6dLum2w/EIpgJsEYT0/D/d+xI9X2lgYj8+dBJxn5OWZRs62MJQIchYux880IlRh79IZz/Vk03Y0bgZ6+zs8R0cPTY3sR/nJcZZZfydg6yac2WTFUqFHDYzO75zuAqPEiu1Z5+U8S8VaBl/mrMvBDy8nF/GJihkcXaIPX/reShaY5bYz0bRsJZNYeDhfCJqewM0l70L6uqU4Scj7SHrLqXnvUeeRcLryHD2SQCij79nJWf//CHwVHvnFGv7yHX2M0v4zxdqlRxCWhm/kHT2Zy7jxzzGviqMhoLO/oVIyaP38tHeXvwM10KIvfNabe4qILksxHsYsyEtA2RBYLbbzne7Go2m4O1KSEhISEgUIu4PYOgP/0fPGzax0LVSnAVtBwttC3V15S3j1/KgoGxMq1ZCYTLR+yeVAeeKODkoIiXUMhlU5lTA10IxPpwSoMHAwoh9lzNAb1uukMGeNmOauFw33L4eZqsW7atnPr6IxCL45gs/wB+6UtOJzkz30MT6ap2dCvt8bK1jTmq+JPtQLIxHO5/FdChXmI0HxFFpjCDv3xbL+ONnmPhXrtw14xxqUib/b785gENd03j0lVT/Pf1b7uyTHu5EOPU62DQWmDTsYJgsVpA8gjUV7VDI5Bj1TmAiwCpdShP73KXLKuPv5FUdq5rZ46rigWGTZRD7U25239YCZcWLEZ2alPFzJzMeRdQ5Qs/KDBbIleqcRayBceZYttSx96ro7A9N+GiFRDYkRV/btIae1zayYL6ZMK7bQ08DXa/RzwW51pjMAXC6eeaIWkErMyTOD3I1E8Nud3jGMv6K8yz2NaqUsy9LpDn7s5bxzz1cU65n74eo14uEICRFv+ICdfYXTQwp+XCaifmUmMx22/OBTApYCqn+4XCYVjGIp+mXzfb7Yi87V39zPu97qW3vcr3vpba9y/W+l9r2pl/m+PODdHSPqq4Wml07Sr5vVXsrcOw4/Kc7k5cFPR5M7Wfl+RGLJePv0/9Ws34tAvv2Y+jZvTDdfts5ea6CfEKA3GTEOP/OW8jnfHQoJXRDgSit0ItEImV9vbtOMnFaWa1HnKTMp11PawDuumfDrPfz+0MP48AIc7Uv69mJGn0ljk+eoT+vtrQVvO8WDXPPD44cw001l2dc789HHsMfzz6GHVUbUaG1ZNz3MC/br9FVwhGaRjzB3C9ZCBjpPo34ICunF9p2zPi8PHdoFMOTTMh3Dzpyfg+S2B70IOwYxpiGiQHy/DcZ6nAy3IX11g56XXlchnZLM7pcfTgycRLVentRr8m4k+1DWj5GK5KQZ/z+ZC/7fZUJ9HKbWZUM6ZvvPj04xlxvi16+ZD57yOSApLMPYOTef6SnCYMt528mnD4EQjGQnDNF3IexsQD0qgQMWiX8oRj6R91QKeU596Pa9TbI6o7Da1sBX4HPHvF8QmYAjHbAxxd4LNUYHx+nv+8ZY+9dq1GVvGw5fkec7/uWq2RAEPC4Qjm/n/aEoOLOfgLn5zGKp5GokObsKxDn0j8Wyv83sTBrEYkK8Tnft0zPKk6mhoagJC4/DzGMqVS5n4WLGNKirixi0aNosf/666/njMDz+9kXxUsvvUTf0Nncfvvtxd48dLx/gjzB2RD3PZ8zXyx6vT6vg08uE+93rpD2hvm2MJwLyE5LtlM8Tb9stt8Xe9m5+pvzed9LbXuX630vte1drve91LZXPA0MDKD7BeagrvrQBxDS60u+79DatXD/+WFEenpRU10NmVyO0088RZP2VdVVaL/2aloBkO92/Fu3ULEfOn4S9jvfck6eq8Bx5kArLZZz8pw7xlPl7fF4AnZbFZzTjrLe96GX2QJG28pqWulX6vb2DvXh6aGXk9t52t+LTW3rceaVXvrzhqo1BW/HXmXHj4/fB0/EB0d0Gjtatyav5xKYy+QIu3Lu28nHqa2wNmOVuh0v9O+nP69u7IDi0DMIJRI0XV1e3VzwvkPhGB7dfzC53Q53NOd++sxVEIIeKEOejNt574478fDxp/D2bW+CQa2nl13atgNdh/pwcOok3rXrLfR4cLbnT6ZmQkPLD7I1xtR+1TcwjNEp5r7v2tSGCrMWtTbiZE/B6YvR653omYLT6cVl21tK3h/cfrbAUGM3LJnPHoOuG3Eo4LGshNmdqgZSNa7L+ZsTfB+prtCiqZHlLJDfr2i04uhZB8ZdMezZked+WlowZq4s+jEMdOxA7PBj9Lyhrh1V/LoCT1OvtZvOy/O7GL4jFsN9G806BDxRhILxnN/7QmeSArC2jr3m52t7iSErin15Qo4Er84nJ/n+RsZHPmp0+jnf9zhP5NfL5BAibLyrwmCANs93+YVA0WL/d7/7Hf2fzzEn4/jSnXdyOfm5FLFfVVUFuVyOiYnMETvT09M0vI+k9M8VkgPQ15dZpkYgjvx8bldCQkJCYvnR+7NfUCfAtmsnrFs20wODUtE0N0Gu1UIIBDD+1NOouuJyuJ58iv7OeuMNVOgXQrd2DU3qD09MIDIyAvDvsdD4BPp/9RugqQG1d74V5UScQ0xaCBaaeEyAYyyzjzzgn38wW6EAwMaWuY2ZembwFRqwp5IrERVieLF/P3Y1boE74oVGoUaHlQnRfKgUKqyqaMfxqTM46ezCDjCxTxj1MvPEGcqdQjTOS+WrdZXY1raJin2lTAGr1oSRw2z/MW29FjPF/v35+W5axms1aWj/+pgzkFPaLTNXAePdSHgyKxdbrI14c8eNVOiLXN6yC78++gCGfWPonOqBBbOXBQ/zx2gjc8BJr7gi5Vr3j/lpxwjp0ydCn1BlZaeTrhAGx734/A9ehEIhw9b1rTCWUCpOjk8neRaE3Vy+WeLnooyfcLTt3bhukwHVtgr6WBy+XCNrhC+U1Nszzay2egsV+0OTuSOq54KyfVtS7KurUgHYDhe7f2ns3vnFZNUhMORB2BVGLCvszu2PQGzG0unPbztLun4kPftx2Sw9+9H5pfGLwp5AyvcTXtbyorIsfHvaohb7X//61xd8Q0gI36pVq3Do0CHccMMNVPiLY/PI+TVrWC/RXFi3bh1effVVmtzf0MACZtxuN86ePYubb765bI9BQkJCQuLChhwcuA4dpudb3/ueOd8OEfMNt9+Gwft+h+7//hFcBw8h7vFCU10N08VsNFsh5BoNLJs3Yfq11+F69AlU2uzwHj2Kvvt+T2cHKyqsQJnFPtk2gvIcHBCNjXiom0/GQSlVCnjdIRrYpyjjMWk0Esc4H0NGxH4wnD+4rBDukAfP8hF0H9zxLvz49d9g3O/A/ccfopdtqFlNFwFmYp2tg4r9U87MsXWk/53giXhz5tePB1k1Qq2+Eqvs7bhn2zsQC0YQ6TtOZ6FDrYNhzW74p9hCRjavHh/FH59lzvA9b9yA791/COGoQMvj0yWz3FwFcqgteGdvUzRqDLi0eTv29r6Cx7uew51tb5j1bwZcw+xxRGKQa3QZB/w9o6yyoa021T9bmdaz/+vHToOE+AuxBE73ObF9bf58i3yQ+eKRmEBL3CtMS6dnX8PFfjASp6PxFAYL+4Uvd6FxhKev11emFmQIdXb2s5OPHpwv8op6qGtXIDLWDU19KohyUhL7i4LGDjsGj49BHRHw0jPdWL0p9dnt9kVhS04cOf/vgwR5/ydIGr8CcXkioze/YM++Yh49+wYu9onQ5/365yKL5nxR1DP1pje9aeG3BKDC+9/+7d/wwx/+EHv27KHi/MEHH8QVV1xBU/eJwz84OEgD+WYL5Utn+/bteOyxx/C9732PPhaysPDQQw/BaDTS25aQkJCQkCgGX3cPPVVWVkJXN78yv6a77oRrcBDel17B1Cuv0ssa3/ymolKG7RfvomLf99rrOPza6xm/SwTLHzwb56OJFOfggCjdcfd6QlTsB/xhlFObjQ67IQgJOlqPBPEFx0sT+/cfewgRIYoVFS24rGUnXu07iNfGjyb797fWrZ/1NojYJ/R6hmiFgFFtoOF8YjAfOeSdCk5nTEYSQ/BINgARyNd1XEYrS4InHqeXK9ougjwr2Z7gC0Tw07+cxT6eU7Cq0YQ9mxvwu6dOUyd9aMKLtip5prNPtsGTGQhYiBs7rqBi/5Whg7ix4XLM9M7wRQPJx1gbjkNuyhSFfaLYr0uJ/Sore0wk5f2loyycjnCyd6oksT/FZ47bzFqa8r/UnH3Siz8bKbGf+byKVRKkqqNc1L71/2G86xi0jaszXhNCKw8HlDg/XLK5Hg88fBJNMeCFp7pQ17wBpDI9LiTg9Ueh5Bntc5k4Um7oWh/Jf03IEZ8hjZ9UsyQXAcrh7Hu9kIli/wJ29hfVJx1x9j/84Q9jamoK//M//4O9e/fixhtvpGP1RDf+m9/8Jl58kc36LRYSXvCJT3wCK1aswG9/+1v88pe/pGP3PvOZz9B+fgkJCQkJiVLEvqYlVbY6V4hYq3rn22HbxcbpKaxWVF9T3Gz06quuQPuHPgD9xg3U6Ydcjrqbb6K/E8LhsgfTxj3nUOz3MYHb0FIBvYGJvEAZBQphcoxVKtirM13lYiCi/qkedhzyzs2307/fXr0p4zpbeNr+TNi01pwRfJNBZ+Z2+lM/E6FPAvlICwAJ7ksn5mIOvJyPzcvmRw8co0KfONpvvqoDn3zrGsjlMtRWaJMp7enITJX0VMgq4y9Eu60FLaYGxIU49o0emvG6Iz5Wwm9XGaAhbZ+azOOwXt7C0VaXagfQaZQwpzmQ4nnSu18KU9zVrrYtrWM/rYY7++GZxT5534t5B3VZZfw2PvPe5StfS4zSbIeiIVV5S6oGBsd9VLxtXsn2IYnzA1ncue66lXAjASGewAtP9NP9w+uP0Gg+GQ/o05/nMn4Kz3lgZfz8uytfGT/P+CiXsx/1+iB4RWc/8zP1QmLRpPGLbN68mf4vlDpIXP9CrF69uuDvSSXABz7wgbJtp4SEhITE8sN3tpueappTc6fnAynnX/WZT2H0L48iVlcLuUpV9N/V3XQDZFs3o9pup+5utb2S3g5peBYikYXp2becW2ffwUeIBXzhsh6yTIyy263Icj9no3d6EPd1slL9G5ovw4YaJnRWVbTBqjXDFfJQ152M3Bvzzp7lsLlmLU3YPzXZhUuat2EimCleHQEnKnXsIHSEJ/HXG6sh5zPRRWJuVvovM4rFuZmc4c/pZ9+5HZdtbUjmTNTa2OMfniQHvOaMMn5K0AMhEoI8azRePi6r34H+M8N4afR1vFO4Awp5fudt1M+2tU7J8h/kal3GWLxpb4Qe+zfXZPb+19r18PgjUMhl+PQ7LsKXf7wPnQMuREjff5FM8TFk1RVLTOwnnf2ZF72m3CFa6k8Wcmr4Qo6IzZRy9hdqStXJfneyBcO4GETkMuf2Kzrw1As9MPliGO73YHjAhahKnvwkVZLzqrk75GWDf5zJ03v285Txp18mU839+0BhzHX2leaFz6M5XywqZ19CQkJCQmIx4086++UR+wSFRoPGO26Htq11Tn9PFgjIf4U2Vb4dL3Mpv+jsKxfY2fd5QnDzALWGZisMRvaYSM9+OZnkiwi2EsQ+mQ3/7Zd+SMP4SJn+Ta1XJn9HZs1f3noxPb+5cm3Rt7mqcgU97ZpiCf7Zs+on/Kmfhz3MEa835xbJR0m/PtkXyDi0LGiQG++jXtnMZqGL1NoLOPsaPeQ6VkYfnS4ugHJr9XoYVDpMhz10UUTkgVOP4/MvfwtD7lH2OPzscdQp2AE36dkXIeKd0FxrTgpckaYadjB+3a4WXLS6Gia9ErG4gK7B3CDDC83ZF8v4Z3P2B3jFSn2lgY7XS6eCBxLG4gn4guWtlBE52cfE/rrWC9clXUqoVQrcfk0L2F4B9PdPY9oTTop9jXZxeL5kcYpAyvhj3NnPW8afFjQ4U4ht8WX8PsRFZ18q45eQkJCQkFjexP0BhMRZ983zL+MvN2R8H0n4J8SDTNwttTL+4UEmFioqtfRAVG9k7mCwzGn8E2OlO/sHho9h0j+FCo0FH7v4vTnu+l0bbsVnL/0gbmi5vOjbXGVvo6f9riGEYxFMcmdfr2Lb5Ugr4x/mlQIN5swe9UQ0DCHgKejskz53EkpHDqftvJRbpLaCO/sTvhy3V2VvpKeRidxpRvkggYRtFWwRbMjDhD3h+b5XaZ++2PowIop9uSZH7HcNsgqEVc25uUzvuH4N3nplM/761vW0dWJloymjR7yUnv1q/riXWhn/bD37A+NsP2iuzXUpVUoFTNxtd7rLn+tBMjBO9bP7Xy+J/UXD1pWkHYq97qfOOjDtDSXFvla3OMS+LFnGP3NAX0IMLCV9IjzIfS7IDWyxL+r1Ir4MAvoksS8hISEhIVEE4YEBeqqpqU46A4sNhY6JOSFUvoN50hIgBILnROyPcJe2qpY9v+JBqr+MYj/ojyJAKgVIIjt3touhd5q9/hsrV9MwvWyUCiV2Nm6ZNYU/Hbu+Ama1EfGEgJ7p/mQZ/4ZqFng2meb0J8v4TZnOfsLHFgTkGn1O/zvByQWu2aCigi8dMoudHDcTp9cbyDy41tazAMHwSOa0gJkgGQSEIb6tMSGeHCX42tBhGjI45mdVCHUCe57kaWP8xHaDVVkVCHRbbXpcv6OO9u8TVjaaS+7bdyz5Mv7inP3mmvzvUxt3952e8ov9nmE3XVjSa5VoTctbkDi/kIWxOl4VMzziwbSXOPtMXGt1ikXl7NMyfjGgL2tcIIVfJlMqS85aSUf8/k5Eo4g52eenynLhLlDNW+yTWfVHjhyB1+tFhBwQpIUnSEhISEhIXCiEB1hpsnEFK71ejCgWwNmPuFzJAyy5vnyOKA2LcocgxIVZxT4V52VimgeYVdj0JfWr9nCx32TMH4I3F8gBa6uZOeidjt6kuN9UuyaPs89Ec6M5v9hXWniffRZOLxO4ZG59NmqVHFVc+I7x9gkRcZxaeJiN6iuGRnNdhrNPFi/IQgZhMuDEq8OH6BQDEjJo5825Mu7sE2dYLMnP5+xnIzr7ZPwe+dti9jfnhV7Gz9tTmrm4y4ZMIVgosX+ok2UxbFxRuaQmHSwHWvnimcsVwoQzkCrjXyTOvlyRXsbPL8xXxs+dfblyftst02qTbQDRSTZxRHL283D48GG8+c1vxuWXX4677roLx48fx2uvvYarrrqKjrmTkJCQkJBYyiQEAV3f+y84H36E/hzuZ2LPuKIdixWFlgmneBmd/eg0E2DqCuu83BSRMyfG8fD9Z/CtLzyBf/+np/Dkgz1JMTYykCX2eRl/oIzOvtPBnpuqPKXOhRASCfS62GJPYxnFPqHVxMT+gZGjCMbDNCVbdPYdwWl6356wD94wKzetM2WW8Qs+tkCgtFTnvX3R2S80V76xivXmjzsz9xlNAxf7430QYpGSnH0SOkgY42F8Iv934lF62mSugzwWzgjoIyGBRMySBYhCYjVzu/XQaRTwh2IYdgRmvT4J9wtH2cJD1RKbAS86++T5IftDPsj7Z1AU+wX27YqFFPtnWMXG1tX590OJ80djPROyikQCrxwbTZXxL5aefb44RNL4Y/LZe/bJwvN8kMlkUBr5aE9uUksBfVmcPHkS73nPezA9PY23v/3tycvJ3HryYfPpT3+65PF4EhISEhISMxFxueF+/gXEeEn5QuPv6cXE089g+qG/YOrV/ckyfmPHInb2eRl/OQP6yPNOUFlnd1tnY2zYh9///HWMDHgR4iFh/WddNJjP644gGIhSl8depct09sso9qf5HPLqEsS+I+hEMBqijnStIb+DPldEZ/+0g016qDTYUGOsghwyOsrOE/Emw+1IXoBGqS7R2eez5U2pAMd0GqrZQe8Yr3gQoYsHWiMgxBAZL65vv9HCFkImfA5EYhGM8pJ9vZLtl/3uYXrabG1AIhJMth8Qjnczh62lxgBFEc4wSeVf08IyCrqGxAiywkzyyoUKk4YGly0l0sMKw5FMEbT/xBi+/6cz+MpP9tEyf/K81PMFnELOPinlLidkEeJUH1t02rq6vO8Piflj4q87mfXi8oUXXc++IunsK4pL41fK4Y/O7zhAacr8/JfK+LP47ne/i9raWjz00EP46Ec/mgx1ISPzHnzwQbS0tMw4Ik9CQkJCQqJUhn7/Bzh+fR/GHmHu4EITGk+5kt0/+CFivNzP0D6zs3/80DCmJmZ3GhdW7JdvQSTqmk46+/PB7w3j6Qe7acl1S4cV93zqMtQ3WZJu/ySfr15bb4aCJ4kbDEygkoWB9HL/+eDkYr8UZ3/Ix8R2i6WBJu+XkyZTXUbYX72pmo6ts2qYG+cMuXFs/DS7f3NDzt8nvFzsWwuIfU/hMn5Coyj2p0M57pe8ik2ICI8UV8pv0ZiosE8ggRHvBMYCk8mxfOmPsdnSAERDGQF9T7/GKic2ryh+P1vfzqYPdA7OLvbHpwNLsoSfoFLKqIgnhCKZ74OfPXQcR866cOA0+7xqrNbnJPHnlPGXOaDv7JCLpvyTfazOLvXrLzaMfKFPHOy62MS+6OyTnv2Y2LOft4yfXTYd8eFbB344rxGSqjQnX67R0Kk4Fypz+sY6cOAALeE3GAw5JX1Wq5WW9Xd2dpZrGyUkJCQkJBAcYq6gr4eVfS80oXHWI02I8r51TXV1xkFCvhnx//erQ3j2ETZK7VwjX4Ay/ggv41fNQ+wTgf/HXx2E3xdFZbURV93chrpGC9ZsZE7w6WNjmBxlYr++KXU/Or2KBsgRQsHi56kXghwczsXZH+Riv62i/FMYNAo1XUQQqTOyMv0KLXsepsMuHBo9Ts+vt7HS+lKcfTK3fkZnvyq/s09QiGK/yL59ckxYq69K9u2P8jL+FZYWrK1igX+EFuLsR1Nl/KQM/8zANBW0u9cX7wxvXsmue3rAk+zbj8cF/P7pTnSPZC4ATIpif4mF84nPKwm+I4TSnH1S0j/uZI/rvbesx0ffugUfvi13H1nonn1xdGNDpb4srT4S5cXIgxlJMB95dcSAvsXSs69Qimn8aWJ/BmefXMcZdtMxqHNFKZbxX+Bj9+Ys9kkIn15f+MMyHo/TsD4JCQkJCYlyi+9Af2qG90ISnmCupHb1Kjbqp4h+/cFeJry8rvKWyZ5fZ9817zLHk4dH0Hd2CkqVHG99zzaoeVnymo2sx7u3y4FhPrYrXeyTkUziAalY9j8fvJ4QIuE4vV17dfEO5KCXif12PlquFGKeKSRiM2/7Sj6Cj1BnYj3PNi17vvs9w8lwwLW2lGDO7tlXFejZnyrS2SdJ9dGsBGzR2Q8V6ewTavSV9LTPNUjbH+hjMlRjR8Pm5HWaLfUZzv6LR9l7bef6Wjo1oFhWNllpOj/p2+8ZYe0mzx4Ywr2PnMK9j2cuuImieKmN3RPRadnzEgynXiO3L0oddWL6v/HydtxwcQvsFs15EPtsYaXWVvx0C4lzh1anSibeqxahs6/klSikjF8U+2Lyfgbc2RcT+8M892O+ZfyqCzicb85if926dXj88cfz/o6I/AceeABr166d77ZJSEhISEgkw/LCvIw+ODICITp/4Tcb4Qm2uGDasR31t91Cz1ds2zrj3wzzgLloVEBkluTshUCh48nmC+Dsqyvm3rM/Oc6cv5Xr7Bnl88TlJ+PviCs7NckWKOqzxq6JB6TBrNFwc9qOMbYd9koDlFlj6GaqBhDL+MU58sUSHDiJgf/8IEK//zK8R59FgifTzyz2mbNv0zCxv3/8SHKhgYzpS4cG5wU9BQP6YnEBbj97r9gKBPQRAWjUqUCM8b5Rdlsi8qoWdjvTY0iE2HM3G2KmwX4yag8JGFQ6ut27GrdCp9Si3lADi9aMRITto4JSi30n2Xv7up2lPb+kt5+kvxOOdLIFgxePsAqgEUcQ3kAkp2d/KZbxE/SaXGd/io8SrDBriso5INcjTHtC8yqBzmaYO/u1tqW5kHKhQ6otdHwRLV3sa7SLy9nPLOPP4+zz732BL1yE43M3lpWm1GepUhL7uXzwgx/E66+/Tvv1n3/+eXpZf38/HnnkEVrC39XVhb/+678u97ZKSEhISCxT4m53qqxPEBAcZgf0C0lonIkHZaUdre99D5q/+iVUX3P1jH8zMsjcRYKvzCFY52v0nujsz6dn3+Nm22PM4y63rkwtIqjUCroAkI4u6ezPX+xP8DnkVbX5A8zyQUbGBWIh2kdPHekSCHTuJ4eoSARcmHzo+wg/9G0I4dw8h5WVbRk9++ll/OS+CVvq1uf8XczNRLJMpYVcl/uYSG820XRKhQymAo45EQKrW9hrcLpvOvN3Gj1UNvaYhcniQvpqeBn/mI+9fxot9fQ+7PoKfOemL+Bjm99DL09wZ//4oJ/OZyeLDhfNIcl98yom9g93TVKH/0gXu1/2eJx5nP2lKfZJBUO22Hfwqo3KAlUbhZz9SExAIK1CYL6QSQoEydlfvOgNbP8hnwIqXsa/WJx9FV94JaP3okX07Kec/bmLfZXk7M8MGbf39a9/Hfv27cPnPvc5etlXvvIVmsLf09ODz3/+87j22mvLva0SEhISEsuU6BQrVRZZ6FJ+4nqFJ1i/scpuo2JFVV0Nmbzw12YoEIWLCwqCjx+Inw9nv5xp/Mkyfus8xL6LbY8hj7vctip1u6SPXyw3FdHqmUgNlcXZF8V+8f36Pc5+ekqEvlJR2sFxaJjlFymaN1LhLEz2w3ecmSTp1BmrcUnTNmyuXEvT+NOdfZGL6jbQU7JYEB/vpvtozD2RDOfL1ys96WKLLJVWHeQz9FKv5qn2Z/ozxX76CL74JHseZkPs2RchY/ZEKvU26vRTuNh/4Th7b1+7s7kodzqbLbxv/2TPFF4/PUXL2kVOpYn9VM/+0nSfxZ79YB5nf6bS/XTIFAK9lgkrt6887bbRmJBcSJGc/cWLOMb0jkvbudRfPGKftHelevZlGWP20hEX/JPO/rzK+I3Lpmd/zq/y7bffjuuuuw4vvfQSBgYGaB9/Q0MDLr30UhrSJyEhISEhUS5ijiyxPzAAzerCQVTzJe71QiDZM2Qer40JodmYHM90bH3eEGz68ia3n2tnnwjKVBm/FXOdMeDl6d9GU667bK/Ww1Khg3s6mNGvn1PGX4ae/Qlepl5KOF/v9OCcSvhJGWpklIVJqnbeAZ2jC9N7f4NAz2GYt92YcV0i1D95yfsxNjaWTK23cWefYFQb0GFrxcTEBKae+gXCh5+CV0i9Gkpz/lA7UexXWWd2s5POfn9KHIto6lfCd+y5op39Co0ZGqUmeSAujuNLJyHEAe7KHe4jCzAaXHkRG0FYKk01JlgMKtqu8OBLrOKHJMKPTvmp2L/+Iht8gQh1/S80Z1/MY7Dz8vxisBjUCISCyfaO+TIxzapHDFolTPrFIR4lctHx10YZY61EZFFVpT6330+FEKdHyAUFovJE4TL+bGd/XmX8ptT9S85+Lvfddx/cbjdN47/++uvx/ve/Hx/4wAdw8803S0JfQkJCQqLsREWxr2CulL+fBZYt9OKC2maDTFncAayYJn9ey/jFgL4y9eyTCgEhHJ6Xs08WDNxcdOZz9onQ3X1lO9QaBTZszS2T1+rLU8YfJw4kT2ivbSg+bLCXh+OVGs4nOIeQiEdpeb3MXAV9GwuoC/Ydz3sgm00FD+gjbK5dCzmvKgmPsGoB18t/QnR6jJ5XWfOXvzuSzv7M5dWrmyuo20cc2mlvKEfs08fjGEj2eROxPv7HbyP8/L05vd/k9Ww0seBFQlOe1gchnFqM8sfY61tlnZsrTO5vbQt7rjwBJmD/6pZ19LRzgIyEE7D/JHueqq0aaLloXmroeUBfKK38noQqEiqLdPYJViO7HVcBZz8UieGT/74XP3ywuFDGMSd7LRurTVIS/yJGz9t4xNwSnUG9aF4vNV90IGX8MQXfpqKc/XmIfePycfbnJPa//OUvY8+ePfjYxz6GJ598EtFzEJQkISEhIbF8ifEyft2qlUln/1y0DWhriu8hnuBz4sUZ8ee1jL9MYj/qYmXdMq02WTVQ8m1E4vQ/wcCFRjY797Thrz6+Na+zn+zZn2cZ/9REgI5lI5UCFfbi3d1e19Ccxu4JEywNXlO/ih5Uq+vaAa0RiUgwWd4/Eyq5ElYtOwjdykv4ScBf1MmEa8w1Du+RZ2YcuyeWrlfN4mYbdCrU2tm+05lVyq+ubiZjEYCQD3Eve19EJgfhP/0K4l2v0vC+bBrMtXnL+EXIc0BRqBCHgqbJa/iEhrmwtsWc4fRfvKGOOs2RaByDEwE88Sr7vNi9ofixfhdiGb/o7ItJ/vnoHJhG95Abr59x0iC/2Rhzsus0ZGVtSCxSsT/OFjz1vD1qMaBKK+NP9ezn+bznCwAx/lERmkcZvypthK4U0JeHX/3qV3jLW96CAwcOUMFPSve/+MUv0tA+CQkJCQmJhXL29ZuY6AmPT5Q1cb6Qs6+pYcnos0HcTdHZb1tZed6cfXmZy/ijLhY4qEw7MCoVn5eJCp1eBaWqdEEnlvHP19mf4K9PdZ2haEfLE/HBHfJQ17vZ0jAnsa9tXE1PZTI5FPVr6Plgz+GibuOOdTdhS+U67GzcQn9O+KaRSHOzhICYxD9zGT/p2Z+NFfVMrJ3OEvtypRrqKlZiHx5jjyk8ejb5+2DfsZzbEkv3DUodTd4v6Oyr2P6q1Sjm5TKKzj5hz+Z6WqLczh/PKyccONEzRRcULtnA3ptLuYw/zMU+mWDh9LJ9odI8B2e/QBl/z3AqZPREb2b71EzOfkOVJPYXM2Iaf5i3sxBnf7FAsiTENP6oYoae/Ximsx+Jz91sVkpl/DOzfft2fOlLX8KLL76In/zkJ7jmmmvw6KOP4l3vehc9/93vfhfd3d3l31oJCQkJiWVJbIr1EmtbWqDiqfCR0bEFvD/u7FdXFR1AR0bDkfntHaurzmMZf3lH74n9+op5HAz5uSAxW+ZWGZAs4w+UT+wXy6ifBeBV6ezQKEs7OBYm+jIC7giKxrUlif0bV16Jv17/VmiVTMwl3GwcpMxghSxtewqJfbGMv5gSeVEc5wvpU9e209OIKPZH0sR+//Gc63fY2Mi+FnNjXhEvRFjFQUKpzRCyc6XCpMbaVhvUSjmu4L3/KxrY49l7mD1nW1dXw2YqXhQvWmefl/GTdgsSRkgWNqwFxirmw8KD2khAX1xI4NkDg7TvXqQ7Xex3FyP22d82Ss7+knD2Uz8vHrEvZgfIEoqU2M+Xxh/L7Nmfj7OvLFDG3+3sx3PDryJOckUuEOaVzED6x0g5P0nmJ0F9P/jBD9DR0YEf/vCHuPXWW8u3lRISEhISSRwvvoShf/4mAkOsvPhCh3zpx6aZAFHabdA3s97pyMjIvG977PEnMPmb+3KccLGSQFNkGf/IoCsZ/GblJeL+C2D0nljGXw6xb5pjT7ZWxw5Sg9zZJ6X450rsD/uYUCSz4UshRhx4H9mHZNDynneCooGJ/fBoT9Fz69MRuNiXV7bAtDk1BlJpyb+firPlSxH7nYPTVASmo6lhowHDYz05Yj/UfyKnb3999Wr84xUfxztXvzH/4+DOflwU+/Mo4Rf50vsvxlffvynpMHc0MOdO3LTrdrEFiKWKTsN79rmzP+FMVW0osiZYzAQJMySQgL4H9p7Fv/3mIH72SMqg6y3B2Sev+7hUxr+knP3kz4uojF+j4aP3BHnStUc8nvO5Ii4AlKNnX6HRwLR2DVTVVdBUpRZLf/Tar/HHs4+hj7dvXQiUJYaRpMP+9re/xc9+9jPq9isUClxxxRXluGkJCYklghCLYeyJpxA4feZ8b8oFTcw5ja7//AHCAwOYfPY5LAfCRHgLAmQqFRWdSbE/PDqv2xWiUfT8+GfwPPcCTv7TP2cI5GQlQXVpYr++yQITn2XtLaLfdbGP3guNT5RB7Efn5eyLKdKkjP/VF3rxzX94DK88U9roxYAvAo+LLb5UlSD2R/xMXNcZSpv/HuY9+aqqJsg1qX55md7CeuCRQHz4NEolwUftySzVsOy6lbr7xOVXGHIDB4PhGHx8gkFVEePm6uw66h6TMvHhyUBeZz883otELIrIJM/MkMkR97sQdWQeGBM3f1PtWpjU+Z9rgffsx+XMXdTzg/35QHIH0p371lpDcowjcbN3rkvlCCxF9Flp/OM8j6GmxOkCVu7sj04Fcd+T7Pu6Z9RH95VIVMDgRGoRqm/Uk5xikI9pb5hmCJCnub6y+PeVxLlHb8isntHpF4+zL+Z1yBPypGufHsiX/XOcv69Dsfl9z238l6+i6ctfgFzFFj7I4sKIl33m68URoRcAc66bcjqdePzxx/HII4/Q3n0yem/Tpk34/Oc/jze84Q2oqGBjXCQkJC58wsPDOPqv34G/uwcyjQatl+w+35t0wTJ53++SJdq+HlZSe6ETGmdfvmT1ncy5N7Q0lcXZD/f2IcEDZj0nT1HBb//g+5EQSAiaM+nsB4XZneSRQeaGkYA5Ixccfl+E9tWejzR+MjYwXxlkqbiPshJt7Qrm7M4F8jwQzLMkws/Ws58QEnj8gRP0/NlTUzmuz0wMD7IKBXuVARpeDl2K2G8wlubsiwF82oZVOb/TtW9BZGIA8eFTAG4p6XYFLvbllhqoKmrR8L5vwTHtzlsqL5bwE9ecJLmz7v7CyGUyrGqqwOGuSfSM+LCTDQ+gaGpa6Wnc44AwchoQ4pDrzYC1DsLIGVbK37i1+McRZkI1Ktcke/bLjUalQHuDBWcHXbhqW1NyvNdSRZcV0DfBZ9tXlzjbXnT2fWkZGOStdKLbASEaoJ9ZZoMaOrUc49MhnB32YgV7+XMY5gsDNTYDVMryv4YS5YPkpZDPPrFnfzGV8Ytin6TxC3z0aFLccyHOfs4avScGfaZB9OhDZ55Co6oGtZh5gY8cT8j4hB+CN+qn4/zIp2mlvmJ5i/33ve99ePXVVxGLxdDY2IgPfehDuO2229DaWuDTQEJC4oJl6pVXMfSt79CSK0IiHIb7+AmgPjeBWWJ+TO17FYEjR5M/+5eJ2A9PTGQk44vOfnhgEKOPPk7d7Hhz6TO6g2eYINO0tiA2OUkFf/x/74X9438DkIMMuRwaux2YnJz1ttzcZausNkLPnTMiTsPzDJWbq7MvCv75EPN44O9l+5huDQuWm1/P/tycEjLdQK1RIhKOQU76OROg+QjTU5nu80wM9bPKiwY+Tz4dsmgwEZhC2BWj5xN8DjXp2Rz1T86pjF909jUFxL5734OIDxYewUfn0Oe7XOzZt7DtUVc2Qs5H1xUK57OZiz+oX93Kxf5oZosBqU6QmauR8EwgevpF9tjqOhCzNlCxHypZ7LNti0JdtjL+fLz7xrV48PkzuOOqDix1xJ59cfTexBydfUvaRAxikK5rt+N49xSOnnXAomMLaGSRxKQl1QMhdA16cUOB2xqaYMnuUgn/0oAsRC9KsZ+W2SGkFZ2TitGMTwYxoI/39Yd49kc6r40cwa+P/gnNpnps60hbsSyCqRD7nrBqzFApFk+bw3kR+0ePHsUdd9yBN77xjdi2bVv5t0pCQmLJMPLgQ1ToWy/aCoVGTcX/9OsHob/t5vO9aRcUZJRaz49+Qs/X3XoLRh/+C6IuFyLO3DCtCw2xlFzDS+p1TU1UiAt+P3r+50f0MuOObWj4x8+XdLvBTjZH2nTpbtRv2YKj/+/z8B8+gomnn2X3V1WZseo/423x+d4k4VihkNNQORIoFyiQeL1QyJRK+tyQtofEPEP6gieJ8wwYVrTPmMY/W/WCmMZvomX8c6s22LKjEd2d47j97RfhiT+fxGDfNAZ6nKhtLu6AbJiL/caW3NF+fzr1GO479mDyZ4vahP+q/Rom/FOIJ+I0HM+mzf27QpDKkPAo64HWpoXzieia10NhsNLy90DXAcCa2UseHDiJsfv+GcrtbwRq70xeLkRCSPjZ+11eoEc/naNdbKFCHKlXDC21rF1j0pW778jtjYh7JiAMseoKkkUQsLBFNuLsay4pPkshwcV+WBT7C+DsEy5aU416q4AKolyXOGKIYSjCnufxpLOvL7nigYwlJOX5t+xpx9o2W1Lst9aw56m93gKrXsALRyfROeSh7/HfP9OJ4bFpvOdWC+x84W5oki0KSUn8SwODSYOpSf+i69lPr+yREbFPKpXowmt2GX+Wsx/N/Zwa9rDg3kHvCPx5FgNmYirIPl9t2gvH1SfMqaaJhPH90z/9kyT0JSQkEOap5U13vgVVV7KsjukDB0oqsZWYHe+ZTkSmnFBYLGh59zugqmXOnq+HBWYtJ2dfqddh5cc+AuOO7bDt3EEv8x04hAgP8SsG4nqHeWWEbtUqmFatRO0N19GfB+//fUn9+mRfD/HeaB0PkxOTj8+52JfJINey0mghPL+AwAAX+xVb2di3fDz18Cnc+/3D6O1yJC/r757Ck3/uxhQXAklnv8QyfhK+9GL/awjEQrjxTRvw5vesR0NzBZrabPT3g32s1WI2SIWFmKlA/j6bExOdyR5NpVwJd8SL10eOot/N+tDJyD1S4l4sxP1ORMOAUg2VPXdcn0yhhGnzVfS85/CTOb8PdL2GRDSE+ECqiocQ5fPs5TojZNqZxRURZ88eYNu/c4296G2v4cLRwee3pyO3s/YZMfFOU78C8qoWyFRaCEEfEs7i22rENP5QQlmWNP7lAGnFyAzom5vYJ9xx1UpsWmHFO25Yg40rKpP9+Sf73Elnf2UjW/gZGA/gW796Hb969DSePTSOD33jadz/1Bk89uoIXjnGclOkJP6lgZgns+hG76nlSJCSLZ7ILy6y54j9rNF7oTxif8LHvovIrZ2aTAWJFsNUiB1DVF5gYr+oT9f7778fu3fvRjMvnfzTn/5U1I2/7W1vm9/WSUhILGqIyCEClKC222BobQGUSoTGxhElbmydVMpfLiJ8UUVdX0dTZDVNTYiOjtFSflVjafO/lxrhicmk2Be/+quvvgrCurWora3F0b/7e7oYQhx55Z5LirpNb2cXPZAgY/xUfBGh6a47Mf7MXtqKUkoSfzRCUoPZea0+Jfadk0EEz7HYJ8g1WgiBIITQ3MU+caeDJ1mAnHXLZgQLvP+Pvj6ESDiOP9x7AO/7xB5MjPrwl9910edk33M9uPaWdfT3Yhn/tIu5SsXw+Nm9+NWRP+GapkvwwcZUm2BTKzsQI+7+jstnL6+fcvjpYoxCKUN1nQmTk5mPhjj4hL/b82EcHT+J/zv5GJ7rexUtVva+auanhcrtp5+/HzFogNo308uEKRYeKK9ogEye37E2bb4Grpf/hGD3YWi3k8/QVG9pZHIouWiQTnRqmJ6qbLO/308PeOD0hGDSq7Cx3Vqy2Hf5SFhbPL/Y55Ayfpk3CG3TWgR7DiE+2gms317U/cTc7D3thXFBnf0LCbGMPxITEI0JmOCTFkgZvxCZLZEhkzuvXYXLN5hpqCGhsUqPockAJniIJRH7SsFHk/5J9sOLR0Zo4n99pQ6DEwEq/EXIOtiaVrYAJ7G4EfNkCHq9GrHE/Fq9ygUZmUnqVRQ8kR8KOciXvcCd/ILOfp7Re+P+1MLzyckuNNZWl1zGX0ol1wUj9r/0pS/hW9/6VlLsk5+LcRcksS8hcWEj+HzJlVd1RQVNNNWt7EDw1GkEjh0HtpTWLyUxSyI9+dDmM+Y1zY3w7X8N/p4eWC/fk3ndKSdibjdQu7TTp3MC+qpTYj+dmhuuo2J/7Ikn0XDJxQVvhzj/cR9zm2muBCnZ3rA+GW6mtlpRccN1cD74cEnOfjjEDkCImFSpFBljjhbS2R8dciOWp7dbxp19cdFiLvj7+hD3eiHXamFasxpBvtiUcR1vFD4+XpC0Mdz309fg84ao0CecPT2JnZcxQUKCoUoJxiN0TbE59VNBdgAm0sSFhWPcRxP6Z2Ogh217ZY2BtlikIyQEOAJswbLaYMflLbuo2D8ydhKeEOtHbrEUFtfeQ0/C9dIfaSq9cMkbIFfrUmLfXjhHQmWrg7xuFYTRTsQ7XwE61iV/F3Wwv0/4nEjEU/tPdIo55yp7PT0wnomXjzMxfdmWhpKC6Ugwm1atoO4x6flPl+Dpj0dpqWITALxB6No2MrE/dLLo+4k6WZWCE+YF7dm/kEivfnjqtQHE4gLtubdbtJicLE3sZ7Om2UzFvhiWVl9lxOSEHxva7dh7cIiKsb//q520JeL0cAx/eakHZJ1g54ZGtFQp0Fo392kdEue2jF+EfEd5S5/+uSCQhSSxFlSeUACzOPtiGn8+sS86+4STE524vvbSkp19u24Ziv17770XK1asyPhZQkJCIuZiB+EKkyk5ukS/YX1K7EuUjQhPh1da2ZeQmvSt80R+Kx8jN/LQXzD23PPo7uuHTK1G9Y//mwrYpQhJkg8PDsLr9SVzCYiz788zP75yz6V0hF54fAJBMvqxvj7nOrFAAIc+9kla3lzxja/BzfdPy4YNGdezXHcNfC++TJ9vbZ7byYcYeJQeMrTQZfxHXhvEn+87gjWbKtH0nkwxKtfwMv55OPuuQ0foqWXjhuR7Oxvi4hPMVg0SAuDgydx1jRZMjHrgng6ip9Mx57F7Ay7mZPuimdUAJADRYtPC7QxhfMSH1rRBAS5nAPv2DuKam6w8IwA49CoTzy0rcsfTucJeGsSnkMlh01khl8vRampEn3cI3dP97O+Is58naiAR9MK59zf8BwGhoU7o2zdD4A58thOejXL1pYiMdiLW+QoSN/4VrQIg5fui603KRaIucp6J9Sgvk1fb6zFTGkMgFMWhLvaeuWYHMWmK3w/IwhcpCx8Y82J8KoD6tI8Pmc4EhcmOuHcKmvpU4J1+5XY4n76XLlwIodkrN0hFiNiSMBkjzr4gOftFoFTIsXtjHS2d/8Ef2PuzwqzJWcCaq9h/6gB7TdrqzFR8EUiwocfnx13Xb6C9/WNjY7h6exP9T86TyipyKrH0nH3ScrZYxD753EnQDHzu7PMFyhyxHxXL+NnPJDk/HbL47Qik2vl6XYMIljCeT3T2L7Qy/qI+IXbu3Ak7SSTmkAR+MmaPXJ7v/5o1a/KOgZGQkLiwiLlYf58iTVDqNzLxFDzbTQWWRHkQ2yXE51rTxFw2InDjgQD67/0V+n/xS4T7mEBJRCIIDJQ2i3wx0fW972Poa9/A0c/+Pyp6yOKFssCsd9LWYLp4Jz3veZ4lhWfjOX4CMa+Phvqd+PJXaSUAwbxhfcb15Go11n7h71Fxyxtg372rJGdfo1OcE7EfjwvY+zjb/qmJ3PdYUuyHZz/Iifn86PqP/4T3tdczLncdOkxPK7YWrs6ZGGXCrqHFjDvfu5069xWVWrzjnp2oa2KBfodeZfPYTSUm8ZODuDEfL/XOEvuE2gZW/j0+nHm0+urzvTj62jgevJ+JIcd4AMMDLpriv2oD601Ox8kP7io0Fir0CTtqN2Vch/Ts5yPy2gMZ4jY0cJIKWdHZl83g7BMULZtp/z0J3Qv2sO0VXKyKRSTmZD3RpZTxv3x0lJZ6k9C0lU2lL/aJpfzjztznXRT5mobVycvU9gZabUDG8QW6D81+B0EPXdQg9d/jEXZfktgvjr9913bs2ViV/LmyhEkLM7GyyUSrBAhtDalFsbZ6Cz78xlVU6EssfYxm9t2g0SogL8MiUTlJ8P2PiH0Z3zaSxp8Bn/qUdPbTKp8I02E37f1XCQnYo6S9LoEeN/sOmg2yUDAdYse09uUo9rO55ppr8NRTTxX8/eOPP44PfOAD89kuCQmJJUB8mh0oK62pgwN1TTW0ZOxePA532pg4ifIEIYpl/AqDIZlOT6ooyAg6gu1Nb6Tp6eLotKUI+YIWxabKYqF99Zarr5xxEdnMWxn8R47mDepz8Xnx4sJJIhqFwmyGriHXvTe2t8N2682Qk2T7OTr7Yhn/QvTsnznmoK45we/LvX2ZljnaiSKc/b6f34uJZ/bC8dvfJQ+sYoEgPKd4v/4M4XyTXOxX1xlo8N0nv3AtDdEzGDVoamOfCROj3jmF8435J5OBTb5o7oJGDRf7Y1linzj7hO4zk+jpnMSpI2zBYO3GuuQCTN6yzbSDu4uqNtCgPoJNY4FenbtQERo8jXjXPnretPlqftkp6noj7Kdl/fKKmStDZEoVjOvYfhs4e4CeJlwpcU+ITo+m8lG48KfCegaeeZ0tNhD3dS7GS0rs5z7v9mvuhmrbrTBvyxzGpl/FFtv8nftnvX3By6o9ZAYbvGH2GksBfcVBWjLuvqEN77ttA9QqBTatKI8o0WuUWNnEbmtl49KsBpOYnepaE+RyGSoq5zYGdUGRpcr4E3zhlXxPpyM6/SlnP/P3Dp6mXxGNoy3AXP+zLmaAzMZUwMkWChQqmNQXVuBkUZ+uQ0ND+N3vfpf8mXzp/OUvf0FnJ3MW0hEEAc899xw03FmQkJC48Mv4RQEqQtK7R0dG6dxy++7CPdQSpTv7Yhk/wdDeRpPqHff9nn4pmtethfWG6+AeG4O/uwdR99IU+3GXi227XI7tP/kf6rbPViqqrq+HsWMFfGe74Tp8BNVXXZnxe/exY/TU/pY3wfvs8zTwULd6ZVmq0FLOfnoZPzsf8M/eU14KsWgch/alBCFZTMgefVessx/sOovxJ9nCPal4cB89BtTXYeqVV1h4IVm4KxCyKcQFTI7zNPA6Az0lzj45kCQ0tVvwyrOpypJSy/iH/SmHOxAN0GOLfM7+5Jgf8ZgABS/79HpSj/mJB09i2sEWJLbtJuXssYJlm+k9mgaVDtvqN+LVoUOoN+YGAJK+0clHf5gM2rPsfiO8R55BeLgToWF2XKSuaqRifjZ0bZvgOfAYHV1HELi4F6Hl7s2gY/oS4QB1w1UVtQDP8MhmzBnEsW4HPW6+ctvMlQXFif3MJH9y36otN0KuzHSUDat2wv3KA9TZ1+5MjQsUQwwTkdTrkvCwBRiZuRJBJ3tNpJ794iGfWbdfsQK37mnD5GRmiON8+MhbNuOpfV24ctvM7ScSSxezVYeP/v1V8PgW4che+l2cYGX8GvbZmV0dStr70p39iJD5me7ki7e2WBwrghG8btGhy82yX2ZDDGqt1ttLmr5ywYh9Ura/b98+HD16NPlB8+yzz9L/+SClcJ/61KfKu6USEhILzsTe59H/i3vh2bwZNddchYTdVnIZP0F0S8X56BLzgwivqDv3uTa2t8G571UI/Aux+V1vR5CIAQtzVcW/WWqEefsBmTxAhH6xkJJ8IvaJK50u9knQXIC3Nxh37ULLNVdj5M8PQXXxrvJsb9LZTyvjN7LtDuRx3ufDwVcHaDAe6Uf3eUJ0CoDfl+ngJ0fvzeDsk4yHyV//ll1fo6Fj+hwvvgzTnW+mTj/BdPGugoshk+M+xKIC1Bol7Z/PxlKhgdWmTzrtpTr7I2linyxleCO+nNvXG9QI+CMYHXajsYW5kh43F5WyVFWBvcqAlhV2jPOgx3xl/Nnpy29Z/wYa3HdZPRvtmE7s6JOITg4AWiNsV78Lcp0J0JqQCHnhPcQWT9Q17bOG6BG0TSyYL+oYQtzvTop9de0KRMa6EXWOUuFOfk8fltE+4yLCc4fZZ+7GFVZUV5Q+km02Z78QmoaVgM5EcwyEsS6gIbXQ4Hzmlwju/wvC7/0GNHUrIHCxLzdXwR/iIyulMv6SKUevfjokgf+2SxtLCnSUWHqQz+VQidMbzgUyIuDjCcgScsDAvi+i3FDKdvbj/OMinMgMU3GIYp84+/yzZcg7ikA0SEerzsQ4D/arNua2ey11in5H/+xnP8PTTz9Ny/eJs//5z3+e/pz9f+/evTh48CDuueeehd1yCQmJsjP22OOIOacx+exeHP/HL2H0+/9N3++zOvtpZfwETU1Nxsg0iflBk/VJ37pSCYWRuaiisy9CxqNZ1rP+c7G3PbpEy/hFsS/mEhSLeR0TTqSiJJ1gZxc91bc0Q2k2QVdfjxUf/iDUdeWZViA6+2ptes8+W0snyfRiOv18Ie/Fl5/ppucvu3ZlMmzJKwpcjizp7BcW+8N/+jMd3UgWhlZ96hP0sql9ryIyPkHzDYjLYuQ5CHn/foAdVNU3kV733AUBskjQsSbVW1xqz/6IL1OYu3kyfvrt1zWxz53xEbafkwoHP58OsHNPalTftt0tBRctUmX8mWK/xdqIr1/3Oay1pYLoCJGpYUQPP0bPq3e9GQq9md62opaFGAd7We+9pjYtNXAGFHoTZLwHPzhwAgkXq2AxrGKLDGKQHWkbIMgr2VSkfIQiMbx8gn3mXrll9pGEhaixsc+Yienixb5MJoeiaSM9H+/PbN/yn9lPAwz9p/dlOPuCoZKOkCNIYl9CYpnDv0fkghwJLvYjvFU0d/Qed/YTrC9fRJzcQsS+NSbQUwEJdDp6Z737CT6yj0xlWbZi32g0oqGhgbr8JI3/5ptvpj9n/yfJnFreLyghIbF0IOVRZGY7wX7pbiosgydOwt/bO3vPfkVm36A4siw0keukSZROnFdQqG02yHgvG8HQznrzCc3vfHvyfMrZX9piX91cWjmpeS0LDQsODiHqSYlDmtBP3OBNTIyUG9HZ16aNllOpFVByh0wcTzdfiJtOnGtSsr5lR2MybT5b7Itl/DON3ht/8ml62vpXd8O2czvNL4j7/Zj8xS+TKfwqW+HKnuF+9t5v4I56PjrWpkYXluLsk4M30dknKfkETzg3NrqCO9BifgFpaSDHfUTXX33TGuro6/RKbN7RWMRc5dl7nxNkTN8j/0NSo6Br3wrFipTrL6/JXBRQ1xQn9uljrF1JTwNdB5DwsVJSPRf7MdcELYMPDbBRkXJ+3Xy8eHgYgVCcOvPrW3MnDxQLSeMnuH0ROoKvWJQtLNgwPnA0eQBOyvdjPHQwNMzehwkPO6iO6lL7Fxn3JyEhsXwRF41JGb+gZ5Vx0WyxH8/s2SefMtG0vn1HkH1+EpEvM1hRHWHXF8erzoQ4sq/asIyd/ULp/LFYDJFIJPk/GAzC4XDgwQcfLPe2SkhIFAEpz80eV1IMkbFx6gQSV3D1Zz6Fim1b6eXTrx+cg7PPDvLj/gBifK65xNwRn2dNZeaKs8ZuQ8fHPoKqu98F06qUCFjyZfyD3NkvUeyrzGaouFsvBswRgmeYs2/ZuFBiX3T2U2KfuL1i8nG5xH5/NzuQqa03QKlSwGTmYt+TXcbPLhdCocJjDR2OZEWITKGAkb/fQ9099DQ78yCb4UEu9mdIe29dYYdWp4JKJYe1hJJyZ9CFQCwEuUyO9grmZHvCmc4+wVLBqgVSYYUskElvVNH2gns+dRneds9G6PiBYzbkINEd9uR19vNBEvNJ4j6UalTe9IGMagFFbbbYT1UWzIa8jr13/adeZrdlsEBd3QwoVNQRT7gnEBpiQlnBr5uPR15mvak37m7NW21RLEadCnrutE+5i9935fWrIVNpkfC7EJlgbTPCNBsXSAiPnKUH62IZf1hjS4bzzWd7JSQklj5kYgpBllAgZmCf2RFXVrZAlrOfPX5PrNSqlKmhaN4EfZxVDvki/qJ79muMlf+fva8Ac+w8rz5ipmGenZ1l3jWumdlJDImTONTQH2zTpG0aaNI22GDTcBqsA3bIMTOs7fV618uMwzyj0YhZ+p/3+757xTPS7Iy9cM8++0ijGUlX0tW933nPec+L6RytZw3Z93q9+MhHPsLG761evRpr166V/2/YsAGXXnopPv3pT8/91ipQoGBaELF+9b0fxNB3/wfpvECrmRDt7ZUJFi3+Xeeew372bOcp0flIRqNyr3h+zz6NQtPY+egtpW//5JEQ1W1S9vNRf83VsF+8Mec2ncP+uiv74eFh7Ph/H4X7bw9VdL/YlJc7RlQqGFoqDxgzLeJ2at/Bg/IUgzj1aqvVcKzkNv/5U/Zz1UmrjZNu6q2fS7IvjbWTlf28x88E9BUnagmaVpBKMfeOThTqLOduyNzfaJx27GAsmsD4CCffze2lSTIR7vd87CLc+rZlLLyv7Nc5xUfMNdvqUWV2lVT2pQKClAtAWQbstYi8BHp+/TSKsTvkYcqQQaOHTZdpjymFUBefEEGKvs6ZcS0QyIqvMvDtUdmqoTHO/Hj5hYJ0gi9adTWUoq+Gys7bIBJd29nv1NQy4CzeenKs34Nj/VPQalS49vzSVv9yUePg+9BEXiFpOqi0ehhblrDrUVGcSHn4Z0lIx6MI9x4AYuLz0vJ9x1zBvqFAgYIzE5JrkWz8KZOuLGWfEBXHTSL0YUH86yxVrPhoTnLS7i9y/ihl49fv34zIvZ9DIpD73Gcd2f/2t7+NZ599FitWrMBFF13EKiC33norNm7cCK1Wy5L4f/CDH8z91ipQoGBa+I8eY+PWIsdPwL1la0X3jfbyWaSGdr5QdJ2zQX7MYgpxbHJSJhZqU2E/rraaW6EiRUKxFMxO2dfPEJiYrXC/3j373b/4NSIjI/Bv5mpluQh2cWWZUuAlhboSGAXZ9wtl37tvvxxmqM3KO5hvZZ89p6TsV0CYSoHOszLZb+Nk3yqU/UB+z76s7Jcg+9Jkh6y2EOPChfL+VXPRhdAU+U5LGOidYnZ5i00vuwumG/VUU19ZUFyflxPENmczHAZb0Z59gqMqX9mPy8p+OZCUnFpLdVlTGcLdvBdd07ys4Hf0PhpbeBuJuroyR4rKaOVKvoC+pkUOsCMkj/Jed1PbipLbuWUfD/Zbv7gKDqth7sh+Bco+wdDEyX5kiE8lSE9mlH1CYP8mdqmxuhBK8n3PbCzv81KgQMGZC2miCtn442Z+TIgVBPQVKvuRZDTHhm9LJGG217IiqkWIXr7g9NMHIvGIXFA2Ht2NdMiLhGg3OmvJPo3Wu+aaa3Dvvffim9/8JrvtXe96Fwvxo9voZNQlFmwKFCh47RAeyKgoA3/6c0VWpAzZb+eX1dXQU0BaOg3Pzl0lR8ERQSi2ANXVcOIQVZT9ORlFR9CL9qmZIKm1Cb9fHlUzHwj19SM2NFR4++Ej8Ly6nV1P+nxMrS8XUm6EtbP8nudsGBdxlTRwoosp2+PPbZrXfv2cNP48Zd/h5GR0qoKgs1KYmowwmzrlANQ18KKFTRQTSin7pXr246JQp80qHhFZbXnzndDW1KDpTW+cdlu2vsDP783tnIjPNXqnBuSQPLvRWtLGT6nS7He+CBu/FxI2fipClINKAplo8ccS+JmVnhPafNjWXMl/35FxSZQLY9sq+bq+lhcLJGU/HeLff2MbD+AshiExYrBDjEE8WVRLZH+qMrKfUfY52U9N8nOSysEDA4OHt8oj/MJRfmyyKMq+AgVnPTI2fjXiYoxtKWVfSuMnxISyPyqO59Svr3XUsiKq3cLPcV7fWFmFX7PWCL2fnx91ztmHnJ4RZN/tduPiiy9m16uqqlBXV4c9e3gC7cqVK3HnnXfi4YcfntstVaDgNEEiGMThb3wbnseeeM2fOzTAF8mEYHcPQjQ3uwykKHujfyBH2SeYV60q2bcvk/0SIV5aQUwVG//c2fipR78c6GyChKXTiPvnJzOB5t/u/ZfPoP/LX8/pj6figvvPf83525BoESkHRNLzwwcrARFYKkBRbsXIT3+Oqd17mF299orLMV+QlP18q7qzOtdmfjIY7uNkt2WBS1ZASgb0GWew8YsZ7dlkn9B44/Vo/8p/wJJ1DMjHyGAAxw6NsTFJ6y9snNVr+fn2P+DzW76NJ4+/gFS6sN2oT9j42xzNsAtlv5iNn+z6Gq2KpTT5vGFZ2bdUqOyXE8iUHD4qB+/RIrIYrCsuRsdn/gjtQt4CVQmM7ZkWE7LxE9T23FYBY1vpNpRRNyf7tRWOOJxJ2Xf7ZqfsxyeHkAz5ZLKvXXYJu0zH+b6qdTUiLML/zMKyq0CBgrMX0nlNndIgLjJDkuEwklnZM5Kyr0rYoIvyYnpEkP0xEW5aFU8xsk+wmXmr0Ew9+1Lht1onju16E9Sm4sf5s4bsm825lry2tjYcO8YDkAhLly7FUBG1R4GCMx3UJ3/0O9+De/PLmPzbg0UV8fkEpZATdCIN3/PwY2Wp+6TQEjnSWMzQ1WYWvpbVXEny7NpdoBBTL7TkACgGXQ1/nOiYQvbnzsZfnrJPmQtqC1f4Er75Cenz7tnHTsRIJnH4a99AdHxCTnmnwhHtSzT3nhAUM+4rsfFbO2dH9sllYl++nF2naRKEmrvfOi2BPRmkkil5tF6+su8SZN8zMTuyPzzghU8oq0MDnOzTvHgJpQL65NF7JQL6EkLZ15W5P0mgY8mrL/JjzPrzW+FwVU4svVE/nup6Eb5YAD/f8Qf853P/LSfiS6F5g37e+tPuzCb7hcp+dgji1GQYIb8U0Femsi9sn2TjnwnJQV7QMnXwxPlSUKlnlypval1Bd2b/85V9Ai08s63++Rhx832sVpD018vGz0YJOuoygYNE7tUaaBedz1+fgM5Vj4hQ9s0GRdlXoOBshzbLxp/QpaHSCSt/trqfSCCp0qC293IsPHgRK/RGhY1fUvZdCa7sE2x6TtgDiciMobAEp4qfO1S2mrJau85osk+9+k8//bT888KFC7FrV4bUDAwMQJ01HkqBgrMFkw8+nBNod/wHP0aKCNFrhJCw8dfcdSez8kb7+uDZUTpNX0LgOJ/dbe3szBntZuhYwGa200guKaU7v2e/VB+5ViTHK8r+yYEIVkIavVemsk/Q2PhJrhILfSWQ9yuVimU6HPrK1zD039/HiR//lN3c+pY3s/FthFCZZD8RCCIywomeZeHsbPwE+wpO9gmNN98I+0W5AYZziUg4M/kiX9mXyf5kqOJ031Awhl/+z2b86VcH0HV0Qlb2KeFegqTs09+SjT1f2S9p48/q2a8EbDv6A9Bo1Lj0mtKp8NNh+9g+9l64DHYWjHdw/Bh+c+gv8u+7Pf1M7bfozKgyOeEwCrIfKe5Qsdn1ct/+rJV96/Rkn7Y3NcQD50wL5qcdhBL46+/4Z+iveh80ZnsB2Te2LmehfcUQjCQQCMdzSPqc2fgrJPsEdR3/7vp2PsUu9TXNIpeAt4gRdFWNGRu/ouwrUHDWQ+7ZT6uRSCWhkYKGs/r2SXRKqPVQp7TQxY1QpTRyQJ9UvJVs/ASbiZ8/AlmJ/cUQEo4joxC11LYza/zerBj5O97xDmzevBm33347/H4/brnlFhw5cgSf+tSnWDDfb37zG6xbt27ut1aBglMYEy9vwZSw7nd+9EOs9zXmdsP9l/tfk+dPBgIsnI9gXLwIjTfdwK53/+JXSMWmP9AFTwiyL8LNJBDxd23g3+XgHh5OJSEmrMCl1GadIPuk7J9pY0xeS7DPVIxS1LtmngUuQWPlZF/aJ+YS9Hl6dnKyX/v2t7KCELWNhMnOr1bDdslFjGRbRP5DcAYbv/fAQYz/4Y84+OWvyvZyuRVhFnCddw4LmDOtWI4F730P5hPhcExOfpfGh9Gig8YBST3l1NMfDmVmAZcDIq/JZIqR+N//fCvCoQRbDDW3ZdLvTWad3OcYCmYeX23IBPQV++7JAX0VFI8Im57kVvZzL26Xx95VildH+XHk2rZL8bXr/pVd7/UNICgS2o+6eWZDh72FuzQMVtkRUAxWQfapVUIm+xX37E+/sEt4hpGmgCeNlpHu+YJl6fnQLsisnVQWB0u4n6lfX+qrd9oMMMzRvPoa4ZggQi4VEiol+7ExPgpQX8fHEEoBhpmefX5cUwL6FChQoNNqZBs/kX2tGCEco+kxAuRATWcVPdVZZH80MJ4h+3Z+TLeb+PkylE4UbRmTEBZk3xCPyco+znayT+F8X/3qVxGLxZil//zzz8c73/lOPPLII4zsUx+/MnpPwdmGwb/+jV02vfFWNFx3LeredTf72ffiZnj3H5j354+NjLBLQ20NU/Vb3nwHNA4HIkPDGBDbNqOyn0f2CdVCFfW/sg2peLxA2S/VR64lYqpSsUIDhbQpmB2igpjpnE6oha2tHGgEWZ6P8XsUykeZDWq9HtaNF2D5Zz8NS+dC2K+4HOf85Ieoe+fdbFvNC9ozbSIlggJp/zj0pa/C9/wmOUHfnKXMzwbGujqcf8+v0Pj3H4VaO78WYYnEE/EmjATG8fePfhE/2/8H6HQaORneI3qqywWp9RJSYnxQS7sLWl2GzBEZllTskCC67Hah7NN4vXTWd1ZWRmZh46eiwVAfV1jOu7j8GfL5wXtDwVFo1Vqsr12JFnsjGq11bPzdkQnuHDrq5pcL7DyRXkrjp57LZJHFmk0o0OOjfrmdopw0/uz05ZkC+sLdPPvE2LwUav3c9MSXA1LyjW3LAY0O5kWlcwDGRWZDgyguzQWoaOAUqf5SHkC50NTmunIkRd/QnAk21BLZF5+XEtCnQIECOl9Kyn4ylYBGmiokbPxsDZFOI42MvV6T1CKS4EVt2YqfUkFj5STfZuECCZ05QvHSLtuwsPnrY7xwqhbFgjMFs/bak6pPIXwaDf9wPve5z7FxfPfffz8ef/xxZu1XoOBsQniIjz6qu/oqdmlaugR111zNro888eS8P398mNufTWI2udZiQc1b7mDXB/70F8RKjMAjAi/1VBcj+1XnnsPs46lAAO4tfARUNgktFdBHoWiS6i8FgimoHDO1S8xk4y82NvFkEdrHi1dk0ydSb1++DOu+803Uvu0tMNZnQsXousqgZ4QzPsar7vkI7t7Lev81LicWffyjWP1fX0XN29960ttI2/Va9NxFhOppElbkQ2PHmILQ5x9iCxC7kxMmj+iprpTsN7RYsXwNn62+dFVhOrDZwp+Xkvrz0/gJLFchC6z/MZViuQ4aMbWh3BDCVIoXHeyzDIF7oYcnsW9oWgWLjjsDltbyY87hiePs8tiEpOzzvnWr3iIv7YLxUEkbf3+3R3ZY6MtQtyULv0lrhEU/PUkO9+wtq19/PlB/+z/BeOcXoa9uKvk340LZb6iZ29GSzXX8GNIzXFnBUOVqgiqrKCKRfVP7KuZUoGR+jdEi2/gVZV+BAgVaXVbPPtn4BdmXxu9RkDQhR9lPahGNh9n4vXiK/16ra8S3vvAUtr04AKPFCb0YvxeIBmdW9iP8HKNSyH5pNDU1Yfny5dBVoD4pUHAmIBkMsb52QjbZabjuGnY5uW37jFb6k0VseCSH7BMs52yAc/06Zn2a+P19RS29RPTp9xToZhDBftkgUlB/3bXs+sjjT8pBhHFhrZouNE56L+IizE9B5ZDbJSrsr5aV/XlwVYRE8J3rnOlHjFEbiL6pmV2PZY2FzEZg26vskvrq66+5CvZlS3NyI051SMq+USj7PWJsHNn4SY22O06O7BOZv/Nd5+DN712J8y8pzDGQwuhylH21mrkuCNlJxtmBmfqa6oreZ6lNgEIItcJuWQlSqRRe6uOf9WXtF8i3L6/hoxIPjx+HJ+qDO+xhRZo2Gye3lP9j1plLJipLNv6AnxNeu8gxmAkDPlGcNc3sboj0i3C+BZnxeK8V1AYz1Nbp23ckG39D1dyS/cWtXB072jf9jOp80H5laFpcQPa19mo0v++bMNz4cfZzhuwryr4CBWc7Mj37qtyefUnZj3Myn8oj+5FYCH5xbiBiP57uZOflAzvGkNKZYRbOOOlvpif7wTPSxl/WEfatb52dynLvvffO6n4KFJxuSLh576fGboPGmFlsWhcvYopl0jMFz649QDtXq+bTxm9u5eSKQIvmzg99ADs/+g8IHz6CyMgITI2547J8osXAuLCjpBJaf+3V6L/vT/AdOAjH0DDiBgO3VKlU0LucwPh4SbJP91GU/dlDnnogMhAq7dmfCxs/qcMHvvglpKwW2N51NyKi7cN1znrkTsEthKGlCdHubkQHC8k+uQ6kwoH1/PNwOiKSZ+OXyD5hPDgJm1D2pxjZt1VM9o0mLfteuqpNciZANiQbv9SvLoEyC1gLTZ6yHxEOC0NtJvytHISDua+zUuwfOwJP2Auz1oQNjaswIaY3LKvlZP/4ZC+OT/Ee73ZHMwvvk2DTWZiq748HS9r4Mz+XR/a7PP3sssXKXROlkI5SIVdMw8gKmDuVMD4lbPwiEHKusKTNNSuyTzA2LUakZx9gsEBDxYogd5bpa1qgTvBzlaLsK1CgQIJWkxXQl6a+e0nZ9+Qq+1k2ftazHwvDH+MtWbZECt4UP27F4yn0jQCWZApTOg380SBsatO0Nn4DPYdaA5Ww/59VZH9MGZ2lQMG0iIuFK4Xy5Ssc1vXr4X32Obhf3gL7PJL9+EhG2c9e3hsbGljRgfqh/YeOFJB97z7ej2palglPygeN17OsWY3g7j3wvfAirMIWRTYrUv5L3q+e244VZX8ObPyzVfbnwMZPAXr+IzyNfDeNk0ynYWxqYvsWxH5XCvrm0sr+xEubmaWc2kf0DYUW9dMBUkCf0aRjzhnqS5cwHnLLNv7JCpX9cBbZnw5Sf3q2sk/QmIzss0+Giyv7lGtQ0fZIRQ3RNlApjk9yIr+iajG0msxrarDWMjJPRP6FwW3stiXVuW2AVknZL2Ljp9dPIYVSroFNBMvNhB6Z7OceD/ORmuL7Ny3+1PrZhRLON8ZFYn5DNSn7lYXpTYelgux3D/kQixfP3CgFyhiYevmv0DQtLVlEDsf44t3C9vHKHl+BAgVnFrTZPfvpVGHPviD7qazxplzZD8MnCsFWIvbRjMPp6PEQzKL9zE8hr6aa6ZX9VJol+c92hOppTfapF1+BAgWlERfKtTRbPhuWc9Yxsj/56quw3XnbvDw/WXWlhG1zawvCodxFMVmjiez7Dh9B3VVXyLeTOu89cIhdNy2dfpSW/fJLGdn3PreJ/Sdoq6avfhrruHqoKPuzR2bqQWVkX22bO2WfAvYYKOxOnHBJ1S8H+mZux44NDiIRCqH3N/cgHE+g+t3vwNjzL7Df1V5xGU5XyDZ+kw6TUW9OCNB40I1WxwI5Lb4SyMq+efrTtEW28ccKlH1CvrIfFS4cg/hulr89EtmfneVanmlvyt2PiQgudLRhz8Qh9Pp5QWhJTR7Z11tK2vjp/g6nSW6TKEfZp6JMt6ePXW+1TU/20xLZd5yaxahEMoVJn0T2zYiH5y6jo9Zlgs2shT+UQNegF5VENRhbl6Hlg9+FO1yaxOcq+wrZV6DgbIa2hI0/JpN9fg5KCgdAJqAvIiv7RPY9gQxRP3bUA1M7J/s+mqhi6phe2U+noXOdmsf6k8Hp0xipQMEpjMTERM64uWwYFy6EzuViff2hw1wdnWuEh4bYJdmedKIamg3bUq7a+w/z3lMJ0Z5epCIRaG1WWYEtBVL+ze1t7Dr1A9tXrkDVG27JWUC/1PsqjgkrLsEg9ewrZH9WoPc0LOzvldqu5YC+OejZD/dzsu+68Xos/sd/gG3jhWi5o7zClbRfJSY92PvP/8pyH7zPPIsdH/oYAkePsVaQmksuxukKOaDPrMdgINflkG3j907xUXqJeBK7tvbNOIov28ZfjrKfb+NXi3aiwp792dr4xZi0Wdr4pUC8ajEKKRtE9rOxpLqjhLJfvOcyewxgOWSfsgGof1OjUqPRUleWsq92Tm/3L4VkKo0Xdg3A45+fzJaJqTBIuNJr1XDZ5nZSACvENFpnbeXX17ZBNY0bQiL7FsXGr0DBWQ+Z7Ke4si/Z+MmhRjlRko0/mZU1o05RQF9U7se3RrUI89onDCYtIuEEDEF+jPeHSh/DcpR955lH9mdVov/MZz5T1kmCxvMpUHA2QCKz+TZ+ycpfvfECjDz6OIJkgb6Wh/bNJcL9nBCaW4oTdtuyJbJCmxBBgux+R/jcbMeqlTOGddHvV3/1Sxg8dBit69aytPORLAv33tFD+J9XfgmTxoCLlvD+a2MdP2jSqC9yEUxn+VdQfMRddHwCKp0OtqWZsVWV2PgTfj87Uc6Fsq9vakLdFZchtWwJ9DRasZztsJihr6lBbGIC4YFBVvhSWa2IiQKCafky/lgztAOcqsgevXdMkH2NWoNkKsmUfVOjFjq9ho2F83tjOLL3GF56+jhc1Ua8/xP1M9v4ZwgvK9mzL8g+FfOK9uzX1SLyGtr4pZn21YZCst+ZRfZtBivqrbUYFT3e7DYdV/aL9ewTnGzknLvsgL6BAA/no9F/OrW2PBv/LMn+y3uG8M3f7oDdrMNXP+pEeU0G5WN4gr8n9dXmopkOJ4sFjVbsOTGFo31TOH/J3AUAUhEkGk/JAX1hLswpUKDgLEX26L0E2fiFYEH2/VQohLQYo5tD9pMaRBNR+OP8AGIIWxEUBeCmNisO7RkH/K1Aoxe+MBc+aFTfAfdRVNVWQ6/R5Sj7xhQp+w1nnM9oVmSfxutNB6fTCYej/JE+ChScMcp+bfF+oJqLNgqyvxv+I0crJm4zITTA+4RNJcg+kSkqRNB2+klNbeQL1zBdFyPUyoHWaoWhtaVg3jsp0H888DB/zGQUg74R6KGBvsrFRvDRwZpIhkk8r4LyENoj8hSWL4Mma5xaOdBYxMI8nUYyUNmc7GxQoSDUz/cvfdP0ludSsC1eBPfEBOvNX/bZT2MyGoX64CG4t2yF5QY+6eH0V/Z1GBznBHVV3RLsGTmE8dCkCNczY2zYD+9kBLu38iKHxx3BH3+9Hde8ofjM+pCc8j+Tss9t/FRMiEUTbPRcto1/YvMWVuCL19cjXV/Pii7scSsl+8HZk31SaSaEqlJlKiwSNVsbYNAa2KJtcXVhUKhVkP1iPfsEZ1VGPbbaiewLaWcGst/hynUUFEPae3LK/sEeXoTwheL47I824x/uWAKKujgZ9I348MTLA7j7pmqMiPaQ+jlO4peQq+xP7/6qBOFIpjhFNn6F7CtQcHZDJ9v4SdlPMpGDXKcJfwBJnw8pG1f6UzlkX4to0o9UlB9ANFEuctTUW9GxxMnIfszfAKT3I0A9+wD+dugJ/PXgYwhr47hl6dVs/RqJR2VlX+dsqOjceMaS/b17+czZbCSTSUxMTOChhx7C73//e/z4xz+ei+1ToOCUBynW0/XsE+wrljMLfKi3D/s+83m0vf2t0Fx04ZxtQ1iQseyxe/kwdnYgQGT/yFHoGxuQisflVHXH6tU4GbP3ocnjOObm87GlMK4V5k6m5NPrDp7oQrCrWyH7FSK4l5N9CkesFPTeSyfKVICf5GYDyoJIRaOsaFOqmDUTOt7/XqiXLELnzTexooVqZAT111zN/me7Q073nv2BIH8t5zat5WRfWNddVZzs7985ykbEUWEgkUii98Qknn8MePv7G3MILi0+yrXx6/TqjHPAF0F1LSdnkvPCs30H+w8ah/bhD/IRoDRFg0ZmVhCcGZJt/JUvG6aiPqTIlqnWwqEvnEhAdvql1QuZO4gu85Hp2S9O9h2uTAo9KfuhyPRkv9/PP6cO1/SBqal4FGn/5EmR/RMDvIfeZNDAF4zh2388hB+2N6HGOfuwv988cgjbDo4gktDCJtoq5jqJX0J7A3/vh91BBERhay4QjPD9idoPpEW+AgUKzl5odZKNX4WkGBOtczrZGibh9SFtMheSfbLxJ2MIR/kKNh3jQnNtvQ1NrTZ2Xo6EAXPABZ+Fix5dk705OTKxVBxp8OczpFLQUs9+4ZTq0xqzOsLq9fqC/yaTCa2trfjIRz6CK664Al//+tfnfmsVKDhVR6OlUowMaZyOksRr9Ve/DOu557DiQO89v4PnkcfmbBuCvfzgZW4rvXg1dvJFNAX1scujR5GOx9nB1NRaukgwE4iYPNr7PLtu0nIL7XF3pm/fKp43cIIXFhSUh5jHwzIVCOY1s5vvrRMOq6R/9rJZbGhYdo3Mtg2DxgbaL9pYsTvhdEAkJHqxdSlMRniQ0LnNa9glhfWFEhG4ajhhGuzlRZf1F7Th2jcuYrbrE4cnMTaSW4xJxFNIJlJlkX0qEtiYmg34vRk9ouUtd6Dqjbei8eYbWbGRjlEnfvgT9js6TuW7c+bTxi+9L7XmKqhLJLO/c93tuLz5Aly/+PKC383Us+8UPfv00FbbzPtYRtnnx8tkyIfE0ZcROr4D8alRpNP8vY+7qT0qDbXJChh5EaUSpFJpdA1xsv+JO5dhQaMdoUgSL+4unExRCXqG+WM+ta0XWw/wwkUjS+Kfe1iMWjTX8sfuHs59/w/3TKJ3ZHauoZBQ9s0mpV9fgQIFhTb+7KJ1ksh+kZ59CuiLJhNyQF8iwdvEauqsUGvUaGnnP+sjFgSEVX/QP5rjFCNbP3/eNHRpKjCceT3781JOXbt2LV599dX5eGgFCk45REZG5R7Y6fretVYL6t7/d2h/1zvYzwFS2+YAqXAYEUHIrAuLJ41KQYEEsvGTNdu7dz/72bF6ZcnRSOVg5/B+9PmH2Fzsu9feljNmi21TZye7JHVfQWlQ+Ezc52fFIAJTY9NpNjZRO8u2KCmsMemfvbIfG+b7lrltZsvz2YiwUDvdca4S1JirUG12wSIIqicyxZT9bKy/oBUtC+xoaOafz9RkbmI+hQpJgUXSOKLpYBXj5oJZIXB6pxOum27Awg++H6u+/B8wZ7lDdKTqV4B0Kn1SNn53hFv466yln7fd2YI7Ft0As65Q8ZZ69kuR/bpGG2tfqKk3swXedJiK+OCN+aGCij0nYXLTHxB78XcYue+r6P/hRxB54BtIp8ixxUm5rrplVsfI4ckworEkU/UXNFpw7fn8O7Tz8OzHGUdiSYx5+P5C4tfAWCBr7N78YIk0gm84UzQkl8LnfrwZ37z3oEzcK0FIKPtm0XaiQIGCsxv67NF7yCP7ZOMvFtCX1CCWSiCQ4MfESFxS9nlx1mThbW7ahB7BRASxZBwTQe7WCopQv0gyY+FXGa1QG07NEaunHNknom84AxUcBQqKQZ5bLWbKTwdaMDZcfx2z1MZHRrkr4GSfX8wv17pcspJbagQaJXQnQyEEd+zC2HPPV9SvXwpPn3iRXZIit6GJP1afd4gdVAmWLGWfXAAKckF9692f+CdsueMubHvne9D7r5+Hd99+TL66nf2+6rxzZ/3YOjG65qSU/cGhGV0jZysoWZ9UeMJwlCus7U7e11xt5IqCOzIFZ5bFesGiatlqbxXp6QFfpCjZN4uFykyQ/i4YLG5fJ0dG/QfeyxV+2i8a6itW9aWvrmkWNn53WFL2Kysy5Nv4ySVBI5nyQZMQ/uHzV+HWty6b8bF6PDwzodFWB5OOv/+xUV6c1NiqKIkUaXc/Qsd3IjYhsipqZud8klTvhc1O5mjYsIynQu/vciMS5Z9xpRgRhSEqIJiyiDIF9L2WZJ96+GOJFAvZ23WUhz5WgqCi7CtQoKAo2c+y8bv4eTThyyj7qazCK9n4/akoYukk69+PJIxyzz7BbObnRk1Ch0AqjvHwpGzZD0SDOco+kX21rbIpNacLZlVS/c53vlP09lgshoMHDzKyf/vtt5/stilQcFop+8YyF9Ck8JO1PXDsOLwUwLZi5gXqdIhKSekzkDFyHdiWLIZ37z6M/vyX7DaNw4HqCy84qeeXqqSr6pai2uSCXW+FLxZgVtk2tMKyoB3QaFjflTT2S0EGgw88yNwZEqiCvf8L/yG7RKrOPw+z1eUzNv65UPZbMXcdu2eWqk9rj4EQL4oscPLvYZXByRwvnogXG9oyRGzDBVnJ8w5eFKde+5Mh+xYrf5xQoPR4NxqXufzfPovxTS8guaB4KGApBAJ8MURZA5oZlPNioIIHoc5aWeZDKhFD+MQumIy1rFBKxUJ/NACXyVGU8Gt9M29btyD7C7L69eMeXqhpeMtnEdj/ArxbH4R/99NQafgSSVfTPKt05r5RvpjsbOHb21xrRbXDALc3in0nJtBaVfljDk3wY0VbnRkXrW3Drx4+wH6uz3OPzCWWtnOy3zUcYK0JhOMD/DMlbD84iovXNFX0mCHx3aE2AQUKFCig7JmMsp+WHWrT2fhZQJ+w/FuCvChMrVx0PvD6KOCWFxM1CT2oMz97PK5s4xfKPiXxqyyF02LOBMzqKPuzn/2s9ANqtbj++uvx6U9/+mS2S4GC0waR0dGylX0JjjWrGdmf2rsP9jki+4YylFfbsqWM7BOc69bC8fa7pnUDlAOyxbLHM9rZgrzN1oz97iPo9Q/iIjoY63RsZBuNWmN9+9O0GpxtoGq1//ARdn39D77HQtMOfPd7CGx7lbVakFvDvKAdfrGPVQppTm0yUL6yH5v04Mi3vwvjBeej/uYbmQNFIvu8U1hBfh+73qBBv3cwR9mvMjpkoktp/FU1ZqRSKSxb3ZCXHE/KfrQo2ZcsiDNBSuQPTkP2CVqzGY033lBxKKK0fZYi/fAUvCeNLZJwdKILf9j3N3zAcjeabPWYlGz8lsqUff/OJ+F+6lfQrr0OVUYn3GEPjkycwIWtGzBbSGR/oSD76WgIqRA/htHIJdu6qxnZJ2VfY+Gfob66ZVbpzL2C7C9q4QtIOj6uWuDApj1jzMrfehFX+ivBsJuT/cZqE269dCHr3zdqUzDq5480dzQ5YNBrWN5A/5ifjQ881pdF9g+NykWASgP6KIlfgQIFCuSe/RT17Ocq+8zGH5eU/VyyL8EesuSo+tnKvjbBjzPdPn78zw58pYA/goGeUz/z6NbTEbM6OzzzzDNFb9doNGzsnlHM91Wg4GxT9stVPp1r12DwL/fDu3cvbHfdeVLPH5PIfuvMZL/uqivh238AuhXLsPTut2NUtCDMFrTQJxWf4DByYtlua+Jk38eVTrZt7a2M7FPfvkEh+zJCu/eyxltDexvMIiSx7r3vRs2K5ej7/b2wX37pSeUpSIUcsuKPPfs8/IEA6m+5adpsCfcrW9k+QtkOtW2tLMSRVGFjXR2844ozIxsRQfYNRi0jooQ6C1eviZwSJqNTTA3/8L9cgeGhkZwefJvotc8O1puVsi/+LlTCxn+yCAplX3IQZOPn2/+A57u34PNX/D1W1C1hx4Qfv3oPG7/54OGn8KHz3pFR9um9qcAeEh3hOR9p3wSuWL0Rfzn4KP584FGc37Ju1q/lhKc3x4GR9vOsBZhsrFdTb2iBur4TqdETSAb4Z6ojG3+Eq0eVzJHvGwtlyH6aE/9VHZzs7zgyhjeeBNlvqjaxFPtPvv2ceZ9oodWosazdhT3HJnCwy411HUYc6+fvDWEqEGVKv7283ZVB6vO3KGRfgQIFdB4tpuyLnv3EpKdEQF/mfGoOW3L69SU3GkEX55ddWWQ/GAvxsXuyjT8FlWjtOtMwq5795ubmov8bGhoUoq/grEN0lBNmQ335CzdS2Cm9P+aeRHyWqi0hGY0iJhZ65Sj7NPpu9de+DOe110xL+MoF2aDoYEl01G7gB9h2G1c2SdmXYBDhbgEx6k8BR2D3HnZpWZ8hL0Tum297Iy6897dw3Xj9ST2+RPZpxOKx730fY7/4FSa3bptxCgAhHYvh6H//D7tO0xpmm8R/JiMskvj1Rg28YoavZDF3GfjlZIT7IYjwS6OFCpR9f3Fl31xmGF65yv5sERTbl590T9/9bYO7kUgn8audf2TOhd3jhxjRJ+wePsCyOygQj1Brqcy3HnfzgmE6EsDNS6+CSWNAn3cQWwd2zep1UGGSxiHS8WpRFW9lSPl4AUttz/RqapdenLmTVg+to/KRk4NjfsTipLhr0CQyGgjL2h3QqFUYnghizFO5X2BIUvZrXtsQqRUd3JVxsHsSU4E4PP4omyZBxQtJ3Z9VQJ9i41egQAGb9CbIPjI9+zS6mRAfH0fc7ytU9lOZ44c+zMe6mh0mfPK/N+H5XaNZAX06djkSHCtwpWUH9EF3ZubNzfoo29XVhS1btmBsbKxo6BYtWP/xH//xZLdPgYJTGslwGHGvV7bxB8rsjaYRZDQKL3zkKMKHjgDrZqdUhXr72EgtInWlxv7NJ6RxJ5Q8rlHzA3WbrUlO4PZFA6wIQMo1IXCiC1VKSB9DIhhEWFj4LevXFvx+Lsg1OUisSxYjGghAFY0h5nazgkv1xgtL3ic+lbHnxj38urkM18jZbOPX6jnxpUWKw2DLCeiTxs4VQ7GReYRIqEIbv0X07Afnh+wHSpB9T9TLvuOEXu8gnu1+GU/0bpJ/Pxmewq5hPvWDpnXYDTaEwdXuchCfHJbJPoX0XdFyIR7r3YQ/7X8E/7Tu/RW/jh4fD9xrMNfCrOdkOS3IviqL7Gs61kO99c9IRUNQOeqhylpclovjA/y8sLCZk3sJRP6JOFPP/oHuKazhmYllIRpPYmKKfxZN8xjIVwwrBdk/0O3Gijb+3rXV23Du0mrs7/bi1YMjuGpt+f2ukyKnwi4KVQoUKDi7YchqRUqkVXLPvr6mBrGJCfgPHy1u46clpQpQR63s6mgwimP9U5iYCuHSlXztST37hPzVJ6n7OWn8Z6iyPyuy/8gjj7Ce/ISwVBSDQvYVnMmghX0qEkHIx8m92mKB1mIBKghCMy1bysn+4SMIDw9j+JHHELdZUXfbm8p+DCLPUuL9ydi9i72+Px14BPFwFHc33FHy73xidAmF8kmg0VmUdD3sH0PXZC/WNa5kkwCIvCb8fiQmJ4HGRpzt8GzfCSSTbH69viHTxz2X0NltWPvNrzObb3rHTnT97BcI9XPCUwrxKU5SKC8gIVR+JYm/OEaHRa+32P1tegvUwjHjEmQ/lAgjHI/Iye/ZkGz8FICXSmZs4tFIhTZ+m7Dxz7Oyn9+zTwGEBCpyUMLxL3feh0QqwY4BDaZadPn68MSxTXK/fiXHKCL4qUhAvk4gsv/C0DYM+Iaxa/wAmhqbZkX22+2ZdH1Z2c9KYVZp9bCuugy+HY9D7arsOSScEAF2Ur9+NiiVn8j+vm4v3lbBYw6OBdhi1WbWwTaLqQgngyXtLlDNYtwTxs6j/LiwuNUpK/tU3JgKxFDukYycDYSm6sy5Q4ECBWcvdFnOt1Q6c922uBNuRva5OJLMKp7SuYd6/NPqFNIJXoT0i95+jz+GgJh6okpmXHJqlZq5xIKJMOvbjyZEz76i7OfiBz/4AZqamvDv//7vaG1tlRc3ChScLTj0pa/Cs2On/LOupvKRUqbly4AHHkJw/wHs/MjfM4We4HviKdivuxb1d715xsVxsIuTfesc98F3e/rw5wOPsOtvXHuDPPqqlLJvk9iOAFlkiewfn+xhZJ9C+mhOe7C7mwcKrlyJsx3UG0842WkI5cLUwgnOTGQ/JtT8qtvegKkHHmKtJtZFna/JNp5u6O/mkyiMtWkgTEUvruoTTFoDLHozUw7IOt4mgvuyYbYaWJI/mV2yLfiz7tkPxSoOSqskjd9aguyfV78GfcEhjAQ4cb5pyZVANM3I/v4xvkCrrTSJ35uVJxIJsAKkSWvELUuvwX37H8KmgW24ec21FT1mj4+3Fi3IIvvFlH2C64q3Q220ItK0GrOBlFbfWYTsn7u8Hr955CAO9Xrh8Rda+QfHA/jhn/bgqvXVrD1SQt8oLya31tvmtLhbDmjMX2u9hY0TfPWwWyb7DqueXZKStr97CssWZaZNTIdhNyf7jTXFzy0KFCg4e5V9sRxmsC5axEYUx0goylP2JSt/mualpPn9x7Om2xwTBXlVWisXBVhQbAqM7Adjwdw0/jNU2Z8VSx8eHsZ73vMeXHTRRYzsl+rhV6DgTEQyGMoh+rRat6wrtGHPBLK2ayxmgBwyqRQca9dA43IycjXxh/sw8eJLRe/n3vIKPI89wfr1Aye62W2WhXyW/Vzh5f7M6xvyle7F9McF2c9S9gkdIum6x5MhluQ+IER7MwEpZyvos/Ps5H3HVbMg+6FYmCmbySIzx0tBsuJHRkaQipdOSYt7OUnR1dZi1Ve+hLr3vYdNj1CQi1gsiWFh1VZV8T5qR973oE7MlR8P8UVKPqjn2ST68rPH70k2/nLJvmz3p5rDPFj5M8q+vijZ77C34h1rb5ft+jctvgrLqxYVfS/KRdqXRfbTKWapJ1zRsVHOBJHmJJcD+q70iRyRjiLKfj7Z1xgtqLribVDbK+/XT6XT6B7i+8YiMXYvGwsa7WycXSKZxpNbeWBgNp7d3s+U/+d25R57+7PI/uuBxc02OXyQ/dzKw7POW84n0ew9UbplJRuRWBJTYp9qUMi+AgUK2DQ3NXOI5Sv7+WJDKk9g1iS1sk1fo1VhdCozyvhAzyQrqLPfib79JnsDzFruAmDKfjJb2VfIvoxFixZhXEllVnCWIjbACay2ugoX3vc79t910w0VPw4F5C384PthveA8rP76V7DqP7+I9i/9O+quvor9fvLVHQX3ifT04vA3vo3Jvz2IfZ/+LEK9fKFo7Zw7ZZ8UtC39meceEGFbxSAl8dvzlP92Z4vcxyvBuoiTfUrlP9vhP3KUtYFQzsJsVPPvvPy/+NXBP+PZrpfLvg+NsFGbTaywFB7MTErI/+wlZV9jt7NAR9v5573mKuLpgLFBUpsBZ5UJYW1hOwuhRgTSkbJfCharrqBvXx69J8YGzQQK/zMYecZDcB7IvtSzn53GT/tKvyD7lNNxXvNafGLj+/HRNe+E1WBBrakKjdZMaGmdtXr2yj79LMbjVZtdaLE3skXh3tHDZT9ev3cYsVSctVPUmzmxT8XCQNhXENB3sqC++nA0CZ1WheascL5s3HIxP2Y/9nIPElktHIReoUaNTEZOLbLfYstJ6G9v5BNYzlvB3QcHe7yIJ2YuQI5P8ddlNWlhNSlp/AoUKODt35IvLZ1FT/PXSMl8ZT+phTbOz5VGkw6jk5lcmP0n3GxaDkEqCNA4WGo1IwRI2VfS+IvjU5/6FH7/+9/j6aefZum7ChScTYgODMqj7jRGIwvbmy3qrrgc9e99D+xk6aeDnU6H2isuY9dp/Fl2+GUqkcD4Pb+T/U3B7h42ikRtMsFQz5WVuQCpddnkZNDHQ7KKwS969vOV/XYHd/aMBsYRiUdy+r6l6QFnM3wHD7FL0+JFFRPpw5MnsHeU33/fWPlkh55HL7ISSln5qQBBo/YIGvvrQyhOFwwP8kJXW0cVfCJtPtvGT6gVc+WnI/tSkr5EqNkooAp79glGMWIoJCz3c4V0Ki23GFhFxgCBLPvhZBQ6tRZNljq2f13Udk6ORX59Y6ZdRxpJOCtlnxZ4guwT1jasYJd7Rw6W/XjH3N1yi5FafOfiHq6cq002qAxzF3jXL0buNdWYWSGmGC5e28T67t3eCPYcz4yxI3QLsj8xFUE8kTplyP4ioewTOprsbPSfFELoshkQjadwoKv0vi5hzMP30Vrnmdkfq0CBgtkiLZN9af2rtVqhrc2cP1JsnkoG6pQGmgQ/llDR2y+Cc6nYSmNBNXp1TiJ/M5F9rZiEkxXQZzyDe/ZnRfbXrl2LFStW4OMf/zjWrFmDSy65pOD/pZdeOvdbq0DBKYCYIEr6lvlpVbEtXUJ+JtafFBnKEO3Bv/4NsYFBaG02tHz+M7CJAgHNrZ9L5ZXs4QRaxLPn9Y/OqOxTMFk27EabrHL2ebn6Z2rmJCDhnmQ29rMZ/kOcpBs7K1P1aVTMg91Pyz8fmThRdBpKKegauQIXLuGuSHo5ydCYzVDrlZTs6TDSz4lX28LqjMNFjJ+UUCeT/eI2/uzxepKyH4smkUqmS5L9RDLBni//czeZtPOSyE8TB4jw5yv7JyalefUt8iSOfKxrXFXwXsxW2S9G9veMHCp7/5fI/uLqjAsq7uHHV51rbgMyB8Y52W+pLV1A0Gk1uGwtdz48uzNzjA1HExgTyhS97aOTvKBKpH9IhNpRCv7rAbtFh+ZafqynPv3sdhTKISC8erDwfBGKxNE/lmm5GBPKfp3zzFTRFChQMDuIEH7WX59MZwqdxvb2rL8preyrRMif02bItB0Bucq+vT7Hxi+Rfb3Ss5+LL33pS2zsXnV1NSP7HR0dBf8XLOAzbBUoONMQFTZ+Q2tGwZpLsLF8Hfz7492/X1Zi++/7E7u+8APvY8+96sv/gSX/9EnUvePtc/bctHCWyP7VnZewS2lmdjH448K+nBfQR2iy8MVf7xR3QugcdlahJe9zZLi0W+BMRzqZhE+kyhoX5/Y1zwRqrxgIjLCgMkqU9YS9mCjRD14MMyn7SZ9Il38dxjieTkgkkhgbFsRrYZU8R96Rp+zXmIWNPzSdsp/bsy+RdZ1ew/5nfzef796CDz30GXx+y7fx3r/9E7747HdwbKqH/d4o0tmzg/7mAgERIEeKSbZKTZM2CAurMouwfKyoWwyH0c5UlAZr+Tb5dDolB+dpBRHPJvsrahexYqQ77MFIaKIisr8ki+wnJvmxTVc1++kggVAMH/vms/jB/fw7nU32W6ch+4TL19Yzonx0wC/3+A9OZPpN2c9jvJA0NBFg4YtGvRrVjtdvQXrJWl7kvmBl7nt23gpB9g8Vkv2f3r8P//mb/dh9dCzHxl/nOjMX1goUKDg5qNJE9jMtQYYFbdOSfX2cn0elVv+GKjOWtvE2o5BwR0k9+7XRJPQDhzKj9xJnvrI/qzR+su/feOON+Pa3v60k8Ss4q0DBZrFhvkDUi3Tz+YBp6RJEjh2Hd/8BFtzX9/t7mWXfvGolai67BKOjo1Brtai99GI2Vm2uQAtiT9QHo9aAW5ZcjcePPY+x4ARiyfgMyn4h2W+21uOw5wR6pwaw2rqYuQ9Mzc3wHzmCMLVCnKUJ77HBQd6vbzFD31Q+ySBF9969D7Lrb1h2Lbb07mAtF6TuLzKUl4CtF8p+qL8fzmnIPs22VVAaQ31eJJNpWKx6VNda5O8BkX0i5b7tjyGpd6JOtK6U07Mf8EVzyL5J2PIJfVOD+NHu/2Pp9hJokXJo/BhS8SQuXXYhjELZDzIb/9yRqIA/luNAkHDCw8l+5zRkX6/R4avX/AtGx8ZgrEAxSfo9AI1DUqlhaFqEhGcEqXBmrKleq0eno50dXw57jmM9pg+QpL7MQT8/Ti6q7kDIwz+vuGdELijMtkRy71NH0TviB70b1CtaX2VGv6Ts101P9l02PTauasTmvUPYtHMAHU0ODIr7Zifzt9fY0D3IiwFN1ebXNUPjbdctxbmLLVi2KJPHQFi7uBYatYqN1BuZDCN7mujeY7xws+3gKNYtqcOYR1H2FShQUARsPA0n+7TmkWDIUvbz0/g1KS1MMX5+igmjV0O1BcvaSLQYgDecgEso+3ZoEXnqVzAFB4FaGzs3RIWyb0inodKfmcekWTF1WsxQEr9C9BWcbQgPDrL0fCJqFNA3XzAtWcwuvfv2IzY6xhL4CVW3v2leF3qvDPCE+HOb1rB+Y5pFSt/3EX+upZaQSCURioeKBpPlKPtZIX2mVq4KhUTuwdmI8PET7NK+bCkLaSwX+8eOYjQ4AZvOgpuXXo2Fdk4kD0/wx6tE2af2EHIY5CPp44RKp5D9adEnRu6Rqk9BcZmgSiuiA0fgfvIXiL34WzmgzxcNyLN8S9r485R9svCH4xH87cST+Jcnv8qIPiXdv2PtbfjGxf+Kj13wHvZ3k9GpnOJAaI6VfV48oMT/DNmnrJ4uT/+MZJ9Ax5EaE09tLxfxSd76o3PVQ2vl902GONmVsMzFi4WHJnP3/6MTXfje7l/JzgPCcTe/TqGB2a0Wso1/lsr+qCeCRzbz8aeEPcfGEQzH4fZGZ7TxS7hwNX/unUfGclwBWg0/zg+OcwfJkT7e19/R+Pqm15O7wylyJrJhNuqwtNVWkMofjCQwIVpUpH7+sSnRs+86M1U0BQoUzA5p0Y+vSquQECn5BAMVzsXat1DZ10AvbPwREXZKZL+9wcJGhkZFztUabwrvnkoiNnQcJvF32co+S+PXnpnHpFmx9csvvxzPP//83G+NAgWnOCgUj2BZsGBeSTfrw9fpEPdMYfx3f2DWd9e558DQ3IT5BKnwhNX1y9jrk1KriyXy+6J+FqVCf2cRyabZaLY2yKokjaIikLJPCItWCEJ0fAKpcK519UxGRJB92/LlFd3vqJvfb1lVJ1QJNZzeJlYBJ3JTLmi0o9poZEQ/PlY4USUhKfsuhexPh15BWiicj8a/UZaC5HCJjvJjRNo/wezrRo1hWiu/FNDnF8p+OBSTA/f+5Ymv4NmBLezx19Ysx3dv/CLesOw65rxZWsOnW3giXj6D3jw/PftScGC204BU8mgiCr1ah2bb3Pa7E+KTEglvgsbMrZjJUEbZl74HhBPe3hzn0bNdm3HC24d79vxVvu2l3m3sktwAuc8zclI9+39+vo+Nz5OI+Z6j4+gR4Xo1ThMsIgV6OqxfUsuWt91DPnh8EdnGT0q5pOwTjspkv3i6/6mA1Z28MLOvK0P2s50KPUNeePwReIRbRFH2FShQkAOpZz+tRiqL7NO6RVo/pvPW3mTj1wmyH4hxEaOh2sycRpQtkhB/Z4tq0TzB24xMIofGT4X4FD9/0Ln6TJ08NCuy/3d/93c4cOAAPvShD+Evf/kLNm3ahJdeeqngvwIFZyzZFz318wW1TseD+ogcHjnKLptvfxPmGxMiSKzeypNP6801JRP5vRHRp2ywsf7xfNSbqqFVaxFOROCJ8MWfWYQahge4chceHsaOD38Mg9/+76JK85kGlrR+nJNz+woesFgujghSTzPNH/7TPhx/NgbXeCtzTkiV6ZlAJzKzyJqIFclNUJT9mUFhdQM9Hjmcj8g2wWawQqvWID4hwg9TSaSCPlQZndNa+aWefVLQqSdbIusqfYo5Oag3/V8v/Sjet/ItslOAUGVyQgUVEukkK7zNV8++V4TFSe0G2eF8LdbGWTn8AgdeRGzzH5CK5Y6WK1D2qxqhNtlzRu9JaDTXsvcgnkrg8Phx+faJEP9sDowdZcVLmhjyshglenHjOfLfpeJRJP38M9G5Klf29x2fwO7jHtZz/8Hb1rDb9hwfR5ew21NafTlwWA1oq+dq/a6jY7Kyf9GaJpnsUzhf16DvlCf7axbyff3YgJ85HPLJPq2vqV2BYDbS2L1ZdZIqUKDgTIUg2xTQl23jJzjXr2OXMW1uIKw6pYVWhO95xSQbUvbZfawGmezH0hnV3iyU/YlwZhKKlNB/JmJWR9o777yTXVKvMCn8+ZUQWtDSbYcO8QAEBQrOPLLfIc8DnS84Vq9i4/cItqVLYV+xHOHR0sn4JwtS38dF2FuNSM6WyT4l8udNzpoSJIcCuIqBErpb7A3omRrAYHAUK7EcJonsDw4inUphcuurbNQbTTgY3/QCsGI5I/3Hf/QTRBIJ1H/i78+oSmt0dBRJrxcqrRbWRYsQ9uSO3CoFUnalgLFmXROe2ceJenWgBZ66fvT6B7EA09upJRDZDxw7LmdPFA/oU8h+KUyMBxCNJKDVqVHfaMPeMd6SUmXkoYYxiewzp8Q4u30oOMoS+RtFES0bpMir1CpWRAgH4zLZVxv4YoSKBRuaVhVkc+g0OjiNdlZscIc8bL7wfCj7Q/38e15dn7GkHxX74gJ75RNJ0tEQxh/5MdLxKLx1zXBd+paCv4m7M2Q/o+z7kL3Eo+PCouoF2Dawm4WIrmngThl6LyQ8fmwTjCkdEqkEFlctQHvW9iamxLFUb4LaZAV8mbT4mRCKJPD9P/Lw1BsubMc157XhFw/sgzcQw/M7+ee/QMygLwcrFjjQOxrEk1v7EI4mmSJ1wcoGfJ+Os/4oI8+JZAp2i/6UHldHgXtNNRY2NWD/iQlcsKoRA+O5rq2nt/HcicYayxl1bFegQMEcQE3HhDSz8SfzsqIWvPsdCKxZjMDT++EK0Qg+GtCnQn0YMMT1oCONR4zdI2U/HvbCZtHLZD8qyL7abIdJhEuTjZ/dlk5DfxJjtM9Isv/Vr35VOUgrOOtARaxsZZ+bK+cPjtUr0f8Hfr35jvnt1Sf4YwG2KKaDZ7XJmafsj5RU9olwlEKbs5mT/QBfWBvr69lYwVQshsSkB96dPCOA0PeHP6L5i59D371/xNjTz7Lbone/Dca63CCo0xm+g3zknrWzk01dKBfDwXGm3lMKf6CP7G281GT0OpmVv8vbh8txUVmPZWrlvf7xYmRfjN7TOx2zDiw70zEskd86M9QamojAXStOEyf78YlMi0rCN5Gr7BcRZel7bbUZ2Oi9YCCOsCDraV2SfbaU0VAK1WYXI/ukZlsEKQ6JHvu5QCqZwohQqmsbMtshFZ7IZVIpEkc2M6JPmHrlAdg3XF/wN5le+iaotPqiZJ9QZ5ZGG7rlY3S2UvNC71aWO0K4YfGVuc/h5s+httdWdGwl98XPHzmBYXcQ1XY93nHjcjZvfkmrndnXj/bx/YHC9srFyg4HHts6JPe0N9dZmeLvsOjgDcax5QCfOLCkzXXKr73WLK5lZH+vIPuDE3wxvbzdjkO9PhZmSGgUypsCBQoUSJCObzygL1bgeEWNiznaCElB9ttDaQwk+XGe7qHXquGyGTEW9sJq1iEhpDmJ7LsuvgP+Z36d89jUr6/Rz5yxclaR/dtvv33ut0SBglMUtIAkFTrmnkTC76ehwlwdnSx/5NlsYFuyBPaVK5BQq1F13rmYb0wKq73TYJfnZktkf8g/KvclS5iKcGLoMJae+UwzuF/AVqZsElQaDXR1tYgPDSPa2wvfwUNyP1Z0bAxj9/wega28v5YQ7Oo+o8i+98CBWVn4u31cLSQl89i2rP0uroYx6GDj10YC48xGPtPc8els/Am/UPZdrlOS7L/SvxP/++rv8c+XfhjLal+faQ5DA/x7UtvAFwaSjd9ldCAdCSAZzATJJbwTqDJw0ie5ZorBZudkPxSMyz3yCW0MiAPWacg+jfY7PtnDxi9KY/5I2S939vxMmJyIIJFIMdeAQ4SpUdGpT4RuLrBXNpEknUoicXAT/0GrRzoWgWfzn4E1N+f8TdzDjxe66iak4nxPTGal8WeH/xHGRB5CKBFhWQKEFnsjBnzDiCfjzH20sXUDJsYzY/pibv4aVM7K+vXve+oII/W0oPzwm5bAZtbLZDa7V50p++ny3AKdTVaYDBqm6rP7NvDCTX2VkZH9Xcf4vrMka7b9qYo1nTV4fEsPa3OgwohE9q9YV8/IvgRS9hUoUKCgUNkXo/dEL302aBwfqf7sOtIgP1s0bUQc/DhMKn5TtYW1VxHsZj2kBtG42grtisthWrgOpqfSBWRfZThzyb4Sp69AwTRIRqPY+aGPoudT/4Jj3yNTJaBvaIBaX5hGPNegKubqr34JjR/7cEWp7bOFlOotKZGEapOL9d3TglkiNflk3ynsy8XQ5uC2WYnsE/QNPKXf98JLbJygsaEeVW+6ld0WeGUrCyMkm7tE9s8URE50Yfw5TnSc69aWfT9SVo/t9bAetjbVQkyMhqDWqFDfzGViq78ax729+PtHvoCPPPQ5PN77wrSPZxIjI+Mjo6yIJYEIotSzT8r+qYjnul+GPx7Ei71bX9exe9lK91RYfA9MdqSmct0S3MY/fc8+wWrnvYJDfT4cO8RT2dNWTlqt06gNNWaXnLUhjd4jnh8N5/Y6zhbjI5ysNrY4ZMWFxj3SvkKuAsrrqATBI1uRDnqYjdJw5fvYbb4dTyLlz5Bw5oxIJdm8Y42tChqzTbb/p/NsnbUiw0DKGpmK8s/GojPjlqXXyH93becl0GpytY24IPtqBz8elYMTA1P4/ZNH2PWP3LkW7aLXnrC8PfOdoUJAU235vfVajRprFvFAPsIC0e/f4OLBp9E4/54uaa9sqsHrgVWLeAGGAgcpvyASS7EAwzWdTtY/K4Hs/goUKFBQVNlPqZBMFJ7HUnRuSPP1sETiA0l+rKW7JoWFX0KOjT9lgO7CN0NjsjHyaxR9+xLZV5+hY/cIs2IQy5Ytw/Lly2f8r0DBa4Go243ee36H6DyMcwv19CIyMopUKAzv3n3sNr0YH3emwR0pJPsalRqNNq6sj4QyC/Jcsj+9sk+YCE8iEudhXLp6rqSFD/NFs3P9etgvvQSGOr7YNTU3oe1td7HrUtvE6Y6434/Rn/+S5RFYzzsHjrU80KscPHjfHsT3udBxaCMSR/lJbcmKeixcyhf+jZF2NpLNIEbGPN3/EiaFtbwYjHW1zGFBhRZyq0hIBAKACEk8VXv2u8W4t96p12d0IymV+bb2bGU/JeznOcp+GWTfJsj+/h1jrEWjbaEDcRcvvFh105B9ieyGPaylQOrbD88R2R8b5mS/uS2zP/T4eZvC4uqOih/Pu+1hdknWfU3bKpg61gKpBOI7H5X/JjLIA0nVNe1QqdRQGy2ACABNR4JFlX3pvfVE+THJZbDjkrZzWUGCEpav6by0YFsksq+qgOxv2c8/37WLnLj6vLac3zXXmGQy21RjYn33lWD90oyDqb0xo+xng2z8pzrIPttYzYsUD4uxhK31NlbQWN6RCZiUArQUKFCgQIJ6BmU/lUrIyr50lgukBNnXaQpahMh5lRDXk8kUEvEUP6eQy1Ek8mfIfuFUqbPaxn/jjTcW9I0lk0lMTExg3759aGlpwa23cqVOgYL5RGD7DvT+4Y+MqJjXrEb7uZm05bkABckR9E1NcC5bisCJE4yYnomQSIsUNCah2d6Afu8QRkK5o9q8Mtkv3bNvN9qYO8Ad9uD4ZC9W1S+VlX0Jrg3rENNqsehjH0HXfX/Csg99gJFjQuAMUPZJBT32vR+wjAJjYwNq735b2X23dN/xUf5emINODB7mZGfd+a1IJPl1rdeGr2/8NAw6O37w2wfQ5dyLPx94FG9ouaroYxLRN9TXIzI0xKYhQBRZaMwjQWOx8N64UwzeqF8uMNEEgvy2ktcCnokws7UbjFrZ1j4VFmTf5EB6ap9sP6eQueyefdp2So4vBpsjo3hS8N/F17ThwQne4jKdjZ/ILMEtlG2zRY9IOI5IaG6V/aYs+3iPj5P9JdV89F+5iAwdR3TgCKDWwn7O9ZgIROG67C6Eu/cg2bsbaZG8HB08xi7VdbyYQIQfBgtAGSGR3KSUWtGzT4n7VEz0CGXfZXBAr9Xjv679DIZGh1lqf/73Slb2neWT/d1H+DFw/aIMaZVA32kal7dp1wBaaiu3g27IIvvZNv5sJZwWrsHcoQSnJJa12THsDmPTzsGc4sXKhdXYIsJFycZPAVoKFChQIIGF1UpkP8/JRaDbMjZ+jpSgsikhX9dnK/tmHWilwB6Tzi+RBFTk8tLqYSJlXxQIjKkUI/uv/ariFCb73/3ud0v+rq+vD3fffTfqKYhLgYJ5RM9v7sHoX/8m/xwfL5wbfrIID/JUaOPiTiz+h4+x6/mp2Geysi9Z8alX+vHeTaivqsNKc2dezz71ppZ+XJoHTqOvjkyc4GS/MdMjS3Z9mjow7vXCuXYNmurrYG5oQCLE+zxjExOIC2v56Qr3llfgeXU7CyZc+i+fQsBUfvU44IshmUgjpUohZQtD67PAZNGhc2ktxsZSjNxRj/ZQnx/bNh2BetyButBiPGvdjAur1qIBxfuRTY0NjOxHssh+bGrqlLbwDwQy3zvqyx6bRimfLxSztcvKvskh2/hNnRtksm/RmpjrgraZ/rYVhX3uVluG1F1x/VJG/n2DkrI/fc9+9rg5s1WPyYkgwnNA9mPRBCtuEJraHAiFvYwkZ8h+R0ZaKQORHl4IIUVfa3UBgREYmhdDbbIhFfYjOnwc0DoRGRLKfm1mvKnKaEU64kc6mkv2zXoTC62k8Z6UiSAdk0jZl4qNIUORvvmwD6loiDkGVPaMfX46BMMJHOvn7/PyBcULnHdduwSRWALXnlveY2aDyO/br18Gn8+Puiq+WG2oMp1Wqr6Epa12PLdrlE0QIHQIsr9qIS/OmPQaVNmNGFXIvgIFCrKg0mTIPgVGF7PxS2Q/vxQgup1yXENk4yfQI5GEEQnzEoHKYIEpW9mn9lHDmavsz3kjcFtbGyP7P//5z+f6oRUokEF26MG/Pciu113DFczEhLtoMBWp/v5tryKaFc6UjdGnn8XEn/+a07+cr+zrzoLilRTQV2XIJfs3LL4cS2s6EU3G8LPtv8PP9v8BsUSsII2fgrUmnvwl4gefz7k/3ZdweOIEu9TVZxQsGieoKUJ+tWYztLU8HDDYxa2gpytGn3iKXTqvuQrWhZWpoV4P79uOG0JovD6ON9y1FjfduRgajZqRzQWiP/aZh7rgHuekxhaoRSqVwiM9z5V8XHIYECJZifxxQfYpnO9UxEAg1yJPM9Rfa4yPhGSyT6DjjUcimBTQJ8i+eeG6zGz4ZBy1gpRL37F81Ise7eo6Ey64jCvaPqFiT2vjF8o+kdxEKgmLlS9sImL80MlgZNDH+v8pPNDu4N/RseAEAvEQC/Bc4KosiZ8KHwSVI6vYp1LD1L6KXQ9370M6FkZ8nH+umrpcsk9IhwtnoGS3SUjKvlOEIpZCysszRLTOOqg05blYDvV52Zz4tgYbqmzFJ2mQXf3z770ATTWzC3p623VL8cZLMsUgSvuX2gFOJ7K/pDW3tUtS9jtbnPjonWvxgVsXnfJTBRQoUPB62vhVSBRT9rN69vNLAWHRhlgviqVSQB8hLiXyR8S9DGau7J8lNv55Sf2y2+0YGHjtF2IKzh4wFZLIuVqNzv/3AZbMQfPa495CpaDrf3+JsV/8Gts/8CHs/8J/ILBzl1wUmHr2ORz//g/hfeoZ+A4cLKns67MI6pkIRlrEQjlf2bfqLfiPKz+JNy68Fjq1Fgcmj+GXO+9DIBbMKPtEyg+/gq4tWzG5+UmkE5mD9LLaRezyqLuLkVBK3tdXc5LqXM9JUTEYxIi409nKH59wY2rPXnbdfunFFd/f5+E5B1FjEEvrFjL7Po18k7BgES+IxKJJdpLUatVQxTUwhu3YNX6gpPptbGxkl+Ecss8/f53j1Fb21aJ/+/Ug+xOjuT3swXiIhVcSbNAgHeLvobFlKQuYI6QDHrm3XArBzAc93vs/cQlufesyVsgh+KJC2deXVvbtBhu0Kg3SSMMb9cEiesbnomd/qH+qwMJ/dIJ/Fxc6W6EvkyRLSHi580pNqn4WTAtW823u2YfUeC8zXDISbrIXkv08ZZ9QLYqTtK/LPfvTtBZlk319dfn5Kwe6+We7fslrdy6gPnci+bT+XbOYf9dPB5B1lk0jEMi+fsPGBVi98NTMBFGgQMEpQvZT1LMvGfVL9eznFgzDgryTa0iC2aiTg/uyyb5Kby7s2VeU/fIxODiI3/3ud2huPjNDzBScGohNcjulxm5jyfj6Kq6cRUd5krWEVDwONyW8E9JpePfsxehPf459n/k8m+fuvu/P8t8Ge2ihmQEp/RIZ0uX1mZ9poH5o6icmtYVG7+VDrVbj6taL8M+XfJj9/Gz3y/x2lVpOC3/p0V143HcrnvJdj+g4D1IjtDmaWIBcOB5Bv48XT+qvvZop/LWXFwZnSTCIEXHB7tOX7Ptf3sL2Owrk09VUvlifcHNyGTMEsbJuccHvOxZzEkm45pblaBdKf2O0fdpQOFMTJ/vMxi8Q8/DvlN7lPKXJ/ooq/j70vMYhfYlEEu4xbmtvbHHmJPGTlVwlxsVp7DVQG8xQWTipTQcn5dR4Uvbpe/Dk8U2szzwbRKr1Bt4/mEynEIhxF4FtGhs/fV/JUcAeO+plbR2EuejZl8l+VjjfMXf3rMP5aDIB22Zrbr+7qYOT/cjgESSHuYXf0Lwk529UIlCJRhvmQ3r9tK9PZfXsT4f0VGa0X7nF0IM9guwvrdyifzL413efh8+9cxXaRR//6YI1ohBpMWpzFt8KFChQUAq01pwuoC+RLAzok39H51+1ClYRVMsfT8WOQdLfRkQhXDWNsv/giyfwrXsPIhg+eYfcad2zf8klxQPK4vE4fD6y/qXxn//5nye7bQoUlERcEBOtnS/qjPV1iLndiIyNA47Moih88DBSkQg0TifWfv0rGHv6GQw++DD8hw6z/wRSmem+od6+nOdIuCeZW0Cl00EriglnKiRSSEFWNKs9lUzhNz/aglQ6ifd+vF62XK5rXIFrWy/BU/0vyUREBRW2PnEQe4a57TaUsmD8eBd0i7k9l1l+bS04MtWFw+MnsNa2lKXt66+8HAah8BeDvq1VHr93amrNM7ea+Ijss+LGNXJluRIMj/P93GhXo95aSDKqaiy4/PolCPgDzP5NabMnDo/D5HMBLsBfRAnNt/FL7Suysn8KJvEHYyG4I/y9uKB+Lfa7j6DvNVb2x4b9LI3fZNbBWWXC6KhP7te3662ITfACl76mVSa1ZOtnyn6dSI0Pe/CtzT/FvtHDrGjx722fLPpc5BggtZ6+Wxbd9GoDEdvx8CRz5tRZueocnoNFSjFlXyb7NbMg+96JomRf62pkhREayZc4zI8rxuYl4GUVAWniR14af7YTiZT9KaHsl2vj11U3F/R9FsPAWACT/hh0WjULmZuaLN4SNh8gotyWNeLvdMH5Kxvw4ItdWNxiUyz7ChQoKAtqbcbGP5Oyn8wLi6JjucOiKzjeWIjsh6klUoVoRDwmkX1vrrKvEmT/gU0nMOYJY3A8cFq1T8052e/oKH6i12g0qKmpYUn8l19++clumwIFJSGpkBpB7A11dcDBQ4iOjkK7mPeIE4K7drFL6/q1LJSs/Z13Q3PuBoQefxLjm16E/fLL0HDuOTj6re8UKPux0VFZBX0t5tyfCmRf6i0eGw2gv4e/x76pCBxi3jPhpo4r0R8eZj34Nr0VW57vwp69XIXUqWKIp/Xo7xrDwiwheqGjlZF9Cukjsl8OJGWfWilSUd67fjrBs2s3kp4paG02VF94PsbclQfK8Z59HVrri7sC6KR2+XVLWGhkdg+/etIMtEFutciHobaWtcCkYjEkvT6gqSkT0HcKKvs9gtjT/rnIuUAmd+HEa7df9HZNyuRXWkwM+rjbwKG3IUbz4en9q+X7rdriYsm+qSDZ+LnTYvf4AXl5cnDyGI67e2BFoepJffEEcs1IbQv5oOcL7H8RThU/jVPhoWOOlH1K9J+c4NvQ1JohzgN+/no7nJX161MvPgvEo33Wkrt/0XupblqC5LGtQJTvr4amxTlkP6PsF4Z1StNDjk/2MEcEPZ7DUHocaK6yX54DcdcR7hhb2VENo35Wy6azDjSZ4Nv/cBnUyeIFRwUKFCjIh0ZS9lMlAvrSCblnPy0Iv0bY+RNIw24pbC+zmrSIivyjbGXfnKXs8zR+I+KJFMan+NmnNmvde7pjVmete+65Z+63RIGCChCTxoSJ/mJpRjsp+7y7k8Y3JxDcwxOgLRvWy/fVulxY8o//gEUf/TDGJidhSfAvf6ivLyekLz4ikf3yrJ6nM8bF6C6pt3hUzBJnvxv155B9jUqNT2x8P+vbX2FfhEPPcJKz1rQTqZql2Nevx/BwCNlRdAsdbZmQvjJFQa3DAZ3LyUbCxQYGgXZOmE4XjD71DLusu/LyWY2yi8XjSIf4aWxlayasbDo0Njug06kRjwPGsA1+QZ7yodZqoa2uQmJ8gk+xWL4sE9B3Cir73R6umlMoHCnd0jjHoeAoOjC/+wX1+G1+pg8HdnHC17ZQFMRCbvxh7wPs+mLnAsRPcKeQrqYlR8FOBzI2fonoL3C2sALGXw4+incvvr3gOaUiDaXJ5yM21ovoU7/GQJ/IgliwgJ3JSdk3Ow1zQvYp0Z9gtuhgEgFHpLLQRAGCzSAdZcsDuRsIapMVKl1hcUPTuJSTffaDFob6DuphkX+vEu9DupiyL3r23WIiAdn66RhVCql4lH0mcs++P8dDUBS7joqRe1nj8RTMDFLFRkZOv0KtAgUKXh+oNZKyr2YqftE0fkHu6XxKK3ZNlo2flP18mI1aBIv07JuK9OxPeKMsmNagU8MpMnDOBFQsV/rF/Ot8HDp0CP39mT5dBQpei559rVD2ycZPiI5leva9+/YjFQqxwDHjoozaL4F6/QmmxkY2Ao7U44hQ8wlxSdlvPhvIvjuH7I8MZYY5j48WScA2O/FPl/w/bKhbCa+bFwbamjRoX817bcemtDmTEdptzUyhnAiR3bj8QdHWhbwyEO0/vQI/STH3bN/Brtddc/WsHmNX12F2wkurUljaVJ6Sqtao0dDCiZjFV13QF54NHan7tJ9T60tWAU1/CpL9HkH2O0QCfLuTK7KDWeP45qtP/5ff34wDO8fYymLJympceNlCRBJR/OLAfWzk2/LaRbim9WLEJbW4iuchZHr2PagT3yvC21a/EZ+46P1swbJjaB/6/blTBgiBuCD7eQp1MhLE0D1fQFIQfYIjzBVzsrDLPftS4vAs4fVwAmxz8McjhBI8LJJgmWZCQDFQbgFBW2LMnbop4/YxNCyESqsru2e/Oi9QVBpHWArxSXq/01AbrVCbZ+6Dp+PY4R6+/adTSJ4CBQoUnG6gkGE5jb+IjT9JPfsplRxgmixi4y+m7CfEdUnZZzb+VGHP/vgUP8/VuYxnVPtR2cp+JBLBl7/8ZTz66KPYvHkzTHnjsr73ve/hhRdewC233IIvfOELsForq/xLOHLkCO6//34W9GexWHDRRRfh5ptvZi0CJ3Of++67D88++2zBfW+77TbccMMNs9pWBa9/z35G2S8k+zTfnFB14fnT2vBVGg10TY2I9fUj1NMHdHClMCbC/kzNzax6eCZjPJRr46exWxImRvzTLoSDQhirW3M+DJ0dwKODmIw7kfRNAiL13ag1MIJGCm23tw/LkRvAVQqWjg54duxCZJ5D+uI+P7zPv4Da294IjeHkq7mRo8eQTiSYem4W2QOVYudxCiszQGtLsdyDctHYakN/t4+R/VI2foKurg7hg4eYsh+dcMvKvn4WQYLzje4piexzh0ibsxk7h/czZX8+Qd+D8RE/dHo13vKe82BxJKHTa/DTV+7BcGicjZ0kl0vUG0YsyIteGkHyM8q+h02seMfa2+H1efGm5dezRcQ5dauwfWwfnuh9AectzjiPsm389jwF3ffqo0hFAlA56lF//fsw8sevwhH0AzYbs/FLAX/x2MkdsaYmRRuBPfNdoMIGwagxyCFK0yEtbPuElFD2tY7i+5ba4uT98+7BgnC+nDT+ImSfwhHpv7R91WIcYSnQcxDo+cpZzPlDCQTCcaYltdVP3x6gQIECBQrmKqCvSM8+tWoJLd+gVyMZzpzrEmISSD4sRq3c3y/17KsMlhwbP+vZN5gwNsXPVbXCJXdWkf1YLIb3vve92LlzJ5YtW4apqakCsn/ttddicnISDz74IHp6elgiv65C62p3dzf+53/+B2vXrmVFAxrfR48XDodx1113ndR96PYVK1awPIFsVJ3hwWtnCoK9fYgHA0BDQ07PfoGyPz7BCCiFo02+so3dVr3xQsxkJDQ0NzOyH+zthV6Q/WxlvzRlOvNs/PT+jc6g7EsIB6lLSg0VUnA21cNc74BeHUcspYO7ZwAtS1fKf7usZhEj+13e3CDE6eDcsA4Df/4rgrv3IjmPfftd//sLTLzwIozxOMt1OFmEDnJLt2n58llVh+kz6BoYhg0LUF1bWeG0qY0TErO/Cv5IaTKsE60v8bExTLy0mU0NMHYuhN55asUhxhIxuTeeesVjvgizwRMGA/NL9n2id6+q1ozOpbUsG2EyPIUXercy8vfJiz4Al8mBYbeX9aUTtFauNKvEiDlStenzfMOya+VsBcJ1bZdix9h+7HUfxmhgPCeAMaPsZz77dCwC76sPs+u69TfB1LGGXXdGY3Iav17PF0GJeDLHWTM3yj6/jYj1TJh65QGEn/k/BO74J1iXbZRt86Tsl/Ic2DdcB/ezv4V1RZEAYEH2EQmw15X9naLrdNzq8w6WSfaHKkriH57kr7vGYYBeV37RTYECBQoUVAaNrOyrkaT+/Dwkydqf5tTVYNAgJch+ehobvyVL2Y+Gp7Hx600YE+OO65xn1gSRsmz8v/71rxnR/+xnP4u//e1vaBRqXTbuuOMO/PGPf8THPvYx7N27F7/97W8r3hgi6fTYH/jAB7Bq1SqmuN9+++14/vnnWYHhZO5DZH/JkiVYuHBhzn/nKWhZVZALCmjb88l/xvB3v184ek8o+2xuu0rFA8d8PviPHkPc64XabIJjNU+Fnw56YdUPiZC+RCiMpEgnJ2X/dEU0yYnAdKDFs2TjJ7txwBdjAV3ZPfuliEMwwB/fqIpAZ3NBpVah2spJ+VgfX+BL6KziRZShILeNlwP78uUsjyEdiWBy66uYD6TCYUyK8YzjL7x4UiRJQujQIXZpXrFsVvcnchsVSbHtzZWNfaypt0CjU0Gb1CMwGS+D7I9j/AWegm694Dycatg1coBV82nyAxFrQrsg+8PBMQRK5BLMBaYE0bPaM6R35xDPAWm3tWBZ7SJ2PS1G8EGjkxN9VWY6t9CA3wRSocLWlQZLrdyW0OflBDRf2Xdk9ewnDr+IVDgAXVUTNB0bmNVdY3HCmUjK3/WEmn/etAsn4qk5eN2Fyr45j+wnwwEkxzPhpulEDFMv38+uhw5vzbXxl1D22Ws9/xaY3/PfMDYXjphUSUWPdEoO+suGlIlAqClT2Wf9+mVgxM3fi4bqMyesSYECBQpORWikNH4W0FcsjT8pp/FTWKr0FyKzr7iN35hl45da3PIC+gzpQhv/WUf2H3roIVx55ZV417veNePfEtk/77zzGAmvBDS27+jRo1i/fn1O1f6cc85BKpXCgQMHZn2fiYkJhEIhtLbOzk6r4PXF2LPPMUs0KZBkt6YQPclyTCFucuCYSBFPTLjh2clT+M0rVrDfzQR9C1/4kbJPiAwJ9cfhgNZ6+o09IsL6f7v+jH9+6Wt4uY/3jpcCjWcjoqASqph7jC+ma+qsVD9hgSZ+X6ZfNxsBL7/dpA5CY+GfRW0Nf7/Hx2NFe2mlWdjlgNovaq/gkz3Gn9+E+UBg9x5WJCJEx8bhP3zkpB4v6nYjPjTMik+mZeVNHsjH3w49AUOE73d1dZXN12ZzZR38hBcJJGbs2Y8NDSN44gRrZ7GeswGn2n781wOPsesbGzfIx/lGax0L6Yul4vi3Z77FkvnnU9m3ZZH97YO8X35VdcZung7zVheVyS5vo0qjhUao+wlv8QJXg1DzR/y5v5eyFmjaBZHnZMiH+D4e+Oi8+Ha5LUnrqIU+DVg0nJT7Ej5WXyBEo7Pv25/yhEr27Ju0uaR3/OEfIvrgN+Df+xz7Odm1HSnxfkSGjvH3R7Lx22fXIkKFDZWeL76S/twiIqHWXF12z35svL9CZZ+/7saqM2vxp0CBAgWnGmi8KYEIPRX585FMZ8i+yUA9+1wUkc52dpFbk6/sx8V1Cq+l0dKUxq9LA854EvpUCo60mp2zx6aiZ6+y39fXx/rgywWN3SN7fSUgQp5IJFBfn6tiuVwu1g4wPDw86/uQqk/YtWsX/vVf/xUf/vCHWf7A/v37K9pGBa89iNiPPfe8/HN4cBCpYJDZ9Akae0b50ope47h7ElO79rDrphXLy3oeSdmnueNE/MhNcDqH8z3dvxkPH+Xk4OX+7dP+rUSU7HobdBod3GOc4DS1OWAX1c3xkeJW/uAUv92iDrOkbUJdCy+6TPhyK6zVTOnkQWKVqOd1guzTKLuEr/xwv3IREI4BlWg7mniRq9yzhXcPJ4PWRYugsVReKDo4eZzZxPWC7FfVVv4YZis/4UWnSWXX1VSz8XsQITXOdWuhmWXWynyB3gvq1zdoDbii5cKcvr7PXPZROA12DPpH8Lmnv4GBeQjrk+zsVpt4P5Mx7BvjxaBVNZlCTloo9ypTbk+3pGQnfMXnsjfYONknG38xZT+++X6Ef/OP6P3u3wERP7SOOlhXXlrw+C5B9t3hKdnKH5sl2afvpmzjzypyFFP20+kUwr38POp++je8KHEgc7xOeEaQDPszNn5H8YC+cmBo5CGrgf2FRT8pWHQmGz+1WsTG++TxfuVAUfYVKFCg4LWBRquRbfyJdJGAPqbsc+pqNGjlPK24WFOWGr2XyJqGQ45UIvtUMvjogAef6JuEQW9CMpmC28vJfpWt8glKpz3ZNxorSyWkkLxK+/Wpx156rmLPTwGBs72PNCWA/v7d7343I/sUIPiDH/xAIfynOMKHjyDmzig54aEhJGguOFOJ7CxFX4Kumis60b4+BI4fZ9fNZZJ9eixS8cn/SkonFRVOVwv/891b8FA3J/qEQ+PHpyXXJya5m6HRwnMPJGXf2PssHLE+2cpfDMEprkCa9HGoxLir+kXcYu2NWxHxZe5XZRLOi3SSuQnKBRVcDB0LGCkNbJu+cFEpou5Jto8Rqu+4jV1OvPSyXEyaDTyi0ORcv7bi+0biEdx39GEgrYIhxhPPq2sqJ/s2Gz8mEj8r9dnTd8dQm1Faay7LkMhTAbTdFF5HuK7zUljzEuAppO+T69+HdkczvBEffr7/3mkDCWcD71Sujf+IpwvxZJyRy0ZzhrimIxLZz3VhSEp2SbJv5d+5kQKyL75XnkzgKNRaVF31DqY+ZB6fb4NVrHjoe6U3aE+K7MeiSXk8UbaNX+7Zzxqdl/aNy0F8pOaP3PdVpCcHodLqRRsDEB04inTIO20afzlwnHcLu/TteAKpaLikjX86sp8a7WKtACpbDbS28vJ6RkRLQ0OVQvYVKFCgYD6h0WR69lPp4jZ+Wh8RTAaNbOOPiWVO0Z59Iz8nJgWNDfijgI4fz23JFKoSKaj1RoxPhZFMpbFQpcYj9xyGzzvzWNYzKqBvwYIF2LeP9ymWg927d6OpwtnkMyl9xYoN5d5n48aN6OjoYD39ElauXIkvfelLeOCBB3JurxTJZBLjNKf6FEc0GmXhUNJl9m0z/b7c2+bjPlMUHEagzzKdxsTRY9AS8aO1r82acx8IS79/y1b2t/qmJiTNprKfW9vYwPr8/Xv3ISLU2YTddtLvy2v1XtHlvu6D+MmrPC/jiuYL8dLQdkYA9nTth0trL3qfPQMH2W2t5gZ228QYJxqOyAmEEvQ9rkNf9xga2xsLnjsgDoZmQ1K+TWs1wawJIZQ0Y/8rO9CyZhm7j3vczfqu/fEgjvQfR52+quzXbTpnA6LdPfBt2YqRa66as/d36qln5GA6wwXnQf3QI2wf8B04yGztlX5Ow0NDmNzFW0hSba0Vb8+fjz/G5qXXooGd0Kh/LRieYiGplewjojgOdVyH7sFeaJKqovdRU0Dp6BhzNSQWtCF+Cu3TLxzegh7/AHRqLS6oWlv070ww4MOr3oFv7fgZJiIefO/FX+DuzjfM2fZ6RCq93sjfv71jPIthhbMz5zNJ+LlNPaU35zyOSljevUO9CBd5Hl2Mf1CD3uGc7ZBs/BbqKbRWw3TH5xGNJxEwmRDI+ru4ipNxA7WhqIEh9wg0Gl4cGhkeg6tWX/Hrdo/zQpzJrEUyFZd/7xcz7g0qXeY+wyf4jkbZAhE/osK2r+k8D0ki5D07Mb77eUawodZgPBBGLBaf1T6StrcAtlqk/OMYfPF+pBZfLN9HLTqGNCoNQp4g4kW+L4TYoGjRqe3I+f1zW4/g0S2D2LhqHBeuqEE8zu8fjSXh9vEHr7Kq5+178FqeI5TnPj2392x97tNte8/W556r7Y3FuEhLVv14MlHweyq2SzZ+nTZj348hDb2OnIrxgvvoNLwaHkunoYUK/b3DqG8xAZSvI4J1k2odDh7jLnAnVKzo3dM1hLrGU7uNt6amBtoyWpXLIvuUcv9f//VfeM973oPly6dXSg8ePMjG833wgx8sf2tpYSHS/enDyQcp9MXU+3LvQ28G/c8GjeWj10JBficDepwGkRB/KoN2eNpO6TL7tpl+X+5tc32fGqsNXXu584L6tsefex7qKS9UIb4AN9fWwmAwyPfxNdSDdORUgC9Wa84/V/59Oc/tWrKYqby+R3iPsMpgQPu1V8N0ku/La/FeSbftHtnO+pyWODvw4YvfhcEnR3Bsqgfj6Sk0GGqL3qc/xNtdFlUtgNNBAX28u8ml8SCU4mpq0Jcs+l6GQ1RXVcNiUuU8dp09jh4P4BsN5dynzloDvycImNUwaAxlv+7kxgvgvf8BxAcG4EilYGpqmpP3d0RkOzRdezVUZjNqL7kYo088iejuPWi47tqKPydrKISUP8D3nY0XYmxiouzt2R88hhcG+QSJN7bdjFdeHYHDaWQBpJXuI3X1VTiECWjjBpidFiCQLHofR8cChA8dRvWF56NpwYJTap/e0rebXb+m81IsaVs07eN8yvz/8Pmnv4E9E4ewxNWBN2+49aS3t79vUE7uraqxoK6+Dode5uT20kUXwoDM/tsXC7FFh8bmynkcU+MCuPcBhmQI9UWeZ0XdUmA3T9Kvqa3BxPgE6mgkolDRiexTe0xjS1vRbQx6F4LmEVjJiaKmY5YaZosRXk8UFosDBkOq4tfdc4wXLlw11pzja/woPy5YDZbM635lmL1u7cINMOl18O9+mt3ecNmdGN23GfGenUj375NdDo2N039vZ/qcBtZcg9jmPyB9aBP0Ky6X73NO61qcP7YOVRo7mkp8Xwg9Ez3MyqlrXpLz+80HRnC438/+P7VjDHdc1oxrNrbjxMCU3Ada7cy87tPxfKo89+m9vWfrc59u23u2Pvdcba/DQU7eMRbQRxS94HlUXPUn2CwGTCANDVIYRxoum4nxvvz7RGNc/6eyLa1odVozDAY9YmYbEoLsGyx2RFJ6Zu3XCB25c1ELLDbD2WPjv/POO5m6T2Sf0vhJzc4H9c7TrPv3v//9bJzd3XdXNr6qtraW9WGOZc1JJ3g8HhbEV2wCQLn3IacB/c8H/Q3Z+RWcmqBxYOl4HOb2NtRexscxkb0+KWz8+qpcu6aOEvmzQD3IlcDc3p51vQ0tn/00TEX2u1MVsWQcz3VvYdepv5mcLZ0O/poOjXPFLR+kIEr9wu32FowMcrutRR2AXh2DUzMlj98r5qQJhvhtFmtu3bCultueJZUw32LrDnFCUS6ol9wiHB2hft5icTJIhsM4/sMfI9jVzfrWay7mmSTSfhbcsQthkflBuRF99/4Rwz/6qRzkVwpTO/lxxrR0SVnBkBJ2jR/E/27/A7t+fdul0Ezx45KzenYhMRYrP0FpE/pp0+qb3/QG2C+9GO3vegdONXRP8haSS9pnnhBAkx5u7biGXb//+BMV71/FEPDzz9pg1DJrPLW7kCuFbOwranP7vaU0fpWxhI3fW9zG7zTaoVfr2HdrLMSzM/yxgNxbaE6maRVSchulHnhjhC9Y6LPWiZ79eGx2Nn6/l79upyvXth6KSz37mdtTE7wFSF3Tjqor3wFDyzJol18GfV0b1LX8+yqF9U2XxF8uNIsuYEGg1BaR7N6VuV2twT9d/P9w04IrS943lYghJaYGqOv5FAUJA2NiGzVqDIwF8MP7j8Ljj6B/jB+/WutzsxgUKFCgQMHcQyvGm/LRe0W4ZjIJlUihNRt58N4A0my8tqsEMdfr1Cz4Ly7OrH4fF4jVWdNuKAB2eCIIKaWGXJVS9tFZQ/ZJQf/xj3/MFIfPfOYzOP/881ky/6c+9Sl84hOfwDvf+U6WwE+j+Ww2G37xi19UPL+eevxpNB6F6FGSvoQdO3YwQr9s2bJZ32fbtm34v//7P7nHX3IDUGvC0qWzS8tWMP8YF0FpdVdeIffOU4BewsMJqM6VS/a1omefoNbrYS+zX1+C69wNMC9oh+2Si7HmG1+DvqGykWevN3aPH2Q9y7XmKqyo4ovZRYLsHxw/VpSsd/t4nkWrvZEFb40McdJSpRGhfRofVEizUXzhYOEYt1BEHHRFgJkEZw0nPV5f7sG6SvTxTsyCjBnqeH9zNK+4Vyl8h4+g/z++jNEnuQpZdevN0Nn59tI+Q0WFVCSC/Z/7AoK9fRj9+a/Q/4f7ENqzF76D3MZdCpOv8kwB88oVZW/P/uEj+NO2Z9jnQyr2Da1XYM82/rksXFrZcVSCRZykNHE9I4+lYKyvR+073g6jeG9PFVAYnCfCC0/Ndl6lnwlU4GqxN7JMiG4PLxScDGgEJcHhNLGi2O/28HFy6xpWQpvVN5+Txm+2VxTQRwW5GlNVTiK/T+RZWNQ6aMQ84FKQHt8kkf1YEAbRsy/13VcKaSHkyCf7Us++COhLp5JIufl+qq5pg8ZsQ/O7vwL9RXfx26pamHVf3tZZ9OuHInE8tqUH/lBcTuW3n3OjPIqwErAWg1SCjStUZW1LIpnCsJu7xf7nU1dgYbMDiWQaL+walIsALXWKKKBAgQIF8w2dHNCnQrJIGn821zMbM+cXgstuLHmetZl1ciJ/QEyX0pgyhXQau5dN9imUt5KsujOC7BNobN1f/vIXRvY7Ozuxc+dOPPLII3j88cexZ88erF27Fv/2b/+Ghx9+GIsW5VbNy8XNN9/Mkv9/+tOfMiJOj/3Xv/6VpftT8YCU+K6uLqbcl3sfwo033sj6K7///e+zbaVt/853vsMI/xvf+MZZbauCuQURnWzVNBWNyiPQqi48nwWJUV8xjeCLiEkP+nyy73TydHEibStXQGOozH6jdzqx/nvfQd073w5NkbaR+UQoHsYDh55El3f2JOXFIZ4qT4RRLcLyFthbmOo1GZ7CZIQXSbLR4+M9SotrFrLLUUH2nZpJps5pVEnY9PzA6HHnhmRSAFg8yZ/H6sglJFVN3GXhD+ceYqQZ2JOzIvu1J032aT87/v0fIumZgrGhAau++p9w3XSD/Hsaabbi3/8NusYGFgy5+x8+ieCOnfLvY1nHnnwkfH74jxxl1y1rV5e1PfFUAr/94wtYcHAj1k9djvdveCv6urwsQIbsYwsWOYo/l9+D+KEXkE4UFmAIZjF+Rktkfx7n0M8XRkKcHDv0NphFkM5MUKtUaLSJkMlQ4b4+W7KvtqTwXzt+wgpmpMLfvIRnRhRV9vPT+AWpTAanmLJcDLWC7EsOG2+EE0ybipN2Sg0uBbXRCmj1MKeEYhELVhzQRwnE21/uwcQoJ7wBSdmvyn3e/DT+uHsISMSg0hmhchQWRomY6+sWZN6LWSj7j2zuxo/+vAePb+XTUQjWVZfKYXspYcEsB5E+Xqgzti7PWcSNT0WRSqVh0KkZqb/u/DZ2+3M7+pnKT1DIvgIFChS8lqP3KI1/BrJvyg3jcwpHYzHYzPoM2aeAPnb+zCP77iAMwjWQHU57JkBbERnS65miT/8Jk5OTrGfdIYLRThak0lNS/kMPPYSf/OQnzCVwww03sMwAgtfrZdkB9POtt95a1n2kQgW5ECiM79e//jXbWRYvXsxeB7UCKHj9cejLX4PvyFFUf+87MFRXIXLsOCP2pNYTKaPFma6uFrHBIcT6B2Qbf/ZylgLVqCgQHR2Dc/06vJ4gUlnueDlK+L731YeZ9ZjCyGpramFDZcnPXZN96PUPMmJ/1cKLEJ4SwWIaHRa52nHE3YXj3l6sRK7boVuQ/SXVnOxPjnHS4tB44br0Loz+5ZtwqN3woQWeidyFtc/LF/86xKDPa4epaSUnxgiCCSOS8VihjT+cIc1bB3ZBG1GjgULppoGkPkdGZ0/22aSFAUoL12Ltt/8LWquVBaflF32aPvkJjP/gRwj19kFlNMLUUI9QTy9iwlVSDKF9+1nYn6VzIbR5hahSeLJrMwyDQv09YcPYsB+H9nDSt+68FqhFMm020hRac+83ER/rgddsgvMCfiwsbuM38IT617B29deDj+Hg0FH8S82HodfOzgY3GuLvQUNW4n05kCY+UHFrrmz8hwOH4YsFmGvgnUtuwxJRGCtO9nOVfTaOkt6DRAxJH7llCpWCGpMrk8hvXy4r+1am61OVqzTZp+OiyloFc2xStvHrDWL0nuhTnA40b/gv9+zE4X0jsDkMWLmmI0/ZzxzDQoLsm4SNXwrnMzR0sCJZMRibFiE2cmLWyv6JAe7umBDbRNC5GqB11iExNYZI30HAWt7ElEi/IPttKxAulrZfbWLv5yXrmvG/D+xnzz0qFP+WOirilD8uVIECBQoUVA6dZONPqZEscswl11Xmb9XQa9WIJXgBoJSNn2Cz6OETjxcoYeMfmQhCKknbHGeOhb9isp+PSq365YAcAvS/GChkjxT8Su4jgdL4qeVAwakJ7/4DzDo9vukFtNz+JoSEqm9atkxWYXT19YzsE6GSlP187ar+mqsx8vwmuff69cD+0cP4/tZfo83ShM82fLzk31Ex4Ld7/ooHDz/FftaqtUzp/caLP8Yn1r13RvKbjadOcEvrhS3r4TDaEQZfpBKW1y2WyX42Eqkk+vy8/31JTQfoLp5xTlpcdU6YFm1gUxAccKMfLbLyJ8EvyL5JHYLKxLMNItEEs8XWNjaADtUpaDBFn5lwSlQLFVOy8VOR4tubf8aKHP/m+ASc4JXWoxNdmPJPyUErBEO9ZOOf/fQLSaU3rVzOiH4paO02rPryf2L0qaeRIlv/3n2M7MenpiH7e3kQWdX5M/eYS0ru9j1daExyF0A6lcZff7cLE6Oc7G24sA3ReOHIw/iex5EY62HXw127i5J9qddMk9TBFwoCuRx03rDffRT37n+QXd85vB8Xtm6Y1eOMBrmyX2+pTA0uVkw6WWU/oguiyuDAV6/9NKYmCh+XqctCtc9X9hkZt7iQ9o5yK7+xtqSyL43f80X5Z24Rar1qmp599nsi++P8/QpkKfsz2fhJ0X/m4W50H+Wvye+Nor/Hk+nZrzIjhYwrRAoNlJR9iezrGzsLjsMSDE2LgJ1PzFrZ7xvlx6NAKPcZTAvWsDDAcPdeYPXMZJ9aDiIDR2RlP5fs8+NYg4u/LofVgNULndh93INAOJ5R9ot8FxUoUKBAwdyBCHymZ7+Ysp9F9rVqGA1axMT511nCxl9K2c+28UfSelY0MAjDuzRu96yz8StQMF+gmeZE9AkTok+fEsIJpuWZTAWdIHvyz0XU09a33InWL3yuwOL/WuHV0b34ygs/gCfsZcngu0cOlPzbh7uflYn+DYuuwI9u/QqaLfXwRv342b7fIywCscoJ5nu5n/eKX9tZOCt9eS1vqzkxlUv2e6cGWHHBojejyVbPFv9S4F7dylVQ06xsWw0adDyorq/bm3Oglci+WR1kJIcCrT7wtafxrXsPsVmpFh0/oE708fsTqs0Z5TWVTuPwxHH2M23H11/8IZsc8MOtv8Hnn/km/mf3r+WDOMEobPyRk7DxB0T6vnXD+hn/Vme3oeWO26BvaoTOxbe7lLKfjEYREv38VeefW9a2/HrXn+AYbWHXV26oY0FwEtFfuKQGrupCkhcd7kJiNydPklqZThZa+U1kb1Pxz8rrnz8bP01+oM+RQCMe7z36kPy7faP8O3wyNv56U83slP05tPHH9WE0Wupg1BZXDZJBrj6rdAZmaS9GxgkJb/EiVY1RIvt8v5aVfZnsl1b2CWqLq6iNf6aAvicfOMiIPn1XG1u4O2/75h42cig/oI8+53AimtOzHxWKvaGxs+RzGJoWF4QVlgsqGg6N833XL0i3BFPHGnYZ7uEjUmdCbLQXaSrK6IysPSkbw+6Msi+Bxu9J0GlVqHVN/xkoUKBAgYKTh16f1bPP8vhzkcyy8WvUKpjE+a4cG38sq2efxDbWBifgT3A6bBFtBGeajV8h+wpedySDGcWY0tG9Bw4gNsAVZ1NWgKK+PrcvND+N//XGs12bcc/h+5FMJeEy8sXzH/c/XNTO/7dDT+Cpfl7YuGvxzXjvOXexZO4Prn47u+9waBwv9m4t63n3u4+wwkCV0YllgthnY2l1J1MYaQ75WCATFEbqOWFJdQfr8Q/6KatUBQ0ScDZzEqp2NqBOOwKDHoiEEhigeXoCPq9Q+tQhwGTDk6/0YsofxYmhAFPErEZONiZHeNgfwWWiCaZ0wE4iEA8yZZ+gpfnY8TC+v+c32NTzCrstlopjLOguCOhLBoNIBConsKG+fsSHR5iF37yWk4VyoXfyfa2Usu/dtx/pWAz66mpYOjpmfLwB7zAOHOuFOeiCWq3C+gsbcdWNmRBSUvXzQaR+7KHvs5nlluUbAaMV6XgUkcHCSQsqtQoaca4K+MsrGlWKRDKBf37iK/jM5v/CL3bcix9t+z9mdzcIUrx/VMw0Pwkbf725pqL2mDm18QurX9wQRrWw2hdDMsCfi4LfioGU/elC+qSAPtrXScnwiZ59S1yQ9WkC+tjjW6tgSvIFUCQRhVbHnVBRQdpL4fA+XoR7w11rcNVNfN87sJv3xpvMOrlowB43HkVaWCApQ4GU8thI94xkX1fTDF1VE1RmJ3TOygJPRycjSEpFjAJln7thYmN9SId4sUUC5VgkR7uQzlKFAoc2s0t1fSdUWaGB2Tb+xqpMoWZNpxMW0Q9a7zKxRaUCBQoUKHiNbPxM2S8810uCU5p8o5pcsu+ahqDbsgL6EokU4rFkDtn3RfkxXnoEm6LsK1Awt0iFcu3hJ378M3ZJqehkp5aga8go+xqzueIAvvnGI0eekVX6/7ruMyzMi8Z1HZzMkLGhwCizrf9+79/Yz+9YexsubsoowS6DHVd0bGTXuz28n34mvDrK7ePn1q2Wg/myYdab5FFhrwxkxlUddXOyv1j060s9+DR2T1fF7fMqZwPUqjTaq/lndHh/pr/d6/bLZD+lt+LxVzLOgf4RP6wWvi1TE5k0eK1aA7uef6aUtk7vD+HtS9+IdicvMFDImmTHluzcBApNVNv4wTk6XrmVf+LlLfJIRo2pskwEWdmfLG4Pn9z2qmzhLyfB9fDECbjGOaFftroBZosO51zUjpXrmtC20IGlKwtbOMiyHB/vYyS/5oYPQtPIC2Hhnn3Ft9nI3/9gcPpxgbPF9qG96PcOIZyM4onjm7BjaB/b/z59yYfYaJzhwBgmQryXvBKQU8UtwiQbLLm2993b+vG/39qB44fHZrDxT5WdmVEMtKCg4pek7NcYpyH7wenJvlpW9kuM3zPYWRsLFcCmIl5MRbl13RyPl6XsM7KfSktGDqQ1yRkD+ui9CYnpGq0dVehYXAOThUYAomg4XyDOv/86jY5ta3xiAGly3eiM0FWVHk+qUqnR8oHvwHjnF1hgXyUYEoo7IRhOyMSfoDHboapuZdeTwzwUU4J320OIPvxtuJ/8JX+tkQB82x9n17XLLy14H6ioQGioMuXYQy9Z28SuN2Yp/goUKFCgYP6gzyb7RXr25fOAKs1caUbhBCC4bKVt/HaLnj+aKNyGAnGos2z84SQvGqhFJoBi41egYI6RCuaqtGERwOfIU1+pZ1+CXpCvUwWkyA0JG+6ty66B0+TApU28d/vRnufxYs82fP3FH+HrO37CAumIDN3YfjnesOy6gseSSG/f1Mxkn1TAQx5uhT+vvrRavVH0Tm/p3yETqj0j3Ha+TASO+Sc4ebdqAvL8brWTL+RbjdxpcWT/iEyifB7+uZkNCezv8WNiKpzTa2t38gPv1FSsgNwQRkLjGPKPsutLXQvxH1d9Eu9feRe+ed3nsKhqQU5CuQRddfWsrfxuQfZrLubFlEpAoX2llP10KoXJbdsrsvAfHe2Gc4L3GhPJJ5DCf8c7N+CGOxZDI6xk2QhTGBkRnbY1jOxomjjZj5Qg+wYTf4xIcHYj2GbCM11cLd1QuxIXtmxgiv4bF16DVfXL0GZrmrW6P+wfZSqyRWeCTZfbyrB/F1eeKVBuOmU/mogyp0g5oP69ybzwyaCfJ7TTv7g+iuppyH5CUvatJZR96/TKPk0RqLNyB8OByWPYObSfXa8Vo2LLIfv0SZvE9zKpScxI9hPxFGvbIZjMerbvLVqeyeBxZhFfQijGyT59JoTIICfY6ppWRuin3T6tjrU4VIqhrM+EXpk/r2gl7f/Jwdx2kegIL2L6tj/GvjPx/c8iHY9AX98BTeuqnL+dCkQRiiYpmgR1omdfwt03LMMNGxfg5o18X1agQIECBfMLnWTjT5GNv7SyT2cF4u3Usy/BOU1An9XMyXtKI8h+MA5NlrIfSmnBytFpFlUFi7Wy4vSpDoXsK3jdkRTKPpF5tT5TTXPmkX1S83Vi8kOxfv3XExPhSabMkZovqYtXtV7ECFB/YBjf3/or7BzipGxj6zn45vWfw40Lrij6WO1OTgL7vEOsVzYfr/TvZAWEUCyMl/t3sL/pdLUXWJ6zcX7LelZgICWd7MKULUBhXtVGJ1bULmF/45/giqJFH4NaLM5J2SfUx6gPXwWPOySP4PMLG7/VrMJzuzn5pmRUtu0jftiquYLvy3Pcuwz8M9znPsLIVI25Cja9hdmD19QsYwnu9YL8ZLcdEGg6A4EmLlSC0MAgS9aHRlN2gF4xZT8RCCAlFFcJ4aEhxD0eNhrSsTqXTJRCV+8oNHRyMauwoJMXMModHaZp4K0a6ib+uZGNn+z8+SArNiEWnjmVvVLQGMe9olh0S8fV+OTFH8A9d/w3rmzhhZSlro5Zk/1BHyfyzfbGHJcEFZlGBrlle2ykeFiagcbQiZ7ycqz8VN3/2bdfwJ9/dYCl0vvF/F2vKFwl9VGmIEhW++mV/eJTaVQWoez7SrtRGqy8uPa3E08ikUpguWsRFk75ywvoE20CZpFInFTz/VPqvS8GKbyPSL6U3r94RWY/dOT1qAcksi9aClgKPt1f7IvzgaGJXMeXNxgtSvZTQ0dyXBwJNvWAY/zhHyJxcBO77rr0zQWuG2m0Xn2VWR75lK0SffTOtWiuUfr1FShQoOC1gEEi+xTxnOXmkiAf65myn7Hxm/QaGIQroFTPPiEhTgFE9rNt/KTsS+zD5jAWnYR0OuPMejUKTkukRM++tsqVIWIaDewrcsfEEUzNTadkvz6p1AQi3JKVngjs7cv5DPdmWwNuX3EjPnvuR/CPF70fbYLQl1r4k1U2moxhNI/sUk/09175JR7v3YR/fvIreOzYc+z2SxecP+32UR7AIidXkF/p34HnB3lf/GXNF0Atxmb5xbg+mzlzgFWLPlt12I3mVr7o7Tkm0ruFzdlo1OBgj5dVQ990xaIM2a/nJCcQ07MeX3lbDLwIcGiSOxI6q/h2ZaNe2LdHsmz8J6Pse/fsYZemJYunTeEvBXYfrbaouh84LoLK2lqh1s1cDaYRZn43Vymra8xl2f7JMh0dPp5DsCg8kTkwUgmkRvk2ZMMsndzKH0U+LQ6NH8OESLl/ZWQ3K9Ssrl8qj47LxmInJ/v7xg5XbKcfkMl+bitD0B9DOMT3ufERf8nHlZwj7hlC+kghePaRLjmZl/rVf/Rfz+P4ITe8Hv6mRfX8O0FFsZnIvlaQ7pLKvnei5DY3WHmLUiKdhEGjx5vbr4JKUjVm6tmn9gGVGiYRXBQTMUTTKfsRUQAymLTy/lddZ0Jtg62osh8UNn6rzsxeQ7iXuw80DbzgVCl++9ghfPW3++ENFBapitn4Cfl/S/330GiRDnqQ8GRCQOV2CY0WCc8IQKp+3QKYlxQeIyWyz0frKVCgQIGC1xN6fUapT6YL10aplHRbGhqVSrbx2y3Tr73sFr4eiotzcL6NP5DQwiBG4+YXu88EKGRfweuOJI0Go53RbEb9tVez6+YVy1mPdj5MzZwk6+dh7OPJQB4VljcX/E3Lr8fXL/40vnvTF/HW1W8o6EEuBo1aw9K/pcT8bGwZ3skcBITxoBvD/jGoocJFbTPbx9fVrmCX9x98HKOhCZaqfWFDJpU+4ONEymbPHDQpXVxK0W5r4GSi9/gUm88dCvODZlAoiucsq8d5K3hxoG/UD7sg+6GUGUlvRm1zCmWfEvhLkv2Syj4n+9EKyb5EyI2dhTPSywERIik/Ij+RXyb77YWhesXQ6xuEPsxPMtU106u2ElJj3TQUHRp7jZzuTttkbOdBZcmhQgXdKiXTxjTyez1b9E0N4ovPfgdf2/4jPHl8E7aO8OyHqxZeXPTvO+ytrGBFUynGwpnPvjJlP5fsZ49+JGVaUuHz4dDbiyr7iXgSP/32C/j9T/diy6YuPP/EEQz1+ZFSJzHQuRPVTSb2uM890o3tL/fK4XwukwN6je4klH1eKGA97tHgtMo+4a7Vb0CVij+fiiZizNDrToFzGlsVzMKWH1dxUhybJo0/Eua/M5oySgjtT7fcuRpLVlVjzTm8lUhCkJLsWf6HGWn/OJL+SUam1XW83aYSuL1R/OmZo+geDuLxV/gIyXzEE0mMefjn2yimUngDuTZ+ag0wirR/aaweFRWTAV6QqrnuffLfFlP1CYOC7DfXVl4AVKBAgQIF86PsE1JFyH4mtI8r+5KN3zED2XcKi7+0XuU2/kyRN5jQyMp+9iSaMwUK2Vdwyij7GouZhaet/e43Ufd37y76t4033wjL+nWov/oqnEqQRoU15FnpaYEp2YorQZMg+31e3itPIJK/eZj33L958U24pI27INbXrWTK/UxYW7OcbU9Q9DJf2bERpqxxYn7BpaxOM7NPfeu3O3DPk93Q1fCFf6t9irxVGB8J4elHSLGlH1OYivKD5+Xrm9EqFLJJImIaNTQq6rpSw59lu3flbWsxsi/1MFMRJVsNlW38Y5UF9FVKyItBY7fPCdnv8fXDEOEExpnXJ1wKyRGu6pvaVuSQFlMHJ/upvJAygs3CT1jauL7s/vVSkPIdqGjw8x33whP1waq34LzmdUX/nsjx0hqe0n7Ew3uoKyX7LdOQfcL4SCb4MRuSc2RSuBAkdB2bwOiQj43Ue+rBg3jpaf6eDi3Yh6nqYSQ29rIpCLS79Z5wy+F89ZbpR8Yl83r2aWTcD/60G68c5McElUYnh/elA8UDC5eI3Ix2WzNuXHwF0qIooDaVR0K1WWQ/IqbIS1b9YpB+ZzRmVBQprO+KGztgFEn0EoJZNv6UcJgQ0aZiRKV4btcoJHfm09v6csZ5ShgcD7K/sRi1WNDEv3e+Ii4A6dgUJwWf3l9WeEkDag1s669B1VXvhHbNdTAvLe58GhjjrRItdQrZV6BAgYJTZfQeISWU9mzI5wtVmrWhmYQTwDYD2W+qsWBVZzWikrIfjEOlN0JtsgEkTMT1Mtl3KGRfgYL5S+MnZZ9gXbiQEf9ioIT+hg99AOY2nsR8qkAeFTYDMSgXTRaukPdMDeakn1NSt91gZYr83298L75/83+yJPtyYNdb5VR+OoTesORK+XeJRBKhGD9o2mvs2HtsHJt2DeCFPWNIO3hIn97Xg/Xn8ff9lU2cwJnUIUwleMGAZlHTuCqXjR8yh90R2AzcLeAb8xQo+xIWugpJMvXxU8ZAPBnHVIRnCczWxp+KRFjP/kmTfQcnHdSfLyGdTLJxkfyxC4sWxdDjG4QhwsmFI2vc13RICbJvbM1tbTExZV+F1EQfgoe3Fu3Z1yT0sg17tjg4zosJC+1t0Ig2lUvbz59W8V5Vz3uqj07x96ccpFIpFtBXVNkfy30Npfr2S9n4KVySUN9sRZVwVMSaJjBVw/eNLQM7cP4NTVi0IuMaYmQ/S3UvhmSQ5whIhH7v8Qk88Uov7n+xX/4bKfAyJVTnfHS4WvGdG7+Aj699N3P2QJBrTZlkn3oPzWIRFE5zsh+LJWdU9snGXw6C8aBs45fS743tK8u6b87zRhN4ce+YfAwacYewv6swuLBvhH/n2xrs8uxkb5GpEtI4v8QUf0yy9LPHtjhZcKBz45ugP++NJUMEMzZ+hewrUKBAwesNnVYjj3lNpdTT2/jVKjRUc67QNMPUFJVKhY+/eR2khxweDbHbGt/+RRhu/Di8MU2WjV8h+woUzDlobjpBYynP0nyqgQLyyBZPaMiz8c8WzdaGgkT+x489zy6vXngJs0gTiIhI18vB5QsuZJdra1bkWId9U2SZVUGDOEzVVXh2R4aoeJ2cYCaPb8X119Tiyps6YLZyQm9VBzAe4c9fZTfmHHSp59ZuFXkAk8ECMkZotNbJoV/ZoBF9LiMvCmTnFmhrONlPBkNysONMiA4M0BkC+uoqaEXA42yglZT9rJ792MgoUtEo1EYjdPWZ0ZDT7Su93kHoo/w1O8sg++lknNv4iWC1rcjdJpsLjgtuYdfHHvo+Ym6eVk8wWbSysh88icZ92uZD47zYcPui6/Hla/4FNy24grWlTAcp+JHaFsrFWHCCuQdon641VxdV9pvbbHLffjE4DIU2flIDjh7gRQTXqgQ+/C+X4/r3LcTR5q1snBwp6vQ6Hz32LFO215zTDGhTCNjdcktJMZDrRLbxC2W/f5Rv15Q/JgcMSa0w6eAkS+93P/MbpLy5BasWe6NcPElHRQE0K0BoOlBRQFL2Q2l+32QixdptiiEq2/jLJPuSjV9nQmqEjxI1tVVO9um4Qun3ZM2/ZA0//jy1ta/g7yjzg9DWYINdHGsoOT8fWldDEWU/E1o4HaJxahXg75XSs69AgQIFrz9IrefzV4rb+LPT+InsX3dBO77+0Utw4wUzT01pqrXi3JX8vOOejMDjj8DQ0MFCj8PRhKLsK1Awn0iFwjnK/umGydAUYqk4U+Smm8c9Gxs/JeeHE1EMeIdxYOwoU7uv7cydFV0JiOx/4YpP4O5luW4Aj1sod5oA4sYqbNmXCbzqU7fAtHA96xmffO63WLyyGh/99BU4r6EH55q3whPnyptL9EQ11WTIvmRT93szqpxDb5VDDBdWlVbapfcye/weTWuQJjIk3OX1gkd7OJmwLuK28pO18Wcr+9Fe3ttt7VwIlQg6nA6UsZAIqtkMWZ1OA4tt5kC/6PAJIBmH2myHrrow2LHqynewsLJ0LIzRv3xDTuY3CSKnTRiYsk8OiZ1jByoOzBsMjLI2AJPOyIpQ1HZxQ/vl7OfpsMDVwvZXb8yPqTBXv2cCFUIIdaZqOTiSQCF6FKhDhfdOkRpfiuxLxaTJUOZzGhsKIBiIIamJ48/uv+IXu+7Fi5MvsscjhwIVL6RxguFkBG96+3pErjiEmCkoh0UWA73nrBc/S9mXyD6tSTwiV0DrEGQ/MInxh34A7ysPIvbKn0o/boVkX220wCzmAwfTmfaGeLw42Y8IG78hz8ZfCpKN35RMckKt1sLQwp0b5YIWaQ+9yB1Bt1zSgUvX8GPcy3uHEMprOaDMD0JbvQ0OCz+u+PJ69gk6V30e2ZeU/ZmPw8MTQdayYTZo4BAFBQUKFChQ8PpCWqGk0kWUfcnaL2z8Go0aKxdWF0xTKYVLN/BzhjadxpNb+fqNEIrEITW1KmRfgYJ5VPbVJaz7pzoGfMOySs0suHMAi84szwwfDo7iTwceYddXVy9FjRjlNRuQbYns1ZT4nY3JIa6eW9RB7BpKIZplAR4cD6D66nex4aOhI1tZ/zjN5l5pPogq7ST8aSOMerUclCKT/YkQXLWcePmDWQn/KjULPSN0VpUO+JJS3qXwQwmGOk4S4hNlkv1eieyf3Jgwycaf3bOfeezyCgnH3N1yv351raWsJH5pzBlZ+Iv9vUqjheGq90FjdSE+3o/4Lr6vGCUbf1IHfySEr7/wQ/z60J+xpX8nKsFxLw9RW1azSLbwlwOj1oAmOz+xdk9lnCLT4bmul9mlNDlCgjRyjwIN6xv5+zc+WjyR31lE2e8+xq/7nWOAOo2nT7yIbYO72W03Lb4Sy1ydaHc0swkYLw29ym53RzlxnE7Zl1R96IzyuEqJ7BMmxAg/SdlPnHgV4S4ebpgaPCy3ABRA6tmvhOyLNH6y3KvFLOF4CSt/JqCvXBs/fx06H88cMDYvll9vudh7fJzZ5ulYcc35bVjQYEF7gw2xRApbD7mL2vhbiewLIp4/eo9tj1D2UyEfUtFwhuyLCQjTQerXb6gylfU9VKBAgQIFrwFU6ZI9++msjBf1LI7bVtFmqoUKHuZozeTYaCQbv1Mh+woUzFvPvuYUVfa9Ed+0AWelRoWdLNrFeL5nB7ZgS/8OtiC9vv0yzAc8o3wRbzclsOUgXzDXieomLYr1dW3QLLmI/Rzf9lek0ymZqPhTRnmsCaFRsvFPhOFq4iQnENXljN9bWr2Qqb5rGwrHK0qoFsp+fiK/oY4rrQl38bCzfMiEfJZJ/AXKfpaNP9rbXxHZP+ruhl7061eX2SccFmSfwvlKQWV2oOb6D7DriePb2HttMGrkk+arA/vR5eHvw/6xwuT+bJCT4u8f+QKeG+DjGY9N8er3yjqe91AJOkQeQ7dnZrJPrTA7h/ez/eLSptxAtZFBTv4aWxxwuAyMzNIceQrby4dTzy3Z/lgQsWScFQSOHOEW/kjNJO5e+kZWiCAscXawMZj03XrDsuvYbS8MbkMoFsZU1Dsj2SdLPkFFIT/C1p9N9sdlsi/cAWHxOyqapFMIHt4yrbJfbs++xmSTbfyBWAg6EXIUj01v4y+7Z18o+7rJ4aLtJOXgSB8/rqxb5ILZqGPv+bUX8KLOlgMZ904snmSqu2Tjd0g9+0WUfbXBDIiCCKn7UgBiOcq+1K/fUF15gKoCBQoUKJgfyHQ+rSko6KezevZnA4NRw8ZEE/xi7C4hJUbV6o0a6IVwdSZBIfsKTpk0fvUp2LNPi/5/fOw/8Z1dv2DhYZWMCjtZtDt50vTeicPs8oZFV6DVxsPy5hpTbr7wtZjVONLHidVbr12aM55Kv+Fmll6aGu/F5LP3IB2PyGTfmZWEKvXse4NxmMSIxGDSiriHEy7Cxy/8O3xp4yfR6miakeznK/tG0Rtfjo0/EQohPsqf19J5cjZ+uWdfKPupRAIxygNghYSZH5tOWntGDuYo+zPeJ5VCpP9wWQTLvPgcniwb9iPcs5+RKbUQX0eyWg+OTkyfjr97+CBGAuN44MSTODHZixPe3pwe/Eqw0MUDHaVCw3TYNMgDBjc0rUJdXr/+8IBQ9m1xxJ7+Caqq+Avz5M1iJ9BIScm5Qi0EQ0MexPxASpXENRdswAUN6/CVa/4Ftyy5Gm9bcqt8v41t56Da7II/HsSfDz7KlhJUFLCLdP9ikApeKpNwsIQS8Id4KCVh3BPOsfGz6856uC67i10PHHip6OOmBbkuN42fK/t88eOPBaDTqadX9iP8diMVhCog+5qxwVmH80nvRY0jQ64vXsO//70jQdYzSTjWP8VaIGxmLcsByZD9QmWfoLbx9zY+NYKUcFqoyyH7o4LsV515Ko4CBQoUnO5QpVXyqGkJsrA/SzOWSqWCTkybCYlzSjyRgkY8sNV+ZrZ0KWRfwesKHnAlBfSdesp+z9QAArEgmxV+eIKPWMvHoLDx548KO1m0OTL92TRa765VGWIy1/BO8YNeUs1zUGlEyYZlnFSPTIbYwZCrx+/nf//Kg/zvVVpEoYM9i+ybDFrUCBuUX6iN4bQZUycyijK1O9B0gOkg2fhLKfvxMsh+8AQntobaGuidsw/ny0njn5pi+224fwDpeJw5UoyNM3/2Pf5BjAfdMEVsZSv76ckB1hdONnF93fRp/2Tnty7n7ovAgRfYpd6kkhP5JTW73zvEililQIo4IYU0vvHSjxFORNh9KTF+vpR9+o5tG9nDrt+85OqC30s2fuvEdqQGDsCp5T97JjI2PMJQ/xROHJqUW2BoesUDz/LWgLjLh1tW8ZGdVGR61/o7US32MSkUkgoAhMeOPitP15jO4h06zlsiVFZe1BqezH1fJ7wS2c+EN9J3yLaGJmGoEOk/hJS/yH4sKfvG8gqgZPc3Scp+NAidXj1tz37FAX1imoPez4tG+mpeiKwEksuhKmsxRceJWpeJLeCO9vLHPtjN34/FLTb23juEa8gfihUd06cSZD/hGa2oZ39wXLLxK8q+AgUKFJwyEOdcyjZKpHLzXDKhfbNT9rNbHCOiMB+JJaET1QObsPmfaVDIvoLXFTQWjZLST9WAviExBoywbYD32maDSF/Gxt84LzZ+wrvW3Qmzfv4UKG+AHzh9SZWsuJGqZtCp2QJ7RAT4EUnRrsyM7Itp6DNTFQRckf2WMDoVht3EK7P3PjSFSWHPLQdSQJ8n4mV2bAmmxkbZQk/K93QIHD8xJ+F82Tb+VCyGVDiMwPHjFYXz7Rzbz7c/ai9b2ad8BAIF8KnKyIOwruLhjTSGj4LjDGaNnMj/hmXXsveUyjnUTjAd8ZbgEcF6y2sXzSqPYoFwp1CRQ+r7LoZnTmxmIZfUN7+yLuMgCPpjeHVzDzxuTjbtQV4wcqg4IZyc4I9JqfPbXxrEL773Ep59pBtVh5ZBlVLj8MFRjO/m+8i6c9qnHRVIuHrhxTBrjUim+X2mG7tHafqBfXxChnbF5exyOM9pIPXsa8w21NzwQeg23gXzog3Q2quhbuQZEsmuHaUD+kR7QDnKvkUE9NE0A+1Myv4sbfwU0Meez1x5er30XlTlLaZWLKjOIfkHuiSyz78nNkH2yc0ZzAvyI6hEHkJsvB+IBMrq2WfHbcnGryj7ChQoUHDKQOLzjOync89hMsU/iZgVs1ivxsIZsi+tbvRlhtaeblDIvoLXFYmAWJxptVDpX5+KGo3cKpVQnk32tw7uLvg7X9TPyBEdd5psPIwsEo7j/t/twu6twxUnn+eP4rqm81Jc0XwhLm47F/OFRDyJUIwf4CYS/LK51spUNWkhLC2MCbrzb4OpYw27HlRxwurIUvYJrWKU1eB4EG+6sQZmdQBTIR0jYxOj5RF+GvNl0fHnd0cyNnT7iuVMTU9OTcF/+EiZZP/kwvmkSQCS+yTp88F/7Pi0hYREMsFUcQK1gOwaPwA1vb8xflqprp1Z2U+N8u2n0TDlgBLSSWUmN0Cyf798UjOlLLhpyVXocHB1/qi7uEtFUoYJLdZM8Wp5beX9+gQaqygVbQYCmQkP2aDvyJMnuBOBtlFS0jc9cRS/+8lePPZXXiRxVhmg8XMbuS3G2yfcYyEc3DOEX/9wC3Zuoe8bFwVUwzYsPHgRhjZTAoAa0QY3brv24hm316gz4pKmzHetbpp+/fiuR1nfvXnROdDUdeSQ/WZRyJHUbIL9nOuhW5HJ3NAuPI9dJrq2F74nckBf6YJQMpnCzsNjCIYT0Bit0KfT0IjjjTSNM1akZ58KI5R3wF5vGQubWCLGCggEExUUtHqotfpZ2/ir7LnBfisWclfEwe5JVlg81DMpK/sErUYNi9jO7BaJfBu/FGSpoikRRcZ5ZsMTiPEFnlqFWmdlQYMKFChQoGA+IZT9lArxLKGHkE6dPG212ribKylax8LRDNmXXHFnGs7MV6XgtEEiwBe1Wisnl68Hvrfll/i3V74jk5xsDAnVnuAOeXJ6j0ltfrF3G7teZXTCoNWzxepff7cL+3YOYtsLg9j+cma0R6Wg9+OD576dzTav9L0hAhUZPIrE0ZeREqPYSsErhYghjr4AX1TXV/HFcr2wuErJ1Wy71BrU3fZJ2M+9Ca/oLihK9utEkWB8KoSWtStwg/1hVGkmEA7FsfPl4qSvGCSyRW0UTx7fhAe7ngZ0WlRfyAPcxl94adr3wH/02Jwp+wS9k9vDE5MeuLfwHnP7yuK99P/+3HfxhVe+y3rkD00chy8WgDPBVUyb3TDj2DPW4iIp+3lkP5FMoWckUFBMUqnU0CzkZDV5/FU013D7+AbHWlY86bBzsn9kmr59ycZ/adO5uLB1A5t5f0HLeswWLSJnohTZn4h4mPJPSf8XZRW19u7ghL6p1YGrb16GGy7P7GP2OG8LmBwP48//txMDvR4WSnf7O9bj5rcsgVqXhinkYETfU9OPq2/shFZTnjPhsuYL2GsmNJQg+7GJASQFSZf677PJ/voldTlqdjFoOtYxVp6eHERcBN8V2viLF4T6RoP41P+8gC/+7xb8/pke1tuvksg4QctJfqKIsh8Waka5yr7kyKCyiSGdhopC8SpEKJqQe/ILlP0O/p040jeJ/rEQG8NnMmjQUpt5HurflzIR8qES4YcJ7xi7JNfETMfLETcvwjVUW1gxQYECBQoUnII2/nhuMKu05DkZumARIkhStLlF4kmZDOtFuO2ZBuUsp+B1Rdzvl8n+6wF32MOS7omIHZ/sLansO0TC99aBXUil07hv30P4/JZv4/92/yVHBSUr8fFDY/KB6Im/HcCQCLybDlQkePWlHowNl29zLwYif54X/ojIff+GoV9/BrEXfwfv1oemvc/kGN8+qyaAkZiZkQbqoyU0CtJO4/fy079rrn8fDka4myG7Z59Q5+IL9TFPGFqrCxaHGWtMvA3CXyRBvRQkG/VvD/8NP99xL57u34zj7h7UXHoJu9398stIC2txPkL7DyA6NgaVQQ/r4pNX9gk6F1epfS9uRsLng8bhgGvD+qL71VF3Fxvl9l8v/RgPHn6K3b7UuLzsfv24e5DZklWkpNbw3ncC7X9f/uVWfOWeA9i0iyvd2dB2csU4OXAAZiPfEc1prhBLZJ9GAJKjZTobP41//MeN78fXL/40Gm2ZnvNK0WLleQb9/kzhLBvHRdp/u62ZFcwkt4lnkhPet77vfFx81SKYwpnXalX7YbdxAlhVY8HGKxbizveswKr1zWhqs2PFG80IWTyYqO+C64IolleXX+yhLIk7V94Ml8GB9Y2riv6N58U/slWHecn5MDR2FpL9pfz9mvJHWd5FMagMFjmHgVnQywzo++tzx/CVe/bjhAgtHBwPyQ4AKZEfWr4iihUj+0FO9qnYRHOKy7bwq0VXo6HyINVJ8Z23mXUw5C2m2uptjNyTuvLsLr6PLGuvYqq7BKsIVPJnFSrye/YlSGMOp8OoyFZoKXMihgIFChQoeB3IfiJvvSj37M8eVml6VDrNpr9EspR9qQXuTMOZ+aoUnHY2fq3t9Vl07Rrn1k/CRCh3lBtZV8eCvH/0ypaNMtn/07FH8JeDjyKSjKLGXIXbV9yAtyy+mdmJd2/li9U3vX09OpdXMRL/9INdmBLEpRS2b+7BY/fvx+N/OYaYUMBmg+jgUXhevE8EVfGDYqSX26BLYayPK2J2jQ/+tBFOmx46rSZP2c8l+xJ8wlbrzBq9l032xz2CtNQthEkdziEb5YAC0tjrSmYO+DQ/3bFmNdRWK+JeH8JHjvLXOTaGpCgesaLHI4+z647LL4N2jiY9SMp+cBef0W7beAFURRTjw56Mcu6PBrBrmH8GjSqew1BTBsmQbMnMmq/JKLCPbR3CjsP8M3t571DB/dRVTdAQ4aHxe2lO3IcHAnj0L/vQuy0Ks9qMSCKK4SB/jHxIDheLls8fl1Tu2aLVOr2yL6X9L3JmAgg9pLymeYCcVIVPuTOEWK1K463XpvHW96/CR//1Clx76wrYHBk7dmtbDbpWvoyR9kN4+9o3VeyMuW3FDfiPCz+BWkvuVAC2HbEIgof4yDzXpW+Rbw+G45gK8H17xcJq6LT8OaeKjIyToHPVy2Pj5MenxY1Y4FDwXjao6PbrRw6yQLvVnTUykaaCEDRamEWGRVrDjyGJIgF94RB/bHPed7YUaJQfwaTSykWKmZBMpVnCvhSo5/Hz56x1FroCqODQ2cRf59aD/Hi7cmHu+z6tsm+289cvQMr+TBie5Mq+QvYVKFCg4BSDOkP244lo8YA+1cmTfY04b4eze/YVZV+Bgvm08b8+Y/d2jh/IselnYyLsYeonjfLa2LgBWrUWw/4xbB7ewSytb11yC35wy5fw1tVvhE1vwZbnOcG78PKFWL2hGZdf387mglMY1jOP8PFpxRCNJLDpSUFYwwlsfbF0eNpMCHVxEqpuWYm6d3wFk4kqhAeP5cy4z8fYIF9gWwy0IFehJos0ycr+WKFlnKzk0uK7UNkX4/cCMUTJIsXIPicNZOUvlqpdDOsbV8KkM+KcutVycNtUxAe1VgvrhnXs58D2HRh+9HHs+H8fRd8X/oP10nv37EW0u5v12Tuu4QnscwGdy5njJbNfwtPv83FEkP2LG89hBSGCVWeGKmgoO5xPIvum1kybwL4TE3jgJW5vJ+w9Ns56t/OhtfDJAxY9J5/eyQhrKdm/YwydQa5Wd3n7p7Xxk+1/LiC5XqgVI1QkpE8i+52OLLIvgvdcNUaZqEtkX+Xi49q0vn7YXZnfZ2N5zSI02xpwRfMFWFS9AHOJ6EgX69VXmZ0wNPBe/exWF+pJJyXaJYoUk4LoFoPOxV0PiWyyH5bcPSqojbnk+P7nj7Ndb02nE194H2+hoYUKLVioT90sbPwpdbKksh8SBTqTSCSeCSGRxG9Sqcsm+798cD++fM9+PP0qb3ty+/iCTZrSkY9Foj+figRSsSQb5Ago1bNPrStaZ8Z5wgpdM2BEUfYVKFCg4NSExOdTqkJlX2b5s2f7BiM/n6ihQiAcRzSWYtcJ1A54JkIh+wpODWXfWnm682xwePy4bBse8Y/lqI35yv5YmI98o+A9k9aANfXL2M9E9D96wbtxUeM5UIsFMGFKBFAR0SdodRq84a617PqB3UPy+LB87HplmBFgvYEfZKhoQAWA2SDcxceXBWvW4bd/GsGjvjfisH9hgU04G+5RTlLUJhEclxWgVcfIFNgBMSASvCVIc69JmbMK5U2CxaRjSf6Suk8BZkYVqWlpRlZCwfKs/CvqluDXt30H715+OwsszE6It57H+7v9L7+Crp/+L5vqkAqFceCL/4HuX/6a/a7+umugdZzcyL1iyj6B3AW62sK0dgrjOzrFyf559Wvx2cs+hqU1nbh5wZXo7+EFpfomnjReCmy0Xx8vRBnbuPWfCN23frudvX9XnNMCs1HD0slpLnk+pBT3tpoYs7gvX1uLjsWcBNmCfJu7fYX7BLUISLZtsvHPBagQJo246/FkChXSd84dmWKEXWoxkJV9IvvVnBxS7kTay1tqtIs5yY2NZ/Iz8mE1WPDdm76I2xfdgLlGdEjkKNTmjkLsF3PbW+v5e+8S3yPPNG0rWkH2aUa8hJRIlCdrPhFZCb5gHM9u55/Z9ec3wmjQylMwqF2GeuklZT+hjpdW9sV3z1Spsi8UlfyefY8/gkO9XrkYSE6GR1/uYdf3HB3PVfZFETAfi5szx3+tRoUlba6iyn7+MSi/aMLuXxbZl5T91+a8o0CBAgUKyoMqS9lPZLk6CWnpPHQSyr5B5CXJyr4S0KdAwWtF9udf2Sc79Zee/x6+v+fXeHVwD17u5yOvpJFi+cr+WIgr3o12brV9w7Lr0O5sYcTzsgWccEggdTXo5+TX7szMbSZS17mMK7vPPV6YHE/2/v07uZ36trs3MCWT0vz3vpqZAlAuaFxXdOgYeqIdeOAFA8aGOYk/ElmGSH9pZ8Gkjy/SQzqucmUr+3qdGrXCkp8/Q3zSxxfMTqsB6rwjL5G3avE4jIiQtVxvEIQfCIj3qhxIyq3L5JCVfYJxUSf0VVVcZVep0Hb329htyWAIod4+QKtF821vwlxCVvbps722cB48gUIcQ4kIcyS025vR4mjEl67+JyzGMoQCMVY5bl3A94lSoLCxpH8SUGtgaOaOBkpen/RF2efz0TvWYnk7fz92HSm041OmAkMswCzul17Xjkuu5rkF8XFtSbJP0wNoNB/BrJ27kWSSuv7oMT6/XsKhMU6cFzrbYNQaiij7fBtiY73sc9ZYnNA08aIbFbBOZtrFbEHfMYK6Ntcx0C+KZtIkCimIbnKafV1XJcj+ZBGyn9evT/3s1P+/tM0lk2OpXWZ0MsTJvnB5xNWx0j37ko3fXB7Zl3v2Jftk3oSA7927C9/542Hc/zyf8PD09hHm+iF0DfHCHO23hNoSyv6CBisj+YTFrS4YdLnqik307EttQ6WKJuWQfQoKlIoPzYqyr0CBAgWnFFQ5Pft5x3zZxj97tq83ZMg+CVk0mUUiw4qyr0DBvJL9+V907R09xPrwiR58b8sv8NSJF9ntl7SdV1zZF2RfGqm3om4xvnn957ChrjC0KyR6dTUaVUEv7DkXN7FK5bGDYxgZDOSMwKI+/VQyzVTXJSvqcO7F3BWwb8eoXDwoF8nhowgkzNgcvAyJRBrtnVU817b4AACkFElEQVTQqlPwpxzoO1xcBQ0Hoogk+EJ6IM3V5pq8UVQtYkTcqFDDJHjE9uWP0pIgOQRo5BYl+BuaF8Mo+vYDolBQCZxGiexzAkGz7VvvejN09fVY/tlPo/Utd6Lx4x9ho/kI9os3wlAzc/9uJTDUcCKhNptRfWFuwSd7PyOsrFvKEuYl9HXx7W5ZYIdGO/2hN3Schxmqa9qh1vH38WAP3x/Jwk2q7soFguwL9bSYsp8KZaYoNLc52fkx7E9AFzUyRT0Sz/0cgsKyTcRbK4pgc4E7VtzEXDDbBnbjlf6d8u2HxjlxXl6XO9rP484l+9Fh7pTQN3RA5ainD5+R4nSouFtmPlFS2Rc2/tYGoewLsi8Ry2LQOYWN3zuOdJKr1smwpOxb8c17tuNb9x3CAy+cwPO7RFHwykXyYignGyPLxh9X8edMxPhY0T//3w48ef9xpFPpjI0/r/WmFKR9wiQIfLaNn0j9vhN8v/y/Rw+ywtPzu0dzMgYi0YQc0FfKxk9FxUUtvJC2oqOwECY5hwIlyL7OyY/R5fTsS2Gj5IqwlVnwUKBAgQIFr7Wyr0Ikr/UvnRbtZCdB9g3GQrIvK/tKQJ8CBXOPhP+1I/u7h3kPNAWO0dg8UvKJjN24+Ep2O/2crRSOhriNv1ko+9MhKBb0FrbAT8O380kkhzmRcVYZse68Fnb9lef6mZpPaeNPPdjFCgB0YLv21uXs4LVgsRMNzXZmvz20r3h6eSmkBg9hLFGPNNSobTDjnR/aiPZWvqA/1FV8kezp5bZqizqIEyFOHGryyLvU1zoo1Fb5vpKyL2aW5kNSNqWQPmPzUrlvPyCUvkrgNPJixFQ4M92g4Ybr0PafX0DV+bxgozYaseLf/w3LPvtpVN95+4yPSSPfNg1uxdde+CG+vO0HLOl/OjhWrUTLnbej/n3vYXkAxbBvlLsopLaPfLLf1jl9WwGRPu8rD7Drmo5M0j/NIScsEqruCqHsH+nzsHFlxZT9ZNifU82uqeefcXWEt0QM+XNdAaFEWLbezyUWuFpwTSufc/+LnffJvfuHxjlxXlGbmZZAAZV+L/8+VVXzfSs2ynMsDA0LodLqoKvi25/2lD/GcS6QDvvFiDdVzoQEwoib99o31VjylP3SZF9jcwEaHcsAIMKfrezH1Ua8sHsQR/p8+PkD+1nLRmONBReu4q+dUCdGZI56Qjk2/phw0MRjSXg9YRzcM4ye41MYHwtkbPxlEt1j4jtRnSgk+wPjIZZmLPXb//vPX0E0nsKCRjsbx0mH054Rn/welLLxE+68ajEL6rthY2HGgl3q2Z8DG78UNqpY+BUoUKDg1IOkkZCyPxyYyP/tnCn7amHjzyH7irKvQMHpq+xTL/LuEU723738DmbHJyxzdaLN0cQOH6T6+6KZNPfsnv2ZEJDJvg7eLQ9g4rGfIvr0T5EWFqTLrl0CrVbNRut9/2vP4Sff2oTe41Pstuve1ImGZk7ciPC3i3AqjyAP5YDNZB84hIkE78dubLGxXvol67lToMtXj0SwcASgZ4CrcC5rAhO+RIGNP3sO9vbD7pwxYhllvzjZz9j4OcHX17fDpBLKfoWuhWwbv0co+6WgMRhQfcH5Jcm4BCrufOLRf8dfjj/O0vIpQO7xY89Pex9K3m9/590wr1pZ9PeUcn94gtuZ1zRwhwHB741gYpS/D60d05P95PGtjFCSZV277BLZetwjLNES2af3t7nWysIOD+eNd5Qs4Kkssk+ob+a3V4Ulsj9adKY69bzPNa5vv4yF5nkjPvz2yN/Y+L9B/wj77i2ryZD9cWGHt9gMMAqSx0LxhLLPLms50U55CkcPzidS4zzvQ1fTDJU+l7jSmD2CS3wfJMeLpGoXA/XkS6PjpER+SdlPiDYKk17D1G5Sv99904qckXRSECZzz2Qp+xEIsh9PYWwksw8M9noqsvHTFIz9oni1LCJaArL2jRPCqUT7JBF5KXjzjqsWo7WOFyJO9E/J7oZSyj7hglWN+Ne7V6KhunDfk2z8xQL6CPpayntQQWVxQq0vfjzKD1JUwvkUKFCg4BRW9lNqDAcnitr4yxkbWwqGHBt/jIXcKjZ+BQpeA7Kvm+fRe0PBUUYyDFoDllctwucu+xhuW34Dbuu8HlqNFja9Nadvn/r7qe+awvgarTPPGA/6+SLUrIth8vnf8xtjYYROcDu2w2XCOz+8Ec1tNmalnZwIMbvQ2z9wPto7nUiGfBj549cQP/AcHCIBnxS5ckFp3umAGxNJvq21jXzB3NxZC7MmgljaiN49mXFwEjxi4Wt3GpgyR0SCRu9l4/yVDXDZDPAG43hl/3BBzz79rhiq7ELZnwrLips0fi/gr9zG7xLKvjfqZyF4JwtS4KnA49DbcF3nZey23SMHis6f/+P+h/CdXb8osL3ng2zpyVSSzWjP3m+OHeIKelOrA+Zp7NOk6sd3P8GuOza+SR4p1jUUYOPW6qvMsj2csH4pL+4c7MktgGjM/7+98wBv67zO/4u9AZLg3kvU3rIkT9mO924c24mz92iTtEnT8W/Tpk2z26y2aZy22Ymb2LEdO3Ycx0O2ZVuWLGtviXtvkNjz/5zvuxeDBDclkdT5PY8EECSAC+ACuO/3nvMexzhnnyhWxL7R48gu9qNyQcI+z86+WlHzsa3vEu+pIwOn8HfPfl1cXmIrylhc6OuWnwkFRXJbE7FIMoyPnP1MsX9+nf1Yv3S5TaWpxYnUZAplDKXdNO0yfkLrLMgQ+0lnX2dJttV87c+uxH/++SW4fL2cRDDO2Vd69i3K+yKIQNLZ70sX+63D8PumX8Z/aqhJvEcKrHkoDATHBfSd7ZS3vabWhc+9cwv0Oi1K3BZcub4UFYXyNX3zZJ/4bKFjM/cEC4NTkSzjD0SzTvLQuwpQ/Pa/g+n6j015WzRZhKCFMoZhGGZhoU0r4+9UKmwJeWw2d2ffpJTxUwL/KE2MCkWhS6bxL01ZvDQfFbNgScRiOPL5L6DrP78v3OjU6L1ze+B1fFCWC9P4NhIdORYX3rHuThRapWtN4ozoV8Q+OY5Evi0PxrQZzlOV8Zv7j8ixXIq75D0qcwGIiupc3Hrfcnzoz6/AZdfU4Y77V6C6Xrp6/c/8L/yn30Dk9d/AlpDp6lTuP138jQcRTegwFJUp1oWK2Bfufql0HE+fzBR+hMcj3TpznivpvKU7h4SBqg+2y/7kJ19pmtDJHIvbkQroGyv2yelWoUBCGjk4FU6TQwhF2m/UCoy5TmYgLilah/dtvAcmnREjIS+ahzKD67wRPx499jSaR9qTrv1EHOuVrRvLc2syespOH5eietmqyatERg/vFIs25Oo7N92QvPyM4qCuHNPPvGm5XFA42pxKQ8/o2Z9A7Ec9emijenSOZLaKqOX1813Gr0JTCT5/9adERU3ystzU+DpCdaILld5336k3AOpnN1qhd8nHayiUyf2JoU5cCGffVJIp9tURlPTWUfvA1TJ+Kr+nvvWJ0Chl5+r4vbji7Ic18n1lVaZ0ZCOjZ5/EvuLsB5Jif2Jnfzpl/McG5f68qXQtEJSf1RqzfZyzT+X3tG/+9/+7Dn9z/yrodNqks3/glFzoynNZxOWzwW6RB2e0i48q2z8Wa91GaN2piQ4T0dItq2DY2WcYhlnIYl+LTiU7iyCThy4Tv0vLQ5opxjT33ku5VWrV2hJ29jPnZTHMOcbf2gbPocPivK+x6byV8atif0NxamZ5OiT2W0Y7REhfpbMYnSM90y7hTy/jt0YHoM8vQsFtn0DXz/9RCHjzlrsz/ra0Ikf86+5WynZbjyB0dJf8ZSKB+KFHqag1OcpvOgSaDmAo6hb9+lT+bFdcdWLN+nwcaIugrd8kDvTVg3yqJvCEpKCICsHRKpzjbNy0vRoPPXsKRxsH0NFXiuLiaTj7Lnk/A8MB4cbpbC5YdEoa/7AUDiOeAP7zqzuFA5mTd1JMI6ip9woH3GDOTBLXarVChI6EvRgKjsCC6QWMTYQq3GtdlaK6Y3lOLQ4NnMD+rqO43L0p+XcH+o4hprj96iSAiWgckmKw2inbRIhoNIbGU3J1etlKEqvBCV394Vd+I867Lr0zGcxHnOkYzWipUFlTlw+jQYd+TwgHT/dhQ0NhZs++PxUISVjtRuS6rRga8MPqzZ1zGT8t2oiFrlTL9JSsKVqB/HU5iNs0ONF3FrVG2Woytoy/oNiBRDiAgT/+UPysX3VVcgHFqITjkbMfDwWgNc3f5ICJoMWUpNgvXabIaWSkxNM8ePVAxWLSwWLSixYMqm5RR/KNRZN09uVrEVdEdVAR+3QbE6GW8VNVQVRnhinp7PtTzr4ylYMg4a/OGLaIFonYpI+XKjCIjfS5GX5Ybq+yb/QPB0QvPj1eStNXFwujQbm9lUXy78JK689ESfzTgSoG7BaDCFPq7PPBpVRPzBS6vjoicex4P4ZhGGZhjd4bDPsQUCoqxXFYsox/9mJfq9OK+6AqW58/glBIfg/SZRSyvRRhZ585r/iaUs7wwGu7EfP7z/noPfqgaFTGjG0oWT1pibjq7KsiaLpiX3X2rVof8m/8EMyVq6FxFSIRDSPWcnDC65FQCb/6oDjvWP8WwGyHaVguTNCYNgormwq6j0DjQfTH8tNS11MfWOWrV8KpHRYLAc2nU8ntoy0n4Y1LATKqlcJ8IrFPB/Eb6uXBsZq2PVXPfo7NKKoEqISXZm9TIr9NKR1W0/jbmoaEICGGBwNoOjWE5586gZ8/8Doe/vExMbEgHbXdYigwtxT20bAv+RrXKvPdqb2DONAl59ur7OuVi1NT3S+Jo0alKqDCLsutQ8Eonnz4sHiMVDZdomQzZN2mwy8iOtwLmB1wbroxo0S8scubNamchOANW2VJ+29ekPvNWGd/7Hi6SuU2SOx3jfaKPIvZlPFTm8l/feNFPPSjoxmVGqMjQfR1T503Qe+ta2svyxi5R6hl5wVFDkT2PSFGENJoNcP61HNiyC2Czp4LxCLoevCLSYF8LokO9wAhH6DTw1SYmcQ/opTGO9NK4+k9qPaokzCeCK1DFfuyJSFC90Pv/4QpuWgwEVazAVaz/P1oxACT8lqGEEr27FMoH0ETIOjXVEkjrjtmashYWobb4QmPioqXlWLxStlPlDL+Ey0yMLKm1AlzFjekIMeUcflcxD6xZaX8LH5kp6w2mA1qJUJxnnnWCwYMwzDMuUMV3MaYPFWP1WKJWNLZT6b4zfY+DPK2yQBTj0H1Bu2cUv4XMiz2mfOKtzEl9vt2vpg8fy6d/SO9J0WvT7G9QPzLRo5Sxq/27Ld5Omcp9v3C9aMPDH3tFnFZtPGNrNdJxGPo/8N/I+Ebhj6nCO4bPwjj9rfBqA3DoIzOmk7ffqzjhBD8/YmypNhPx1BQjhKLLIU69YYcC0f0niZnWwOTPoZ+b3BSsU9cvVE+F68d7cfQaDAtjT/7QTM5fm7lAF8NKXPkyNv3KuJIdXFrV+Ti3R/bjm07yrFqfYloxxr1hDCSJiIJlyL2p3LYp6JxRPaAV7hKYTVYMsT+qcGmpMNNaf1nPamxhZPd72BwWMwk12l1KLYV4MyJXvz6f4/g4F458WDjtuLkinW2fWH4FemcGtZdl+HqN3V6EI7EhbOpznBP566r60X5+IFTfTjTPpzRs0/97olIZhhiRY1ctLGN5okANk8o9Zj8ygr6VGX8tIDw1COHhXAMh2J47ikZ4hb0R/A/396FR392HB2t8r00E0LBCEaG5TY40YfosZfE+YKbP5rMLyBo4aj4nr8Rpf2hjpPo+uU/IUFC/BwS6pQi01RUIyYCIIuzr6bGjxW4k4l91dmnhZ64pwehjlOiH7HHJBcUrEp/4USo0zOGInqYlH72mC61SBiLxkVpYkWNXNBUmaqMf1+nXORaW7QCunCqX5+ee+J4sxT7K6rGj8ojtBoNakpTi1uThfNNh3uvaxBdlbuPdOOssp/PlNNKhcyyck7iZxiGWYiQ805YlMKzDqXdkPKQqI9f/s3cyu31enn9QCAqjq8Io3HpFruz2GfOK76m1GizUF9/clwapZyfK/Z1HBKnG4qzu/pEXrJnfxDReAzHlRJv6jGeCjqY9vvkwbXNkhJaujop9uMdJzC8+3H0Pv5dhF95EIHWo4j5PAg9/R/wHqYFDw0KbvmYEHi62i0wV62BXSsPSoeVJPtJ779VPr6BuBTjZWnlqeTaUm9T7Qr5u+bG1EFyb7Nc0MjL0aNvaGqxv6LSKUZq0Witf/zBa8lk/ol69tPLjAeUUXv2XCnWIxFZYtyvlNQWFttQsywf67cW423v2YwcZTvGLnY4k2J/bs5+oyLgV6S9vnlmF8qdJULInhySr/8rrZkLNZNNAmj1SmeWpjvoElo88vP9CPijcBfY8N5PXIo1mydeOIqd2SPEHrU66FdcmfE7deQe9URnS6Cl12zLClne/4ji7msMZkCrz9q3X14txZnFlyPMWnXE5Eyc/bMnhsTYSK2yAn/ojXa0twxh5++bky7/npcnH2OYjV4lnM9qNyDw+kPCTbav3QFLzbpxf0sheeZbPgWt1YlQ11lE3ngc54pEPI7Rg88n73cs2Zz99FFzakhlNjRUoaDViQW7yMFnxGXa0hUYilun7NnPSP0P6qBPANpEAgltLJljJLajyI6i0tSCKu1Hxilu982uI+J0U+maZGigLq1f/4Qq9pX9KRu1aZUsk43dmw7UBnHJSrmf/98fT87qNs60j2ZMtGAYhmEWFupxhSWqyRT7lIeliP2JjJPpYlCC+ILBCGKq2J9iYX0xw2KfOW+QiFLL+HWO1MGW1jaxwJwrNArt1bZ94vy2itTM8rHkmlPOfstIO0LREOwGKypzMtOvs0Fly4QWMVjyUkJb6yqCsbhOBPYNPvcTIeyjJ3ah62f/gJbvfhjxrlMiyM/4lg8lxQxVBFhr18Om9SZL2yeDHOFY62EE42Z4QwZxgF9W6UIoHMN/PnwQn/rOG9h7rBsrrrkCGsThCZox0Nwix/T1Sie0oNyNnkF5vihvYpFH2/Y3771ElA03dY4kS4xNhqkDxFSxb8l1QwcpjCgVvE8R+znuTCFA0wsIz3B2sT/XMn7VrV+ZNt89vc3j+KAU+7ta9ibdTbE9kzj7baNy8aQ2twrdnT7heputenz0s1ehqi6z1358Av/T4rxr+53QpLn6xLGmgaz9+unctFWO0nvlYAd6h4LitdKY5WsZ82eK/bx8+Zpo4zrookYxclBFrWhwTNKz7/eF8erz8vm78rplaFgjt+uX/70HrY2e5IIEzXafyYjFaCSOPz4hx2PmF1oR6pT94q6tt014HQpkK7hZJrDHulNtDPNNZO+jCDQdoto/ODemghPHif0xzr66/1Na/kSQU05p8urYRULfcKmY/zsdsa+OyuzzyzxhI7n7GohpH8ntKHaisDT1mpos+knLFb1hH84MyMWajSVrEFf2IbU9JBSJ4Wy7fA+uqJq49z3d2Z9rGT9x26VlouqH3P3WnplVctA2NyvtJezsMwzDLEzUkGiT4uy3j3SlBfSpPftzMwiNyvdqwB+BRml/U0fyLUVY7DPnjWj/AGI+PzR6PVzXXp28XGs9d/36+3qPCMFfaHFjVcGyrH9z5M0ONO8JCpeTROQxJcyvIacW2mn0Baml5tSvr8vNTCrLvepeaHKKYa3fjNyr7oOu4TI5n5vKkVyFKHvfV6Gv3pBxHWNhFexJsT9eJFBPc6cyVz3YfhIIejGglYFwBYV2tPf78C8/O4KnX2sWLvxLBzrgKCmH2ypv6/gLryD8+sPwxJQE/tL8ZJlxkXvyhRcaV/WndzVAr6y8uqYY31Uwpozf4HQnE/mp9WGgTz7OXLc5u9gf5+w75lzGT/tD+6j88kif754e4Li/7yi+uPPbaPV0QKfR4qZlcn8dDkwi9hVnvza3Em2NUgiVVzuhn2QxhPAeeQmJ0X7hUKf36qucaJbl8CsncVBpzBkl85POe36/ErqnCPax4/eofM2uuMGGkAW9ac6+PxqY0tmnTIWgPyoC9K64th5brywXX5xqL/iNd60W0yBisTj2v55qgZgMCnB8/neNaG8egtliwCWXOGQfvkYLY/7kCeumsgZxmvD0IK6Um88n5OhHj0hX37jjPTAWyoyErGX8Y94P6aPxJsOgfm4kEtCabdBVrkuK/ckC+gi3Iva7fcoBklLKr08bIVRQ4kBBEZXgy78xWybfJ7tH+5BAQoyldFtzk/uQzioX2860DYssDnr/T1YNVFvmnLcyfkKM9dsg25We3jOzSQynW4fENlMlhLpAwjAMwyzQnv240rOvtNVSz74a0KeZQ0AfYVLEPoX00Qg+wszOPsPMnVCb7F22VlXCtinlsuuscz8IJCdqbBAZ8UqXdPUvK9mc1cmikW+//dVBnHhzEA4/pdkn8EbvoYyRYGdP9qG3a2IXaUQRytSvT8I+HduyLbDc/XkU3/f/kHvlvTBd+U5U/fn/ovj+f4D5zr+GsWC8kDEWVsOmU8T+QOb9RqNx/OQ/XsbvfnUKR99shf+UdJ49tjXiNL/Egb/93i50DwZhUsKx1HLb0iop7ptO9SI81I/eqHSDDTaDEIkk4NUZ4ZPRUOHEJ+/dKPrEa0omz1ooGOPsk4Opiv3uDi/isYToJ06fHkC4FGEwYRn/HJz9MwNNiCMhRAyNVkyHnH6X2YlwPILDPbJUeI17uSjvn6yMn/a9NmUBoTavEm1N8u8qayYO5BPXi8cwpCTw52y/E1plZKPK4GhITD2g57qufPLbuvUKub++cWJAiGc1NX1sGb+4L+V1MYYt6Mlw9pUy/gmcfc9QEPv3yBDCW+5eI0LfqOT+6huXi8tqGnKx5bIqrNoopwLse7Ul61z0sZCj33xmWNzefe/fAhdkkCS9n8b2x49F78iVYX2JBMK9M28dmAyqiuj//Q/E+Zwr3gZ9TWpKQzqjEzj7xYoQ7h2aptin5371leIxp8T+5MLcrbx3+kZiItdAFftqAJE6xpAWnYqUcYZTHdT0KeOO8swy/0Mt49cqZfyHzsgForoy+6QVAlXFMryPnJoi9/ws6t5xZa04PdLkEeJ9uqjtMFQhs1RDmBiGYZaK2NfG5fdpt29A9OtHY5HU6L1ZjnFVUb8D6dtV/YY1LWGxv3QfGbPgCLdJkWCrqYGxuAjm0lIEOzuhtc3tIPDV1jfw3d0/wrXll+IjJe9KXt442IJ2bxf0Wj22Fq/Pet1TR/tFzz2Ro3FjFAMYUgLLlufWiv7jX/7PHiGEV6yqgjGLy6YGipGzr80Z3887FurNt9asx4gyem8sOkce7KYIaHrWcB+JxtSCQPPRTvgDcnufeHAfbi/Zh2jMjtNDVEodR0CrQSAUEw7YP3/0cnzky8+ie8CP4dEQKtbU4tDx0+iKlGKffysCcQscLiM0dvmBSm5Xtp7wbFy7pQIbGgoQ8E4ewpbq2ZfOvp6cfY0UPh0taur6eMEwsbOvlPHPoWf/eJ+s3Fg5xtUnDDoDvnHD/8MbjQehtxpEFUCtqRw5yrQG+jmohNilQ1kP5IpTOF9OIg+DfQFRSl0+hdiPnd0r56ub7XBuvmnc75uVRaayAivMU4THbGwogM2sh8cXEeFpdrWMP4vYp+eXeuzTnf1oLCoC+9SAPp8vc2wf8cauTrESXlnrQlVtqq1g21U1olUhQQteGg1ql+diz4sdouql5cwwSkvlYkk2wuEY9u6SIv1P7t8gbqftlFwY1OZljuWbCFNxLfxn9iHU1QhUZBfksyHc3ypCDjX2PFGZ09MjZ8bP1Nmn8ZM0VWEiaNqAimPdNaB3lS8oc0DUtP2JcCtVGrSgpi2wJxP5tWmbQmLfFxhGWVUuujtHRBn/ZFAwZbrYV1tBaKQjbdWBU/J5WF2dGQY6FhoL+c8fuQzdvX0iYHI+qC/PEaGF/mAUjR3DcEzzZo9Oox2GYRiGWRgBfYmEEcZ4HGEt0B8cgtuSM28BfaY0sa8efXIZP8PMo7Nvr60Wp+7tW8WpPnfyA8bJGAgM4YG9vxBp++pMaJU/npWz67eXbxT99wS5jKrTSG7s8YOpEmZnIiXMKLWfDnRpLjWJGxphdfJIdnE+osyMt2l945z92UBiyaEE2Q0rCwkqx/c0J/MBwnEDnu/ejGdGb8WoNw6Hy4T2oBRrW5bnodhtQ2m+JTkmq6jcAb0ugWDCijMh6cTuuKkaZzvk4kZ18cwWXWjkntpbNRGq2BkcCYnnW+/MTzr7PZ1STLqMPsR6U1MaCJO3ecoy/myVHNPhRL8U+ysKsocv5lhcWONuwNU1l4ryfVpgsBjMMCrqKVsLQeOQLFevdJai5fRQciqCeRJRRa5+ZP/vxXnD2uvGufridpWRe1NVUIjb0OuwbY0U1bsOdCTL+LM6+3lyvzCGrGJxixYxvIqrr4EGNuX9kk53hwdnT0h39JIry8btsyXlruRikV6vxcbtstx99862SZP5u1pHxXvSmWPCqvUyIyM+2CFOtW7ZnjIVxmLp9oa6GzGfRD3y80HjyBdBlxMxURo/VcrQQiF95EyWyG8qkp+JmrwyGEvkfpnq2Z9eGf+oPyqqOVRnXxX71Bahtm2sXFciwo9KKyfvWe/zDWYElyadfYsdgVAUJ1qU1pKqzIT/bFCw5Eqlqmg+0Om0WFMrx4weVioMpoIqANQKp7HjKxmGYZiFA1X4EWEYUaCMxaMg4Vgsmizj186xjN+gtLnR/+otZTPzlgos9pnzLvZttfLAvOK+e1D9/vci58brZ3V7VNbz0xOPIhANJj8MQlEpdgORIHa1yhL36+pkunl/rxf/+dUX8NAPjwgR2dI4CM9gSkxb4ilBpQayDfalyuiP7M/eIzrcKxPurYYINNb5Oah1FMkD0kBQptYTA1396BqWgvDGywGjPoahmBuBuBWFJQ7c9vblONQo3as1NXIBpVZJ4KYDXRJglXXyIJmgcuvSSidOKEKsdhqCcqaofbqUHTDqj4iAL7NOvkZUwk+YO19D6MlvwXdChpMN7XoY4Vd+lJxGkC7qVWc/HIsgGJt++JsKOdfH+2T43upCueAxXVKTALKI/UEp9mtyK8TIPaJ+hSxlnwjvkZeTvfr6lVdl/ZvmpNif3kLMFYpYfvVwpxhLN7GzL39nicrH1D3aC68yus5qtGT9In3h90pbw8ZSuAunDtXcdkU1nDlmjHrC+OG/v4p9r3RmLenvaJHPZ1macEyK/ek6+4pADnfL13a+iI4oYt8+sUCkbAKvP5rV2RfjJxWhPVnfPk3gKLr7r2C67qPJKhdfcHpl/BTgp47ni+ktMqCPoGh+qpwpdiRvs7YhH3/75ZuxZlPRzJx9tWff4sDJNrk4U5JvQ0HOxJM4ziVr6+Xn2MFpiv3W7hFRCWA2alGdFhrIMAzDLCzUTKhoQo+CiDz+7fb3IZZexq+MzpstBqXNNb2Mn8U+w8yRiMeD2PCwmB9trZLzo3VmM8ruugN61+QHXyTsvvnqf+Op5hcyLn/0+NNoGmkTrqvNYBH99i3DckHhSO9JkahfYMkTfdhUVv2T772GoQE/PEMh/PyB3Xj1hbNJp4gwRlLZAeuKV4rTvg7ZO6z27lMS+VhGlH5cKo2mg+oRX1iMpvvtLrkts8FSWAKDRopZr1ICv+d3r4jTUusAyi+9BHe9a6sQE0WlVjHarWckJEp/HVZD0qWvK5UOnurE1S2XApTK96+7baUQ0hRcRdSkjeaaLyipX3X3qeRWTBuwjCnZ1w2LwMKeR/8Noef/F0MvPiiqJNSE9oDSD00YdQbxehMj4fFl5lNxZrgZ0XhUiJhSx+SCZ0ZiX3H2q10VaDzVP6XYF736ux5K9uqPTeBX3Ug1PbymeHqvzYaGQiEOqZJiIKSO3vNO6OybI/J2O0d7MKo8n1TCP7Zqoqvdg9PHe0US+o4bZSDeVNidZjGJoHZFrqiO2fdqJ5578vi4v2sfI/YpZC8xIt932rzyaZfxE+G+djHCbt6dfcoEmAB6v9OzRc+NLUslhxoG1ztZIr9GA9uKbdA6ZIk5lfzTRI3pOPt0XTX1P6wxwxRX2gX08WQJfzbXZCZiX60OocW6Y82eZNvIhWL9Min2jzUOTNoeobJzX3vy83CqaiSGYRjmwov9CAwoDMuF9F4/fdZHROXhfJTxG1nsM8z842uSZdnmkmLoZxjIR+PPdre9iWdadwk3Xx3B8dvjcib1Bze9HcvcMpyseVjmApxQ+rKX5VSL9PonfnUSvtEQikqdIgxuoM+HM8elA7tmhdwebVi6cvRRsrpQCpqB7tRcenKzjh+SIWzpjI5KceEqyBEi6bu/2o83T/biyd0dIlxtNpCjqSbyj3hCiIaCOHpaiv8NW2j8lBYr1pbgs/90Pe64fyUsViOONA8nBZ9aTq06+6fbhsVB8ZbLq3H1Tctx89saxAdb73BIOO4GvRblBedmBOKKSimUTioLDpYx7ieJfQ2JHBoj2PSmuIyqEMxKbz+5+9nGJM5G7B9XJi2szK2bcUiX2kIwduwfveaq2Hf48hEORcXIvdJJAvVoLrzo1Tda4Nw8PoGfaO8ZFRURJN4pg2E60Ou4cZl8vhsHEllH76VnIuiCRjGFgkbbeMPyeXaGc/GNzz+D/btT+/ohRSxRAJ+7YPqLQrRfXnd7HW67Z634+bWdjRnvoRFPAMMDQfGmU0vLw330XCags+VAo4x6mwrKuYDZIcZcqlUB80FUXXQYE+SYzrBXvi+dNmNWIamW2fdMEdKXDuVuqJincPYJl12G9IU0pmQZvyFX3kbd8pmJctqfe/2y5N2ddPble01nseOoKvaVhcMLAQX/2S16BMOpcXoT0e8J4Yldsr3j2ikqGhiGYZgLi7ogHU3o0sr4+5SAPk2GSTfXMn4dNEkhrCb0L0VY7DPnBW9jUzKcb6YHnk+flo4+9eUPBIaTvfpUkk1j0S6v2IICXyV0EQOahqQoOdEvXftaVyWee/IEQoEoSitceM/Ht+OWexpgVQ6O8wstcHfJGecJn3SI6lxVydFjQ0PyQL7EoFQM7O8YV8LrC8oPn9ySQjz/Zg9ePyp7+8kcVR2lqfAHI2KR4PXjipOYU5J0t0f7PTj69HPwx6wwasNYf6NsS1DFlCpajyoJ8DSCTaUozyyCscKRGNr7/DAYdLjq+mXIyZPueGPnaDL0Sj/HD8+JWF6dm1FdYHWmSn91iIrHabrhT+Gg+eVaPfLe8l6Yq1YnH//Yvn01LG8kPF7EToU6VnFVXvYxjJPhVPaJsc7+YGAYoyGvGN8S6pVfFuVVzuSYs2yEld5ybWENtDSKMQunlIqL+vLcaQcnEluWS3f4eLeyMJZlXKCaxp+IaKGN6XGo+wRGlTJ+83CeGKNHYj/gD4tFLrWFZdnq6YWbja0M2LS9Cms3S6H12/87iGGlfaZJqYKghRE13yDcIxcGjUof+1S3TdB7QKuM6Iv3ywW/+S3jn9jZp/BLYqJJFqqzP9X4vWxin8buTceJdljl51mQnH3l+bGsCOI9f7YBK9ZOniNCn6tvdBwUn6mELxoQVVHpC2uqsz8cMaB3KCj2x7VpLUHnG7r/hgq5EHRSGUOqQvkk3/zVcbxGrSxUAfZyGyLRuKgGWFs7+3wYhmEY5txDZg8RS2iRqwRoUyhzPBZNlvGrIX5zLePXKoKfYGefYeYAHZwP7X1DnLfXzkzsN460oVkpzSd6vfLgu0c5pTLTg3vb0fWcDiWtq9E01CrK/pOBaaYynD0l3bk7375BiGMSuu/66HY0rC7C1o0GmKPSxYr4E/jCNZ/B+1a9TfxMImfEKw+c15oPilPq86f58CpeMVKOVgZj8Jly8PCLrRkhUM+/0TqtILmHnz+NP+5pxc+faRIBWDR6y2mT1xvu6MXOV6WQr6/SwGAeLyo83hBaFIdrY5qTp9VosEKZz362Y7wT3qSkvTco7vu5YEWVvP+TLYPiubC6Us6wU+eBwZkLjasQBbd8FJb3/Ctytt8hgvzU8YOeMcFmFKAnLg/NzNmnvnRKdKXEfKr4mCnp4YDpqK0jRdZ8jA4rws89eS+zSI0XAXTjZ7arnFTEfkPlzAQKhaZRD3dvQDdhzz590VH1gRrSd3qgSZTyi5+j5mQLxZu7W0VPPVXFWG1GVFRPHsiWCIyi65f/hOBDX0B0JDXSj9i2owwVNXmi8uGPj50RCwpqy0NtWkl4qKdpQrH/7J5WfPTf9mD/yfGp+Np8+VzGB+ZH7NO+GvUoIwCn4eznOCYX+5OV8Y/FH5KlizRdYTqoYj+QSI3eo6kRkwVEqo/xx/sfwtd3fR8/Of6IuGwwOJwU+gatPsPZP9ElH+vyylzY5ildf7asqJD74okxYv+Z3S043jqCL/94L77xszew5/iAaLH4wO1reOQewzDMIhH7RK5NHptSgHCEpgXNm7Ovk7fDAX0MMz949+7DyLHj0BgMyL/yihld98UOGdqm0utTxb48CM835wlBQlhHc9Hq6RR9/FTuTwerox0yCI4EPgVVqRSXOvH2D1yConhjMh0+EExgRX59sjd71BNCPKER7nOBvhcF+h5R8nz8YKqP3zOkhJpp/Xh0vx/RWALb1xTj8x/YJvqOWrpH0dY7+UH+sDeM374kxV8wHMdLSvWAWmp94mwCnqgTFl0Im2/OPlZs/6k+0TdcXeKE25XpFK+okh+WZ5X0+2xp73Twfq6oKXWJ54LaBTr7fbDmuqBBPFnCb6lemzwI1+ikgNA73LApbQxjnX3VbVR7zKfL/q6j4nRFfh3M+uzCbDIcyZ79zDJ+dTGq1F6cHMNod0jxNRFqarzqRmfjdOvwrBZiqEKDerj9cVOGUBuLQ5nPXqwtEXkXryiBlrpI6rmhkXgnj8j33OoNpeNW06PeIVE2H4+ERPl98PFvINB0SAQPDu9+LONv6bpve88mkQw/NBDEQz/Zh8bT8rZrGlIucbinJSOhPp0/7mkRFTOvHh7fTqN1q86+/DyYM+EAEuHgDJz97As8akDfjMR+UDr70xXUDpt8LX3xNLGvuPOTCf3Hm57F06d3ip9bRzvEdVSxn68scNDowURYvgcPtAQueL++yvJKKfbPdo6KyiWV3rR2iZdoKgWAazZXoLaMg/kYhmEWOnq9siibAHJziqFJJBBHQhgtqTL+uS3cGpNl/NyzzzBzJur3Y+Bh6Rjl3HwjzEXT7/Mc8A/hUN/xpEBLd/R7FNGfE3Gjs02KL2PYingYeLVL9n0vL6hD0+nhZK9xNmIdJ2DSBIX4JBHhU1w6goL8CIduFFqnGw0muS1U3tx4qg/xUACHXjstLrPq/DjUIw+y77t+OexWI9bXy/t87ejkidFPvNIhDlap35p4+jXpbOYVyevHlbfpjTeUwmLLLlJVp3NzllA41VlXS/ZVQlTaryxELFcWBM4F9LiqimxJd1/nyBHPOZGjG4Klas246+ic7inL+D0zFPsHuo+J040lq2f1OFyq2B9TFt8yLAVFma0II0oVAuVCTASJJ9mXnhKoYwmGo2juHpn1a0NOry8h95VEyC8CAceijmMr1ZYn32+EJpz6whvxBNF4Ql6+dnNmMn5kqBvtD3wawUe/jOav34/2//kcEt4B6GzKYsz+ZxHzZz5XDqcZ7/jgVugNWjSd7hcVA9SfV6G0eiQScYR7pdg3FmaKfSrFPqUsgLR0jUzo7CeGOhGfh5C+hE8+bpqWoNEbpxb7Uzj7AyNB8RiGRoL4j4cOoKN/YvFP1T0zEvvKyL/RiCEp9gNTiP3fnXwOz7W9Ks4bdAZxMEVTJVSxX2Bzj1ks0uBAizy/fgGIfcqxoOc8Ek0k80CI3kH5Hrz7mnrRwkS9/e++WQauMgzDMAsbvZq0nwDMuaWwKSGs/YHhlNifRtDszNP4dViqsNhnzilt//drxDweEcyXc8N1M7ruH8++LA5AVxYswyVlGzJEvir6dZ2ZQsjsd+JgnxR1y1y1aGsamVDsx8MBxHsbodUkkuJTluUjQ2Q6tCPQr74G1cYm1NuoLB946H9exvPffwxvvilLletzeuDxyQP0ciXA7LLV0q2kPvyJEqPbekax67AU6n/97i3CAT/T7kFztxfuCjlGTdy+ewjrrrs0623EEwkRCDhRaNayyhxQ2+/ASBgdfSmB3NjuEYnvdMBcoFQRnCvqkiMAh6Cx5SaFPIl9c/V4sa93TuLsK2X8M+nZp9aOo71ydNyG4tmJfdXZp96xdFoVsV9iKxTimLBN4uzHBztFGCElm0800u1su0e0keTYDeMqNaa1rTYD/AkjEkovGpR+/Iy/ccltzIlnbkMiJL8W0sfr5eVbUZbWTkALFr2PfhPxoA9Q58/Ho9AW1aH8I9+Gxl0hUvE9e58ad78l5S5cd0ddMtOgpNye/HKPDvUgEQnSNzkM7tT+TzR1e5Pvo9ae0XHtMbRfkTCnkL5I79zd/YRXtvdQS8lkTFXG77DqYTToxOfG0GgYv3zmJP6wuwW/ek4uamTDr/TsT1fs2y3ytfRE9cnRe0FlJOlEPH1GOvr3r7sruQB2ZrApKfYLFbGfnOZgsmDYKydj0Ni9Cw1VA6lVS83K4g99FvYNy0WUWy6rwY/+4Qb8ywfXJ0eAMgzDMAsbg+rs0/m8EjiU7/1BCkdWevZ1WcYDz7ZnX6tcZmJnn2FmTrCnF51PPCnO137kQ9AaZtbj+Xr7fnF6Q/2VKLLnZ/Tsi9OEBr4W+eY0KwfFJPZpgYBweAoRi8aRk2eFu1Ae7CViUSFUxPa1Hheii1BL+b2jqQNkT58Ukw7dCPTLLoXWaMIW407k6foRihnRGKaQtwS2WV9Bfp10uvIcRpiVD4xV1S4R2jXqj+JjX30On/zXF/Dgc81JwUJi5YdPHAUdm29bXYxta0qwZbkUXi8e6EVRQx3MmoAQvbe+O/scdoLceXIXTQZtMisgHavZkFwEoJ5nlZOtg8kS/nPdy6pOBSAHjkTZFuvrWG95E5UFERhc4xcoqIzfPoHYz7fKA/y+QGZP+GTQdAYS/C6jAxWuTBE5XdT2Dk9oVISaEXSbnV7Z616gL0BESY61KQGQ2UgoPeU0Lm6i532XUn6sPm8z3labCQlKktDJ0vIEifIJnH1N0ACnKXU/MeUtsPmykmRf3NpN5RnbGtn7WzFRQGuxw3zvP6PqL34kRL7p1j+HzuqEYf0N4u9G3vi9FO9jqKx14fZ71onnaeX6tH79Lhmsqc0thUabucp+ui21uOMLRMZNuqDtMxXKsZ5q5cRciE9X7E8R0EfbVaSMOuwZCuKVgx3JXvO+Mfv22IA+m3l6n5k0CUBsS1iXDOgLZHne0xkJyufz0opNaFCmmZweaMaAsphVYFWdffl3CTGSMXNx4UJTmi/3264BpQrIGxGtVLSO5HaZYTbqs45DZBiGYRZ2z74mAehzi+FQQvoG0sr40/v6Z4NRcfEpnE/9huAyfoaZBSPHSUzHYaqpQe6mjTO7btiLjpFu4UuuL1qFQlt+hrPf7euD3VOASCAhkvU3bZclvBa/LPGmnuyBs7KUd+W6YnHATU5+2/c/heDDXxThYYEmGbpHHyYWrX+8s9+vuM/2BDRGMyy1G6DXxHCV/XmY9VER+nTnfWtxwxf+GWdztifT79N7p2/YXpVM4ib3idL6H3j0sJwysKcLbxzvEWnb775FlpnuWC8Ty/ecGEDM4sKHP1CDt95TCleFvJ1sqKOwVlQ6YVDLn8ZwwzZ5/ef2tooJAoRa+nouS/hVaktlXkJzlwchGFFo92Gt5SBs1dlddhJYVsX99/vCSRFN1ORWilmrQ6ERDI8ZgzcRTUNtyUkLs13YoPnzdF167Sgshujy9YqfSSxrg1KYUZAdlalPhNpTbiqRs+HHMjgawtO7pet7zcbZjQpTy7rDOmWRaxJn3zcSwcaSVHUFvaeIvHwLrr6pAQUlNmzaVo7BF36B0LM/QNcvvoDoUTkho+C2P4PWnisEvrGgQoyEJHRVG8T7Kh70InpSloqPZcPWCnz2n27IqLrxndwtTrUlcvRlOqfbMys5WruzBA8WyM+BcN/cQ/oSXvn+0LsmL1mfqoyfoAwF4sUDPSK7Qtw+zX9/s23ygL7pOvvK6z0c0E6rjJ8WqWiaCeE0OVCfp4r9JgyGMsv4VWc/rpf7Ei0qqi1HF5rSAllh0KlULA14lCkCTtOcA5wYhmGY849BOX7SKMZP0tkPzV/PvkHp2SdoktJSd/aX7iNjLjj+ZiVoq2riELKJODMsr1tqK4LdZINWKdmhEWeDQQ98YT8q+laIy9ZuKkuWGJv9UlQuy6nF6X0ySG/luhLyDOHZ+3tEh6UL2/Pw1xBXwrcca6+GpU0edHvFgbtSEuuhg3IN8hQBn3PpXYj7R2Cs3ow/3XQzOtq70bBCiugupU+0WHHwVN554wosLzXCanehrdeL/3r4IJ5+rVn06L/whrzP+6+rFnOjiboyO6qKHSLYb/fhLly3dQtC3XKU30QcaZIH56urJw6gumRVsSgnHhoNiQUGoyaYHBG4UknrP5fkOozId5nR7wmKqQF1rkKEe5thrpbz18eiNVlEgIoBYURgzJiAYDGYUe4sRttIF84MtqBcN3UOBC0cqYn5s0Wr0Qph5AmOiMUocbs+uT9V5ZTDp5Q4O3MmT+JX0+KNxXXI1ln+9Otdovpjda0by5XE8dk4+0QAZlgncPbVgD4KoryqdA1ebN4NbUyHWEQZ3WYz4PJrq1G3yg5d/3H0vSqzN1Qv2rXtdtgaLsFolv1To9UiZ/ud6P/9A4iefAW47v4pt5kqAAKn94nz+trNGb+jBaozHVLcF+aY0DscEqX8Ja7McnJacJgvZz/hU5x9Vz6k9M7OsDeYJvazu+mFeVLsHzyrlMjnWtA7FMAL+9pwxapVcw/oU9L4aaKhyRhPpvFPhLpYpdPoxMJobV6lOOChMZK0n4ttpIA+f8rZj+rlY1hITrnaTtClLMwOKIu17kkyMxiGYZiFC42IJjRIQGfPyXD2y+fJ2dfptNDqNCLAG+nO/vhDpSUBL30z5wxfizzgNpbNvGz69LAMqVNHpFkNFtgM8mDz5FCjsMWoTJ9Yt7kcRaVSFJkCDlHeXxasFSO+bHYDyipyRJq0Z/dv5Y1rdaJcODJA5bQa2NfuSJbxjyrp+lT+71Pys/KK5AKCuawBpe/5F+gbLoXNboIzJ+Xk9Shzw4vTnH1xV1oNKotsWFOXj5svrcbbrpbO4/NvtAlnjxz3q9anxCo5xxsaCjP6UCfDH4wkR+qtrpl4RBs5cZeukkKXXOMf/f6sCAujBQISleeD5cqiAk0AcF//PujX3wj7yssm/HutPQc2nXw9RkcyZXGdW+4XZwblTPap6BiR6e3FSoUIkYgn8IffHsWRN3umNR6RyFXCAVWx36mKfVdZckHCOUl/MLWQiJ59UcY/fgxl/3AALx/qTS4UzbYKwWmTItGvhPQh5BWJ+bFe+b5KL+MPBWNYmdMAvVYPXUSKJKpMSK9O8J2SozO15atQcMcnYbrl08h7y3sn3QabeG01SAx3jxvDl41Y6xHR508VAdTzn05T5whCkbgYRbdlhXvCkD5j0tlvnT9n3zmxs0+5CjRNg8idxNkvUpx9lT9/xybRl9jW40VLj2+SMv6Zjd6jYRApZ39ise9TxL7dYBX7GAn+ErusIlFbVPKt8v0aV8R+WGue0TadzzJ+qpyiBaH+pNif+bQNhmEYZiE5+xpozQ44FEHui4WgUXv256Fyy5jm5NOh1mQVmYudpfvImAuOv0Vx9ssyU7ynwxmPvG592jz0fHNuUuwbwhZo4zohpkno5+ZZxQeENqGDOWiDplNxylfmiSCwyJHnRUmxIb8cphv/TAh+QuMuhyGnEBaDdGVHhuSB7dCAX4Sb6RGBq2jqUuruCZz9sVy/pRjXb5WCpKbEho+9dbyzXaEsLlB431QcOtMvQvZK3DYU5k7uKF+xTi4ikLPf1OUTB+3vuanmvM2eToVpecW4PeOWO6DRTSwcqLffqvTte8eI/fo8uV+cnYbYJyHfPqo6+ynh1to8iNdfasKrz7XhsV8eQFRZPZ4MdRKAGg7Y4U05+15V7Lsmfh3Cfe0yyM5sgz5n/H718POnRc/xmjo31tbPvgpBdfa9cSkCE0Evuh/8IkJP/Cv8Z/cne9bUrIuwN4HPXv4R3Fp6vfjZoo8gMdiRfP78Z6TYN6y6WlTC6EoaptxvdBY7TCVyikag+fCU2xxrlPdhX3XFuNs+2iQXC1bWuFFeIIUzOftjUZ392OggYlmqGbIR6mlGrO3IxM7+JD37o/6wEPzpz3k2itwpsV9RZMeaWjc21EsxvTvLtI7ALMv4g3F9UuxTqX5MEe4TOfvqAipR7Uh9TrvMThiVCQThfrkfBLXWBSf285xmsWhCn4E9Q/5kGb86AYFhGIZZXKS3idFhWU76qOR5cvbHlu1TYN/5Oha+ELDYZ84JMZ8f4QF5sGwspTL66UN92D3+frGqV++qEi77o7/cj5w2WTJ/argRxqA12XdMgp8EfV6BFNp35d6JzjNSJC5b5UbMP4rokefFz7lX3QddaQMKbvmYGKdFLj1hsci3glcJ/RpQykIpnC9kzoM3IBcDskEl133DoazO/ljow+RP79mAL338Mnz2vpVZe+wrFbGfTcyMRU3h35Rl5F62UVXpJfsfunMt8iZxI+ebUmVKgeq+TQWJfTWk78zxQex67gxalTJoVeyfGWie0pUnF57Cyui5L7CkHn9Xe6rf//CbHXjyVycRnOR1JnLM6iQAr7jfTm93qox/RC3jn3jBJ9QtA+iMWcL5SDg+87pc5Lr/BtmiMlvUnv2RqBRs0WMvIdgmR0cGWlLCNkeZwjA8FMDm0rWoNcvn1RgeROj5/xUj+xID7UI8awzmrL30k2GpkYtZgeZDk/4dCfNYu9w++6rLx/3+aKMU+1SFUppvSS6GjX3ttSar2G+IyDT69qnSouuX/4TQM/8Fzxu/T7s8ioTfkyzjnyqJ32rWTdrHrvbsEzuUsMNLk9M6BsZN65hpGj/lg5iNWsSggyntaz2s9OVP5uyrVDvLU9uruPpUaeE78Zo432tftuDEPn32FyptM1TKTxNHCHb2GYZhFifp/fTU8pqjhCMTpAvmTeybU99lSzmcj2Cxz5wTwh3SDTIVFkBrmdnYo6N9p8RpdU65KN8/caQbh/d1IHY6B4hrhCtlDCli35qA9/hr8LzxNHJzpXBu2u8TCwQFxQ6xADD0ysNAJAhjYRVsK2SQnmP9taj+3M9hWLVD/Gy1y4Nq1Z0dTBP7X32kGV/9xTHhHmVDlJDGEzAZdciZZOSaCgXyrasvgEnpSxoLOX9qSTeV6Y/llUOd+M2LrWJm/Zsnpi/2iduvkKFwG+pz8ZZLZp6lMBcKFBE8OMalnwitLUc8/0RX2yief+oEnn7kDPp6RlGZUwa9RgdfJIC+gFxUmohuv8xuKLLlw6BNfaB3K2KfkuHJ4e7p9GHfaxOPQyNyLNLZHw170e8fRCAWgk6jRZmzKLnvuCbp2Q93NSaT+Mfy4pvtorWCnOu5uPrpLvNQWO7XCf9wahu6U6X8LqUSxaNUpgT80lE2awNIjPTCf2ovYm3SlbfUrINGP7OJGpbqdfJ2m2Qo5UT4T74uKh4MBRUwFsrKFxW63jHF2V9d40ZRrlm8h/zBqBhlNxZNbsm0S/ljrYdFDgcx8MwP4T8jMwOilMRP26vTQ2dzTRnO51QWVyai2G0TCfHEjo3lyWkdlKLvDURxtn048/kIRmeUxp++MKDTm6FTnuvgFGI/3dmvSnP21XC+WMsh0QKlzylEt65kwYl9okB5v3X2+ZLOvlsJn2QYhmEWF8Y0EywUiiaPuwi1jF8d1zsXTGnfr+YZfNcuRljsM+eEcIfsS7ZWTZwiPxFHe0+L01WF0kU8sFdx6BIamEIykMmonNr6D6D3kX/FwB/+GzmjR8VlvtFIMrgv3nUKI3vk+L+8a96VTAsn1NFev372FLoUV9bnjwtxMdAt+3Wd2hG0+c1iZNaZNnnZWDp6pftcVmCHdh7KgOxWI1xKz3W7ctsq1B/8rz9/QyT5/+V3XxYLDSR81tZNTxxeubEM//G5a/DRO+rPe8lSgeJukrgJhieLPJOQQ1tvOoVLyjqxemMh7EoVwkCvD3qtDuUOKT5aRuXC0kRQlQhR5izOuLyrQ4q8lRsKsH2HFN/9Y57vicr4PWEvWobl/ZY5S2DQGabs2Rfl8MoECLW8PZ1n90pxevnaydPfp4NDGcU2Ek19gemUcvRQd2NSeNNYSmJoUIq/gE++D8xaWeEy/NpjQhAT1mVbZrwdpooVgM6AmHcQCY9seciG99gr4tS+cryrf7ptGB5vWJRr11fkCBdbrRLpHBg/uo7G9k1X7EdPSdcaFsr6iKPn0W8iPtCOqKc/WcKf/pkxliGlEkjNSJgIEvWffvtGfOjWOiH8CXrfqi07vcpii0ogPDNnX/ytWX6exXUmGJWFydAEifzeLM5+oTVfLK6mi/3omdfl363ZAV9IVh/YLHM/yJpPaPFHTeRPBfSxs88wDLMYMRq0SCgjtMPhOHKVMbCCZBr/fJTx61L3mXZ+KcJinzmnzr6tKtOlmw7HeqWzv7pwmRBQjSelM0uYAvIgXy3jt+tGk+O2ckIpx5JYtdKF8Is/FUOu9Msvh7V+07j7CoVjePCZk+j2yoPrWFwjxrx1NEu32GYKIQx5wL1PcdHH0t4ry+3LFQEyH1DJfba+/Z0HekRPNzmJRqUygBxCywxKkCj5nwTT+YYcQYvygTrgmXwGOKGx5cCgiWKt4zguv64S5dWyPHtUua7qRE5f7KfaSaKRGPqV5za/yIo8paeashomI9ciXd6zwy347fE/yO3IKRPi2eedXOzHu04jOtQNGMzj9sX2Xj/Otnug12mwbaV7Xp5rcpK9caXKQKtH8T1/QytcInAtNiKfkzwlzXywz5fh7Fs0UnyGOk8nRwVme/9MhVZvhLZILqTEOk5k/RtyjtWeftuq8YGNv3lBLv5tWpaXLJWvLJYiuaNv+mKfWhJ6HvlXhF78qThPoYHxDtk6YL750zBXrUEiHETo2QcQ7m6csl+fSu8f2XlGnC9V3q+Tce2WSmxTQjJVKJWfoH7zdAIzTONPd9xjOmOyb18drzcWX3S8s08LlQ1uGRpZbC9AdHQo+fw41u6ALzDzaoPzgZpVcqx5UHw20n5P0z8YhmGYxQe1Z6l1gJFIDBZHHkxKq5s6em8+yviNacfNXMbPMLMgNEtnn0Y/dY72iK6clQXLcPrYgKimVTEFFbGvlvGbIyh99xfF+ZxwixzMKUqz8xB57SeifNmQVwrDtruz3t+p9lFx0O5JWGDQSFeou92Lnt4QNIgjx5YSpftOZHcmVfe9rPDciv1QJIYXD8gFh/uvq8LPvnAjvvDh7Xj/zdnntS80qJIgP0e+bn1jxE3Wv1d6r9UkdzX4bsQTyBT7I9MT+zSuT2WgLyD2K5vDBKvNgNx8Rewr7RtjOXWsB3teakeFs1T0jI1GfDg50Jjs1/f7wohF5Y7qmCAcTIygoy+pui3QGjPF4StH5ILW1tU0ItEwL881jUg7HikFqrfAeNW7Rfq/RhHC5O4T+co+q1Y0BPxpzr4xJQRNpcugt8vXY6boSmX+QLzzZNbfx+jyeAwaVyGM7swwz85+P147LCcp3Lw9NdVDHVXZmWVxRpss48/s2fceeQm+468hduZ1DD73U3iPvChK9c0VK8V1iu7+nJgEkPAOYuD5n03Zr//ka51iSgAl4d9+WarffSaoI/l6lcoK8XzEEylnfwbC2q6MxItqDEmxH4xN4OyHxzv7xLs33I2bq3bg8sot8B59WTw/pvLlMOSVwKe2FiwwZ78wV77fGjtkW06ey3JBFjMZhmGY+UE97A+Fo9BRSyeJ/USqZ19N7J+vgD4ji32GmRnkcoY75QG6rXpmzv6e9gPitMxeIkpKTx6WQs2pkwdyZnL2E6kyfqdDL1K/dQ439Joo8nLkwfHKOqMMltJoUXjnp6ExZBdgx5rl7Y7ErUk388ibUlAX6bvg11nGlBOPP3ju6JNCqXwexb7qFKaH9O3c1yZK4MkN3LAsD1azAZtXFM2LODzfffuURzAdZ5+IB31iBrtDEftJZ98phWG7txvRWHTKnv30Mv7+Hil2SsqcQhjn5sn9aXQkJFaS0xEBkb/YjwOvdyPWb8S/3fx5vKPhdtzScC0uLd6Ia2svwwjNPKP93WHK2ksW848g1iz3baoySYf69Hcfk/v5dZfMvBJmIuwWg6hKGd36IbHAQGjd5Rli311oS5bx0+NMin1NAIZ114v3z2xL+FW0pcvFaazrlHDUx6Im4evKV4/73e9f7xSLMpeuLUGZsiCT7ux39o/fjzQ59DprRC9+QhkbR/c7tOvh5N949vwOw68+Ks7b110t799iR/Hb/hqgFHplf5rI2T/TNoyndstFpo/fvW7KMv6pRvKlO/uBtJyOmcy0V539CAwwJSZ39rOl8RMVrlLcXH01zAYzvId3isto+kJmjsDCOigaO4WkSFlAYRiGYRYnNA1LDejT26XYV/v1iflY0DWmfZelC/+lCIt9Zt4J9fYhEQxCo9fDXJpy46aCxkQ9efI5cX578Qa0Nw/BMxSCXhvHGrPsdbaGXdBFjdDF5BvToZTBUvgecdX6GNZvLUadU1YW6CpWw1RaP+F9HlXE/jCJfa0UDu3Nspe7ytiM7ogUQwQdP+9X0u+zOvvzWcafljgu7zuB374kk9xvv7JO9PsuRgqU16tvaBpi32gR/4iEz5MU+yOK2KdRjHajDbFEDC+1vI5wdLyw8YcDIjmfKHOMF/vF5bIs32IziNErxPAYt7ityYOQInRGR4Iod5bg0pJNeN/Ge/CO5XeIbRhRFi/Sw/ko9T5y7EXEwwGMknCKR2EsroM2P1PQv3G8Wyzi5DlN2LR8ekGLM3F6KeVfRZtfkRHS56DRZdQfF0+IFoaATw3oC0JbWA3XJbdAY82Bfe1Vs94OrbsCWrNdhGSGOmSLjgrt17G2o8n3ajqUrr7nuKzquPctDVknVnQNjA+xFFM2cpWZ8UPycyDWuE+0UGgtDuhXXyN/F/ILYZ+eE0DhgMar3pP8OZvYp23+918fAJnnV6wvxZUbZj5adDJnX3XQjXpt1mkdE2FVDlxCiamdfbWMf6yzr0LVNOFeqpTSwrZStlb4FqjYz7EbxXM19jOGYRiGWZwo1foIh2LC2XdGSeynjnvZ2Z8ZLPaZecffIhPNrRXl0Oqn/wY62HccPb5+OIw2bC/eiINvtIvLK/Vn4dZL59PgtyT79a0aHwwuWVpsKpJiv0Tfhm07yhHrkiXD2sKJS9zJXSaxQIwkLLBoUwfcVMJfYWxBo1eK/TU1UhTuU8Q+rTYOjoQw4guLf/Mt9lVnnwL4qHyfRuy19XjFeK0bts2f+3uhnP2+KZx9EnCUp6B3yv71hG8IpmBPhrNPjnxDvnx9v7/353j/Y3+JJ5vkiEWV9hFZYZJrdsGaVjqfcvZdydty5hgzwupUzp5IBTP6lPT1sajOvtqvnwj50f2rLyPy2q/R9r0/g2f3E/L3G68bJxwfeUH2fV+zuWJeQmdUVFGm7p+E1l2Z4ezT43Yp4yIH+rwZzr7GZIP7+vfD8o4vweCa/SKERquFpW6DON/3+wcQD6Ve+3BPExAYEZU32uLMRblHd54RgpomTVAwXzql+TbkOEwIReL43L+/jO6BzPYLo5LjQWKfXP3IgafFz65td8Cw9a2w1G4UP+tqNkFryhSH+pqN4nFrC6qyVjQMjgTR2OkB5Vt+7K1y2sBsKUoT+2pook8Z/ziTfv30xZ1gQg9jXPY3hrIsgIn7mMDZV4l65Oecxp4rKh4WstinrIESJXsivVqCYRiGWdxQm22qjD8l9ucjjd+YIfYXVnvafMNin5l3fM2K2J9BOB8d6D7XJnuab1p2NYw6A5pOS4FfZWyCQzsiBDhiOthG3clwPo3dneHskxtFtxVsk2FgajiYCol0dab1gVMpl96T5uwTxfoumPRRHPBJkXPtJukKk7N/tGkY7//iM/jrBw7g41+TlQh5DiPM87gySKX5lOBNx//dg0ExMYC4Ym2hKN9frORPQ+zTIszHvvoc/vFHh0R7BhE5/CwCz39PnCcXXRVG5K5fXrIZbksuIrEI/tD6MlqVlHyC8h/GlvBHozEMKeXfJYqzTzgVVz69bz8ciqLlbGosmlcJ4RuLR3k86m1Qf34iIhcGYr5hkUYvXOTVV2Zc70iTBydahoQzecdV4xP654LDqjj76WI/j1xoDWLeoeQceVXs93aPIqQEw9HoPZhSAmquuN/yXmisLkT62tD72+8gkZDvQf+ZN5Mj+jS6zP36wKm+jHGR6dCiyD98cBty7Aa0do/iM99+CS09vnFin6oGaKQeTQLQWuxwbblZLD4U3f2XKLj9z2CcIMvDtfU2mO/4q6w5BVTCry7IuexzS313uyxi0SAcjWNYaRGardhXRXggpp80oI/eO9nS+NOJKgGOGlte8jrJgL4ZtBacL9LFvlotwTAMwyxS0p19KuM/F86+mZ19hpk1/pbWGYfzHe09iTZvlxD5Ny67Gn5fRElGT6DQPAxb3XoxBo8o9cvEaFoA0I4T+61IjA4IgQWtLqNkWojIrz2Hv/3BAVEev19J+V9ZnYc4tNBqUn3flcZmhN11CCaMwkFcWeUUZbI0AuzbD59MuqUpV3/+DzDVsVwv7O/BsaZBkUR+49ZUovxSLOOPJxL41oNvYmg0hIGRMGJmpW+/4zisGlmOH4nEk2X1lBp+X8Nt+N7tX8K2cunWPn3mxeTttY90jxP7fd1exOMJmC0GuNJKfh2u8c4+BfNFI1KYEv4JnX1F7LssMun9mNwGw2X3CZdYhERuujXDRaZteOxlGSJ3zcYi5Dkze4/PhbNPDrohX5ad04g5IkfpeW5tlBMoaFHNpAlBY54/sa935MF43UeEoPef3ovInseE4PeffTNr0j9VdXQPSvG+bIyrr7KsIhd/9+41wvWnVoUnX+vIKMcXj7HjOEb2Ka7+1tuTz7/WaIZj3TXQmGb+vj3dLsV+VfHcnx96T+fajRml/N7Zin1FhPuj2jSxP35/DUSCiCuLLRM6+0ooppqbEQhFRZUFYV2AB0Wl+fZxEw4YhmGYxUlcaVX1joZEG6Ajnkj27NNYvvno2TeZLp6e/aX96JgLgrexacZj9544+aw4vbbmcjhNdhzrlCIoRzeMgktvEiLFebALnngOEkOmNGdfOk8kpkjc0xivWOMb4jJTca3o3yXIzf/mz95IiszPP/CqEBTiPrdU4HjzIBKaWEYJ/4DzRvFzidsmPljWLytIJoNfv7USt24tgCdsRFOHB/Ul8++2U1/y0cYBvHJYLkrcuK1K9KcuZlRnv98j3XkSEV/+8R5oElG8/w4LXnqjG4fOSFeRCOqdUIurjBYzjMMhhBOmZCm/CpWj37zsGrzevh8vN7+Od667S1zeoZTxp4v9rnZP0tWn64139lNi/+h+2fPtcJpEeJ83S0Bjeo4A3Yb/1F7RdiD6w5dth6u8UjjF3d1y4UHltSNdaO31i7GJ52IRhwL6xLal9ewTpqIaRPrbER9Q3mNu+bjbmmW7gkkTFGJ4rNM+V3QF1ci/9ePoe/y7iB55Dl2j3Qh1yLF61rqN8AdS4X2dA3JaAo2YnMw9p/fD+25Zhb9/4FV0pIX1WWrWw0iPMxSArWI5wjnlyLlc7hNzhUYkElVF87MY4naZMDgaRu9gAK4SXTKDYKYj7tTFHS+JfaXyJZjF2R8JyRwQs94Egzb7IUDUIz9z1M9XdcGIxn3SDOSFRmnBGGc/KhcGGYZhmMWHhjKUolH093llm6XOkubsK2I/5cPMOaDPuMTF/sL71mYWNdGhYQQ7O0l9wbFcpnBPBYm+Y73yoP+6uivEaXerdM/y9b1wbLxOjH5yKYn86ig+hzYl9jU6vZLCnRpxRiOjVB57uV0IenLni/PMYs47OWjUA09J3xI/tIiJtgGzNowmXXVGieidV9WhvtyF995Ug0/dt1E4aRSodve1y1A0JhF6Pp19gj7Y6H4WO/kuKfZpoYV6gGmcIZVr7z89hE9/cyceeUlWhajz1Ify14nRaMYr3wX76iuSuQqquE5nZUE9SmyFonR5Z9Nr4rR5uH2c2O9WRnSll/ATY3v2g4EIzpyQomfL5dXT7tn37H1Snt94fXKxaSw0Xu0XT59I7lfnYqJCMqAvzdknjMWyLF4V+y5l36WWBTWcT+3Tnm9oXjsJfmppCLYcpZh8MQ5Q7yrI+Lv2PvkalBVM7dJWKMn8fcNBRKJywYC2v/xD/wrL3Z9H4R2fgr7hMmiUyQJzgT6rzsyjs0+4naaMRP65lvGPRnSTOvsjISmEHaaJX+OUsy/bGLxKlsNCnfyhfkZr0nJBGIZhmMWJXTFf+nrk95XTQJ/xitjXxKGdh5Bq00Xk7LPYZ+aVwEkZjGeqqoTePr2DYZpZTsKM3rqlDpmi3d0iDzYLnSERDmbILYFTl+qdJpzWGDRG85h+ZIg52YRZEft7jnXjD3ulw0si/bP3rRRuPbGi0iV64/U6DYLQ4G25D+Iy28swlTegw2vIOJBcXevGt/7iatE3fz5QE8cJCuVTXfHFDDmD5NYSgyNhUblAUO81LeKQRtm2uhhbVsr9oC+eg9L3/Av0DZdCZ8+FVSMF0Vhnn6DV36tKLxHnf3/6BXznwI8w4B+CSWdETa5MoU939ovLHBh88UGEdv0Sw689BptfZk1Q+wiJuhOHuxGLxZGbb0HNMpnK7svSs09J9iMe6SpbIn0Ith4TKebOzTdN+DycbR8WrSQWow537pjfXv2xYj+9jJ8wFcs2mHi/KvYznXMK56OqhHOFc8N1MN/1N2IyAaGvluF96XQoYr98Gu0xuQ6TELq0/3T0ZQb1zTdD3jCGqaxQq0FFmps8F/Jdpowy/rkG9I2GtTAm0/jH76+jYfkcOY2TiX1ZXaNVMgvUiQ4O68KsLKotyxHPV22pfUYTDBiGYZiFR74SeO1Vjq2cZic0cVWyzk8ZvzFN4Bs4oI9hMvG3tqH3Z79AoEOWOKcTOCHFvmV55qisyRgIShGfY3JCr9OLALX+QVmfU1wte/INecVJZ19Fa9TgB0+cwa6DHSKxXhX7Kuay5cJB/q+H5di+26+sxeXrSkXp75c+fjnu2lGHt15VIRPJ7UYR0mfURKDVJGBbvg29iltbrCwMnG+qSpxixB4tRCwFV18l1ykFA5UuH1P6xO+9pgrf+osduO+aSnzm/k1wK/3rAyMpUU8hLVatb0Jnn9hStA5WgwW9vgG0e7tFS8jH175LjMdT++R7OmX2Q56mF8O7Hkbs5CsYfP5nMLz6AxGWRvPm/d4Ijh2SC0R1y3NhU0rJydlXwwFVqLQ/HkuI66Jd9qDrqtYnJwlk40SLfNz15Y5kuf18Y8syei89vC7hHUA8GhYjB9UWhqSzb3XiXKJ1FaHsfV9G6fu+Av162S6TTrtSkj+dLAx6/6pVMOqoynNFa7cvuRA3X+XsbiUrQnX2vcky/pk5DanRe2kBfVnS+EeTzv7En2upgL5MZ9++QJ19eg/98O+vx1++feWF3hSGYRhmjlQoWT1Rv6w4tJqc0KmHXprEvIyfNqV9x7KzzzBjaHvoYYzuehVH/+mLiHhSAlz0YJ+QqfGWFdMr4ScGArJX2G3OTTqv8YRW9A7n1MtFg2BcD5ct1aBj1ITQ4klg74kBfO2nb+A9X3gap71pZe/OfCG2nnq9E/2eINxOI95766qMoLgP3rEGJcqIuxybAZ5EyjknsU9lweqYrwsBBQN+4cPbRSVC4RIaJ+V2GJPubVOX3H+WlTtQX56D67aUiGkDeS5F7KeJer09D1btxM4+QS7+tbVybnqxtQBfvu6vUetKufrDA0FEo3EYjFqYhuXClCavXLR80CKPwyTFUV+PH41KGnytEPtK9kM0nix3VxnoVcSTy4S4Ry4QaAulez4Rp5U2lZqSc7dvTeTsa61OaAzmjN5sd9rYSOnsn5sy/nSo9cZc1iBO06HPkaSznz+9/f58if1mJfGf9tX5Qi3jV519fzL1fmbCmg5+SPBniP1JyvidpuzVG4loGPGAfB7VNqnRwMJ29gn63JgPt4dhGIa5sNTXSbNEG08gGAhDa3PBLtechbM/H2OKTRmj91jsM0wGI8dkr3GopxcnvvoNJCLyHRjs6kJ0aAgavR7m+umXJg8EpdjPU5LXW46cFacFxn7oSurFrPkPf/lZ9IQtsGnlgapdO4rBmF243lTe7g9G8VxjaqWPxFtXvw/PKOX75BybDBOX6bhsBvTElJnr7grEbPkY9kYuqLNPbGgoRH3ZuSupvhDkKuLmjZODovS62G0dFzzoVsQ+zTRXoTJ+yxRin3j7mtvxmcs+jM9s/CAK7bL8XqVfEWv5hVaEWo+K84ZVVyHvqreL8zaNdP2P7OsRbn1BsQM5bov4ItArTi6lw2bcpiL2KeguMihD+DTOzPsdy8lWuc/XlNjPudin94Y6blJsm0YDfY5sRYkOy/GT+YWp7bCInv0Lt8/RJAZvIApauFcX46Yr9lvPsdhvUZx9yu6YL9LL+MVYPEVYz1Tsq2I8nDAkxX7WMn5F7Js8/Qj+7pvoeexbGNz5S8SH5b6b8Mp9U2O0iH/p1SHnqgqFYRiGYVQqS12IQH6PNTUPQWNxwhpLzKuzb8wI6OMyfoZJEh0cQri/H9BqobNZMXLsOPp+8X/iIHX44GHxN44Vy6E1Gmdcxu86sx+hnma0npICvbRQLxLB//fxI8KdbA1Yk337Dt0oBuI2EYxH87aJ0wMaaC2y/NhcvgL/89sjiMYS2NBQgI3Lxs/LTofK+BujRThW8w6Y3vJh9Iixf/KAe6GGUi1W8hRnXw1hW1UzvtxdHUOXLvZpfFuqjD/76D7CqDdie8UmkTY+lv5eeZ/uAjOCShK8tqQhGVpnj8vy5c5WKRpXrksF+1mU/WBs335S7OeZEVUEk9aRGTiXDgVD0kLUuRb7NCJN/T5UZ6SrGJJiv0ecugtTC1pm7bnt2Z+K5i654FKSb592qbwq9tvPodinz7gW1dmfYBzgbMh1GMXrFI7G0e8J4chZmWNRnDfzRUb6rAqS2FdG66nO/m+PP4NnWl7OEPu69tOI95yF7+guDL/yG4Rf/Im4POGTLSZ6V2rBKhXQt3CdfYZhGGZpQCHNMcW9b2ySYt8RVev450fs6/VaWO1G6HSaZKvmUoXFPjMjAmel624sL8Pyz31WiP7R13aj49HfwnNYiv2cdWtndJtqGX+ebxSdv/gndHZLMVXZUIajTcPJcXd9cSfcOiXQTTeIwbhduGLlhXYRmBUIxaFfdilgtmPAtUIE89EHwkfuWpsxYm0iZ584q62D1uFG14A8qC9xW6e8LjMzqKUiHQo+nFDspzn4WqsDVp38eVSZaz9T+nuk2M8zjwLxKHQONzSOfJHernEWiIqRdFatS43Es9r0WRP51WoBl1OLeNA3pbPfrLjDZQW2GfdlzwR6T9gs8rn2BjPFvursRxRnP7OMn3r2Zy/2X9jXhodeaEEkOru5OC2K2K8umX5ugCr2O/q8YtLBuaB/OIhRf1Q8r9Wl8+fsU+l5njKl4sndnWIxiD7X1jdMvGA0EXarcUwZf1iEVP7i0KP4XfPz6BrtTZbxW4PyveTadrs4jQ+0Ix4OirGRYrscqX046ezzwifDMAxzHjBYpdve1emBxurE5hH5PaSLa+aljF+j0eDdH9uO2+5bDvMSr1pjsc/MiNDZRnFqqatF7sYNqP3Q+8XPLT/9OYb27hPnXTMW+9JJyo3GMeqNwR8zi1n35RvX4f+elwnpRF/MgVWWw7jcthMrzMek2M8xi/TlMkWs9Cy7E9Z3fg3H+6RAX1HpzBhhNxEuu5IQPyoPgFXnldxFZn6h9PR0VtXIvuB0VPFDwofCFwkanWazyo8sny8ikvJnAqXmDyhiPzcmR/JZqtckF3O0+ZWiYkTFXWATZfzjnf1MsT/QJ8WTyxhIthtMNHKPaOyUf7+scvJqk/mAJk0QVBafjiGnaMIy/rk4+68f78c3f/kmnnmjG7/bJT8rZuvsV5dOX+zTuDWqAqBKHjVrY75RR+5RON9kLUGzoYhmwwN49bDMUHjLpqJZORdOKuOHPpnGT2L/RP+Z5O8P95xIOvtWpf0q94p7xD5LYxDDPU2IK2X87OwzDMMwFwq70uI22O8Tzn5uRH6vaZBIVi3OlaISJ4rKlv5xPot9ZkYEFLFvrpM9+cW33AznjiupxhXxcBgakxH2ZfXTvr1oPIbhsBRYuRozDiV2iPNukwfPnwqgezCIHLsJl6wqQn/cKdLya0xNMGiiGIzZUKB8GFQpokx1BU+3zawn2qWIoiGlbFx19qmfnJlf8tKcfXpt1YWadMjxVku40919s90CLaT4p8T8mTA44EMkEhe99w7PMXGZpWpN8vck9tOd/ZXrS5ILAYlYFGbL+J79SDgGz5AyGkYrxaAhN1X6n42mLim2lp9HsT+2jF/vynT2nS6zKGejRTbKxZhOzz4ttnz1p3vxjf87JiZiHDrThx//PiXwf/XsqXHhgDMR+1XF0xf75LYX58lqkK6B2VV9TMWh01KIL5vHEn6Vwly5uEWHMhaTDpetnbmrrzrvobSe/Ug8imO9sl2FONJzEiNhRezTYplGC43JClOp/MwOdp5JOftp1SnJ0XvK/sQwDMMw5xJ3vvxe9I+GoLE4kBADuiVccTszWOwz0yYWCCDc3iHOm+trk2+4/PvuSbr5loYGaPXTL00e8A8iTjMz4wm0hjahcaRIpKJfckUZnt3TKv7mnTetEOnX5OyrBGBGCMZkuBWNqSNauqVYO6WknVcXT6/vVS3jHxqRQq5ZGc9Wys7+vOO0UWq2/KBeWZOX9UObLqMJCWP79rU2ZzKkzzdDsU9THogiWhjqbxbnzVWrU7edXwV7mrOfXsLf+9i3YGh8UZz3p/Xse4bk/kJC2RSW/f76ScQ+9X2rZfwNF9LZz1WcfY/s2ddoNXj3R7fj+oJdMGtD0xL7T7/WjFcOduJU26iYiPF3//WqcNYvXVuC8gKrmBf/qz/KiQfThRYQ1ET9mZTxE6VKmF/nORD7VI3x1KtN4vz2tan9Yr4oVJx94rqtVSJvYTY4xpTxEwe65cIWcaT3JEaC8vm1k9g32cR7zVQqR3uGOk8nA/rSR0eOJp39pV3qyDAMwywMSpVpRYlQTEwQimuVqlDNuWnVW8qw2Gemzeip0zSoHKaCfOhzU0JFo9Nhxd98DlXvfTfy73vbjG6T5qETxf2FONgvFxBuvnsdclYsSwp3Eg80/i4CPbwaKb4H4/JDID9njLPfPYJgOIb23tEZiX01Dd7jC4kD25PKHPR19ZOnqjMzR6vRwK2U6WcL5xv7mqQ7+xqrKzl+L110z0TsF7iiomRZ7ypIlrOL7XJXwKiJYot1N7Zsd6NIKSOP+4bhO7Eb5oR3nLM/PBhIlsHHR/qmdPa7B/xCeFOfds089n1PhFp2Te0Q2Xr24wEvEmH5GOjxFqI1mY8wGXR7P39aTuVYX5+TvJ/aEjs++87NuOfqSvHzk680oWdo+mX1nf0+0etvMmiTpe3TRU3u755nsR8MR/HDp86C9PPWlW5sXTV55cZsKFJGa9Ky121XTD62cTLIeY9BBw100NGoC2p/Uj5j9RodvGEffJFA0tnXmOXno6lEOvuhCZx9r+rscxk/wzAMcx6orpDHYLoE4BkJIWFi8222sNhnps3I8RPJtP2x6G02lL/1LhgKpi4/DUSCCMek+Ojx9ovaVVe7rAzYdlUNNl9ahdPtUqyX5lvgsptQqpR6q+5+f1QR+2Oc/bbuUVEmTce5NJKPUvang92qF6XAdL3Xj/WLA/sStznDcWPmj8vXlYpqisvS3POxqK/dwEggq9j3jc7O2c/T9o1z9cVtG80w5Jdhhfk41lf5khUHsZaD8u+1wXEBfcMDwaTYTyTFfmoBYaKRe3VlLpE2e65Ry65pgYEc8xcP9IgxfFoaqWaW76nEqBSD8UgIUN6XUzn7v93VLgQ/ue8fv7MBP/z89fjCh7fjM/euEP3sq6pd2LyiUITl0d9Ol7MdnuT7nt6PsxH78+3s/+yp42LBgkIj77+uGueCtfX5MBp0uHxtwZyqiVTnPaJJlfITBTY3lufKxVSCnllLPAGNSRX7dcnpDInR/gyxT9UoqrNvVwIfGYZhGOZckuMyIaocBjS3jiJuUL4buYJ/xrDYZyZl6M396PnRTzB84CBGFbHvXLli1rd3qPs4PvHE/8NX3vgeorEoen39MIQt0EQt0GgSuPYWedsn22QZ/XJlZa8kXx6UdoYVZz9mR47DlAzKKsqzwajXivFVe08MzLi3ltxmNThulxKStaZm/ntzGcn7b1+Nf/3EJhQqjmY2cpTQxIF0Z99CYl+WwftGp+/sk2Dp7pD7lMN3cly/vooqeuL9qWDIWPMBcWrWBMYF9A0Pym1zk9hXRVLOxM7vKUXsN1Sd+xL+9DL+w43D+PNv7sTP/9iMXQc7xWVau6yqiKtiPyArF6DVJeerjyWeSODNE7148aDs9adJFxQkZzbqsXlFEUzGVHDdO26Qi4JHGoennZC/77hsK2gon1kJf4azPxhEfJ4S+Qc8ATz+sswh+NR9G87Z9IRitw2/+tItePeNs3f11TR+IjymlH95fh0aclO3bdHoQa+UKvblNApZ7YG4zMTQKWX8oXBMLBARXMbPMAzDnC80JnlM0UkmnlkeF6T37jPT49zNfWKWBE3/+2ME2ttxdPee5GWOlSugyIJp8/pLjfjjk0fRWL8HPmdAlJIe6D4qyvgtPlnOnJejhUER79QHTDRUOJLlo3Sg/XJoBWoLDHhluAHFhSmhSIKDDvZpDvZsxD6R6zQLYdnRL0Udi/0LS7KMP61nn8avWDQz79mncvtgIEKTImEdPCxWhi01G7KKfe/hFxHrl+XsMf8I4t1nkin18n7D45x9d54RCb8nVcY/Ihckxi44vHmi57yF86WXXZMAVqHwyqs3lUPjcAP9LUh45fslFhhNuvpjcxRIPP/86eN4dk8LhpRFFqrOIEe6u7s7631TzobFpEcgFEVr9wiUfMMJoQWBNxSxv65+5u+9ghyzaI8IR+LoGw7MuA0gG+298pOOwv9oMWOixzof0LbTouNcoDR+Ymzf/or8WriRek5tGuWr35R6jrQFVYiNyEUcnc0FrTJRQnX1KWcjfTGHYRiGYc4lVqcZoaAPA/0BVCzbApztgh/ZzQhmYtjZZyYkNjoqhD6hMUhHR2s2w1ZVNaPbIaHw/B+PIR7VoKh1BXJNUty/1LwHvd5+WHzyILSgUKZpU4J3e59/nMNXmGtCVywXvwrvQF/cKdz8dMoK5AdAMCxdqIaKmQmqPIe8f4IOapeVz37WOHOuxH56Gf/0nf0uZWxariMBnSYGjbsCekfupM5+IhGH79Re0d9PWDRyO0LBKKLRuNivPUo/eo5ZLgRoTVZoLdnLsE+0jqCjzwezUSumS5wP3C65T5OEXFMnndompcJBiH1Rxi8rEuJ+eXm27aek/YeeOy2EPgn47avy8fG710163zQHd4VSwXCsUS4oTMbZjlHRGkALFHWlM3/v0YJfWYH8TFBD/uZKnzJpIc+ZOS5yoWJRKg8CIpE/NZpyRX49SmyFcCo9j7aE/OpXe/bVgEqVjH79gHyf0WIrJyAzDMMw54u8fLkg7fOEEdUrgX3zNXfvIoLFPjMhgTNnxamhtASbH/hPVL7zHSj68AdEIN9MaG0eRkTqM1j8Lryj4J3i/L7OQ+gY6YbFq4j9cnl6tFGKj4oiu0huVynMkcKluSv7WLwy5UNBpW7Gzn7qgJ6C+c5HTzWDmZXxW11w6KQoHewPCLd8OrQ1yfL5fKMUnbqK8SX8hLGoBhpyNAOj6H/y+/CdeC3Z32/QhKHVSAEV8EXgGfIjFktAp9fCElNCzXKLJxREL+yXrvWlqwtgNZ+fcugNDQV4762r8Nm3rxQl90Rjp0c8b6rYV8v40539sew7IR3fTQ25+Pk/3YQP3lonsjSmYlWtvI9jTTLwcjIOnpHP4ZaVhbOaMU9UFDnmVez3exSx71gcveoWoxT7wbgeRuW9YTVYUO4qEVUDawpla4VNedto0gKPyNlX0WUZu2c9Ry0MDMMwDJONEiXIOBKIimk9Ehb7M4XVDDMhwdNS7Fvq62Byu1Fx79tgXZMZajYd3nhTjqyK6eVB49GX+1FiKRQzoCmsz+KT7r1fJwXQkbNSfKypy0zCL8yVYl+Vd2PFPoV6qZDDZ7fMTFBRAJfK5uVK/yqzIJz9pKg3O5Cj90CLGMKhGIYGlFWkKWhVxGZBWPbr6yqy78dagwkFt36CZv9h9OBzCJzdLy53bbmVLoJZcfcD/ij6lRJvd4ENMU/3pOF8/cMBHFDE7I4N52/fotLwt127TGRflBc6hIimkXjkWGvtSgBbsmdfCmRtFrG//6QU+5sb3CJIbrqsrM4Tp8eapyH2z8rqi62rZ592P99iP+XsLw6xbzalxL5axt/groFWI7/qL63cLE5LldQjtWef0LrLRV7DWGd/1CfL+M9VXgHDMAzDZKOiQop9XTSBWFR+pylfZ8wM4KeMmZDgGaVXeZkcyzQbQsEIBlrkjG934aswacMY6PNheWC9uMwUtEMXN0CHKL7/TBO++6v9OHBaBuStHSP2ixSxn/x5TBk/zfZWWTaLnmjq2VfZvPL8lFkzE+NSnH0KCAuEZWiYRquF0e5Ark6Kx6422Sc/GbQo0K2kvBdq2qG1OjNczLHY11wJ49XvT36jaFxFsNTIknWzkhcQ8EfQ3+tLJvFHh6Rrb8gtmXAmPa1X0D49tgLlfEGVKuqCGLn7yTJ+74BYTIkpAX00du/I2X7xvBPD3rAYg0mLHauqZxacR9kEZNLTYsfASCrYcCwdfV6ReE994ZvmsNCmiv3WeRP7/sVVxq+IfQroc0alC7JacfOJrWUb8P3bv4Lr/OriWeozlCpajAWV48W+4uzbLNyvzzAMw5w/qipzkUBCBMqOKJV24mCEmREs9pmsxAIBhNpkv76lfvZif9fu49DEtQiZR3FFuAWrTHKMmf+wHtq4FhavXLUza+XB+R/3tKK1W55fo5QAj3X2VYrGOPs0yk1182caziduTwn0ojAuSsdmLiw0acGmvJ6etDA+nT0Xbr1s9ehUevEno6dTjmJ0WmOi399atwmaKZaG9bWbUfTWv4TeVQDDuuuhNVkAgzkZ0kdl/L2dI0mxHxmSzr5+jLMfDMdwpn0Yf3hdpvvfcvm5Gd02XSqUUMumDg80dloQ0wDRsOjXV8v4+/06/O33XsH3fnta/Hy02ZMM3JtptQw5zZVF8r10RhmnmY09R+Xzt6Y2f04tDqrYb+8ZnXaLx1Iq46cFHVowCSUMuHbIh3vM1bhp2dXJ31OLSZ41Bwj5xzn7hHPTDdA48mGt2zhe7LOzzzAMw5xHXA4T1HSmgR5pSHB2zMzhb28mK6MnT1GyHkyFBdDnzT45fO/rNLZKD5OzBbm2AhTWO3H8dT/8AStWBjZi0CfLonVaPwxaFywmgwjoI8FNTnu3P7vYpwNat8uCvl4puNQPgO1rSvDSgXZsmYUzv2FZAT54xxqUcAj/goFaK6jsnNzlzj4vTjR7sMqeizz9ABACOts8WHuJLBWfiC5FZBbqpfturd80rWkSthXbxD81gZ3yAsxKIF9Ppw9njsnqgsraPESeVcv4ZQk6Cc1vPfgmnn+jLWMxivbP/j5ZEn8hqCgkcdcvnP1r1udA58hDbHQAkeGeZBn/UER+LRxr9uDw2X4cbZJif7aOe32ZA83dPpzpmETsH5PP3yWr51ZRQ+07dBzgC0Yzgh1nA72Giy2gj6AxiMGEHvZYAts0DpiUVP10EkHfhGLfX7oOxoLiceMicxfJggfDMAyzNKDj+ji1Dkbi8A7L73Qu4585/JQxSdp+/TC6H/gfRL0+eI4eE5c5V62c9e319A0j3KsXJTgbNaeEW1r2ts9gQ4GsGDCfLYR9VAq1iCaColwLvv0XV+OGbVW479rxZdbkLKmjxApyrVlDvP7s3g345p9uQml+9kT0ydBqNbhrRx2qFCeSufC4ldaKPccH8Olv7sS3HjqBgM4Ot046+13tMmxuMrrbpbTPjzWKbwlL7fiRe9NBY8uBRXH2Tx7uF2Ex5dVOVNflIurpyxD7+04NJoV+jt0ketfffUON6KFfCM5+o1KVYMiRAj463IOYX4pxXzwlbH/x9Akcb5Fif+Msxb461eL0BM6+xxtOpvVvXTX7fn3CoNeJEXxEu+ICzBZ/MCYqM4hcJT9iMUDVFOGEUh0RGd86QVMmEFac/bQy/mzQItueY3KRbOuKzEorhmEYhjnX6K3y+ywWlC3B7OzPHHb2GUEiGkXbrx4Spye++nXEI5E5i/39J2TPf8TiwaqIB7rqjeJNunFrGQ495YU/aIcJsgeYfKZ8lwkFuRZ88t4NE86zLs234WQrOf/Z+55pAYDKv5mlQZ4yOm7XYSmmCS+scOmGodPGEQ5F4RkKoSR7qzyikRh6lekN5OxrC2ugEwJn5j3dGmtOst1E/KzV4NJrKxClEv54DNAZhFMeisTw0M5W8Te3X1aGj9y9RZw/lzPap4uaa9E76Ic/GIU9pwhoOw7/mTcR80lRPxpLCdujiginXvDlVbmzqkogZ5/o7A/A6w/DrizYqew9MQDKkqstsc9L+0yp24LeoaDo2y9yzj4fYXBUCmWX3QijYfGsi1tMOoSC8qs9kUXsx8nVVxfIxjj7Y3ntaL8YMUmLVaUXKGuCYRiGuXixOE2IekIZx17MzFg8RzDMOSXS2yuEPuE5fASjJ2RquXPVqlnfZm+f7KfWG7ww5pUCOdK1c67cirXmA8m/M2qCGIobUZAzdalsiTJHu4h76i8K0ickqJ/vIwkrtJoE8izSnezrlmI+Gx1tw4jHErAYY3BoRzJmic8Ujc2VTOMntl5ejVy3BaEuuailza8QWQCP7TyDwZEw8nMsuHHrBKsQFwiqjinMlSF9bX1+WJfJhQjvkZcQ7pbTNzwRuYpuNaUWzdYvy591VQKNz6RFOpKX+0+mFm1Udh+XCwrbVs2Pc1ziVh7fHEP66DUkCnJSUz4WA7QwQz37gqja7ZhCbdfQGM3Q6CZe7yeR//IhubhD1VYMwzAMc77JGZPPxc7+EnD2T548iUcffRQdHR2w2Wy47LLLcOutt0I3yWz36VzH6/Xi4YcfxpEjRxAOh7F8+XLce++9KCgoOE+PbGET7uwSpzqnE3GfD4lYDFq7HZbyMoz0yDLOmTI8SCXPGpj0XnTYVuCb//Em/vo9OmxaXo169yCOBUcwGneKsLWjMSe2uaYW+5evK8W+493YvmZu5b7M4mBVjWzzuGSFG3k5dvxhdwuGomaQhHbrB9AHuxD7JExeef4MwpEAim4qSn4ZtDbKvvpiq0f0cmtp0WmWkLNv18rScJNFj6tuWAbPyCBCnVIk00LCgCeAh56XwXbvv23VgqwyqSl1oXcogLZeP3ZccimGr/kAIq88iERYtigMh0koxsRCxZOvdSIcjc8pIZ+4dG0JfvPCGTzw2CGsVF5TNYW/pdsnWmi2LJ8vsS8XiNp6SdTOPgNgUJkeQIs2iwnq2Q8lJnb21akLuiwjFtM50tiPvuEQrGY9rlhfiuEh2TrDMAzDMOeLgiIH+pGqjGRnf5E7+01NTfjud7+LvLw8fPSjH8XVV1+Np59+Woj0uVwnHo/jO9/5jlgUIIH/3ve+F319ffi3f/s3BALKKIeLHFXsW9euQf0nP0EN7LBvXD+nFTTfsJLirPXity05CIRi+M7/7Yc3EIGhag22WHfDpAmixngWI3FLstd2Mijg7N8+sQmbV/BovIuBS1YV48Ev3oyP3F6Pwly5utsakwt0eVGZcN/X7cfOP5zEC78/iVeebcUTvz6EeCwuFgCaTkuBkg9ZVq/NK8u4/e4Bn+gZn67Yz9f34orS07jt3gZYlHL0lLNfiWdebxUj6+pK7bhyQ+Z9LRRqy+QEjDZldKDI0vjA12EqXQZNbim6wvJ5phGBH3vrOmyoz8VVG8vndJ/vuHGFyAug5/prP92LaEyOhdu5T+Z30GICVQDMB6WKCzBdZ/8/HjqAL/3siPhcSmdwVHH2lf1uUTr7kfEhhXElm0E7hdh/Zrd8z+zYWC5yABiGYRjmfFOQb0NY1AZKyBxgZsaC+gZ//PHHUVJSgg9/+MNCZK5ZswZ6vR6/+c1vcOONNyInJ2dW19m3bx9aW1vx93//96ioqBDXq6+vx9/93d/hpZdeEn93saOKfWNpCQqvuRq5Wzajf3RuZbDhkTgN9oLDEMYf+2XZ/dBoCD949DDevnI9yo69iHuMD2IobkMcWtGzPx24hOfignq8vSOAW+nf7/LpYCyuhbtDCnnqye/pkIKbdo0De9ow2O/D0IAPo0qfV2G8mQIdoFFaScTt9PvwZ994HrF4AjdsG8KOdTkoLp48oI9uv85wDKbCd4jLEvEYwj3N4ry2oAode6VrSgJ5oe6n5OwT5OyrGN2lKHv/V9HV1QXPj4+Ky8jRvXJLFdZWmZIjEGcLVTh8/M5l+NLPj+FEyxB+8nQjPnFPHna+KUMMd2ya22JCOjTJg6CFhVF/BJPVAPUNB0W1CPHkrkbcd/3y8WJ/ETr7g5M6+6NTOvuBUBSvHu4U57mEn2EYhrlQ0LEfLVuraT/s7C9iZz8SieDUqVPYuFGGuKls3rxZOPNHjx6d9XXoND8/Pyn0CZfLJQT/oUOHcLFApfkk6rOll4c7O5NinzA4HNBoZ7970H0kAvKtaRSVzBqRck/v0Z1vtuPQaB60ShL0QEyeTlfsMxcnqtgf8ARhrd0Ap9YDgy6OBKW7UQ/9ldW4/q566PVaUb5PQt9sMWDrRiNy9UMiKV+TNobs1UOyRJ3E/u9fa8bf/89BnGiRZf/ZoNF7RMw7jERcOtOJoU4komFoTVZonAWiUoCYTpXKhaKmVIZidg0ERPVDOvQ5SiF6hM08vy0I9Jx85h2bxPndxwbw/i8+g+4BP0wGLbavnr+2HJNRl8wl6BKtRBOz54TMCyAef7kRwbDMLVnUZfwU0Jfs2ZePYfTQTkRPvSbOx4NyQUprmXhiCe3HkWgcdose9RU8i5RhGIa5cFOZgmnO/kI1UhYyC0bs9/f3IxqNoqgoszw7NzcXBoNBOE6zvQ6dFmex7AoLCxdEQva55vcvPIrWzmY0//TnaPunf8GJr3wNkZHUfPp4OIxIrwzO0mkmHlfl84YQjUiRMxUBfxTauBQLIb+8zm2XleGt1ywT53/xXBssdfLAfzhuE0FsBv2C2R2ZBRzWN+gJwFK3Qbjsefr+5Kz7629fher6HLz745di5bpiXHF9Jf7882/B6iIZMmYszHQo9x6XWRRXrStEXbkL0VgCz+6RpcvZ0FiccsBrIo5EQL5/4n3y700ldSKcr3tQFfsLd+GKnGoqg6PHO+zNdH7jiUSynJ3C/OabrauL8Y8f2i6S92mRhdi4LHfey8QriqRr3dWfEvs0JeFz330J3/z1cdFGQAuSrx+TYp8WIUd8YTzzunT5M8v4LYuwjD/l7NOUhb4n/gPhl3+OqHcoOWJxMmefFtSIXMfiGTnIMAzDLD1ynWakL9tnG7vNLJIyfrV33mwe74jRZcFgcNbXob8jZ38sJpMp6+0uJXa/+TJ+1PsMSluAf1j9AXT+7ikMvr4X+099BgXvfw+obtnf3iFGMWn0GkRf+THCa9bDWFAprj/iCWDvrg50tpxCT+cICoqt+Nhnp04Y7xmQSfwRQxAjfqsoCV5d7cJbiovwh93N8PgiGKq5HonubrzcVIfiisXVF8ucf9wuKbp8NGs1vw4wmLHR9Dra6u7FTfdthk5Ji6+ozkVF9RaxkGc06REfUqpWCiuhSltfIIrjTVLo3bK9FCNhI7784z042TI04f1TpYvOloOYdxAJvxxTF+uX4tBUWo+RcCzZ/7+QxT49T/kuswjpoxF86UUIlKuhFv7Qe/ZcsGVlEcpzExgKGHHgVC8218//ZA0S+/tO9KJrMPX5/vzeVtFCQDz5ShPW1eeL6gZaZLzjsjL85qU2PLrzLDbVrkEsFsdwWhl/JDC9XIeFIvbD6ld7JIRgO01WkS9qqOtsMo1/sp59Cpokcuws9hmGYZgL+50WJzNQKbzT6FjszxRNIltN9wXg7Nmz+PrXv45PfvKTou8+nb/8y78UpfrvfOc7Z3Wdz3/+86isrBR9/elQX//zzz+P//zP/5z1dsdiMRH2t1A53XQS/976f/RC48vb/xLxjl4M/ewXiHR1Q2MyofprX4Lv4GH0/ugn6ChchqHSPNx0eSlM665DKBTCM482o6sts3f/lrctQ0GpWSyWEPR3Y8+/svcEju70ImQbgDEyAMOybXjnW8rF7x54/DTeODkoZpDrdRo8+nI7Ll2dn/x9+u1ku+1sly3k6/B9z899G41G/Nl33kA4Ese/fGg9HHt/BLQdgWb9zbBsuW3C+/E/+hVgsB3Gt3wYsZKV4rJdB7vwk2daUZZvwd/evxyBiAaf+6/9ImPiu5/eAk0imnXbEk9/B/H+Fmh3vB/m+i3wP/JlYKhD3HaLvgpfffCUKH3+6ofXLOjX6RsPHsOp9lF86LY6bKh1JP+uo3cEX/jJcTFX/psfX7dgtnemt7PnpAc//UMTGsrt+Nw7VsMfCOJffnYCfUqGg8Wow8aGXLx6pB+bluXi3ddXiMdNi5Dvuq4Ca+vc+OsHDggH4Xt/cQkikfCieNx0+oc9XXjypdP4au6vxO/1q69B9OgL8vzGW5AY7kas6U0Ytr8N8frLst7OH97owxOvduDyNW687+b6BfH+Xyz3vdi292K978W2vRfrfS+27b1Y7/tcb+8//mA/yjwxcV5XbMEH3736vN33QoaMbMqpWzTOvsUiXTt6gsdC7ns2936617FarVkdfLpMvY3ZQuP9srUILBTy8wvws7O/wLBBh9b+s1hZtx613/kmDv7FXyLQ0Qnt6TMwjIwgptHhhONSwKvDsTPHcfMNxWhuakd3uxT6t92zDh2tQ9j/ehtOH/WgvMaVfNzkoI497xk9KH7WGnwYCtnxzu11oPcN/e7S9SEh9s90BpLltjVlbvHGGns72W4722UL+Tp83/N337l2I3qGgtAa7DBUrEGExH73qQmvU1RYgCaPbNUpWr4BAyG5Dx57Qgb6XbZeLjBVVRXD7TyKgZEwPCEjihy6rNuGvCL4+1ugC/tQmJ+H5mHZKlS8cjMOHZSLfmUFUjxf6OdqssvKizuF2A/HjRnvu+Zu2cbjtKYuXwjbO9Pb2bq2Woj9U+1enO2JY2DQJ4S+02ZEjk2P1l6/EPrEDZfVw27TihajH/3uGJ7e24sV9TLfxZ1jQWlpyaJ53HRamB9AWCnjJzS9cl8njKM9SCQioiQyp6gMvgk+c4NR2YKV77IsqPf/Yrjvxba9F+t9L7btvVjve7Ft78V63+d6e11OE2IeH3Q0znsejq+6Z3DfS4EF0yRN8+61Wi16e2V/rcrQ0JAI4qPE/dleh3r6s7nvdFm2211K6PU6FAblgd+RtsPiVGcyofC6t4jzvc++AH9rK0ZM+VQbIy473mtEIhpBW5NHlPTm5VuwaXslLr9WOjynj/fCMzR5+8PIsPy9UedDQO/AhobUnO4NDXJ02snWITR2yHL/ImVcFsNMRo5dBo8NjAShK18pzsd7mxAPyl75sUQGu4BYFBqDGfocuQ9Sv/bRJrnfXbIy9WFeWyoDyyYr5dc75Iz4hH9YpvAn4tDZXNA580WyO1Hsnv+y9PlGHWNIpfzpUHuDOgFhMVNV4sTd18jPq+/86k389hU54u+OK2tx/3XVyb8jh5/aCohbLqsRIZD9nhB+/LujizKJXy15jEEn/hGRPjnxQC3jjwW8U/fsj3DPPsMwDLMwcDlMIpGf4NF7i1jsU6BeQ0MD9u/fL5L0VWhsHgn6FStWzPo6q1atQk9PDzo6OpJ/4/F4cObMGfG7pY47nitOWwKyd5kovGYHvWMwevIkRo4cg8ecEuOj/jL4W4+j9azsSy6096NnoBVBkxflNfIA8ej+zAWWsQRGZMiXVedFTkFBRvgeCQ0aj0VJ4Gfa5X0U5S18gcRceNQeYgrp0zryYcgrFYK7+9dfge/knmRKvkpYCdAzFlSIAD3ieNMg/KGYcHkbquR7g6DQuInE/muHu/DQzlZo7YrY93kQ6jwtzptK6kU6bO+wrDAqXgQLV0V5UsRSz346vqAsk3MscrFPvPvmlWiocIgcgt6hICwmHW69vAZ1ZQ5cu0U695uX54mxgASFBL7vVvl9oH4uLUaxr4YdRpAalygmn2g0iPmGERnomLpnf1jt2Z/byEWGYRiGmSv0XTSqZM8YbPy9tGjFPnHrrbeitbUVDzzwAA4fPoynn34ajzzyCHbs2IG8vDzh1jc2NgrnfrrXIbZs2SIc/O9+97vYvXu3WAz41re+BbvdLv5uqVNiqxGnXZoAYnF5MG/MzYV1zWpxPhYIYNiSmmigiZlxcu9R4ewTT1oO4pPPfgV//tQX8Ib5ZXHZycP9CFFQ2gREfHLlzaQJwK24iOlQWF86i0EgMReeHMVpVNPCc664WyTkB9uOo+fhryH01LeRiKX2y3CPDNBTAyeJPcdkWT85uumprjWqs986mDGekjICvv1/b+KZvV3oUsZJxpr2YeCZHyXFPrGYnP0C5T3ZM07sq87+4v8ypSDCj9xWj1yH7Lu7cXt1smLhE29bj0/ftwH3XJ3aL4gdm8pRp+wHizGJn7AYpdhPhvTRAkD5CmhyZBUbjYokdJOM3ku+v9jZZxiGYRaA0dOOBA4hBlv+wj/GWmgsKLFPLv3HP/5xDAwM4Pvf/z527tyJm266Cffee2/Sjf/a176GXbt2Tfs6BIUXfPrTn0ZdXR0efPBB/OxnPxNj9z772c+Kfv6lTkX5WlhicUS0QLs3NcLQefml4pRkzbBFOvtBs+zR33kwjnAohqg+jIB9CLpEAoZ4Av32DoTMXkTCcbz86rGs90dzzxMBKRYM8UjWmeOr0sS+Qa9BrmPhziVnFp6zr4oRx9qrYb7vn+G69C5ojGbEe85i+JVHkn8f7lPEfpEcuyfGrR2VYv+SVZkjOysLbdDrtCJRn0q5VQ41DsGviOBBKJUAYkEhAU1OMWyrrxAX9SvOfski+CIqypOfe31D/oyFDfVx2i2LX+wTLrsRX/zoZWLiwjtuWJ68nNz867ZWjZs4QBUa912bGtG4OJ19WakQTHP2TeUroM3PXNiIG20Y8ckKrHRoRKE6fpHL+BmGYZiF4OzTkQodZVGwNzMzFkxAn8r69evFv4lSB8nBn8l1VHJzc/GRj3wEFyMldctQcSaKU3YjzvYcx7aGLeJy69o1MLicGApoEdOakNBEMZDXhbJOB7whKca9rl5Yg0bc1eXC6vhRHLKb8Fp+D0ztduw/chbXXbtu3P2NjgahSWiRQByaqAb5rvGJlssrnOINS7O+3U4T9+Aw0yJXKSseVHqKCa0tF+5r3w1TcS16H/0mhl55GNaGSxAfGUWk41SGs9/e50dXv08sMG1ekSn2qdWkrswlsyQ6vVirdA7tPiaD3IhOFGDT2/4KQ4MDKF57Kfq9IRjdxSIHYGAkVcYfCciqmIU8xlCjAcLRuBB8JWOc/aVQxp/ev/8nV1bAap7eAkZNiV30+//+1SasV/JFFmMZfyiuTy7nm8uXwxuKIHZ6t7xAo8WXf3EY+0/14fYrh/Gum2T+BTHslULfbNSJTAOGYRiGuZCkj4FlvbDInX3m3FBe5EKuXx4Anu4/m7xco9Oh8C3XYtgsRY/GMILiSjfi2lQZ9EhOL2qcW3DX3/4zzhTegI3eENaFm8Xv/L3Zpzb2942I04gxiHDYlnXmuMmow6oatzifzflnmMmd/cxgOcK28jLoqjcA8Rh6fvN1BB/9CmI+DzRWF0ylstT+zVOyBWh1dY4IMhvLcqWH/2ynDDHzeEM40pgS7v2eIGzLt0Ffswl6e6rfv28ogHgCMOq1i6JKhRY2aLIBQRMIlmIZ/1x4322r8e1PbkZp/sSl7gsVdb8OkNgnNFqx/2c4+yYrznbIANbHX2rEJ772HM4ok1eGR8NpC0J8UMUwDMMsHLFPFZjMzOBn7CLAaNDBqjj1zaH+jLJd853X4VhlmTifSMRw45o1GHXJyQXkzPsc/Xj7xsvEzxvf+i7sDK5EbaIXCSphDhgxkkV0tXVLJzRq8mM0ap9QzF+2rjQjGI1hpkLtISZnP562HxMkTIyX3SeCx6LDvUA0DHPlaphu/xy0RlmOve/UQDKYLRuq2G/skmJ/18FOxEjFK/QrwWVj6R6Q0wCK3LZFs+qc55SLcGpFwlJ19mfLYhW6qtgPKmLfWFQDrcEEbV6ZEP6ExmTDqD+S3A9oEevnf2wSPw8lxf7CX7RiGIZhlj7OtFC+9KwlZnqw2L9IsOjKRd+9TxNDjzc1hvDFtr2IxWWpatzmRHVOKbx5PeJnr6sf1bn1cFlsyeCx9oob0RdwI6z09h85JXui0+nplWPNNHofgnoXbGP6YlVuuawa3/jUlbhx69Ief8jMHy7lA5/aP9QxceloLE4U3vEpGPLLYdhyB0re+Y/QKg58a/cIugaCon1kXV1O1ttfXiUXAdp6fHji5Ua8sK8tY1xktoqCdLG/mIIm811S0KfnE/gCMsDzYnf2FzNmJaAvlDAkS/gJjd6YbGdJGK1iGgrxjU9eJU47+wPwByMY8rLYZxiGYRZWNSJNUCJ0WpauM4WfsYsEXV4lyoPSyXn8xB+Fu9880o4nDr4AY5gEShz28jJoNRrkVNjQ3PA62msP4t5Nb8m4nRu3leKNUD00lkHx8+kzqXF+KoOK8DHqfdC5CiZ1zlZU5WWM5WOYyaDyrRy7KcOBHIu1fhMqPvodGNbfCI021XP86mEZTrmhoRDWLCX8RGGuBdvXFIuS/B88dliM4SOD90+urp/U2e8akKn2JYsgiV/FrWRpDKSJfX9IcfYt7OwvVujzlJyPN8I1iOeWw7Eh9RluKqkTp1G9XJQyGbQozLMiP8ciwo/OtnswrIh9uoxhGIZhFgJ5TrkAreOAvhnDKusiwVZcgSuGAtAkEni2cRd+dvAR/OTYI7APFMvfa0dRVSFdzR3LN8Cb0w+71Yz1JangJqKqyAZb5Qo4jLJUv6dNOvzpeJURZFadF9a8zBA0hpkreYrjqIqS6fLqIbkwdbnSPjLRAtTfvncr7r+uOlkOvbLKhYYKWQlApc/BcHQSZ38Rif1sZfxKtQQ7+4sbk1GLE5EyjO74c5iKqpOXW2plkG3QKj+X7Ra5jy9T9u/TbUOpMn7lwIphGIZhLjRqtZmey/gXfxo/c24oLnAhMWLGnXovnsjNw4u7DyG/ezlsozIkT6P1obrUKc5fW3sZOka60GCrhlbp8Uxn7dp6dOx+Cr0UAtWPZDkoQRUDgUH5s0XrhbMgFWLGMPP1gd/YQQ7k+LFhE9HZ50VT54hwPLetKYZvRFamZIN67q/ZWIQbLmvAS/s7sKLMCJvFAKNBi3AkjkFPcNwqqSr2F8PYvYnEPr1303v24+HUxANmcUFJ+v5gDMGwbMtID7EsL6rBiyeGgb2nYUsT+68d7sLptuHkIpqbnX2GYRhmgXDDtioMenzYuEKOCmemD4v9i4QStxlPh1Yg0FqOlc1S1BMaxFBnOoVnwqV4V7ET8fAIzHoTPrzlfnR3y3nkY6EDw46XNIhpI9DFDBjqD6BUMUuH+oNIhHUi0d+s8S4qp5NZXKVcM3H2D56WORXLyh1CyPrkwIhJoTRyKt+n9wE5/pRe3zMURL8ngMK0TEkSycmAPmV+/WJAHYk54AmLx0Dz1SkLQXX200L6mUWGySDbV+g1HRdi6S6FNyiDKu0WwxhnfxihcCTNRUlVfTAMwzDMhYJCvWsLtShehFNyLjRcxn+RQCXJTYmV8Mal0Debgyh2nsVdOQ+jXxOC3+BCQe70nByqABgOFCFokyPJmlrT5pArZf0++xA0EdOiCixjFgckwmcq9hs7pbqvKZn94lOeMgmgX2lTURkeDSEQikGzyMR+rsMo8gjC0Tg83jB8gUiysiHbWEJm8WA2yq/2UDie9fdetV1DcfbrK2QFVs+gHx6lYkZ9nzEMwzAMs3jhI7qLCFNlHoaaTuEjjj/CpJWOTcRWiOeHV6G6dPozlSntOWCtgEbXDYzmo61dukREW4ucY+5zDgDDdunsR8b39TPMXPu2Jgroy0ZTp1yYqii0zXnsn0jkL0/1tNO8cqIozyzGXC6mILdch1mMMewd8ie33WE1LNqxc0ymsz+2jH+s2FcnpZDDX5hrRu9QUAT1UbuLy25Cn8ydZBiGYRhmkcLO/kXEjs3lOBPLw87Y2uRlOw07EIMOFYUzcyTNRZWwG6TIH+qSTmcinkBXm5xPrrf0whdzoID7Ppl5Rk0J7xueXokxZUo0d0lnv7zAOicnPFsi/5n24WR45WJDrUQgsT/ql4sndk7iXxI9+0Qokt3Z941x9onq4tT+m+s08yxjhmEYhlkCsNi/iLhmSyVK8y34/ehKtBbtQGfVjfhdo0WMM7t648xS86tKHDBD9ilHvQZ4hgLo7RlFNJQQ/fr5un7ELbnQ6XgXY+aXujKXOKX+ea9Sej4ZvcNBhMIx4VwX5ZrnQexnlvGfaVPEfppYWiwU5kqx3zPgh1cR++TsM4sbGqk3LWd/ArGfr1TPMAzDMAyzuGEldhFBTs1br6xAAhr8++ka/Ptxmar39hsaUJY/M8eTXMxo0AavU/br7/zDSbScGUj265eHI9C6eOweM/9QebHqSJ9pk20jk9HWK2uRq4odoh99zmKfyvjTOLuInf3yIhl0c7J1SIwVJOxWdvYXO6aksz+B2A9mc/ZToUfcr88wDMMwSwMW+xcZ6+pysLrWLUK5aDRTbZkLd1+zbMa3U15oxZC3GL1lJ8TPh95ox/49bcl+/aJQDMaCynnffoYhllfKQLFTrVJoT0a70nhM+/pcyEvv2VcY8UXQ7wmKoLvKRSj2NysjbA6c6hVBg2oSP7O4MSed/SnK+JWefaKy0Ap1LUzNxWAYhmEYZnHDYv8ig4K33nfrqqTT/+dv3yjK+GcTABXPrUe+vh+e3C4kEkCPknhOYl/rt6OoYG7iimEmYllS7E/f2a8pSY2cnIuzT8n1kagUUS09spWlNN+e7JNeTNSV5cBpNYhpAruPdInLaDQhs0Sc/QnL+CMZo/fU61QWy/cIO/sMwzAMszRgsX8RsqI6D5//4Db8xT0rUFM6e0FeVlGMylENespPIqGR87lj2iiMxkH0hdwyiZ9hzgENlTnJ8nOaET8Zbb1SkFfPYV9Xk8uNem3G2D9V7NeXy+1ZbFBbw9q61Ix1wpEmAJnFHtA3XuzT+yVbzz5x1cYy0e+/rj7/PG0pwzAMwzDnEhb7FylbVxVjeeXcnE4SOLohN8IWH4bzZQm/3zGIsnAErdH8ZD8ww8w3deU5ouSYSs8HJxnBN+ILY1iZG15T6pxzVYxbmQSgjv1r6VbEfsXirWJZV5u5UME9+0spoG98GT+5/dFYYlzPPnHPWxrw3U9tQX3F4ly8YhiGYRgmExb7zJzEfru/HKXBCLoqjmOwvAndlcdRGoqgR1uIikLHhd5EZolCbSTqGL3mLjnuMRtNnR5xWuy2wmqeu2Odr5Q3qwsMrYqzT4sPi5VV1S7odangQu7ZX9oBfSPK1AVq31IXBdKZS4glwzAMwzALCxb7zKypLnWiKV6MVd4w4vooOkuPIWTxojCUgK2ojA8amXNKTYmsHGnqkoJ7MrE/l3aVdNw55qSz7/GmqgrUcYCLteR7TV2qbJt79pdSQN94sT/qk/us02YQ1SoMwzAMwyxdWOwzs8Zs1KO6qhjukcwwp4TPgdqyuZVMM8z0xf5kzv7IvIr9grQy/jPKyL2yAtu8VA1cSC5ZlRqTyc7+UnL241lbWwhe1GEYhmGYpQ+LfWbOo7v6fcUoCCujnKJxDATdqC3lfn3m3FJTIgMgm3t8eHl/Bz7ylWfxtV8ew9BoUFweiyeSaf1z7ddXUVPKqXx/5772RV/Cr3LJyuLk+fSEdmaRB/Rlc/aVMn6nzXTet4thGIZhmPMLi31mTmxeUYRTkWKs8coZ3WWhCFpj+ahVXFeGOVcU51lgMekRjsTx9Z+/ga5+H850jOKv/v1lnGgexLceOoH2Xq8YMdmgjOqbK/nK/PGznV7sfFOK/WUV83PbF5KSfBuuu6QSa2pcKMnn9+5iR+3FJ2ef0vd/8fQJPLarLaOM32HjRR2GYRiGWepkRvEyzAwhx3TQVIbLhoIIaTXYMhLEkzlVsJp512LOLZQJsbwyFwdO98Gg1+KOK2vx0ptt6B7w43P//rL4G4tJh/fdVIs8pxTpc2XdsgIxlmxoxI+CPDtcFg2u21qJpcCn374R3d3dYnGEWRpl/NSz3zsUwP/98aT4+a3X+jHil9MpuIyfYRiGYZY+rMiYOUEBTw01bnS35OOO/h744kaULKu60JvFXCS8//bV+P2uk7j7utUodttw2Uonvvf4WZxt96Ao14x/+NClMMI/b/dHlQRf+vjlQhQXFxeLUy57ZxYaZoMU+zRi78CpvuTllDMx4pNVWE4bi32GYRiGWeqw2GfmzJqaHJw6U4Jlhh60RvOxosZ9oTeJuUioLXPh7h2VQuirCeNf/cQVwu0vdsZRWexEd/f8iX2GWQyYjKkOvX0nejLE/qhPOvss9hmGYRhm6cM9+8ycWVXlwq7QCrwYXIEnApuwomrx9zAzixezSY/ta0qSIWUMc7Gh12nFP+LAqd7k5VTxogb0cRk/wzAMwyx9WOwzc8Zm0aOysgiP+LdiSF+A8kLHhd4khmGYixrKqyACoVjWMn4HO/sMwzAMs+Rhsc/MC1tWyjndNHKPgtMYhmGYC1vholJRZBfBiyO+MFp7vOIyJzv7DMMwDLPk4Z59Zl6446o6kfy8tmp+Us8ZhmGY2WM2pr7eNzYUAolutPX6EY7EUj37MVnSzzAMwzDM0oSdfWbeUsrfe+sqlOZbL/SmMAzDXPRY05z91bVuVBbJEEsVLuNnGIZhmKUPi32GYRiGWWKYlZ59VexXpYl9jQawmXlkJMMwDMMsdVjsMwzDMMwSLeOvKHLAZTdliH2bWc/ZKgzDMAxzEcBin2EYhmGWYGsVsabWLU7LC6xJgW+3cFwPwzAMw1wMsNhnGIZhmCXGlRvKUJpvwQ3bqsTPRoMWlUWOpLPPMAzDMMzSh7/xGYZhGGaJsXV1MSrdQHFxTvKy+vIcNHeNsLPPMAzDMBcJ7OwzDMMwzEXA+mX54rTYbbnQm8IwDMMwzHmAl/cZhmEY5iLgqo3lKC90wKz1X+hNYRiGYRjmPMDOPsMwDMNcBFBAX31FDvQ6/upnGIZhmIsB/sZnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglBot9hmEYhmEYhmEYhllisNhnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglBot9hmEYhmEYhmEYhllisNhnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglhiaRSCQu9EYw555oNAq9Xp88Tb9sqt9P97LzdZ0Led+LbXsv1vtebNt7sd73Ytvei/W+F9v28nPF973Utvdive/Ftr0X630vtu2NzuB2lgIs9hmGYRiGYRiGYRhmicFl/AzDMAzDMAzDMAyzxGCxzzAMwzAMwzAMwzBLDBb7DMMwDMMwDMMwDLPEYLHPMAzDMAzDMAzDMEsMFvsMwzAMwzAMwzAMs8Rgsc8wDMMwDMMwDMMwSwwW+wzDMAzDMAzDMAyzxGCxzzAMwzAMwzAMwzBLDBb7DMMwDMMwDMMwDLPEYLHPMAzDMAzDMAzDMEsMFvsMwzAMwzAMwzAMs8Rgsc8wDMMwDMMwDMMwSwwW+wzDMAzDMAzDMAyzxNBf6A1Y7MRiMbzwwgvYtWsX+vv7YTQaxeXhcFicTyQSCAaD4pT+MQzDMAzDMAzDMEsTm82GkpISnDlzBnfffTd+85vfzPg29Ho9zGYz4vE4IpEI8vLysGPHDlx77bXQaDTTvh129ufIY489hkceeQSbNm3CunXrEAgEkkKfztM/epHoZ6028+ke+zPDMAzDMAzDMAyzeDEYDELoE6QT0ykuLs74mRYFSNQTFoslefnq1avh9XqF0He73di2bRsefvhhPPXUUzPaFlabc4BE/XPPPYfrr78eN910Ew4cOIAbbrgB73znO+Hz+bBhw4bk39JlqrOvrsZM5fSnv+AMwzAMwzAMwzDMwmZ4eDh5fqzes9vtSdP3iiuuQF9fH/70T/9U/EwmsaoTabGABP573/tedHd3o66uTvz8/PPPz2hbWOzPARL09CJt3rw547zT6RS/p1UYKuMgaGVGPV9VVSVOye1XX3Cr1Zq83WyLAeplVNIxGdnKOqa6DsMwDMMwDMMwzFJFM4PS9/m4L/X+yOVPp7W1FTk5OaLym06j0agwkOln4tZbbxWnb33rW3HXXXclKwFoAUGn04m/nwks9udAbm4u7r//flRWVmacb2xsFL+n1Rd68YiGhobkefobglZw1MvUkn51oYCgso3p7JjqggEx3VwAtVyEYRiGYRiGYRhmKZOYY3baVOZpunFL96WavKTniPRcNxLupPHUknwqz1f1WX19fdI0pj79/fv3i597e3uxe/duXHXVVTPabhb788zZs2fxhz/8AWvXrhUvJv0rKChInqcVnNdee038La3g0GW085DzTy86rdjQDkLin8L/6Dxdru6g2VZz1AWDiZjNdRiGYRiGYRiGYRgknXcimxlbVlaWPE96Tv17k8mUIfrH3ub69etFmT5x4403ZmS6ka58+umnxfknn3wSpaWlon18JrDYn0dOnjyJ7373u8jPzxcl/XReffHV86Ojo+L3RCgUEqck6mmnSO/xSN+hVME/EbMR7um3zzAMwzAMwzAMw2RnrDYby+nTp5PnKyoqxDS2dLGfLtLVKgHSdwMDA8nbS89ra2trE/qRHP5PfOIT+MAHPiBu88tf/jJGRkYwXVjszxOvvvqqeEHIxb/yyivx3//93+I8lWwcPHgwWdpBLyL9nlAFPK3guFyuCcfzTST0z2fvCcMwDMMwDMMwDDM5zc3NycUBVZg/88wzGVXXW7duFfqwvb1dmL60KEDn0ye+kZb83Oc+J9x/ag//5Cc/iaGhITHyfbqw2J8HHn/8cfzkJz8RffmrVq3Cr3/96+R5tUx/cHBQvKD0QtLvCRL2dBmd0u+ziXcKdZhoEWCuvScMwzAMwzAMwzDM+YP0H1V7U8A7CX0S8qrue+WVV8R5av1+//vfn5HnVlhYKPr6SfBPFxb7c4T6KKiH4tJLLxUCn/r108+TY089Glu2bBHBfFSqQas0BIl7Ks2glR+qABg7mo9eUJX0hYD0Xo6xqGEQ6fAIP4ZhGIZhGIZhmJlVSWfTXWMT9rOh6j1Vm6kt2yTeyQw+fvx4sp2b/obau0n8v/766+JyEvQvvvhixm1SDz+V8peXl2O6aBJsD8+anp4efOELXxCi/LbbbsMPf/hDsQpD/fpPPPEEHA6HWLVRV3D8fn+GoKd/3DvPMAzDMAzDMAyzNFixYoXIcssmsylkr7OzU5ynim8S+XRKupFMYdKSJPRXrlyJEydOYPv27WJsO/3ds88+K37/13/919NacCBY7M8Bcu4feeSRC70ZDMMwDMMwDMMwzDnCbDYnQ/cogI8C9CaChDtVbZN4ny+oUpuE/5133jmjqm0W+wzDMAzDMAzDMAyzxOCefYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglBot9hmEYhmEYhmEYhllisNhnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYugv9AYwDMMwDLN4+Ju/+Rs8+uijGZcZDAa4XC6sXbsW73vf+7B9+/ZZ335raysqKyvnYUsZhmEY5uKGxT7DMAzDMDPmb//2b5GbmyvOh0IhdHd34/HHHxdi//Of/zze+c53zvg2P/jBD8LpdOJb3/rWOdhihmEYhrm4YLHPMAzDMMyMue6661BeXp5x2Yc+9CF84AMfwJe+9CVs3LgRq1atmtFt7tq1C7fccss8bynDMAzDXJxwzz7DMAzDMPOC1WrFV7/6VSQSCfzgBz+40JvDMAzDMBc1LPYZhmEYhpk3qqurhatPLn0sFhOX7dmzBx/72MdEL//q1atx2WWX4TOf+Qw6OzvF79vb27F8+XJx/qmnnhLnX3/9dfEzLRz85Cc/wa233ioyAS6//HL83d/9Hfr7+y/go2QYhmGYhQ+X8TMMwzAMM680NDRg3759QsSToKdefBL5n/jEJ2A0GvHmm2+K/v7Tp0/jiSeeQF5eHr7+9a/jr/7qr7Bhwwbcf//9qKurE7dF/f8PP/wwbr/9drzrXe9CR0cHfvGLX2D37t3icjU3gGEYhmGYTFjsMwzDMAwzr1AyPzE8PIwf/ehHQpD/9Kc/hcViEZe//e1vRzQaxZNPPomenh4UFRXhzjvvFGK/tLRUnCf27t2Lhx56SIQBUvCfys0334x77rkHDzzwgJgOwDAMwzDMeLiMn2EYhmGYeYWEPKHRaPBf//Vf+N3vfpcU+oTX64XJZBLn/X7/hLfzhz/8QZxee+21GBwcTP4rKSnBsmXL8MILL5zzx8IwDMMwixV29hmGYRiGmVfI0SfI0dfpdOjq6sJ//Md/iLJ9tbSfevGJeDw+4e20tLSI0+uvvz7r7w0GwznZfoZhGIZZCrDYZxiGYRhmXjl+/Lgo5afRfD/+8Y/xla98BZWVlbjkkktwzTXXYM2aNXj55ZdFGf5k0EIAVQB8//vfP2/bzjAMwzBLBRb7DMMwDMPMG01NTTh69Cj+5E/+BOFwGN/+9rdFOj/17FM4nwoF9E1FWVmZSPWvr69HYWFhxu+ef/555OTknJPHwDAMwzBLAe7ZZxiGYRhmXgiFQviHf/gH6PV6kcAfDAYRCARQVVWVIfSpjP+ZZ54R59XxfIRWq80o63/LW94iTr/3ve9l3M+BAwdEsj+N5GMYhmEYJjvs7DMMwzAMM2OeffbZ5Ng7cvBpJB6l67e1teELX/iCCNAjyNWn8XpOp1OM5GttbcWvf/1rsQhA+Hy+5G3SCD4a2ferX/0KV155JXbs2IEbbrgBDz74oOj7v+qqqzAwMICf//zn4vY+/elPX6BHzzAMwzALH01CTchhGIZhGIaZAhp19+ijj2ZcRk6+2+3Ghg0b8J73vAdbtmxJ/o5G6331q1/F7t27hdNfXFws0vVJxN9777341Kc+hT/90z8Vf0u3+2//9m/weDz44he/iLvuuksk+//whz/EY489JhYKqHR/06ZNQujX1dWd98fPMAzDMIsFFvsMwzAMwzAMwzAMs8Tgnn2GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglBot9hmEYhmEYhmEYhllisNhnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGWWKw2GcYhmEYhmEYhmGYJQaLfYZhGIZhGIZhGIZZYrDYZxiGYRiGYRiGYZglBot9hmEYhmEYhmEYhllisNhnGIZhGIZhGIZhmCUGi32GYRiGYRiGYRiGwdLi/wO0CxBieALfvgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for algo in algos:\n",
    "    df_ret = results[algo][\"df\"]\n",
    "    cump = (df_ret[\"daily_return\"] + 1).cumprod() - 1\n",
    "    plt.plot(df_ret[\"date\"], cump, label=algo.upper())\n",
    "\n",
    "# Min-var and DJIA\n",
    "c_min = (min_var_df[\"account_value\"].pct_change() + 1).cumprod() - 1\n",
    "plt.plot(min_var_df[\"date\"], c_min, label=\"MIN_VAR\")\n",
    "c_dji = (baseline_ret + 1).cumprod() - 1\n",
    "plt.plot(baseline[\"date\"], c_dji, label=\"DJIA\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative Return Comparison\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Cumulative Return\")\n",
    "plt.savefig(\"results/cumulative_return_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3456294",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Tabulate key metrics (Sharpe, MaxDD, etc.) for each algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c101491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A2C",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PPO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SAC",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "07d6ba6a-8e65-47ae-ae21-016322929669",
       "rows": [
        [
         "Annual return",
         "0.04216432047722063",
         "0.05988297041317492",
         "0.06634727843866917"
        ],
        [
         "Cumulative returns",
         "0.055226115537146514",
         "0.07863716589470049",
         "0.08720777098413746"
        ],
        [
         "Annual volatility",
         "0.15063204667071928",
         "0.14986832342099374",
         "0.1485070263984851"
        ],
        [
         "Sharpe ratio",
         "0.3498161232280903",
         "0.46372979304245515",
         "0.5076836762831635"
        ],
        [
         "Calmar ratio",
         "0.2927233155879807",
         "0.40721541024295027",
         "0.4307242648867686"
        ],
        [
         "Stability",
         "0.6449376478744385",
         "0.6990056132330618",
         "0.6755267836616798"
        ],
        [
         "Max drawdown",
         "-0.14404155129401625",
         "-0.14705477471357953",
         "-0.15403654692198718"
        ],
        [
         "Omega ratio",
         "1.0674771858379324",
         "1.092309425437028",
         "1.1039838332132321"
        ],
        [
         "Sortino ratio",
         "0.507361363462318",
         "0.671374943802728",
         "0.7293232726537522"
        ],
        [
         "Skew",
         null,
         null,
         null
        ],
        [
         "Kurtosis",
         null,
         null,
         null
        ],
        [
         "Tail ratio",
         "0.867501368832775",
         "0.9008323481278725",
         "0.8260575224815427"
        ],
        [
         "Daily value at risk",
         "-0.018768752781779814",
         "-0.0186058466330719",
         "-0.01841094176364002"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 13
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2C</th>\n",
       "      <th>PPO</th>\n",
       "      <th>SAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>0.042164</td>\n",
       "      <td>0.059883</td>\n",
       "      <td>0.066347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>0.055226</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.087208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>0.150632</td>\n",
       "      <td>0.149868</td>\n",
       "      <td>0.148507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.349816</td>\n",
       "      <td>0.463730</td>\n",
       "      <td>0.507684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.292723</td>\n",
       "      <td>0.407215</td>\n",
       "      <td>0.430724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.644938</td>\n",
       "      <td>0.699006</td>\n",
       "      <td>0.675527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-0.144042</td>\n",
       "      <td>-0.147055</td>\n",
       "      <td>-0.154037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.067477</td>\n",
       "      <td>1.092309</td>\n",
       "      <td>1.103984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>0.507361</td>\n",
       "      <td>0.671375</td>\n",
       "      <td>0.729323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.867501</td>\n",
       "      <td>0.900832</td>\n",
       "      <td>0.826058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-0.018769</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.018411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          A2C       PPO       SAC\n",
       "Annual return        0.042164  0.059883  0.066347\n",
       "Cumulative returns   0.055226  0.078637  0.087208\n",
       "Annual volatility    0.150632  0.149868  0.148507\n",
       "Sharpe ratio         0.349816  0.463730  0.507684\n",
       "Calmar ratio         0.292723  0.407215  0.430724\n",
       "Stability            0.644938  0.699006  0.675527\n",
       "Max drawdown        -0.144042 -0.147055 -0.154037\n",
       "Omega ratio          1.067477  1.092309  1.103984\n",
       "Sortino ratio        0.507361  0.671375  0.729323\n",
       "Skew                      NaN       NaN       NaN\n",
       "Kurtosis                  NaN       NaN       NaN\n",
       "Tail ratio           0.867501  0.900832  0.826058\n",
       "Daily value at risk -0.018769 -0.018606 -0.018411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf_stats = pd.DataFrame({algo.upper(): results[algo][\"stats\"] for algo in algos})\n",
    "display(perf_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
