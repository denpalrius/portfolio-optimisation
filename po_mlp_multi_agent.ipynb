{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c5a8a",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f8e10",
   "metadata": {},
   "source": [
    "This experiement demonstrates the application of deep reinforcement learning (DRL) techniques for portfolio optimization.\n",
    "\n",
    "By leveraging state-of-the-art DRL algorithms, we aim to create a robust trading strategy that dynamically adjusts portfolio allocations to maximize returns while minimizing risks.\n",
    "\n",
    "Policy network architecture: **MLP backbone**\n",
    "\n",
    "- Compares `A2C`, `PPO`, `SAC`, `DDPG`, `TD3` all with simple MLPs\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "- Data preprocessing\n",
    "- Feature engineering\n",
    "- Environment setup\n",
    "- Training of DRL agents\n",
    "- Backtesting\n",
    "- Benchmarking against traditional strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfb03e",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b8f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy matplotlib \\\n",
    "#                stable-baselines3 \\\n",
    "#                PyPortfolioOpt \\\n",
    "#                pandas_market_calendars quantstats gymnasium \\\n",
    "#                git+https://github.com/AI4Finance-Foundation/FinRL.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "51776d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import (\n",
    "    backtest_stats,\n",
    "    get_daily_return,\n",
    "    get_baseline, backtest_plot\n",
    ")\n",
    "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import (\n",
    "    PortfolioOptimizationEnv,\n",
    ")\n",
    "from finrl.agents.portfolio_optimization.models import DRLAgent as PGAgent\n",
    "from finrl.agents.portfolio_optimization.architectures import EIIE\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9e5cf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1d8f66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f3e16a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"portfolio_optimization_mlp_multi_agent\"\n",
    "results_dir = f\"results/models/{experiment_name}\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c1461",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefbe65",
   "metadata": {},
   "source": [
    "Define training and trading/test periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "542703af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: ('2013-05-02', '2023-04-30')\n",
      "Testing period: ('2023-05-01', '2025-04-29')\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2015-01-01\"\n",
    "end_date = (datetime.now() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")  # Yesterday\n",
    "\n",
    "trade_period = 2  # 2 years for testing\n",
    "train_period = 10  # 10 years for training\n",
    "\n",
    "train_end_date = (\n",
    "    datetime.strptime(end_date, \"%Y-%m-%d\") - timedelta(days=trade_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "train_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") - timedelta(days=train_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "test_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") + timedelta(days=1)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "train_dates = (train_start_date, train_end_date)\n",
    "test_dates = (test_start_date, end_date)\n",
    "\n",
    "print(f\"Training period: {train_dates}\")\n",
    "print(f\"Testing period: {test_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a425c",
   "metadata": {},
   "source": [
    "- Fetch historical stock data for a given list of tickers within a specified date range.\n",
    "- We use the DOW_30_TICKER stocks\n",
    "- The data includes `date`, `close`, `high`, `low`, `open`, `volume`, and `tic` (ticker symbol).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "46c577ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2015-01-01 → 2025-04-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (76791, 8)\n"
     ]
    }
   ],
   "source": [
    "def download_data(tickers, start_date, end_date):\n",
    "    print(f\"Downloading {start_date} → {end_date}\")\n",
    "    return YahooDownloader(\n",
    "        start_date=start_date, end_date=end_date, ticker_list=tickers\n",
    "    ).fetch_data()\n",
    "\n",
    "\n",
    "df = download_data(config_tickers.DOW_30_TICKER, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb738f",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We apply feature engineering to the dataset of stock data:\n",
    "\n",
    "- Add technical indicators (e.g., moving averages, RSI).\n",
    "- Calculate turbulence indicators, which measure market volatility.\n",
    "\n",
    "This Enhance the dataset with features that are critical for modeling market dynamics and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "47dcd423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=True)\n",
    "    return fe.preprocess_data(df)\n",
    "\n",
    "\n",
    "df_feat = preprocess_data(df)\n",
    "\n",
    "# TODO: Normalise the data??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdeb82",
   "metadata": {},
   "source": [
    "## Covariance & Returns for State\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002710f6",
   "metadata": {},
   "source": [
    "- Calculate the rolling covariance matrices and daily returns for the given dataset of stock prices.\n",
    "- This prepares the state representation (the state of the portfolio) for the RL models in the RL environments for portfolio optimization.\n",
    "- The **rolling covariance matrices** (`cov_list`) capture the relationships between asset returns, while the daily returns (`return_list`) provide information about recent price movements.\n",
    "- These metrics are critical for modeling the dynamics of the financial market and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "48b6f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance_and_returns(df_feat, lookback=252):\n",
    "    df_sorted = df_feat.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df_sorted.index = df_sorted.date.factorize()[0]\n",
    "    cov_list, return_list = [], []\n",
    "\n",
    "    dates = df_sorted.date.unique()\n",
    "    for i in range(lookback, len(dates)):\n",
    "        win = df_sorted.loc[i - lookback : i]\n",
    "        pm = win.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        rm = pm.pct_change().dropna()\n",
    "        cov_list.append(rm.cov().values)\n",
    "        return_list.append(rm)\n",
    "    df_cov = pd.DataFrame(\n",
    "        {\"date\": dates[lookback:], \"cov_list\": cov_list, \"return_list\": return_list}\n",
    "    )\n",
    "\n",
    "    return pd.merge(df_feat, df_cov, on=\"date\", how=\"left\").dropna(subset=[\"cov_list\"])\n",
    "\n",
    "\n",
    "df_all = compute_covariance_and_returns(df_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7d720",
   "metadata": {},
   "source": [
    "## Train/Trade split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "886a8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_all, train_dates, test_dates):\n",
    "    train = data_split(df_all, *train_dates)\n",
    "    test = data_split(df_all, *test_dates)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_df, test_df = split_data(df_all, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bcfe",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273f79",
   "metadata": {},
   "source": [
    "- Create instances of the **PortfolioOptimizationEnv** class for both training and testing datasets.\n",
    "- It also wrap the training environment for use with Stable-Baselines3 (SB3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1bd7cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_portfolio_env(df):\n",
    "    env = PortfolioOptimizationEnv(\n",
    "        df,\n",
    "        initial_amount=100_000,\n",
    "        comission_fee_pct=0.0025,\n",
    "        time_window=50,\n",
    "        features=[\"close\", \"high\", \"low\"],\n",
    "        normalize_df=None,\n",
    "        new_gym_api=True,\n",
    "    )\n",
    "\n",
    "    env.df = df.reset_index(drop=True)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "train_env = initialize_portfolio_env(train_df)\n",
    "test_env = initialize_portfolio_env(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "fc0449b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent = DRLAgent(train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6387a",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b89e4",
   "metadata": {},
   "source": [
    "Configure model algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2434d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_configs():\n",
    "    model_configs = [\n",
    "        (A2C, \"A2C\", {}),\n",
    "        (PPO, \"PPO\", {}),\n",
    "        (SAC, \"SAC\", {}),\n",
    "        (DDPG, \"DDPG\", {}),\n",
    "        (TD3, \"TD3\", {}),\n",
    "    ]\n",
    "\n",
    "    return model_configs\n",
    "\n",
    "\n",
    "model_configs = prepare_model_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1272b4",
   "metadata": {},
   "source": [
    "Train multiple reinforcement learning (RL) models using the specified training environment and configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e6e331f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(agent, model_configs, results_dir, total_timesteps=200_000):\n",
    "    training_times = {}\n",
    "    trained_models = {}\n",
    "    for model_class, model_name, model_kwargs in model_configs:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            model_kwargs=model_kwargs,\n",
    "            policy_kwargs=model_kwargs.get(\"policy_kwargs\", {}),\n",
    "        )\n",
    "\n",
    "        trained_model = agent.train_model(\n",
    "            model,\n",
    "            tb_log_name=f\"{experiment_name}_{model_name.lower()}\",\n",
    "            total_timesteps=total_timesteps,\n",
    "        )\n",
    "\n",
    "        model_path = f\"{results_dir}/{model_name.lower()}_model\"\n",
    "        trained_model.save(model_path)\n",
    "\n",
    "        trained_models[model_name] = trained_model\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_times[model_name] = (\n",
    "            end_time - start_time\n",
    "        ) / 60  # Training time in minutes\n",
    "        print(\n",
    "            f\"{model_name} training completed in {training_times[model_name]:.2f} minutes.\"\n",
    "        )\n",
    "\n",
    "    return trained_models, training_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training A2C...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 89          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.819      |\n",
      "|    reward             | 0.015592448 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000534    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -3.46        |\n",
      "|    reward             | -0.029930312 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.0071       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.289       |\n",
      "|    reward             | -0.002992932 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 8.89e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 42203.0390625\n",
      "Final accumulative portfolio value: 0.42203038930892944\n",
      "Maximum DrawDown: -0.6194825718698154\n",
      "Sharpe ratio: -0.5853808582439327\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.855      |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.411      |\n",
      "|    reward             | 0.003468927 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.00011     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.855       |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.359        |\n",
      "|    reward             | -0.025241064 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000709     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.855       |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.241       |\n",
      "|    reward             | 0.0051872665 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 3.85e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.855      |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0513      |\n",
      "|    reward             | 0.018293824 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 3.67e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 45861.00390625\n",
      "Final accumulative portfolio value: 0.45861002802848816\n",
      "Maximum DrawDown: -0.5858933098046528\n",
      "Sharpe ratio: -0.5145710776428546\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.813       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | 0.0015994625 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.55e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.813      |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.0198     |\n",
      "|    reward             | 0.004208637 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.13e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.813        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.164         |\n",
      "|    reward             | -0.0015821449 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 6.89e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 66281.75\n",
      "Final accumulative portfolio value: 0.6628174781799316\n",
      "Maximum DrawDown: -0.4543703249694079\n",
      "Sharpe ratio: -0.23114631474365555\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.676        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 60            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.215        |\n",
      "|    reward             | -0.0024053152 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.7e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.676       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.536        |\n",
      "|    reward             | 0.0075409277 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000211     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.676       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.00488     |\n",
      "|    reward             | 0.0014668668 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.676        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 76            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.557         |\n",
      "|    reward             | -0.0068232813 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 76036.6953125\n",
      "Final accumulative portfolio value: 0.7603669762611389\n",
      "Maximum DrawDown: -0.4066707831295555\n",
      "Sharpe ratio: -0.1255673249303122\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.574       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.00289      |\n",
      "|    reward             | -0.006149445 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.14e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.574        |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0192       |\n",
      "|    reward             | -0.0009429727 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.37e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.574        |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.132        |\n",
      "|    reward             | -0.0073445076 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.92e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 84717.515625\n",
      "Final accumulative portfolio value: 0.8471751809120178\n",
      "Maximum DrawDown: -0.42302071382988715\n",
      "Sharpe ratio: -0.036987051911661475\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.49         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 97            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.0796        |\n",
      "|    reward             | 0.00015996608 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 9.76e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.49        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.567        |\n",
      "|    reward             | 0.0011258937 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.49       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 2.93        |\n",
      "|    reward             | 0.034614798 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00577     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.49        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.0753      |\n",
      "|    reward             | -0.012358423 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.69e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 111157.59375\n",
      "Final accumulative portfolio value: 1.111575961112976\n",
      "Maximum DrawDown: -0.3584738002635496\n",
      "Sharpe ratio: 0.17314460064921708\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.39       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.005130578 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.00014     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.39       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.286      |\n",
      "|    reward             | 0.014133595 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 7.15e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.39        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.416        |\n",
      "|    reward             | 0.0011594724 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000167     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.39         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 131           |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.362        |\n",
      "|    reward             | -0.0033078603 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 8.13e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 116969.4375\n",
      "Final accumulative portfolio value: 1.169694423675537\n",
      "Maximum DrawDown: -0.3518820124373938\n",
      "Sharpe ratio: 0.21204287289366291\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.31       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.289      |\n",
      "|    reward             | 0.004964169 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 5.95e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | -0.31          |\n",
      "| time/                 |                |\n",
      "|    fps                | 94             |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 142            |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2699           |\n",
      "|    policy_loss        | -0.779         |\n",
      "|    reward             | -0.00092179334 |\n",
      "|    std                | 0.997          |\n",
      "|    value_loss         | 0.000405       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.31         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 147           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -0.966        |\n",
      "|    reward             | 0.00033313446 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 0.000527      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 143545.703125\n",
      "Final accumulative portfolio value: 1.4354569911956787\n",
      "Maximum DrawDown: -0.3495599136689215\n",
      "Sharpe ratio: 0.36895128785077036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.225        |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | 0.00375       |\n",
      "|    reward             | -0.0027558596 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.01e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.225        |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 157           |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.232         |\n",
      "|    reward             | -0.0011275805 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 3.59e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.225      |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 0.767       |\n",
      "|    reward             | 0.015432585 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000406    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.225       |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.931       |\n",
      "|    reward             | -0.017573083 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000611     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 132991.890625\n",
      "Final accumulative portfolio value: 1.3299188613891602\n",
      "Maximum DrawDown: -0.35600754095690956\n",
      "Sharpe ratio: 0.30984856708523206\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.167        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3300          |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 16500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3299          |\n",
      "|    policy_loss        | 0.159         |\n",
      "|    reward             | -0.0019212331 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.5e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.167      |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.0926     |\n",
      "|    reward             | 0.011656744 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 1.19e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.167        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.533         |\n",
      "|    reward             | -0.0038585505 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 126444.1015625\n",
      "Final accumulative portfolio value: 1.2644410133361816\n",
      "Maximum DrawDown: -0.35856685070674454\n",
      "Sharpe ratio: 0.2706598799577274\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.126        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 188           |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | -0.00785      |\n",
      "|    reward             | -0.0018486768 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 4.67e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.126        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 193           |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.838        |\n",
      "|    reward             | -0.0019188444 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000415      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.126       |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.353        |\n",
      "|    reward             | 0.0040957383 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.126       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.002340849 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000881     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 126861.3203125\n",
      "Final accumulative portfolio value: 1.2686132192611694\n",
      "Maximum DrawDown: -0.35592582481637225\n",
      "Sharpe ratio: 0.27319533930436163\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0924      |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.0714       |\n",
      "|    reward             | 0.0009309487 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 8.5e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0924     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.6        |\n",
      "|    reward             | 0.011192631 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000267    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0924      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | 0.0064898683 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 4.13e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0924     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.299      |\n",
      "|    reward             | 0.010687023 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.000226    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 124121.28125\n",
      "Final accumulative portfolio value: 1.2412128448486328\n",
      "Maximum DrawDown: -0.3512368658661901\n",
      "Sharpe ratio: 0.2576780631021987\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.066       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.177        |\n",
      "|    reward             | -0.007324573 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 2.6e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.066        |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | 0.305         |\n",
      "|    reward             | -0.0063065253 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 6.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.066       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.313       |\n",
      "|    reward             | -0.011577551 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 8e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129162.9765625\n",
      "Final accumulative portfolio value: 1.2916297912597656\n",
      "Maximum DrawDown: -0.34965364398762555\n",
      "Sharpe ratio: 0.2862014159363205\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0405      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | 0.0030084848 |\n",
      "|    std                | 0.992        |\n",
      "|    value_loss         | 1.27e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.873      |\n",
      "|    reward             | -0.02190463 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000519    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 2.1         |\n",
      "|    reward             | 0.018977972 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.00303     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.714      |\n",
      "|    reward             | 0.037600756 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 0.000428    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 130862.4140625\n",
      "Final accumulative portfolio value: 1.3086241483688354\n",
      "Maximum DrawDown: -0.3604165431887063\n",
      "Sharpe ratio: 0.29571252710758833\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.0178       |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 263           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.234         |\n",
      "|    reward             | -0.0029327918 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 6.73e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.0178       |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 268           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 2.38e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.314         |\n",
      "|    reward             | 0.00028618056 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 9.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0178      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0843      |\n",
      "|    reward             | 0.0063689356 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 6.62e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140654.609375\n",
      "Final accumulative portfolio value: 1.4065461158752441\n",
      "Maximum DrawDown: -0.3520683914211825\n",
      "Sharpe ratio: 0.35185307208547195\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.00669      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.121        |\n",
      "|    reward             | 0.0029016319 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 1.79e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.00669      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.365        |\n",
      "|    reward             | 0.0029636768 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 0.00019      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.00669     |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.020141479 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 6.56e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.00669       |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.47         |\n",
      "|    reward             | -0.0030052476 |\n",
      "|    std                | 0.995         |\n",
      "|    value_loss         | 0.000256      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 127673.953125\n",
      "Final accumulative portfolio value: 1.276739478111267\n",
      "Maximum DrawDown: -0.3540426422134306\n",
      "Sharpe ratio: 0.2783415793240773\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | -0.015962124 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.942       |\n",
      "|    reward             | 0.0077071446 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000483     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.223       |\n",
      "|    reward             | 0.0070565525 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 4e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 125440.390625\n",
      "Final accumulative portfolio value: 1.2544039487838745\n",
      "Maximum DrawDown: -0.35620513352884686\n",
      "Sharpe ratio: 0.26514735070331463\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.647      |\n",
      "|    reward             | 0.008003428 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0347       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.125       |\n",
      "|    reward             | -0.005868934 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.0646      |\n",
      "|    reward             | -0.07350705 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | 0.017904563 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 128395.625\n",
      "Final accumulative portfolio value: 1.2839562892913818\n",
      "Maximum DrawDown: -0.3458452419568666\n",
      "Sharpe ratio: 0.2837786885023362\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.0471         |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 6500           |\n",
      "|    time_elapsed       | 333            |\n",
      "|    total_timesteps    | 32500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6499           |\n",
      "|    policy_loss        | -0.0929        |\n",
      "|    reward             | -0.00024977466 |\n",
      "|    std                | 0.995          |\n",
      "|    value_loss         | 3.29e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | 0.0051692403 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | -0.615       |\n",
      "|    reward             | 0.0025110878 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -1.05        |\n",
      "|    reward             | 0.0054233563 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000783     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 130804.1640625\n",
      "Final accumulative portfolio value: 1.3080416917800903\n",
      "Maximum DrawDown: -0.34228509709215793\n",
      "Sharpe ratio: 0.296825128629583\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.0798       |\n",
      "|    reward             | 0.0011206544 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 9.49e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | 0.0061891084 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 4.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.396        |\n",
      "|    reward             | 0.0005389192 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 127168.0078125\n",
      "Final accumulative portfolio value: 1.2716801166534424\n",
      "Maximum DrawDown: -0.3596773572110177\n",
      "Sharpe ratio: 0.2771482216946849\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.398       |\n",
      "|    reward             | 0.0023423398 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | 0.18         |\n",
      "|    reward             | 0.0029579718 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 7.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -0.318       |\n",
      "|    reward             | 0.0008924792 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 6.81e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.0687        |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 1.03          |\n",
      "|    reward             | -0.0077558937 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.000609      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 128222.359375\n",
      "Final accumulative portfolio value: 1.2822235822677612\n",
      "Maximum DrawDown: -0.34373425571461413\n",
      "Sharpe ratio: 0.28425737660550493\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.0777        |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 389           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | -0.0637       |\n",
      "|    reward             | -0.0092035765 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 5.71e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0777       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.375        |\n",
      "|    reward             | -0.003449422 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | 0.0777    |\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -0.228    |\n",
      "|    reward             | 0.0160957 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 3.59e-05  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 138982.25\n",
      "Final accumulative portfolio value: 1.3898224830627441\n",
      "Maximum DrawDown: -0.33196688210943404\n",
      "Sharpe ratio: 0.34749508895763503\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.308       |\n",
      "|    reward             | -0.004431875 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 6.33e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.0895         |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 8000           |\n",
      "|    time_elapsed       | 409            |\n",
      "|    total_timesteps    | 40000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7999           |\n",
      "|    policy_loss        | 0.385          |\n",
      "|    reward             | -0.00083511166 |\n",
      "|    std                | 0.999          |\n",
      "|    value_loss         | 0.000148       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.027833818 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 420          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.586       |\n",
      "|    reward             | 0.0088782795 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000188     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150584.34375\n",
      "Final accumulative portfolio value: 1.5058434009552002\n",
      "Maximum DrawDown: -0.34707410719884935\n",
      "Sharpe ratio: 0.40717694200805654\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.104       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.558       |\n",
      "|    reward             | 0.001215077 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.104       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | 0.002215195 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 7.89e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.104          |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 8500           |\n",
      "|    time_elapsed       | 436            |\n",
      "|    total_timesteps    | 42500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8499           |\n",
      "|    policy_loss        | 0.785          |\n",
      "|    reward             | -0.00012195854 |\n",
      "|    std                | 0.998          |\n",
      "|    value_loss         | 0.000446       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.104        |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.006812359 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 2.92e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 153761.28125\n",
      "Final accumulative portfolio value: 1.537612795829773\n",
      "Maximum DrawDown: -0.34008839976226757\n",
      "Sharpe ratio: 0.4214480430552383\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.118        |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.0107      |\n",
      "|    reward             | 0.0067299134 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.27e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.118       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 452         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.255      |\n",
      "|    reward             | 0.008403654 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000121    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.118      |\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 458        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -1.37      |\n",
      "|    reward             | 0.01119546 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 0.00117    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140565.15625\n",
      "Final accumulative portfolio value: 1.405651569366455\n",
      "Maximum DrawDown: -0.35708407826606703\n",
      "Sharpe ratio: 0.3519841532714884\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.127         |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 464           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.0977        |\n",
      "|    reward             | -0.0040004295 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 9.16e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.127        |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 469          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.196       |\n",
      "|    reward             | -0.021341236 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.66e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.127       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.739       |\n",
      "|    reward             | 0.016495282 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.000387    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.127      |\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 480        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -1.65      |\n",
      "|    reward             | 0.02571982 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.00194    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140039.0625\n",
      "Final accumulative portfolio value: 1.400390625\n",
      "Maximum DrawDown: -0.35194919906794453\n",
      "Sharpe ratio: 0.3507700881447386\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.135        |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 488          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.018        |\n",
      "|    reward             | 0.0006462631 |\n",
      "|    std                | 0.999        |\n",
      "|    value_loss         | 2.44e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.135       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.992      |\n",
      "|    reward             | 0.014292257 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.000508    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.135       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | 0.006407787 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 4.86e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 154017.171875\n",
      "Final accumulative portfolio value: 1.54017174243927\n",
      "Maximum DrawDown: -0.34980522965350014\n",
      "Sharpe ratio: 0.42101892146439207\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.147        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 505          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | -0.007876579 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 4.02e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.44       |\n",
      "|    reward             | 0.004107017 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 1.85        |\n",
      "|    reward             | 0.023079114 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 520         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -0.896      |\n",
      "|    reward             | 0.015103857 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000609    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 143596.125\n",
      "Final accumulative portfolio value: 1.4359612464904785\n",
      "Maximum DrawDown: -0.3562998409309548\n",
      "Sharpe ratio: 0.36760496983263513\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.155         |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 10100         |\n",
      "|    time_elapsed       | 526           |\n",
      "|    total_timesteps    | 50500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10099         |\n",
      "|    policy_loss        | 0.0807        |\n",
      "|    reward             | 0.00093368796 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 8.26e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.155        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -0.153       |\n",
      "|    reward             | 0.0019317077 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 6.2e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.155        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10300        |\n",
      "|    time_elapsed       | 538          |\n",
      "|    total_timesteps    | 51500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -0.66        |\n",
      "|    reward             | 0.0025957483 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000327     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.155      |\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | 0.248      |\n",
      "|    reward             | 0.00127556 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 7.04e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129229.4375\n",
      "Final accumulative portfolio value: 1.2922943830490112\n",
      "Maximum DrawDown: -0.3588775663346685\n",
      "Sharpe ratio: 0.287587057776887\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.159        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10500        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 52500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10499        |\n",
      "|    policy_loss        | 0.0225       |\n",
      "|    reward             | 0.0008219678 |\n",
      "|    std                | 0.999        |\n",
      "|    value_loss         | 6.08e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.159       |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 0.0274      |\n",
      "|    reward             | 0.004208755 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 2.2e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.159      |\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | -0.0232    |\n",
      "|    reward             | -0.0080957 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 7.13e-06   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 138972.84375\n",
      "Final accumulative portfolio value: 1.3897284269332886\n",
      "Maximum DrawDown: -0.35485688869471077\n",
      "Sharpe ratio: 0.342904792976134\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.165          |\n",
      "| time/                 |                |\n",
      "|    fps                | 95             |\n",
      "|    iterations         | 10800          |\n",
      "|    time_elapsed       | 567            |\n",
      "|    total_timesteps    | 54000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 10799          |\n",
      "|    policy_loss        | 0.0508         |\n",
      "|    reward             | -1.6331805e-05 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 3.49e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.165        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | -0.008907293 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000278     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.165        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | 1.28         |\n",
      "|    reward             | -0.012402537 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.165         |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 11100         |\n",
      "|    time_elapsed       | 584           |\n",
      "|    total_timesteps    | 55500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11099         |\n",
      "|    policy_loss        | 0.528         |\n",
      "|    reward             | -0.0035754507 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000217      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 165873.390625\n",
      "Final accumulative portfolio value: 1.6587339639663696\n",
      "Maximum DrawDown: -0.3561764780241655\n",
      "Sharpe ratio: 0.47647295072425966\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.176         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11200         |\n",
      "|    time_elapsed       | 590           |\n",
      "|    total_timesteps    | 56000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11199         |\n",
      "|    policy_loss        | 0.213         |\n",
      "|    reward             | -0.0029642365 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.85e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.176        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 0.0864       |\n",
      "|    reward             | -0.004045792 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 8.6e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.176       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | -0.438      |\n",
      "|    reward             | 0.007732341 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 164032.15625\n",
      "Final accumulative portfolio value: 1.6403216123580933\n",
      "Maximum DrawDown: -0.3588011620144612\n",
      "Sharpe ratio: 0.4665900428480805\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.186        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 606          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.002180568 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11600         |\n",
      "|    time_elapsed       | 612           |\n",
      "|    total_timesteps    | 58000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11599         |\n",
      "|    policy_loss        | 0.368         |\n",
      "|    reward             | 0.00021157411 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11700         |\n",
      "|    time_elapsed       | 617           |\n",
      "|    total_timesteps    | 58500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11699         |\n",
      "|    policy_loss        | -0.726        |\n",
      "|    reward             | -0.0042642546 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000322      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11800         |\n",
      "|    time_elapsed       | 622           |\n",
      "|    total_timesteps    | 59000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11799         |\n",
      "|    policy_loss        | -0.0583       |\n",
      "|    reward             | -0.0017226863 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 5.2e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 178872.375\n",
      "Final accumulative portfolio value: 1.7887237071990967\n",
      "Maximum DrawDown: -0.3549404799894449\n",
      "Sharpe ratio: 0.5346801891763973\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.198        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 628          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.17        |\n",
      "|    reward             | 0.0056288075 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 1.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.198       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 633         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.511      |\n",
      "|    reward             | 0.008489827 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000229    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.198       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 639         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | 0.0359      |\n",
      "|    reward             | -0.01387401 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.94e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 172574.109375\n",
      "Final accumulative portfolio value: 1.7257411479949951\n",
      "Maximum DrawDown: -0.34605314908286766\n",
      "Sharpe ratio: 0.5096920167663502\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.209        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12200        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 61000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | 0.0011156532 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.209       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12300       |\n",
      "|    time_elapsed       | 650         |\n",
      "|    total_timesteps    | 61500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 0.248       |\n",
      "|    reward             | 0.002526427 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.52e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.209        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12400        |\n",
      "|    time_elapsed       | 656          |\n",
      "|    total_timesteps    | 62000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | 1.49         |\n",
      "|    reward             | -0.054196123 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.209         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 12500         |\n",
      "|    time_elapsed       | 661           |\n",
      "|    total_timesteps    | 62500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12499         |\n",
      "|    policy_loss        | 0.501         |\n",
      "|    reward             | -0.0066839415 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000274      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 162369.109375\n",
      "Final accumulative portfolio value: 1.6236910820007324\n",
      "Maximum DrawDown: -0.3458314194077733\n",
      "Sharpe ratio: 0.46651864791749537\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.217         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 12600         |\n",
      "|    time_elapsed       | 667           |\n",
      "|    total_timesteps    | 63000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | 0.114         |\n",
      "|    reward             | -0.0028549018 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.91e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.217        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12700        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 63500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12699        |\n",
      "|    policy_loss        | 0.982        |\n",
      "|    reward             | 0.0020724502 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.217       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 678         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | -0.01260726 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.73e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.217        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 683          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | -0.798       |\n",
      "|    reward             | -0.012247453 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000598     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184883.21875\n",
      "Final accumulative portfolio value: 1.848832130432129\n",
      "Maximum DrawDown: -0.3464806048397485\n",
      "Sharpe ratio: 0.5624926206269237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.228         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13000         |\n",
      "|    time_elapsed       | 689           |\n",
      "|    total_timesteps    | 65000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12999         |\n",
      "|    policy_loss        | -0.392        |\n",
      "|    reward             | 0.00041345155 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 9.14e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.228       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 695         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | 0.0585      |\n",
      "|    reward             | 0.008829598 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.49e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.228        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 700          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 0.67         |\n",
      "|    reward             | -0.011907138 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 211704.609375\n",
      "Final accumulative portfolio value: 2.1170461177825928\n",
      "Maximum DrawDown: -0.34749542139225464\n",
      "Sharpe ratio: 0.6605597220083652\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13300         |\n",
      "|    time_elapsed       | 706           |\n",
      "|    total_timesteps    | 66500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13299         |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | 0.00092606567 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 1.65e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13400         |\n",
      "|    time_elapsed       | 711           |\n",
      "|    total_timesteps    | 67000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13399         |\n",
      "|    policy_loss        | 0.0619        |\n",
      "|    reward             | -0.0002829833 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.96e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.242       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 13500       |\n",
      "|    time_elapsed       | 717         |\n",
      "|    total_timesteps    | 67500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | -0.334      |\n",
      "|    reward             | 0.009027854 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9.53e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 13600         |\n",
      "|    time_elapsed       | 724           |\n",
      "|    total_timesteps    | 68000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13599         |\n",
      "|    policy_loss        | 0.834         |\n",
      "|    reward             | -0.0012904383 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000598      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 197814.703125\n",
      "Final accumulative portfolio value: 1.978147029876709\n",
      "Maximum DrawDown: -0.35352576300940397\n",
      "Sharpe ratio: 0.6073822080989905\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.254        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 13700        |\n",
      "|    time_elapsed       | 730          |\n",
      "|    total_timesteps    | 68500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -0.0338      |\n",
      "|    reward             | 0.0036288144 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 4.71e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.254        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 13800        |\n",
      "|    time_elapsed       | 735          |\n",
      "|    total_timesteps    | 69000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | 0.596        |\n",
      "|    reward             | 0.0023111794 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.254         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 13900         |\n",
      "|    time_elapsed       | 740           |\n",
      "|    total_timesteps    | 69500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0021177887 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 170874.46875\n",
      "Final accumulative portfolio value: 1.7087446451187134\n",
      "Maximum DrawDown: -0.34827366454402287\n",
      "Sharpe ratio: 0.5042979834960912\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14000        |\n",
      "|    time_elapsed       | 745          |\n",
      "|    total_timesteps    | 70000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13999        |\n",
      "|    policy_loss        | -0.231       |\n",
      "|    reward             | -0.007986224 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 751          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | -0.137       |\n",
      "|    reward             | 0.0013069906 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.06e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14200        |\n",
      "|    time_elapsed       | 756          |\n",
      "|    total_timesteps    | 71000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | -0.535       |\n",
      "|    reward             | 0.0031174654 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000239     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.262         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 14300         |\n",
      "|    time_elapsed       | 761           |\n",
      "|    total_timesteps    | 71500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14299         |\n",
      "|    policy_loss        | -0.124        |\n",
      "|    reward             | -0.0015546838 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 3.64e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 159412.28125\n",
      "Final accumulative portfolio value: 1.5941227674484253\n",
      "Maximum DrawDown: -0.34591248444628786\n",
      "Sharpe ratio: 0.45304130262702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.267        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 767          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 0.228        |\n",
      "|    reward             | 0.0009797779 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 4.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.267       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 14500       |\n",
      "|    time_elapsed       | 773         |\n",
      "|    total_timesteps    | 72500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | 0.238       |\n",
      "|    reward             | 0.006871758 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 8.96e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.267        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | 0.43         |\n",
      "|    reward             | 0.0039941072 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.267       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | -0.255      |\n",
      "|    reward             | 0.004053354 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.25e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 145600.328125\n",
      "Final accumulative portfolio value: 1.4560033082962036\n",
      "Maximum DrawDown: -0.3468826031339769\n",
      "Sharpe ratio: 0.382373752922527\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.27          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 14800         |\n",
      "|    time_elapsed       | 790           |\n",
      "|    total_timesteps    | 74000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14799         |\n",
      "|    policy_loss        | 0.303         |\n",
      "|    reward             | -0.0014685441 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.8e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.27         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 795          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | 0.0029781773 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 3.33e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.27          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15000         |\n",
      "|    time_elapsed       | 800           |\n",
      "|    total_timesteps    | 75000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -0.205        |\n",
      "|    reward             | -0.0005407603 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000351      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173816.484375\n",
      "Final accumulative portfolio value: 1.7381649017333984\n",
      "Maximum DrawDown: -0.3431131958107837\n",
      "Sharpe ratio: 0.518402556357476\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.277        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15100        |\n",
      "|    time_elapsed       | 806          |\n",
      "|    total_timesteps    | 75500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | 0.0022116266 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.61e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.277        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15200        |\n",
      "|    time_elapsed       | 811          |\n",
      "|    total_timesteps    | 76000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | -0.484       |\n",
      "|    reward             | -0.005395098 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.277       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 817         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 0.0973      |\n",
      "|    reward             | 0.003926189 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 5.27e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.277         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15400         |\n",
      "|    time_elapsed       | 822           |\n",
      "|    total_timesteps    | 77000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15399         |\n",
      "|    policy_loss        | 0.227         |\n",
      "|    reward             | -0.0014865714 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173916.015625\n",
      "Final accumulative portfolio value: 1.739160180091858\n",
      "Maximum DrawDown: -0.35687374059024646\n",
      "Sharpe ratio: 0.5127264537858992\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 828          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | 0.0008497203 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.42e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15600        |\n",
      "|    time_elapsed       | 834          |\n",
      "|    total_timesteps    | 78000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | -1.77        |\n",
      "|    reward             | -0.011336385 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | 0.0607       |\n",
      "|    reward             | 0.0072708996 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.14e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 180463.84375\n",
      "Final accumulative portfolio value: 1.804638385772705\n",
      "Maximum DrawDown: -0.3570378198895646\n",
      "Sharpe ratio: 0.5391624371537331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.291         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15800         |\n",
      "|    time_elapsed       | 846           |\n",
      "|    total_timesteps    | 79000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15799         |\n",
      "|    policy_loss        | 0.369         |\n",
      "|    reward             | -0.0019597528 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 7.92e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.291          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 15900          |\n",
      "|    time_elapsed       | 852            |\n",
      "|    total_timesteps    | 79500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15899          |\n",
      "|    policy_loss        | 0.48           |\n",
      "|    reward             | -0.00046478581 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 0.00014        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.291       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 16000       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 80000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | 0.806       |\n",
      "|    reward             | 0.029944452 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000733    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.291         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 16100         |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 80500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16099         |\n",
      "|    policy_loss        | 0.166         |\n",
      "|    reward             | -0.0049625784 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000304      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184464.3125\n",
      "Final accumulative portfolio value: 1.8446431159973145\n",
      "Maximum DrawDown: -0.3489735349392823\n",
      "Sharpe ratio: 0.5604267759398199\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.298          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 16200          |\n",
      "|    time_elapsed       | 869            |\n",
      "|    total_timesteps    | 81000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16199          |\n",
      "|    policy_loss        | -0.115         |\n",
      "|    reward             | -0.00033962532 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 1.29e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.298        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 875          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | 0.411        |\n",
      "|    reward             | 0.0022004456 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.298         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 16400         |\n",
      "|    time_elapsed       | 880           |\n",
      "|    total_timesteps    | 82000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16399         |\n",
      "|    policy_loss        | -0.779        |\n",
      "|    reward             | -0.0024115888 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000468      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.298       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 16500       |\n",
      "|    time_elapsed       | 885         |\n",
      "|    total_timesteps    | 82500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | 0.352       |\n",
      "|    reward             | 0.005647774 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9.48e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184537.984375\n",
      "Final accumulative portfolio value: 1.8453798294067383\n",
      "Maximum DrawDown: -0.3519367119080168\n",
      "Sharpe ratio: 0.5546858094577238\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 16600        |\n",
      "|    time_elapsed       | 892          |\n",
      "|    total_timesteps    | 83000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | 0.378        |\n",
      "|    reward             | -0.022685992 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 8.03e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 897          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | -0.314       |\n",
      "|    reward             | 0.0034170116 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 7.11e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 903          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | -0.246       |\n",
      "|    reward             | 0.0013127052 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 3.86e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 193228.078125\n",
      "Final accumulative portfolio value: 1.9322807788848877\n",
      "Maximum DrawDown: -0.34829094952932915\n",
      "Sharpe ratio: 0.5870031888511276\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.313        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.178        |\n",
      "|    reward             | 0.0002883257 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.15e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.313      |\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 915        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | -0.203     |\n",
      "|    reward             | 0.00503344 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.61e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.313         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 920           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.636         |\n",
      "|    reward             | -0.0062189554 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000574      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.313        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 926          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 0.00623      |\n",
      "|    reward             | -0.004166689 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 213506.625\n",
      "Final accumulative portfolio value: 2.135066270828247\n",
      "Maximum DrawDown: -0.35131759570891385\n",
      "Sharpe ratio: 0.6613833796906848\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/              |                 |\n",
      "|    ep_len_mean        | 1.79e+03        |\n",
      "|    ep_rew_mean        | 0.322           |\n",
      "| time/                 |                 |\n",
      "|    fps                | 92              |\n",
      "|    iterations         | 17300           |\n",
      "|    time_elapsed       | 933             |\n",
      "|    total_timesteps    | 86500           |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -42.9           |\n",
      "|    explained_variance | -1.19e-07       |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 17299           |\n",
      "|    policy_loss        | 0.0154          |\n",
      "|    reward             | -0.000107771004 |\n",
      "|    std                | 1.01            |\n",
      "|    value_loss         | 3.14e-06        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.322         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17400         |\n",
      "|    time_elapsed       | 938           |\n",
      "|    total_timesteps    | 87000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17399         |\n",
      "|    policy_loss        | -0.0279       |\n",
      "|    reward             | -0.0061581414 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 1.49e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.322         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17500         |\n",
      "|    time_elapsed       | 943           |\n",
      "|    total_timesteps    | 87500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17499         |\n",
      "|    policy_loss        | -0.71         |\n",
      "|    reward             | -0.0051089874 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 228232.296875\n",
      "Final accumulative portfolio value: 2.282322883605957\n",
      "Maximum DrawDown: -0.34808579252279914\n",
      "Sharpe ratio: 0.7113446540310133\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.333          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 17600          |\n",
      "|    time_elapsed       | 948            |\n",
      "|    total_timesteps    | 88000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17599          |\n",
      "|    policy_loss        | -0.228         |\n",
      "|    reward             | -0.00031965118 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 2.8e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.333        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 953          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | 0.0051029436 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.333         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 958           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | -0.125        |\n",
      "|    reward             | -0.0010785911 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 9.89e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.333         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17900         |\n",
      "|    time_elapsed       | 963           |\n",
      "|    total_timesteps    | 89500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17899         |\n",
      "|    policy_loss        | 0.608         |\n",
      "|    reward             | -0.0049843825 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 219895.796875\n",
      "Final accumulative portfolio value: 2.198957920074463\n",
      "Maximum DrawDown: -0.3460619653530832\n",
      "Sharpe ratio: 0.6854300011376052\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.342        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 968          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0026340333 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 9.64e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.342        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 18100        |\n",
      "|    time_elapsed       | 973          |\n",
      "|    total_timesteps    | 90500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | -1.23        |\n",
      "|    reward             | -0.003904385 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00084      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.342       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 978         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | 0.291       |\n",
      "|    reward             | 0.011743226 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.78e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 206966.921875\n",
      "Final accumulative portfolio value: 2.069669246673584\n",
      "Maximum DrawDown: -0.3436291175520626\n",
      "Sharpe ratio: 0.6432255316305194\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.35         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 983          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | -1.09        |\n",
      "|    reward             | -0.006373407 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000894     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.35         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 988          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | -0.012465422 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 5.24e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.35        |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 993         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -0.41       |\n",
      "|    reward             | 0.085828565 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000565    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.35          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18600         |\n",
      "|    time_elapsed       | 998           |\n",
      "|    total_timesteps    | 93000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18599         |\n",
      "|    policy_loss        | -0.341        |\n",
      "|    reward             | -0.0022143782 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 211347.265625\n",
      "Final accumulative portfolio value: 2.1134727001190186\n",
      "Maximum DrawDown: -0.3380751891922005\n",
      "Sharpe ratio: 0.6586058357395271\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18700         |\n",
      "|    time_elapsed       | 1003          |\n",
      "|    total_timesteps    | 93500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | 0.136         |\n",
      "|    reward             | -0.0016349202 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 3.9e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18800         |\n",
      "|    time_elapsed       | 1008          |\n",
      "|    total_timesteps    | 94000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18799         |\n",
      "|    policy_loss        | 0.59          |\n",
      "|    reward             | -0.0006237783 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000315      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.357       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 1013        |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 0.192       |\n",
      "|    reward             | 0.012815262 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.88e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19000         |\n",
      "|    time_elapsed       | 1018          |\n",
      "|    total_timesteps    | 95000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18999         |\n",
      "|    policy_loss        | 0.103         |\n",
      "|    reward             | -0.0013362152 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.44e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 196701.015625\n",
      "Final accumulative portfolio value: 1.9670101404190063\n",
      "Maximum DrawDown: -0.3374598700637985\n",
      "Sharpe ratio: 0.6080175945150943\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.364        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19100        |\n",
      "|    time_elapsed       | 1024         |\n",
      "|    total_timesteps    | 95500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | -0.0911      |\n",
      "|    reward             | 0.0017301366 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.43e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.364          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 19200          |\n",
      "|    time_elapsed       | 1029           |\n",
      "|    total_timesteps    | 96000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19199          |\n",
      "|    policy_loss        | 0.411          |\n",
      "|    reward             | -0.00059962366 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 0.000117       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.364        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19300        |\n",
      "|    time_elapsed       | 1033         |\n",
      "|    total_timesteps    | 96500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | 0.152        |\n",
      "|    reward             | 0.0019809639 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 3.26e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 182834.046875\n",
      "Final accumulative portfolio value: 1.8283404111862183\n",
      "Maximum DrawDown: -0.34428634463842445\n",
      "Sharpe ratio: 0.553873515854695\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.368        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 1039         |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | -0.204       |\n",
      "|    reward             | -0.020188943 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.368         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19500         |\n",
      "|    time_elapsed       | 1044          |\n",
      "|    total_timesteps    | 97500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19499         |\n",
      "|    policy_loss        | 0.273         |\n",
      "|    reward             | -0.0008010496 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 5.26e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.368         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19600         |\n",
      "|    time_elapsed       | 1048          |\n",
      "|    total_timesteps    | 98000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19599         |\n",
      "|    policy_loss        | 0.539         |\n",
      "|    reward             | -0.0065284222 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.368       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | -0.0494     |\n",
      "|    reward             | 0.008985678 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 4.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 183438.9375\n",
      "Final accumulative portfolio value: 1.834389328956604\n",
      "Maximum DrawDown: -0.33543558363653925\n",
      "Sharpe ratio: 0.5575272211541419\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.373        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19800        |\n",
      "|    time_elapsed       | 1059         |\n",
      "|    total_timesteps    | 99000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19799        |\n",
      "|    policy_loss        | 0.0429       |\n",
      "|    reward             | -0.008031707 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 7.33e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.373        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19900        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 99500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | -0.247       |\n",
      "|    reward             | 0.0027211802 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 5.59e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.373       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 1072        |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.010208181 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000741    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 186220.984375\n",
      "Final accumulative portfolio value: 1.8622097969055176\n",
      "Maximum DrawDown: -0.3389816412974834\n",
      "Sharpe ratio: 0.5706011037476796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.377          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20100          |\n",
      "|    time_elapsed       | 1078           |\n",
      "|    total_timesteps    | 100500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20099          |\n",
      "|    policy_loss        | -0.494         |\n",
      "|    reward             | -0.00056240876 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.000138       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.377         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 20200         |\n",
      "|    time_elapsed       | 1084          |\n",
      "|    total_timesteps    | 101000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20199         |\n",
      "|    policy_loss        | -1.09         |\n",
      "|    reward             | -0.0011860607 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.00071       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.377       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 20300       |\n",
      "|    time_elapsed       | 1089        |\n",
      "|    total_timesteps    | 101500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20299       |\n",
      "|    policy_loss        | 0.0352      |\n",
      "|    reward             | 0.017531198 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000186    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.377        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 20400        |\n",
      "|    time_elapsed       | 1094         |\n",
      "|    total_timesteps    | 102000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20399        |\n",
      "|    policy_loss        | -0.388       |\n",
      "|    reward             | 0.0035719182 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173030.03125\n",
      "Final accumulative portfolio value: 1.7303003072738647\n",
      "Maximum DrawDown: -0.33544805434916447\n",
      "Sharpe ratio: 0.515304621819255\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.381      |\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 1099       |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20499      |\n",
      "|    policy_loss        | 0.207      |\n",
      "|    reward             | 0.01362277 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.57e-05   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.381          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20600          |\n",
      "|    time_elapsed       | 1105           |\n",
      "|    total_timesteps    | 103000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20599          |\n",
      "|    policy_loss        | 0.41           |\n",
      "|    reward             | -0.00029431144 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.000171       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.381          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20700          |\n",
      "|    time_elapsed       | 1110           |\n",
      "|    total_timesteps    | 103500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20699          |\n",
      "|    policy_loss        | 0.0251         |\n",
      "|    reward             | -0.00068282546 |\n",
      "|    std                | 0.999          |\n",
      "|    value_loss         | 6.65e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.381         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 20800         |\n",
      "|    time_elapsed       | 1115          |\n",
      "|    total_timesteps    | 104000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20799         |\n",
      "|    policy_loss        | 0.127         |\n",
      "|    reward             | -0.0038039223 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 1.74e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 181422.359375\n",
      "Final accumulative portfolio value: 1.8142236471176147\n",
      "Maximum DrawDown: -0.3374749909640714\n",
      "Sharpe ratio: 0.5513941747420456\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.384        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | 0.0287       |\n",
      "|    reward             | 0.0012435331 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 1.76e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.384         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21000         |\n",
      "|    time_elapsed       | 1126          |\n",
      "|    total_timesteps    | 105000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20999         |\n",
      "|    policy_loss        | 0.0946        |\n",
      "|    reward             | -0.0013054783 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 1.78e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.384         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21100         |\n",
      "|    time_elapsed       | 1131          |\n",
      "|    total_timesteps    | 105500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21099         |\n",
      "|    policy_loss        | 0.88          |\n",
      "|    reward             | -0.0077841263 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.000494      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192087.75\n",
      "Final accumulative portfolio value: 1.920877456665039\n",
      "Maximum DrawDown: -0.33279059305632575\n",
      "Sharpe ratio: 0.5979398762066906\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.389       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 1137        |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | -0.0775     |\n",
      "|    reward             | 0.001245319 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 3.39e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.389         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21300         |\n",
      "|    time_elapsed       | 1142          |\n",
      "|    total_timesteps    | 106500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21299         |\n",
      "|    policy_loss        | -1.67         |\n",
      "|    reward             | -0.0006260447 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.00167       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.389        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 1147         |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | -0.008336025 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 5.93e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.389        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21500        |\n",
      "|    time_elapsed       | 1152         |\n",
      "|    total_timesteps    | 107500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21499        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | -0.022397328 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000616     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 195808.0625\n",
      "Final accumulative portfolio value: 1.9580806493759155\n",
      "Maximum DrawDown: -0.32804040241931953\n",
      "Sharpe ratio: 0.6136271330708907\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.394       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | -0.01230339 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.394        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | -0.528       |\n",
      "|    reward             | -0.028434854 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000409     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.394         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21800         |\n",
      "|    time_elapsed       | 1169          |\n",
      "|    total_timesteps    | 109000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21799         |\n",
      "|    policy_loss        | -0.411        |\n",
      "|    reward             | -0.0016845937 |\n",
      "|    std                | 0.995         |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 191619.4375\n",
      "Final accumulative portfolio value: 1.9161943197250366\n",
      "Maximum DrawDown: -0.32901325741562815\n",
      "Sharpe ratio: 0.595373621207974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.398        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21900        |\n",
      "|    time_elapsed       | 1174         |\n",
      "|    total_timesteps    | 109500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21899        |\n",
      "|    policy_loss        | -0.0625      |\n",
      "|    reward             | -0.005998506 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 1.76e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.398         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22000         |\n",
      "|    time_elapsed       | 1180          |\n",
      "|    total_timesteps    | 110000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21999         |\n",
      "|    policy_loss        | 0.602         |\n",
      "|    reward             | -0.0036745744 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.398        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22100        |\n",
      "|    time_elapsed       | 1185         |\n",
      "|    total_timesteps    | 110500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22099        |\n",
      "|    policy_loss        | 0.443        |\n",
      "|    reward             | -0.012296149 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.398       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22200       |\n",
      "|    time_elapsed       | 1191        |\n",
      "|    total_timesteps    | 111000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22199       |\n",
      "|    policy_loss        | 0.827       |\n",
      "|    reward             | 0.015277627 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 0.000456    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 185147.078125\n",
      "Final accumulative portfolio value: 1.8514708280563354\n",
      "Maximum DrawDown: -0.31978213221148644\n",
      "Sharpe ratio: 0.5723249415793829\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.402        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22300        |\n",
      "|    time_elapsed       | 1198         |\n",
      "|    total_timesteps    | 111500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22299        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | -0.002977269 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 7.39e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.402         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22400         |\n",
      "|    time_elapsed       | 1204          |\n",
      "|    total_timesteps    | 112000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22399         |\n",
      "|    policy_loss        | 0.149         |\n",
      "|    reward             | -0.0067380667 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 5.85e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.402       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 1209        |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | 0.465       |\n",
      "|    reward             | 0.011832882 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.402       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22600       |\n",
      "|    time_elapsed       | 1214        |\n",
      "|    total_timesteps    | 113000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22599       |\n",
      "|    policy_loss        | -0.163      |\n",
      "|    reward             | 0.012391366 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 8.19e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210759.125\n",
      "Final accumulative portfolio value: 2.107591152191162\n",
      "Maximum DrawDown: -0.3198476280189463\n",
      "Sharpe ratio: 0.6710842808996748\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.408       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22700       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 113500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22699       |\n",
      "|    policy_loss        | -0.698      |\n",
      "|    reward             | 0.018693114 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.000275    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22800        |\n",
      "|    time_elapsed       | 1225         |\n",
      "|    total_timesteps    | 114000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22799        |\n",
      "|    policy_loss        | -0.998       |\n",
      "|    reward             | 0.0059015313 |\n",
      "|    std                | 0.991        |\n",
      "|    value_loss         | 0.000586     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.408         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22900         |\n",
      "|    time_elapsed       | 1231          |\n",
      "|    total_timesteps    | 114500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22899         |\n",
      "|    policy_loss        | -0.989        |\n",
      "|    reward             | -0.0053972555 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 0.000525      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210398.4375\n",
      "Final accumulative portfolio value: 2.1039843559265137\n",
      "Maximum DrawDown: -0.3203782583069823\n",
      "Sharpe ratio: 0.6686239736646316\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.413        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 23000        |\n",
      "|    time_elapsed       | 1236         |\n",
      "|    total_timesteps    | 115000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22999        |\n",
      "|    policy_loss        | 0.0236       |\n",
      "|    reward             | 0.0033041427 |\n",
      "|    std                | 0.99         |\n",
      "|    value_loss         | 7.62e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.413         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23100         |\n",
      "|    time_elapsed       | 1242          |\n",
      "|    total_timesteps    | 115500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23099         |\n",
      "|    policy_loss        | -0.9          |\n",
      "|    reward             | -0.0018620531 |\n",
      "|    std                | 0.988         |\n",
      "|    value_loss         | 0.000674      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.413       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23200       |\n",
      "|    time_elapsed       | 1248        |\n",
      "|    total_timesteps    | 116000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23199       |\n",
      "|    policy_loss        | 0.349       |\n",
      "|    reward             | 0.015010737 |\n",
      "|    std                | 0.987       |\n",
      "|    value_loss         | 0.000154    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.413       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23300       |\n",
      "|    time_elapsed       | 1253        |\n",
      "|    total_timesteps    | 116500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23299       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.004762022 |\n",
      "|    std                | 0.988       |\n",
      "|    value_loss         | 0.000973    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 205517.203125\n",
      "Final accumulative portfolio value: 2.0551719665527344\n",
      "Maximum DrawDown: -0.32305161360556\n",
      "Sharpe ratio: 0.6512330583343678\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23400         |\n",
      "|    time_elapsed       | 1260          |\n",
      "|    total_timesteps    | 117000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23399         |\n",
      "|    policy_loss        | -0.21         |\n",
      "|    reward             | 0.00096679665 |\n",
      "|    std                | 0.988         |\n",
      "|    value_loss         | 2.92e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23500         |\n",
      "|    time_elapsed       | 1265          |\n",
      "|    total_timesteps    | 117500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23499         |\n",
      "|    policy_loss        | -0.106        |\n",
      "|    reward             | -0.0030733438 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 1.52e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23600         |\n",
      "|    time_elapsed       | 1271          |\n",
      "|    total_timesteps    | 118000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23599         |\n",
      "|    policy_loss        | -0.492        |\n",
      "|    reward             | -0.0012702065 |\n",
      "|    std                | 0.99          |\n",
      "|    value_loss         | 0.000192      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 188340.984375\n",
      "Final accumulative portfolio value: 1.883409857749939\n",
      "Maximum DrawDown: -0.3232876286659049\n",
      "Sharpe ratio: 0.5861717194661993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.421         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23700         |\n",
      "|    time_elapsed       | 1277          |\n",
      "|    total_timesteps    | 118500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23699         |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0011096791 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 9.56e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.421        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 23800        |\n",
      "|    time_elapsed       | 1282         |\n",
      "|    total_timesteps    | 119000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23799        |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | 0.0040381565 |\n",
      "|    std                | 0.989        |\n",
      "|    value_loss         | 2.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.421       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23900       |\n",
      "|    time_elapsed       | 1288        |\n",
      "|    total_timesteps    | 119500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | 0.704       |\n",
      "|    reward             | 0.004986469 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.000334    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.421        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 1293         |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | -0.008007012 |\n",
      "|    std                | 0.992        |\n",
      "|    value_loss         | 4.65e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 187872.40625\n",
      "Final accumulative portfolio value: 1.8787240982055664\n",
      "Maximum DrawDown: -0.318643163233704\n",
      "Sharpe ratio: 0.5855130441736071\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.424      |\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 24100      |\n",
      "|    time_elapsed       | 1300       |\n",
      "|    total_timesteps    | 120500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24099      |\n",
      "|    policy_loss        | -0.436     |\n",
      "|    reward             | 0.00544861 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 0.000161   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.424          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 24200          |\n",
      "|    time_elapsed       | 1305           |\n",
      "|    total_timesteps    | 121000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.2          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 24199          |\n",
      "|    policy_loss        | -0.0788        |\n",
      "|    reward             | -0.00019379347 |\n",
      "|    std                | 0.993          |\n",
      "|    value_loss         | 8.4e-05        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.424         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24300         |\n",
      "|    time_elapsed       | 1311          |\n",
      "|    total_timesteps    | 121500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24299         |\n",
      "|    policy_loss        | 0.201         |\n",
      "|    reward             | -0.0013668934 |\n",
      "|    std                | 0.991         |\n",
      "|    value_loss         | 3.92e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192780.96875\n",
      "Final accumulative portfolio value: 1.927809715270996\n",
      "Maximum DrawDown: -0.3228689582774158\n",
      "Sharpe ratio: 0.6043957496090421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.428         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24400         |\n",
      "|    time_elapsed       | 1318          |\n",
      "|    total_timesteps    | 122000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24399         |\n",
      "|    policy_loss        | -0.177        |\n",
      "|    reward             | -0.0004554832 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 0.00041       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.428        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 1323         |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | -0.305       |\n",
      "|    reward             | -0.003540398 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.428       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 1328        |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | -0.535      |\n",
      "|    reward             | 0.050319597 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.428         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24700         |\n",
      "|    time_elapsed       | 1334          |\n",
      "|    total_timesteps    | 123500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24699         |\n",
      "|    policy_loss        | 0.218         |\n",
      "|    reward             | -0.0035956097 |\n",
      "|    std                | 0.99          |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192860.890625\n",
      "Final accumulative portfolio value: 1.9286088943481445\n",
      "Maximum DrawDown: -0.32272353122749253\n",
      "Sharpe ratio: 0.6035211936904459\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.431         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24800         |\n",
      "|    time_elapsed       | 1340          |\n",
      "|    total_timesteps    | 124000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24799         |\n",
      "|    policy_loss        | 0.15          |\n",
      "|    reward             | -0.0035595992 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 1.45e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.431       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 24900       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 124500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24899       |\n",
      "|    policy_loss        | 0.912       |\n",
      "|    reward             | 0.008496328 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000713    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.431        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 1352         |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | 0.0005005537 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.431       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25099       |\n",
      "|    policy_loss        | 0.219       |\n",
      "|    reward             | 0.008518786 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 6.54e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 195846.53125\n",
      "Final accumulative portfolio value: 1.958465337753296\n",
      "Maximum DrawDown: -0.31902913744359984\n",
      "Sharpe ratio: 0.6174449526789049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.435         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25200         |\n",
      "|    time_elapsed       | 1363          |\n",
      "|    total_timesteps    | 126000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25199         |\n",
      "|    policy_loss        | 0.142         |\n",
      "|    reward             | 0.00092630385 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 1.37e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.435        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25300        |\n",
      "|    time_elapsed       | 1369         |\n",
      "|    total_timesteps    | 126500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25299        |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | 0.0050506387 |\n",
      "|    std                | 0.991        |\n",
      "|    value_loss         | 5.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.435       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | 0.0975      |\n",
      "|    reward             | 0.003212769 |\n",
      "|    std                | 0.994       |\n",
      "|    value_loss         | 1.22e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 185393.375\n",
      "Final accumulative portfolio value: 1.8539336919784546\n",
      "Maximum DrawDown: -0.3225158087855913\n",
      "Sharpe ratio: 0.5720806788216989\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 1381         |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | 0.0564       |\n",
      "|    reward             | -0.012094023 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 8.01e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25600        |\n",
      "|    time_elapsed       | 1386         |\n",
      "|    total_timesteps    | 128000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25599        |\n",
      "|    policy_loss        | -0.0331      |\n",
      "|    reward             | -0.002322388 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 2.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.438       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 1391        |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | 0.626       |\n",
      "|    reward             | 0.014500828 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000279    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.438         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25800         |\n",
      "|    time_elapsed       | 1397          |\n",
      "|    total_timesteps    | 129000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25799         |\n",
      "|    policy_loss        | -1.27         |\n",
      "|    reward             | -0.0067292457 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 0.000962      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 172050.515625\n",
      "Final accumulative portfolio value: 1.7205051183700562\n",
      "Maximum DrawDown: -0.32235672432337414\n",
      "Sharpe ratio: 0.513792870916961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.439         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25900         |\n",
      "|    time_elapsed       | 1403          |\n",
      "|    total_timesteps    | 129500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25899         |\n",
      "|    policy_loss        | -0.0386       |\n",
      "|    reward             | 0.00027843413 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.7e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.439         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26000         |\n",
      "|    time_elapsed       | 1409          |\n",
      "|    total_timesteps    | 130000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25999         |\n",
      "|    policy_loss        | -0.356        |\n",
      "|    reward             | -0.0028850888 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.439          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 26100          |\n",
      "|    time_elapsed       | 1415           |\n",
      "|    total_timesteps    | 130500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26099          |\n",
      "|    policy_loss        | -0.0703        |\n",
      "|    reward             | -0.00050384575 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.00011        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 160206.6875\n",
      "Final accumulative portfolio value: 1.6020668745040894\n",
      "Maximum DrawDown: -0.3272440518496649\n",
      "Sharpe ratio: 0.459532452801975\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.44          |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26200         |\n",
      "|    time_elapsed       | 1421          |\n",
      "|    total_timesteps    | 131000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26199         |\n",
      "|    policy_loss        | -0.14         |\n",
      "|    reward             | -0.0007255921 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 5.41e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.44          |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26300         |\n",
      "|    time_elapsed       | 1427          |\n",
      "|    total_timesteps    | 131500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26299         |\n",
      "|    policy_loss        | -0.0416       |\n",
      "|    reward             | -0.0012321312 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 6.98e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.44        |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | -0.222      |\n",
      "|    reward             | 0.023019468 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000285    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.44         |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 26500        |\n",
      "|    time_elapsed       | 1438         |\n",
      "|    total_timesteps    | 132500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26499        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.026992273 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.33e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 169917.515625\n",
      "Final accumulative portfolio value: 1.6991751194000244\n",
      "Maximum DrawDown: -0.3203557257222416\n",
      "Sharpe ratio: 0.5066751788225196\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.441          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 26600          |\n",
      "|    time_elapsed       | 1444           |\n",
      "|    total_timesteps    | 133000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26599          |\n",
      "|    policy_loss        | 0.158          |\n",
      "|    reward             | -2.4259385e-05 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 2.13e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.441         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26700         |\n",
      "|    time_elapsed       | 1449          |\n",
      "|    total_timesteps    | 133500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26699         |\n",
      "|    policy_loss        | -0.086        |\n",
      "|    reward             | -0.0018424665 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.35e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.441        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 26800        |\n",
      "|    time_elapsed       | 1454         |\n",
      "|    total_timesteps    | 134000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26799        |\n",
      "|    policy_loss        | -0.0583      |\n",
      "|    reward             | 0.0010484919 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 2.84e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.441        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 26900        |\n",
      "|    time_elapsed       | 1459         |\n",
      "|    total_timesteps    | 134500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26899        |\n",
      "|    policy_loss        | -0.388       |\n",
      "|    reward             | -0.012403382 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000108     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 186877.171875\n",
      "Final accumulative portfolio value: 1.8687716722488403\n",
      "Maximum DrawDown: -0.3291966033666176\n",
      "Sharpe ratio: 0.5791520480351583\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.444       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 27000       |\n",
      "|    time_elapsed       | 1466        |\n",
      "|    total_timesteps    | 135000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26999       |\n",
      "|    policy_loss        | 0.23        |\n",
      "|    reward             | 0.000401178 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 3.56e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.444       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 27100       |\n",
      "|    time_elapsed       | 1471        |\n",
      "|    total_timesteps    | 135500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27099       |\n",
      "|    policy_loss        | 0.231       |\n",
      "|    reward             | 0.004938903 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 3.73e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.444       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 27200       |\n",
      "|    time_elapsed       | 1476        |\n",
      "|    total_timesteps    | 136000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27199       |\n",
      "|    policy_loss        | 1.11        |\n",
      "|    reward             | 0.009475142 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00113     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 206316.1875\n",
      "Final accumulative portfolio value: 2.063161849975586\n",
      "Maximum DrawDown: -0.3252119388512038\n",
      "Sharpe ratio: 0.6536818689743421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.447         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 27300         |\n",
      "|    time_elapsed       | 1483          |\n",
      "|    total_timesteps    | 136500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 27299         |\n",
      "|    policy_loss        | 0.154         |\n",
      "|    reward             | -0.0027930366 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.54e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.447        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 27400        |\n",
      "|    time_elapsed       | 1488         |\n",
      "|    total_timesteps    | 137000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 27399        |\n",
      "|    policy_loss        | -0.803       |\n",
      "|    reward             | 0.0025976507 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000931     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.447        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 27500        |\n",
      "|    time_elapsed       | 1495         |\n",
      "|    total_timesteps    | 137500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 27499        |\n",
      "|    policy_loss        | 0.58         |\n",
      "|    reward             | 0.0012734169 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.447         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 27600         |\n",
      "|    time_elapsed       | 1500          |\n",
      "|    total_timesteps    | 138000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 27599         |\n",
      "|    policy_loss        | 1.8           |\n",
      "|    reward             | 0.00018714108 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.00179       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 211061.296875\n",
      "Final accumulative portfolio value: 2.1106128692626953\n",
      "Maximum DrawDown: -0.32456740768277925\n",
      "Sharpe ratio: 0.6733965294796513\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | 0.451     |\n",
      "| time/                 |           |\n",
      "|    fps                | 91        |\n",
      "|    iterations         | 27700     |\n",
      "|    time_elapsed       | 1508      |\n",
      "|    total_timesteps    | 138500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 27699     |\n",
      "|    policy_loss        | -0.023    |\n",
      "|    reward             | 0.0020828 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.64e-05  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.451       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 27800       |\n",
      "|    time_elapsed       | 1514        |\n",
      "|    total_timesteps    | 139000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 27799       |\n",
      "|    policy_loss        | 0.271       |\n",
      "|    reward             | 0.012725342 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000142    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.451        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 27900        |\n",
      "|    time_elapsed       | 1519         |\n",
      "|    total_timesteps    | 139500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 27899        |\n",
      "|    policy_loss        | -0.402       |\n",
      "|    reward             | 0.0062549775 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 8.99e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 205540.6875\n",
      "Final accumulative portfolio value: 2.0554068088531494\n",
      "Maximum DrawDown: -0.32274169290638166\n",
      "Sharpe ratio: 0.6537220315524691\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.455        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 28000        |\n",
      "|    time_elapsed       | 1525         |\n",
      "|    total_timesteps    | 140000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 27999        |\n",
      "|    policy_loss        | -0.482       |\n",
      "|    reward             | 0.0017110959 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000176     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.455         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 28100         |\n",
      "|    time_elapsed       | 1531          |\n",
      "|    total_timesteps    | 140500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 28099         |\n",
      "|    policy_loss        | 0.402         |\n",
      "|    reward             | -0.0021539861 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000121      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.455       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 28200       |\n",
      "|    time_elapsed       | 1537        |\n",
      "|    total_timesteps    | 141000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28199       |\n",
      "|    policy_loss        | 1.14        |\n",
      "|    reward             | -0.06640119 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000725    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.455         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 28300         |\n",
      "|    time_elapsed       | 1543          |\n",
      "|    total_timesteps    | 141500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 28299         |\n",
      "|    policy_loss        | 1.84          |\n",
      "|    reward             | 0.00048375348 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.00201       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 206460.640625\n",
      "Final accumulative portfolio value: 2.0646064281463623\n",
      "Maximum DrawDown: -0.3183174147398611\n",
      "Sharpe ratio: 0.6581313368498543\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.458      |\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 28400      |\n",
      "|    time_elapsed       | 1549       |\n",
      "|    total_timesteps    | 142000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 28399      |\n",
      "|    policy_loss        | -0.0501    |\n",
      "|    reward             | 0.00842044 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 2.72e-06   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.458         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 28500         |\n",
      "|    time_elapsed       | 1555          |\n",
      "|    total_timesteps    | 142500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 28499         |\n",
      "|    policy_loss        | 0.0114        |\n",
      "|    reward             | -0.0016564133 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 2.68e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.458        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 28600        |\n",
      "|    time_elapsed       | 1561         |\n",
      "|    total_timesteps    | 143000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28599        |\n",
      "|    policy_loss        | 0.237        |\n",
      "|    reward             | 0.0009491706 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.458       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 28700       |\n",
      "|    time_elapsed       | 1567        |\n",
      "|    total_timesteps    | 143500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28699       |\n",
      "|    policy_loss        | 0.0707      |\n",
      "|    reward             | 0.011439092 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.55e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 224362.453125\n",
      "Final accumulative portfolio value: 2.243624448776245\n",
      "Maximum DrawDown: -0.31971164893458526\n",
      "Sharpe ratio: 0.723325953603108\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.463        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 28800        |\n",
      "|    time_elapsed       | 1573         |\n",
      "|    total_timesteps    | 144000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 28799        |\n",
      "|    policy_loss        | -0.569       |\n",
      "|    reward             | -0.040137045 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000268     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.463       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 28900       |\n",
      "|    time_elapsed       | 1579        |\n",
      "|    total_timesteps    | 144500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28899       |\n",
      "|    policy_loss        | -0.433      |\n",
      "|    reward             | 0.012830445 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000192    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.463       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29000       |\n",
      "|    time_elapsed       | 1584        |\n",
      "|    total_timesteps    | 145000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 28999       |\n",
      "|    policy_loss        | -1.43       |\n",
      "|    reward             | 0.014980908 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.00123     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 224022.21875\n",
      "Final accumulative portfolio value: 2.240222215652466\n",
      "Maximum DrawDown: -0.319344369633208\n",
      "Sharpe ratio: 0.7214239314756324\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.467       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29100       |\n",
      "|    time_elapsed       | 1590        |\n",
      "|    total_timesteps    | 145500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29099       |\n",
      "|    policy_loss        | -0.194      |\n",
      "|    reward             | 0.014067302 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 2.3e-05     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.467       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29200       |\n",
      "|    time_elapsed       | 1596        |\n",
      "|    total_timesteps    | 146000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29199       |\n",
      "|    policy_loss        | -0.0843     |\n",
      "|    reward             | 0.008935938 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000268    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.467         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 29300         |\n",
      "|    time_elapsed       | 1602          |\n",
      "|    total_timesteps    | 146500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29299         |\n",
      "|    policy_loss        | -0.359        |\n",
      "|    reward             | 0.00032777182 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000207      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.467       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29400       |\n",
      "|    time_elapsed       | 1607        |\n",
      "|    total_timesteps    | 147000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29399       |\n",
      "|    policy_loss        | 0.594       |\n",
      "|    reward             | 0.011351878 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000457    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 208634.78125\n",
      "Final accumulative portfolio value: 2.086347818374634\n",
      "Maximum DrawDown: -0.3257842271377126\n",
      "Sharpe ratio: 0.6662536993264259\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.471        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 29500        |\n",
      "|    time_elapsed       | 1614         |\n",
      "|    total_timesteps    | 147500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29499        |\n",
      "|    policy_loss        | -0.271       |\n",
      "|    reward             | 0.0036362973 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 4.97e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.471       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29600       |\n",
      "|    time_elapsed       | 1620        |\n",
      "|    total_timesteps    | 148000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29599       |\n",
      "|    policy_loss        | -0.169      |\n",
      "|    reward             | 0.004776971 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 1.89e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.471       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 29700       |\n",
      "|    time_elapsed       | 1626        |\n",
      "|    total_timesteps    | 148500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 29699       |\n",
      "|    policy_loss        | -0.0372     |\n",
      "|    reward             | 0.013358143 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 1.93e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 198972.53125\n",
      "Final accumulative portfolio value: 1.9897253513336182\n",
      "Maximum DrawDown: -0.32522551252439846\n",
      "Sharpe ratio: 0.6298330857241399\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.473      |\n",
      "| time/                 |            |\n",
      "|    fps                | 91         |\n",
      "|    iterations         | 29800      |\n",
      "|    time_elapsed       | 1632       |\n",
      "|    total_timesteps    | 149000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 29799      |\n",
      "|    policy_loss        | -0.132     |\n",
      "|    reward             | 0.00243962 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 1.96e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.473         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 29900         |\n",
      "|    time_elapsed       | 1638          |\n",
      "|    total_timesteps    | 149500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 29899         |\n",
      "|    policy_loss        | -0.174        |\n",
      "|    reward             | -0.0068785544 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 2.35e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.473        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 30000        |\n",
      "|    time_elapsed       | 1643         |\n",
      "|    total_timesteps    | 150000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 29999        |\n",
      "|    policy_loss        | 0.317        |\n",
      "|    reward             | -0.007987846 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000155     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.473        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 30100        |\n",
      "|    time_elapsed       | 1649         |\n",
      "|    total_timesteps    | 150500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30099        |\n",
      "|    policy_loss        | -0.385       |\n",
      "|    reward             | 0.0031420647 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 8.3e-05      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 183985.765625\n",
      "Final accumulative portfolio value: 1.8398576974868774\n",
      "Maximum DrawDown: -0.3260314401274169\n",
      "Sharpe ratio: 0.5673166005489939\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.475          |\n",
      "| time/                 |                |\n",
      "|    fps                | 91             |\n",
      "|    iterations         | 30200          |\n",
      "|    time_elapsed       | 1655           |\n",
      "|    total_timesteps    | 151000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.1          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 30199          |\n",
      "|    policy_loss        | 0.0583         |\n",
      "|    reward             | -0.00068258686 |\n",
      "|    std                | 1.02           |\n",
      "|    value_loss         | 5.17e-05       |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.475       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 30300       |\n",
      "|    time_elapsed       | 1661        |\n",
      "|    total_timesteps    | 151500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30299       |\n",
      "|    policy_loss        | 0.0676      |\n",
      "|    reward             | 0.002802019 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 6.98e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.475         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 30400         |\n",
      "|    time_elapsed       | 1667          |\n",
      "|    total_timesteps    | 152000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 30399         |\n",
      "|    policy_loss        | -1.26         |\n",
      "|    reward             | -0.0036956328 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.000855      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 182200.0625\n",
      "Final accumulative portfolio value: 1.8220006227493286\n",
      "Maximum DrawDown: -0.32888506369332493\n",
      "Sharpe ratio: 0.557974197827256\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.477       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 30500       |\n",
      "|    time_elapsed       | 1673        |\n",
      "|    total_timesteps    | 152500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30499       |\n",
      "|    policy_loss        | 0.336       |\n",
      "|    reward             | 0.005288065 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000112    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.477       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 30600       |\n",
      "|    time_elapsed       | 1679        |\n",
      "|    total_timesteps    | 153000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30599       |\n",
      "|    policy_loss        | -0.242      |\n",
      "|    reward             | -0.01701279 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 9.51e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.477        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 30700        |\n",
      "|    time_elapsed       | 1684         |\n",
      "|    total_timesteps    | 153500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 30699        |\n",
      "|    policy_loss        | -5.97        |\n",
      "|    reward             | 0.0067160595 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.0221       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.477         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 30800         |\n",
      "|    time_elapsed       | 1689          |\n",
      "|    total_timesteps    | 154000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 30799         |\n",
      "|    policy_loss        | -1.12         |\n",
      "|    reward             | 0.00054285093 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.000664      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 197666.015625\n",
      "Final accumulative portfolio value: 1.976660132408142\n",
      "Maximum DrawDown: -0.33185514649810954\n",
      "Sharpe ratio: 0.6234406416598728\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.479         |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 30900         |\n",
      "|    time_elapsed       | 1696          |\n",
      "|    total_timesteps    | 154500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 30899         |\n",
      "|    policy_loss        | -0.101        |\n",
      "|    reward             | -0.0017481219 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.479       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 31000       |\n",
      "|    time_elapsed       | 1701        |\n",
      "|    total_timesteps    | 155000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 30999       |\n",
      "|    policy_loss        | 0.839       |\n",
      "|    reward             | 0.006569929 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000811    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.479        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 31100        |\n",
      "|    time_elapsed       | 1707         |\n",
      "|    total_timesteps    | 155500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31099        |\n",
      "|    policy_loss        | -0.343       |\n",
      "|    reward             | 0.0005327236 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.479       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 31200       |\n",
      "|    time_elapsed       | 1713        |\n",
      "|    total_timesteps    | 156000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31199       |\n",
      "|    policy_loss        | -0.0965     |\n",
      "|    reward             | 0.022876633 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.84e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 202216.78125\n",
      "Final accumulative portfolio value: 2.022167921066284\n",
      "Maximum DrawDown: -0.33135676443148243\n",
      "Sharpe ratio: 0.6408528084243021\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.482          |\n",
      "| time/                 |                |\n",
      "|    fps                | 91             |\n",
      "|    iterations         | 31300          |\n",
      "|    time_elapsed       | 1719           |\n",
      "|    total_timesteps    | 156500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 31299          |\n",
      "|    policy_loss        | 0.123          |\n",
      "|    reward             | -0.00036878232 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 1.4e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.482        |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 31400        |\n",
      "|    time_elapsed       | 1725         |\n",
      "|    total_timesteps    | 157000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31399        |\n",
      "|    policy_loss        | 0.449        |\n",
      "|    reward             | 0.0009408338 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.482       |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 31500       |\n",
      "|    time_elapsed       | 1730        |\n",
      "|    total_timesteps    | 157500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31499       |\n",
      "|    policy_loss        | -0.0943     |\n",
      "|    reward             | 0.001216744 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 2.64e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 202552.609375\n",
      "Final accumulative portfolio value: 2.0255260467529297\n",
      "Maximum DrawDown: -0.3289156581842312\n",
      "Sharpe ratio: 0.6406860751965515\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.484       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 31600       |\n",
      "|    time_elapsed       | 1737        |\n",
      "|    total_timesteps    | 158000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31599       |\n",
      "|    policy_loss        | 0.0319      |\n",
      "|    reward             | 0.009913496 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 7.85e-06    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.484       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 31700       |\n",
      "|    time_elapsed       | 1742        |\n",
      "|    total_timesteps    | 158500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 31699       |\n",
      "|    policy_loss        | -0.299      |\n",
      "|    reward             | 0.002918867 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 6.23e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.484         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 31800         |\n",
      "|    time_elapsed       | 1748          |\n",
      "|    total_timesteps    | 159000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 31799         |\n",
      "|    policy_loss        | 0.751         |\n",
      "|    reward             | -0.0037502546 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000369      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.484        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 31900        |\n",
      "|    time_elapsed       | 1753         |\n",
      "|    total_timesteps    | 159500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 31899        |\n",
      "|    policy_loss        | -0.682       |\n",
      "|    reward             | -0.008599314 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000486     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 205478.046875\n",
      "Final accumulative portfolio value: 2.0547804832458496\n",
      "Maximum DrawDown: -0.3294990729577646\n",
      "Sharpe ratio: 0.6484349547439566\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.487      |\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 32000      |\n",
      "|    time_elapsed       | 1759       |\n",
      "|    total_timesteps    | 160000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 31999      |\n",
      "|    policy_loss        | 0.109      |\n",
      "|    reward             | 0.00553978 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.58e-05   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.487          |\n",
      "| time/                 |                |\n",
      "|    fps                | 90             |\n",
      "|    iterations         | 32100          |\n",
      "|    time_elapsed       | 1765           |\n",
      "|    total_timesteps    | 160500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 32099          |\n",
      "|    policy_loss        | 0.175          |\n",
      "|    reward             | -0.00039752276 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 2.8e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.487        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 32200        |\n",
      "|    time_elapsed       | 1771         |\n",
      "|    total_timesteps    | 161000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32199        |\n",
      "|    policy_loss        | 0.533        |\n",
      "|    reward             | 0.0010071688 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.00017      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 203925.453125\n",
      "Final accumulative portfolio value: 2.0392544269561768\n",
      "Maximum DrawDown: -0.33099736627792653\n",
      "Sharpe ratio: 0.6443276538919389\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.49         |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 32300        |\n",
      "|    time_elapsed       | 1776         |\n",
      "|    total_timesteps    | 161500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32299        |\n",
      "|    policy_loss        | -0.549       |\n",
      "|    reward             | -0.010923584 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000205     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.49        |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 32400       |\n",
      "|    time_elapsed       | 1782        |\n",
      "|    total_timesteps    | 162000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 32399       |\n",
      "|    policy_loss        | -0.00644    |\n",
      "|    reward             | 0.001820099 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 3.54e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.49         |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 32500        |\n",
      "|    time_elapsed       | 1788         |\n",
      "|    total_timesteps    | 162500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32499        |\n",
      "|    policy_loss        | 0.0991       |\n",
      "|    reward             | -0.026608521 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000295     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.49         |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 32600        |\n",
      "|    time_elapsed       | 1794         |\n",
      "|    total_timesteps    | 163000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32599        |\n",
      "|    policy_loss        | 0.66         |\n",
      "|    reward             | -0.023487855 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.00023      |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 203226.640625\n",
      "Final accumulative portfolio value: 2.03226637840271\n",
      "Maximum DrawDown: -0.33641291236477544\n",
      "Sharpe ratio: 0.6383480845360597\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.492         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 32700         |\n",
      "|    time_elapsed       | 1800          |\n",
      "|    total_timesteps    | 163500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | -2.03e-05     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 32699         |\n",
      "|    policy_loss        | -0.102        |\n",
      "|    reward             | -0.0005934807 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 6.24e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.492         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 32800         |\n",
      "|    time_elapsed       | 1805          |\n",
      "|    total_timesteps    | 164000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 32799         |\n",
      "|    policy_loss        | 0.12          |\n",
      "|    reward             | -0.0074999738 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 1.13e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.492        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 32900        |\n",
      "|    time_elapsed       | 1811         |\n",
      "|    total_timesteps    | 164500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32899        |\n",
      "|    policy_loss        | -0.251       |\n",
      "|    reward             | -0.015635012 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 3.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.492        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 33000        |\n",
      "|    time_elapsed       | 1817         |\n",
      "|    total_timesteps    | 165000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 32999        |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.018451056 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 6.15e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 207187.15625\n",
      "Final accumulative portfolio value: 2.071871519088745\n",
      "Maximum DrawDown: -0.3352400122614436\n",
      "Sharpe ratio: 0.6576320299100152\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.495        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 33100        |\n",
      "|    time_elapsed       | 1823         |\n",
      "|    total_timesteps    | 165500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33099        |\n",
      "|    policy_loss        | -0.0956      |\n",
      "|    reward             | 0.0021095658 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 1.3e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.495         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 33200         |\n",
      "|    time_elapsed       | 1828          |\n",
      "|    total_timesteps    | 166000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33199         |\n",
      "|    policy_loss        | 0.209         |\n",
      "|    reward             | -0.0014189411 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 4.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.495        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 33300        |\n",
      "|    time_elapsed       | 1834         |\n",
      "|    total_timesteps    | 166500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33299        |\n",
      "|    policy_loss        | 0.791        |\n",
      "|    reward             | -0.012734327 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000474     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210484.984375\n",
      "Final accumulative portfolio value: 2.1048498153686523\n",
      "Maximum DrawDown: -0.33178341667603106\n",
      "Sharpe ratio: 0.669948178933513\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.498         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 33400         |\n",
      "|    time_elapsed       | 1840          |\n",
      "|    total_timesteps    | 167000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33399         |\n",
      "|    policy_loss        | 0.202         |\n",
      "|    reward             | -0.0022158718 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 2.59e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.498         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 33500         |\n",
      "|    time_elapsed       | 1846          |\n",
      "|    total_timesteps    | 167500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33499         |\n",
      "|    policy_loss        | 0.335         |\n",
      "|    reward             | -0.0068702125 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.000423      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.498        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 33600        |\n",
      "|    time_elapsed       | 1852         |\n",
      "|    total_timesteps    | 168000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33599        |\n",
      "|    policy_loss        | 0.665        |\n",
      "|    reward             | -0.014414587 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000385     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.498       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 33700       |\n",
      "|    time_elapsed       | 1858        |\n",
      "|    total_timesteps    | 168500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 33699       |\n",
      "|    policy_loss        | 0.689       |\n",
      "|    reward             | 0.028271295 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000754    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 202230.46875\n",
      "Final accumulative portfolio value: 2.0223047733306885\n",
      "Maximum DrawDown: -0.3344697586086143\n",
      "Sharpe ratio: 0.6387805166983522\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.5           |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 33800         |\n",
      "|    time_elapsed       | 1864          |\n",
      "|    total_timesteps    | 169000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 33799         |\n",
      "|    policy_loss        | 0.126         |\n",
      "|    reward             | -0.0044639655 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 2.52e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.5          |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 33900        |\n",
      "|    time_elapsed       | 1870         |\n",
      "|    total_timesteps    | 169500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33899        |\n",
      "|    policy_loss        | 0.379        |\n",
      "|    reward             | -0.008210477 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.000127     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.5          |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 34000        |\n",
      "|    time_elapsed       | 1876         |\n",
      "|    total_timesteps    | 170000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 33999        |\n",
      "|    policy_loss        | 0.145        |\n",
      "|    reward             | 0.0007027302 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 2.33e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 207450.65625\n",
      "Final accumulative portfolio value: 2.0745065212249756\n",
      "Maximum DrawDown: -0.3318928146408535\n",
      "Sharpe ratio: 0.6622202223059025\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.503       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 34100       |\n",
      "|    time_elapsed       | 1882        |\n",
      "|    total_timesteps    | 170500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34099       |\n",
      "|    policy_loss        | -0.206      |\n",
      "|    reward             | 0.011909218 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 7.9e-05     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.503         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 34200         |\n",
      "|    time_elapsed       | 1888          |\n",
      "|    total_timesteps    | 171000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 34199         |\n",
      "|    policy_loss        | 0.148         |\n",
      "|    reward             | -0.0073061404 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 4.48e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.503       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 34300       |\n",
      "|    time_elapsed       | 1893        |\n",
      "|    total_timesteps    | 171500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34299       |\n",
      "|    policy_loss        | 2.08        |\n",
      "|    reward             | 0.005001059 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.00253     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.503       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 34400       |\n",
      "|    time_elapsed       | 1899        |\n",
      "|    total_timesteps    | 172000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34399       |\n",
      "|    policy_loss        | 0.427       |\n",
      "|    reward             | -0.00765144 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000383    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 214988.21875\n",
      "Final accumulative portfolio value: 2.1498820781707764\n",
      "Maximum DrawDown: -0.336877285760507\n",
      "Sharpe ratio: 0.688546613218546\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.505         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 34500         |\n",
      "|    time_elapsed       | 1906          |\n",
      "|    total_timesteps    | 172500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 34499         |\n",
      "|    policy_loss        | -0.0225       |\n",
      "|    reward             | -0.0030343628 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 9.12e-07      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.505        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 34600        |\n",
      "|    time_elapsed       | 1911         |\n",
      "|    total_timesteps    | 173000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34599        |\n",
      "|    policy_loss        | -0.108       |\n",
      "|    reward             | 0.0007707486 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 1.14e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.505        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 34700        |\n",
      "|    time_elapsed       | 1917         |\n",
      "|    total_timesteps    | 173500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34699        |\n",
      "|    policy_loss        | 0.0696       |\n",
      "|    reward             | 0.0072749234 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 3.16e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.505        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 34800        |\n",
      "|    time_elapsed       | 1923         |\n",
      "|    total_timesteps    | 174000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34799        |\n",
      "|    policy_loss        | 0.0371       |\n",
      "|    reward             | -0.005578252 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 4.74e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 220690.53125\n",
      "Final accumulative portfolio value: 2.2069053649902344\n",
      "Maximum DrawDown: -0.3367019888658044\n",
      "Sharpe ratio: 0.7033594344208107\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.508       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 34900       |\n",
      "|    time_elapsed       | 1929        |\n",
      "|    total_timesteps    | 174500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 34899       |\n",
      "|    policy_loss        | -3.06       |\n",
      "|    reward             | 0.013867576 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.00502     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.508        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 35000        |\n",
      "|    time_elapsed       | 1935         |\n",
      "|    total_timesteps    | 175000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 34999        |\n",
      "|    policy_loss        | -0.836       |\n",
      "|    reward             | -0.008404606 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.00044      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.508       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 35100       |\n",
      "|    time_elapsed       | 1940        |\n",
      "|    total_timesteps    | 175500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43         |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35099       |\n",
      "|    policy_loss        | -0.513      |\n",
      "|    reward             | 0.008235188 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000267    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 214598.40625\n",
      "Final accumulative portfolio value: 2.145984172821045\n",
      "Maximum DrawDown: -0.3365681535360121\n",
      "Sharpe ratio: 0.6826710395524217\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.511      |\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 35200      |\n",
      "|    time_elapsed       | 1946       |\n",
      "|    total_timesteps    | 176000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43        |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 35199      |\n",
      "|    policy_loss        | -0.228     |\n",
      "|    reward             | 0.00749301 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 3.97e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.511         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 35300         |\n",
      "|    time_elapsed       | 1952          |\n",
      "|    total_timesteps    | 176500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 35299         |\n",
      "|    policy_loss        | 1.49          |\n",
      "|    reward             | -0.0008400033 |\n",
      "|    std                | 1.02          |\n",
      "|    value_loss         | 0.00137       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.511       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 35400       |\n",
      "|    time_elapsed       | 1957        |\n",
      "|    total_timesteps    | 177000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35399       |\n",
      "|    policy_loss        | -0.0948     |\n",
      "|    reward             | 0.007627648 |\n",
      "|    std                | 1.02        |\n",
      "|    value_loss         | 0.000133    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.511        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 35500        |\n",
      "|    time_elapsed       | 1963         |\n",
      "|    total_timesteps    | 177500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35499        |\n",
      "|    policy_loss        | -0.0282      |\n",
      "|    reward             | 0.0025688764 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 6.77e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 202515.859375\n",
      "Final accumulative portfolio value: 2.025158643722534\n",
      "Maximum DrawDown: -0.3401109792107123\n",
      "Sharpe ratio: 0.6345625826022825\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.513        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 35600        |\n",
      "|    time_elapsed       | 1969         |\n",
      "|    total_timesteps    | 178000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35599        |\n",
      "|    policy_loss        | -0.129       |\n",
      "|    reward             | 0.0042029386 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 1.71e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.513        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 35700        |\n",
      "|    time_elapsed       | 1975         |\n",
      "|    total_timesteps    | 178500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 35699        |\n",
      "|    policy_loss        | -0.111       |\n",
      "|    reward             | -0.018579658 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 2.42e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.513       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 35800       |\n",
      "|    time_elapsed       | 1980        |\n",
      "|    total_timesteps    | 179000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35799       |\n",
      "|    policy_loss        | -0.86       |\n",
      "|    reward             | 0.001249367 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000417    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 207239.359375\n",
      "Final accumulative portfolio value: 2.0723936557769775\n",
      "Maximum DrawDown: -0.3399424496654381\n",
      "Sharpe ratio: 0.6525422277488543\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.515       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 35900       |\n",
      "|    time_elapsed       | 1986        |\n",
      "|    total_timesteps    | 179500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 35899       |\n",
      "|    policy_loss        | -0.335      |\n",
      "|    reward             | 0.011835591 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 9.64e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.515         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 36000         |\n",
      "|    time_elapsed       | 1992          |\n",
      "|    total_timesteps    | 180000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 35999         |\n",
      "|    policy_loss        | 0.536         |\n",
      "|    reward             | -0.0050956276 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000165      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.515         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 36100         |\n",
      "|    time_elapsed       | 1998          |\n",
      "|    total_timesteps    | 180500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 36099         |\n",
      "|    policy_loss        | 0.0671        |\n",
      "|    reward             | -0.0060546338 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 1.62e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.515         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 36200         |\n",
      "|    time_elapsed       | 2003          |\n",
      "|    total_timesteps    | 181000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 36199         |\n",
      "|    policy_loss        | 0.424         |\n",
      "|    reward             | -0.0054005515 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 203337.140625\n",
      "Final accumulative portfolio value: 2.0333714485168457\n",
      "Maximum DrawDown: -0.3379464073569043\n",
      "Sharpe ratio: 0.6380905077795004\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.531       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 36300       |\n",
      "|    time_elapsed       | 2009        |\n",
      "|    total_timesteps    | 181500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36299       |\n",
      "|    policy_loss        | 0.328       |\n",
      "|    reward             | 0.006018255 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 9.46e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.531        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 36400        |\n",
      "|    time_elapsed       | 2015         |\n",
      "|    total_timesteps    | 182000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36399        |\n",
      "|    policy_loss        | 0.171        |\n",
      "|    reward             | -0.009299048 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 3.11e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.531       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 36500       |\n",
      "|    time_elapsed       | 2021        |\n",
      "|    total_timesteps    | 182500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36499       |\n",
      "|    policy_loss        | -0.00397    |\n",
      "|    reward             | 0.002136569 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.00019     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 212327.546875\n",
      "Final accumulative portfolio value: 2.1232755184173584\n",
      "Maximum DrawDown: -0.3329347399722016\n",
      "Sharpe ratio: 0.6765032894677695\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.546       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 36600       |\n",
      "|    time_elapsed       | 2027        |\n",
      "|    total_timesteps    | 183000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36599       |\n",
      "|    policy_loss        | -0.138      |\n",
      "|    reward             | 0.007327112 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 1.95e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.546         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 36700         |\n",
      "|    time_elapsed       | 2032          |\n",
      "|    total_timesteps    | 183500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 36699         |\n",
      "|    policy_loss        | -0.364        |\n",
      "|    reward             | -0.0149328895 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000114      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.546        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 36800        |\n",
      "|    time_elapsed       | 2038         |\n",
      "|    total_timesteps    | 184000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 36799        |\n",
      "|    policy_loss        | -4.89        |\n",
      "|    reward             | -0.033254422 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.0161       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.546       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 36900       |\n",
      "|    time_elapsed       | 2044        |\n",
      "|    total_timesteps    | 184500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36899       |\n",
      "|    policy_loss        | 0.0228      |\n",
      "|    reward             | 0.012300112 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000188    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 213444.78125\n",
      "Final accumulative portfolio value: 2.1344478130340576\n",
      "Maximum DrawDown: -0.3301268663410073\n",
      "Sharpe ratio: 0.684109645307364\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.558       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 37000       |\n",
      "|    time_elapsed       | 2050        |\n",
      "|    total_timesteps    | 185000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 36999       |\n",
      "|    policy_loss        | -0.113      |\n",
      "|    reward             | 0.006709665 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 9.92e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.558        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 37100        |\n",
      "|    time_elapsed       | 2056         |\n",
      "|    total_timesteps    | 185500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37099        |\n",
      "|    policy_loss        | -0.049       |\n",
      "|    reward             | -0.010294013 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 3.36e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.558         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 37200         |\n",
      "|    time_elapsed       | 2061          |\n",
      "|    total_timesteps    | 186000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37199         |\n",
      "|    policy_loss        | 0.592         |\n",
      "|    reward             | -0.0009980412 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000227      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.558       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 37300       |\n",
      "|    time_elapsed       | 2067        |\n",
      "|    total_timesteps    | 186500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37299       |\n",
      "|    policy_loss        | 0.0394      |\n",
      "|    reward             | 0.005017072 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 2.32e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 224938.59375\n",
      "Final accumulative portfolio value: 2.2493858337402344\n",
      "Maximum DrawDown: -0.32903314734415545\n",
      "Sharpe ratio: 0.7264086837091255\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.569       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 37400       |\n",
      "|    time_elapsed       | 2073        |\n",
      "|    total_timesteps    | 187000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37399       |\n",
      "|    policy_loss        | -0.1        |\n",
      "|    reward             | 0.009998476 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 6.63e-06    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.569        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 37500        |\n",
      "|    time_elapsed       | 2079         |\n",
      "|    total_timesteps    | 187500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37499        |\n",
      "|    policy_loss        | 0.231        |\n",
      "|    reward             | 0.0050023636 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 5.76e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.569        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 37600        |\n",
      "|    time_elapsed       | 2084         |\n",
      "|    total_timesteps    | 188000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 37599        |\n",
      "|    policy_loss        | 0.184        |\n",
      "|    reward             | 0.0029456106 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 3.66e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 225572.421875\n",
      "Final accumulative portfolio value: 2.2557241916656494\n",
      "Maximum DrawDown: -0.33004704095518167\n",
      "Sharpe ratio: 0.7270968648886561\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.579         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 37700         |\n",
      "|    time_elapsed       | 2090          |\n",
      "|    total_timesteps    | 188500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 37699         |\n",
      "|    policy_loss        | -0.271        |\n",
      "|    reward             | -0.0017139093 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 0.000126      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.579       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 37800       |\n",
      "|    time_elapsed       | 2096        |\n",
      "|    total_timesteps    | 189000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37799       |\n",
      "|    policy_loss        | -0.122      |\n",
      "|    reward             | 0.006708481 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 1.83e-05    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.579       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 37900       |\n",
      "|    time_elapsed       | 2102        |\n",
      "|    total_timesteps    | 189500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 37899       |\n",
      "|    policy_loss        | 0.139       |\n",
      "|    reward             | 0.012555248 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 4.21e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.579      |\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 38000      |\n",
      "|    time_elapsed       | 2107       |\n",
      "|    total_timesteps    | 190000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 37999      |\n",
      "|    policy_loss        | -1.22      |\n",
      "|    reward             | -0.0103016 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 0.000841   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 235476.625\n",
      "Final accumulative portfolio value: 2.354766368865967\n",
      "Maximum DrawDown: -0.32914461325289857\n",
      "Sharpe ratio: 0.7617983386772393\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | 0.586     |\n",
      "| time/                 |           |\n",
      "|    fps                | 90        |\n",
      "|    iterations         | 38100     |\n",
      "|    time_elapsed       | 2114      |\n",
      "|    total_timesteps    | 190500    |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 38099     |\n",
      "|    policy_loss        | 0.0244    |\n",
      "|    reward             | 0.0054824 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 9.61e-06  |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.586       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 38200       |\n",
      "|    time_elapsed       | 2119        |\n",
      "|    total_timesteps    | 191000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38199       |\n",
      "|    policy_loss        | 0.542       |\n",
      "|    reward             | 0.004130523 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000148    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.586        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 38300        |\n",
      "|    time_elapsed       | 2125         |\n",
      "|    total_timesteps    | 191500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38299        |\n",
      "|    policy_loss        | 0.0469       |\n",
      "|    reward             | -0.005423324 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 2e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 223994.390625\n",
      "Final accumulative portfolio value: 2.2399439811706543\n",
      "Maximum DrawDown: -0.32724713282058415\n",
      "Sharpe ratio: 0.7246214339199903\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.593        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 38400        |\n",
      "|    time_elapsed       | 2131         |\n",
      "|    total_timesteps    | 192000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38399        |\n",
      "|    policy_loss        | -0.0335      |\n",
      "|    reward             | -0.009301575 |\n",
      "|    std                | 1.04         |\n",
      "|    value_loss         | 1.86e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.593       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 38500       |\n",
      "|    time_elapsed       | 2137        |\n",
      "|    total_timesteps    | 192500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38499       |\n",
      "|    policy_loss        | -0.522      |\n",
      "|    reward             | 0.005039252 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.000167    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.593        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 38600        |\n",
      "|    time_elapsed       | 2142         |\n",
      "|    total_timesteps    | 193000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 38599        |\n",
      "|    policy_loss        | 0.964        |\n",
      "|    reward             | 0.0022710979 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000726     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.593       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 38700       |\n",
      "|    time_elapsed       | 2148        |\n",
      "|    total_timesteps    | 193500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38699       |\n",
      "|    policy_loss        | -0.0299     |\n",
      "|    reward             | 0.017850932 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 3.23e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210600.859375\n",
      "Final accumulative portfolio value: 2.106008529663086\n",
      "Maximum DrawDown: -0.3281620904795043\n",
      "Sharpe ratio: 0.6757695598263124\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.597          |\n",
      "| time/                 |                |\n",
      "|    fps                | 90             |\n",
      "|    iterations         | 38800          |\n",
      "|    time_elapsed       | 2154           |\n",
      "|    total_timesteps    | 194000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 38799          |\n",
      "|    policy_loss        | -0.00626       |\n",
      "|    reward             | -0.00013572899 |\n",
      "|    std                | 1.03           |\n",
      "|    value_loss         | 1.53e-05       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.597         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 38900         |\n",
      "|    time_elapsed       | 2159          |\n",
      "|    total_timesteps    | 194500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 38899         |\n",
      "|    policy_loss        | -0.113        |\n",
      "|    reward             | -0.0053696297 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 1.05e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.597       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 39000       |\n",
      "|    time_elapsed       | 2164        |\n",
      "|    total_timesteps    | 195000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 38999       |\n",
      "|    policy_loss        | -0.0822     |\n",
      "|    reward             | 0.018206151 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 1.29e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.597      |\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 39100      |\n",
      "|    time_elapsed       | 2170       |\n",
      "|    total_timesteps    | 195500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39099      |\n",
      "|    policy_loss        | 0.214      |\n",
      "|    reward             | 0.00229548 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 5.1e-05    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 212216.640625\n",
      "Final accumulative portfolio value: 2.122166395187378\n",
      "Maximum DrawDown: -0.3266660556821469\n",
      "Sharpe ratio: 0.681744718973483\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.601       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 39200       |\n",
      "|    time_elapsed       | 2176        |\n",
      "|    total_timesteps    | 196000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39199       |\n",
      "|    policy_loss        | -0.238      |\n",
      "|    reward             | 0.005832676 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 3.48e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.601        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 39300        |\n",
      "|    time_elapsed       | 2181         |\n",
      "|    total_timesteps    | 196500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39299        |\n",
      "|    policy_loss        | 0.125        |\n",
      "|    reward             | 0.0012221019 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 1.02e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.601      |\n",
      "| time/                 |            |\n",
      "|    fps                | 90         |\n",
      "|    iterations         | 39400      |\n",
      "|    time_elapsed       | 2187       |\n",
      "|    total_timesteps    | 197000     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 39399      |\n",
      "|    policy_loss        | -0.126     |\n",
      "|    reward             | 0.01552907 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 1.81e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 224318.5625\n",
      "Final accumulative portfolio value: 2.243185520172119\n",
      "Maximum DrawDown: -0.32697228802795386\n",
      "Sharpe ratio: 0.725631091427742\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.607         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 39500         |\n",
      "|    time_elapsed       | 2192          |\n",
      "|    total_timesteps    | 197500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 39499         |\n",
      "|    policy_loss        | 0.293         |\n",
      "|    reward             | 6.5564896e-06 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 5.48e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.607       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 39600       |\n",
      "|    time_elapsed       | 2198        |\n",
      "|    total_timesteps    | 198000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39599       |\n",
      "|    policy_loss        | 0.112       |\n",
      "|    reward             | 0.016231883 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000137    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.607         |\n",
      "| time/                 |               |\n",
      "|    fps                | 90            |\n",
      "|    iterations         | 39700         |\n",
      "|    time_elapsed       | 2203          |\n",
      "|    total_timesteps    | 198500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 39699         |\n",
      "|    policy_loss        | -0.251        |\n",
      "|    reward             | -0.0018435414 |\n",
      "|    std                | 1.03          |\n",
      "|    value_loss         | 6.9e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.607       |\n",
      "| time/                 |             |\n",
      "|    fps                | 90          |\n",
      "|    iterations         | 39800       |\n",
      "|    time_elapsed       | 2209        |\n",
      "|    total_timesteps    | 199000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 39799       |\n",
      "|    policy_loss        | -0.715      |\n",
      "|    reward             | 0.016351746 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.000506    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 212106.15625\n",
      "Final accumulative portfolio value: 2.1210615634918213\n",
      "Maximum DrawDown: -0.32572013102410124\n",
      "Sharpe ratio: 0.6815023020379856\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.612        |\n",
      "| time/                 |              |\n",
      "|    fps                | 90           |\n",
      "|    iterations         | 39900        |\n",
      "|    time_elapsed       | 2215         |\n",
      "|    total_timesteps    | 199500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 39899        |\n",
      "|    policy_loss        | -0.489       |\n",
      "|    reward             | 0.0021438252 |\n",
      "|    std                | 1.03         |\n",
      "|    value_loss         | 0.000148     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.612          |\n",
      "| time/                 |                |\n",
      "|    fps                | 90             |\n",
      "|    iterations         | 40000          |\n",
      "|    time_elapsed       | 2221           |\n",
      "|    total_timesteps    | 200000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -43.3          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 39999          |\n",
      "|    policy_loss        | -0.787         |\n",
      "|    reward             | -7.0335955e-05 |\n",
      "|    std                | 1.03           |\n",
      "|    value_loss         | 0.000403       |\n",
      "------------------------------------------\n",
      "A2C training completed in 37.02 minutes.\n",
      "Training PPO...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 32995.83203125\n",
      "Final accumulative portfolio value: 0.32995831966400146\n",
      "Maximum DrawDown: -0.6870765335281277\n",
      "Sharpe ratio: -0.782057612715188\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/           |               |\n",
      "|    ep_len_mean     | 1.79e+03      |\n",
      "|    ep_rew_mean     | -1.1          |\n",
      "| time/              |               |\n",
      "|    fps             | 91            |\n",
      "|    iterations      | 1             |\n",
      "|    time_elapsed    | 22            |\n",
      "|    total_timesteps | 2048          |\n",
      "| train/             |               |\n",
      "|    reward          | -0.0034426635 |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36250.859375\n",
      "Final accumulative portfolio value: 0.3625085949897766\n",
      "Maximum DrawDown: -0.6663159979207406\n",
      "Sharpe ratio: -0.7117102785534724\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013269688  |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0172      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00951     |\n",
      "|    reward               | -0.002924602 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.0261       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34406.796875\n",
      "Final accumulative portfolio value: 0.3440679609775543\n",
      "Maximum DrawDown: -0.6824304778101905\n",
      "Sharpe ratio: -0.7398874164460782\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012216426 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    reward               | 0.005437821 |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 0.000824    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 31888.564453125\n",
      "Final accumulative portfolio value: 0.3188856542110443\n",
      "Maximum DrawDown: -0.7003024488477833\n",
      "Sharpe ratio: -0.8047594999965401\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010673275 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.6       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    reward               | -0.03793016 |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 0.000844    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34218.73046875\n",
      "Final accumulative portfolio value: 0.3421873152256012\n",
      "Maximum DrawDown: -0.678428585176333\n",
      "Sharpe ratio: -0.7615720645269528\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.07         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 88            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 115           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011297999   |\n",
      "|    clip_fraction        | 0.131         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.5         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0446       |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.00982      |\n",
      "|    reward               | -0.0039018719 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.00105       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35180.0\n",
      "Final accumulative portfolio value: 0.35179999470710754\n",
      "Maximum DrawDown: -0.6672292889963627\n",
      "Sharpe ratio: -0.7261078677817997\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.07        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008310679  |\n",
      "|    clip_fraction        | 0.0811       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0122       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    reward               | 0.0025050233 |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 0.000842     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 31443.9296875\n",
      "Final accumulative portfolio value: 0.3144392967224121\n",
      "Maximum DrawDown: -0.703334221299221\n",
      "Sharpe ratio: -0.8180837172215025\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.08        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010413777  |\n",
      "|    clip_fraction        | 0.099        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0201      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00982     |\n",
      "|    reward               | -0.002365464 |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.000771     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35314.1171875\n",
      "Final accumulative portfolio value: 0.3531411588191986\n",
      "Maximum DrawDown: -0.6659343962147628\n",
      "Sharpe ratio: -0.729466228232491\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35360.53125\n",
      "Final accumulative portfolio value: 0.3536053001880646\n",
      "Maximum DrawDown: -0.6712110112665879\n",
      "Sharpe ratio: -0.7231081359600675\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.07        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010081074  |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000548    |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    reward               | 0.0015278107 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.000851     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37260.22265625\n",
      "Final accumulative portfolio value: 0.3726022243499756\n",
      "Maximum DrawDown: -0.6490079716536303\n",
      "Sharpe ratio: -0.6781640789569874\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010545477  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0204      |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0113      |\n",
      "|    reward               | -0.013604677 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.000719     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 32777.0546875\n",
      "Final accumulative portfolio value: 0.32777056097984314\n",
      "Maximum DrawDown: -0.6936223144653455\n",
      "Sharpe ratio: -0.7867223696402719\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 226           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.008778384   |\n",
      "|    clip_fraction        | 0.0986        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.5         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.025        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.0104       |\n",
      "|    reward               | -0.0064702285 |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 0.000727      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34723.63671875\n",
      "Final accumulative portfolio value: 0.34723636507987976\n",
      "Maximum DrawDown: -0.6718946843928891\n",
      "Sharpe ratio: -0.7425519307516034\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010189741 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.5       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00848    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    reward               | -0.03059677 |\n",
      "|    std                  | 0.996       |\n",
      "|    value_loss           | 0.000741    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37110.05859375\n",
      "Final accumulative portfolio value: 0.3711005747318268\n",
      "Maximum DrawDown: -0.6658416951682706\n",
      "Sharpe ratio: -0.693129438833149\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 269           |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012385825   |\n",
      "|    clip_fraction        | 0.131         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.5         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0114       |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.016        |\n",
      "|    reward               | -0.0013391994 |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 0.000805      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35071.0625\n",
      "Final accumulative portfolio value: 0.3507106304168701\n",
      "Maximum DrawDown: -0.6767100648774005\n",
      "Sharpe ratio: -0.7284548405459274\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 291           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011993954   |\n",
      "|    clip_fraction        | 0.148         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.5         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0102       |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.0154       |\n",
      "|    reward               | -0.0050700465 |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 0.00084       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36391.046875\n",
      "Final accumulative portfolio value: 0.3639104664325714\n",
      "Maximum DrawDown: -0.6569557211846662\n",
      "Sharpe ratio: -0.7056673031906355\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 314          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.008953013  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.5        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0197      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    reward               | -0.009383097 |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 0.000732     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33009.00390625\n",
      "Final accumulative portfolio value: 0.3300900459289551\n",
      "Maximum DrawDown: -0.6880351584010773\n",
      "Sharpe ratio: -0.7783168981941193\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 32750.427734375\n",
      "Final accumulative portfolio value: 0.3275042772293091\n",
      "Maximum DrawDown: -0.6894190671920177\n",
      "Sharpe ratio: -0.7772051213521569\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 337           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009150382   |\n",
      "|    clip_fraction        | 0.107         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.4         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0178       |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.00889      |\n",
      "|    reward               | -0.0021720259 |\n",
      "|    std                  | 0.993         |\n",
      "|    value_loss           | 0.00085       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33944.2421875\n",
      "Final accumulative portfolio value: 0.3394424319267273\n",
      "Maximum DrawDown: -0.6834341632666587\n",
      "Sharpe ratio: -0.7572589458037543\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 360          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.014287552  |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.3        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00961     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    reward               | -0.022102047 |\n",
      "|    std                  | 0.992        |\n",
      "|    value_loss           | 0.000771     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37343.703125\n",
      "Final accumulative portfolio value: 0.3734370172023773\n",
      "Maximum DrawDown: -0.6501976130671778\n",
      "Sharpe ratio: -0.6915098465144189\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.06        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 381          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00959295   |\n",
      "|    clip_fraction        | 0.0831       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.2        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0226      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    reward               | -0.009237445 |\n",
      "|    std                  | 0.988        |\n",
      "|    value_loss           | 0.000725     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34819.625\n",
      "Final accumulative portfolio value: 0.34819623827934265\n",
      "Maximum DrawDown: -0.6715041782284092\n",
      "Sharpe ratio: -0.7362571727895074\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.06         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 404           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012497382   |\n",
      "|    clip_fraction        | 0.16          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.2         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00363      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.0157       |\n",
      "|    reward               | 0.00042250767 |\n",
      "|    std                  | 0.986         |\n",
      "|    value_loss           | 0.00074       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34931.72265625\n",
      "Final accumulative portfolio value: 0.3493172228336334\n",
      "Maximum DrawDown: -0.6705079434068009\n",
      "Sharpe ratio: -0.7404925197629182\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 425          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00999104   |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000659     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    reward               | 0.0001296913 |\n",
      "|    std                  | 0.989        |\n",
      "|    value_loss           | 0.000804     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33168.5390625\n",
      "Final accumulative portfolio value: 0.3316853940486908\n",
      "Maximum DrawDown: -0.6871027634473277\n",
      "Sharpe ratio: -0.772583029160566\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 447         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010841226 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    reward               | 0.011014495 |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35754.0859375\n",
      "Final accumulative portfolio value: 0.3575408458709717\n",
      "Maximum DrawDown: -0.6624054032993679\n",
      "Sharpe ratio: -0.7153418231737048\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 468          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010935029  |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.1        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    reward               | -0.020231396 |\n",
      "|    std                  | 0.985        |\n",
      "|    value_loss           | 0.000738     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35537.140625\n",
      "Final accumulative portfolio value: 0.3553714156150818\n",
      "Maximum DrawDown: -0.6680326294176191\n",
      "Sharpe ratio: -0.7221193673546343\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35514.53125\n",
      "Final accumulative portfolio value: 0.35514530539512634\n",
      "Maximum DrawDown: -0.671665979052565\n",
      "Sharpe ratio: -0.7274415892699156\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 491          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009723609  |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42.1        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0126       |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    reward               | 0.0043195044 |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 0.000842     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36077.3828125\n",
      "Final accumulative portfolio value: 0.36077383160591125\n",
      "Maximum DrawDown: -0.6631786240054591\n",
      "Sharpe ratio: -0.7154101827380147\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.05         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 23            |\n",
      "|    time_elapsed         | 513           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010121311   |\n",
      "|    clip_fraction        | 0.111         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42.1         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00965      |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | -0.011        |\n",
      "|    reward               | -0.0024564012 |\n",
      "|    std                  | 0.986         |\n",
      "|    value_loss           | 0.00078       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35625.5\n",
      "Final accumulative portfolio value: 0.3562549948692322\n",
      "Maximum DrawDown: -0.6673361376711509\n",
      "Sharpe ratio: -0.7173546201497869\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009668916 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    reward               | 0.00576749  |\n",
      "|    std                  | 0.984       |\n",
      "|    value_loss           | 0.000702    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35548.83984375\n",
      "Final accumulative portfolio value: 0.3554883897304535\n",
      "Maximum DrawDown: -0.6653218532104108\n",
      "Sharpe ratio: -0.7278706358945477\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 557          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010719735  |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42          |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0355      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00914     |\n",
      "|    reward               | 0.0012115052 |\n",
      "|    std                  | 0.983        |\n",
      "|    value_loss           | 0.000779     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37310.7109375\n",
      "Final accumulative portfolio value: 0.37310710549354553\n",
      "Maximum DrawDown: -0.6604336513084635\n",
      "Sharpe ratio: -0.6987620804585641\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.05         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 579           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010675183   |\n",
      "|    clip_fraction        | 0.125         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -42           |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00841      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.0101       |\n",
      "|    reward               | -0.0036465174 |\n",
      "|    std                  | 0.982         |\n",
      "|    value_loss           | 0.000805      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35767.29296875\n",
      "Final accumulative portfolio value: 0.35767292976379395\n",
      "Maximum DrawDown: -0.6634178574031093\n",
      "Sharpe ratio: -0.721298052397823\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011229085  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -42          |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00304      |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    reward               | 0.0034134476 |\n",
      "|    std                  | 0.98         |\n",
      "|    value_loss           | 0.00102      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36219.22265625\n",
      "Final accumulative portfolio value: 0.36219221353530884\n",
      "Maximum DrawDown: -0.6589123442217641\n",
      "Sharpe ratio: -0.7105126565424617\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.04         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 28            |\n",
      "|    time_elapsed         | 623           |\n",
      "|    total_timesteps      | 57344         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011409679   |\n",
      "|    clip_fraction        | 0.115         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000745     |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.0107       |\n",
      "|    reward               | -0.0023747843 |\n",
      "|    std                  | 0.978         |\n",
      "|    value_loss           | 0.000789      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36075.34765625\n",
      "Final accumulative portfolio value: 0.36075347661972046\n",
      "Maximum DrawDown: -0.6627528679514789\n",
      "Sharpe ratio: -0.7172376536389891\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36319.1484375\n",
      "Final accumulative portfolio value: 0.36319148540496826\n",
      "Maximum DrawDown: -0.6611507537022252\n",
      "Sharpe ratio: -0.7041080629242289\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 645          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.00739012   |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0148      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.0095      |\n",
      "|    reward               | 0.0071047284 |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 0.000892     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35269.96875\n",
      "Final accumulative portfolio value: 0.3526996970176697\n",
      "Maximum DrawDown: -0.6669147837357772\n",
      "Sharpe ratio: -0.7275076562678289\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010209475  |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.8        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00666     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    reward               | 0.0063702385 |\n",
      "|    std                  | 0.976        |\n",
      "|    value_loss           | 0.000782     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34071.703125\n",
      "Final accumulative portfolio value: 0.34071701765060425\n",
      "Maximum DrawDown: -0.6826845968267794\n",
      "Sharpe ratio: -0.7497624517840745\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011208521 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    reward               | -0.0178893  |\n",
      "|    std                  | 0.972       |\n",
      "|    value_loss           | 0.00072     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33119.69921875\n",
      "Final accumulative portfolio value: 0.33119699358940125\n",
      "Maximum DrawDown: -0.6889159046146236\n",
      "Sharpe ratio: -0.7792265103014954\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 708          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010780284  |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.6        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00977     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.002380759 |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.000838     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35653.34375\n",
      "Final accumulative portfolio value: 0.3565334379673004\n",
      "Maximum DrawDown: -0.662829764736576\n",
      "Sharpe ratio: -0.7209482424706006\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 729          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010879474  |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0381      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | 0.0051190737 |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 0.000776     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36803.05078125\n",
      "Final accumulative portfolio value: 0.36803051829338074\n",
      "Maximum DrawDown: -0.6486858729657785\n",
      "Sharpe ratio: -0.6906951367942565\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.04         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 92            |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 750           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012355993   |\n",
      "|    clip_fraction        | 0.112         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41.6         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0312       |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.012        |\n",
      "|    reward               | -0.0038291118 |\n",
      "|    std                  | 0.968         |\n",
      "|    value_loss           | 0.00101       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34291.31640625\n",
      "Final accumulative portfolio value: 0.3429131507873535\n",
      "Maximum DrawDown: -0.6763134824920622\n",
      "Sharpe ratio: -0.7392042638690269\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 772          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136313625 |\n",
      "|    clip_fraction        | 0.142        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.6        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00706     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | 0.0049784034 |\n",
      "|    std                  | 0.969        |\n",
      "|    value_loss           | 0.000736     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36302.9609375\n",
      "Final accumulative portfolio value: 0.3630295991897583\n",
      "Maximum DrawDown: -0.6599534652680852\n",
      "Sharpe ratio: -0.7054233479810877\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34594.10546875\n",
      "Final accumulative portfolio value: 0.34594106674194336\n",
      "Maximum DrawDown: -0.6698675846102928\n",
      "Sharpe ratio: -0.7408511571218437\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.04         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 92            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 794           |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.009803021   |\n",
      "|    clip_fraction        | 0.124         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41.6         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00288      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.0109       |\n",
      "|    reward               | -0.0031516096 |\n",
      "|    std                  | 0.971         |\n",
      "|    value_loss           | 0.000896      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35337.12109375\n",
      "Final accumulative portfolio value: 0.35337120294570923\n",
      "Maximum DrawDown: -0.6637415001356257\n",
      "Sharpe ratio: -0.7323473353563472\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 92           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 815          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011124162  |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.6        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.032       |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    reward               | -0.003238851 |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 0.000743     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36113.3984375\n",
      "Final accumulative portfolio value: 0.36113399267196655\n",
      "Maximum DrawDown: -0.6633273725791107\n",
      "Sharpe ratio: -0.7174619614667141\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009059037  |\n",
      "|    clip_fraction        | 0.0913       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.6        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00332     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00864     |\n",
      "|    reward               | 0.0052655344 |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 0.000761     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34663.45703125\n",
      "Final accumulative portfolio value: 0.34663456678390503\n",
      "Maximum DrawDown: -0.67467685752447\n",
      "Sharpe ratio: -0.7326769826819799\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 857         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010209752 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    reward               | -0.00903317 |\n",
      "|    std                  | 0.968       |\n",
      "|    value_loss           | 0.000739    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36231.51953125\n",
      "Final accumulative portfolio value: 0.36231520771980286\n",
      "Maximum DrawDown: -0.6656711145870671\n",
      "Sharpe ratio: -0.7028988837897\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 880          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009966683  |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.5        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000648    |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00934     |\n",
      "|    reward               | 0.0015714928 |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 0.000779     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34608.50390625\n",
      "Final accumulative portfolio value: 0.3460850417613983\n",
      "Maximum DrawDown: -0.6741167853216146\n",
      "Sharpe ratio: -0.7380582866517026\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 901         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011416895 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00204    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    reward               | 0.010177974 |\n",
      "|    std                  | 0.967       |\n",
      "|    value_loss           | 0.00106     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38170.8125\n",
      "Final accumulative portfolio value: 0.3817081153392792\n",
      "Maximum DrawDown: -0.645025412927174\n",
      "Sharpe ratio: -0.666244874290696\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010422999  |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.5        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0223      |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    reward               | -0.007574443 |\n",
      "|    std                  | 0.966        |\n",
      "|    value_loss           | 0.000736     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38679.52734375\n",
      "Final accumulative portfolio value: 0.3867952823638916\n",
      "Maximum DrawDown: -0.648470556601729\n",
      "Sharpe ratio: -0.6587689686562763\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34303.81640625\n",
      "Final accumulative portfolio value: 0.3430381715297699\n",
      "Maximum DrawDown: -0.674482706094699\n",
      "Sharpe ratio: -0.7464041833963377\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.04         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 944           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011228528   |\n",
      "|    clip_fraction        | 0.144         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41.5         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0238       |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.0134       |\n",
      "|    reward               | -0.0027569951 |\n",
      "|    std                  | 0.966         |\n",
      "|    value_loss           | 0.000864      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37406.8671875\n",
      "Final accumulative portfolio value: 0.3740686774253845\n",
      "Maximum DrawDown: -0.6457692673457176\n",
      "Sharpe ratio: -0.685262996913345\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 966          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009613747  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.4        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0115      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00931     |\n",
      "|    reward               | 0.0017414418 |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 0.000739     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36520.734375\n",
      "Final accumulative portfolio value: 0.36520734429359436\n",
      "Maximum DrawDown: -0.6589267730756299\n",
      "Sharpe ratio: -0.7032023738861498\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.04        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 987          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009516461  |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.4        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0209      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    reward               | -0.008263964 |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 0.000704     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35049.875\n",
      "Final accumulative portfolio value: 0.3504987359046936\n",
      "Maximum DrawDown: -0.6779630833557968\n",
      "Sharpe ratio: -0.7406756269103045\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1008        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109661 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0283     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    reward               | 0.004208043 |\n",
      "|    std                  | 0.962       |\n",
      "|    value_loss           | 0.000756    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38712.140625\n",
      "Final accumulative portfolio value: 0.38712140917778015\n",
      "Maximum DrawDown: -0.6341734269816914\n",
      "Sharpe ratio: -0.655630583349133\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011466954 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    reward               | 0.010195673 |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 0.00077     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35177.8984375\n",
      "Final accumulative portfolio value: 0.3517789840698242\n",
      "Maximum DrawDown: -0.6770119098958587\n",
      "Sharpe ratio: -0.7321170494618852\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01073161   |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.3        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00134      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00798     |\n",
      "|    reward               | 0.0025196492 |\n",
      "|    std                  | 0.959        |\n",
      "|    value_loss           | 0.000988     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35823.99609375\n",
      "Final accumulative portfolio value: 0.35823994874954224\n",
      "Maximum DrawDown: -0.6633036964722253\n",
      "Sharpe ratio: -0.722466945888585\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 1073         |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010932544  |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00912     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    reward               | -0.006414738 |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 0.000735     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36149.875\n",
      "Final accumulative portfolio value: 0.36149874329566956\n",
      "Maximum DrawDown: -0.6590944774688807\n",
      "Sharpe ratio: -0.7163216108239373\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34505.76953125\n",
      "Final accumulative portfolio value: 0.3450576961040497\n",
      "Maximum DrawDown: -0.6778854399394605\n",
      "Sharpe ratio: -0.7468979329174038\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 1096         |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010892992  |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.2        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0476      |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    reward               | 0.0024450903 |\n",
      "|    std                  | 0.956        |\n",
      "|    value_loss           | 0.00082      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37664.625\n",
      "Final accumulative portfolio value: 0.3766462504863739\n",
      "Maximum DrawDown: -0.6548571051704599\n",
      "Sharpe ratio: -0.686210942581496\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 1118          |\n",
      "|    total_timesteps      | 104448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0090109985  |\n",
      "|    clip_fraction        | 0.116         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41.1         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0167       |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | -0.00829      |\n",
      "|    reward               | -0.0017072222 |\n",
      "|    std                  | 0.954         |\n",
      "|    value_loss           | 0.000782      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35372.49609375\n",
      "Final accumulative portfolio value: 0.35372495651245117\n",
      "Maximum DrawDown: -0.6703457982747547\n",
      "Sharpe ratio: -0.7252632451983845\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 1139         |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01006638   |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41.1        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0212      |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00929     |\n",
      "|    reward               | -0.021907981 |\n",
      "|    std                  | 0.953        |\n",
      "|    value_loss           | 0.000736     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39173.68359375\n",
      "Final accumulative portfolio value: 0.39173683524131775\n",
      "Maximum DrawDown: -0.6327884438235023\n",
      "Sharpe ratio: -0.6535517035254305\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 1161          |\n",
      "|    total_timesteps      | 108544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011865166   |\n",
      "|    clip_fraction        | 0.143         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41           |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0139       |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.0111       |\n",
      "|    reward               | -0.0021989066 |\n",
      "|    std                  | 0.952         |\n",
      "|    value_loss           | 0.000775      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36304.9453125\n",
      "Final accumulative portfolio value: 0.3630494475364685\n",
      "Maximum DrawDown: -0.665153148089078\n",
      "Sharpe ratio: -0.7033000302586728\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 93           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 1182         |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010220828  |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41          |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0265      |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.0114      |\n",
      "|    reward               | -0.015037321 |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 0.000748     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38344.28515625\n",
      "Final accumulative portfolio value: 0.38344284892082214\n",
      "Maximum DrawDown: -0.6367674162570565\n",
      "Sharpe ratio: -0.6638703286988169\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 55            |\n",
      "|    time_elapsed         | 1204          |\n",
      "|    total_timesteps      | 112640        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011992346   |\n",
      "|    clip_fraction        | 0.13          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41           |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0251       |\n",
      "|    n_updates            | 540           |\n",
      "|    policy_gradient_loss | -0.00881      |\n",
      "|    reward               | -0.0052864566 |\n",
      "|    std                  | 0.951         |\n",
      "|    value_loss           | 0.00101       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37255.37890625\n",
      "Final accumulative portfolio value: 0.3725537955760956\n",
      "Maximum DrawDown: -0.6526145426215623\n",
      "Sharpe ratio: -0.6863330023602664\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 1225        |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007969536 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41         |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.048      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    reward               | 0.011405857 |\n",
      "|    std                  | 0.949       |\n",
      "|    value_loss           | 0.000748    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37442.97265625\n",
      "Final accumulative portfolio value: 0.37442973256111145\n",
      "Maximum DrawDown: -0.6548220830146977\n",
      "Sharpe ratio: -0.6810950411041672\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37355.296875\n",
      "Final accumulative portfolio value: 0.37355297803878784\n",
      "Maximum DrawDown: -0.645021039765834\n",
      "Sharpe ratio: -0.6856683935943955\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 1248          |\n",
      "|    total_timesteps      | 116736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010317242   |\n",
      "|    clip_fraction        | 0.124         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0303       |\n",
      "|    n_updates            | 560           |\n",
      "|    policy_gradient_loss | -0.0107       |\n",
      "|    reward               | -0.0146904895 |\n",
      "|    std                  | 0.95          |\n",
      "|    value_loss           | 0.000831      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35939.90625\n",
      "Final accumulative portfolio value: 0.35939905047416687\n",
      "Maximum DrawDown: -0.6685327140164855\n",
      "Sharpe ratio: -0.7110457583441899\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1268        |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010587714 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.9       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00284    |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    reward               | 0.002128361 |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 0.000753    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33963.8203125\n",
      "Final accumulative portfolio value: 0.33963820338249207\n",
      "Maximum DrawDown: -0.6790880629052486\n",
      "Sharpe ratio: -0.757359616895516\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 93            |\n",
      "|    iterations           | 59            |\n",
      "|    time_elapsed         | 1287          |\n",
      "|    total_timesteps      | 120832        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012040058   |\n",
      "|    clip_fraction        | 0.142         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0233       |\n",
      "|    n_updates            | 580           |\n",
      "|    policy_gradient_loss | -0.0115       |\n",
      "|    reward               | 0.00062624866 |\n",
      "|    std                  | 0.949         |\n",
      "|    value_loss           | 0.000746      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35487.37109375\n",
      "Final accumulative portfolio value: 0.3548737168312073\n",
      "Maximum DrawDown: -0.6698151712137861\n",
      "Sharpe ratio: -0.7247218483880916\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 94            |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 1306          |\n",
      "|    total_timesteps      | 122880        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.01095417    |\n",
      "|    clip_fraction        | 0.151         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00173       |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.013        |\n",
      "|    reward               | -0.0075791273 |\n",
      "|    std                  | 0.95          |\n",
      "|    value_loss           | 0.000726      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37440.390625\n",
      "Final accumulative portfolio value: 0.3744038939476013\n",
      "Maximum DrawDown: -0.6450179710194863\n",
      "Sharpe ratio: -0.680971590732316\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1325        |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012053238 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.9       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | 0.010722523 |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 0.00073     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36236.484375\n",
      "Final accumulative portfolio value: 0.36236485838890076\n",
      "Maximum DrawDown: -0.6569618661764531\n",
      "Sharpe ratio: -0.7099665038994736\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.79e+03       |\n",
      "|    ep_rew_mean          | -1.03          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 94             |\n",
      "|    iterations           | 62             |\n",
      "|    time_elapsed         | 1344           |\n",
      "|    total_timesteps      | 126976         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.012393964    |\n",
      "|    clip_fraction        | 0.145          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -40.9          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | -0.000436      |\n",
      "|    n_updates            | 610            |\n",
      "|    policy_gradient_loss | -0.0122        |\n",
      "|    reward               | -0.00058173167 |\n",
      "|    std                  | 0.95           |\n",
      "|    value_loss           | 0.00102        |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36474.94140625\n",
      "Final accumulative portfolio value: 0.36474940180778503\n",
      "Maximum DrawDown: -0.6642316748214916\n",
      "Sharpe ratio: -0.7061848366880464\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1363        |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009708248 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41         |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | 0.025652548 |\n",
      "|    std                  | 0.952       |\n",
      "|    value_loss           | 0.000783    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34776.0390625\n",
      "Final accumulative portfolio value: 0.3477603793144226\n",
      "Maximum DrawDown: -0.6728347720706642\n",
      "Sharpe ratio: -0.7356185701931577\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36122.8203125\n",
      "Final accumulative portfolio value: 0.36122819781303406\n",
      "Maximum DrawDown: -0.660401868791445\n",
      "Sharpe ratio: -0.7130059516588503\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 94            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 1382          |\n",
      "|    total_timesteps      | 131072        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010818634   |\n",
      "|    clip_fraction        | 0.121         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41           |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0396       |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -0.00947      |\n",
      "|    reward               | -0.0013730411 |\n",
      "|    std                  | 0.951         |\n",
      "|    value_loss           | 0.000839      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 33752.3203125\n",
      "Final accumulative portfolio value: 0.3375231921672821\n",
      "Maximum DrawDown: -0.686477989880135\n",
      "Sharpe ratio: -0.76575385381792\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 94            |\n",
      "|    iterations           | 65            |\n",
      "|    time_elapsed         | 1401          |\n",
      "|    total_timesteps      | 133120        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011034777   |\n",
      "|    clip_fraction        | 0.133         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -41           |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0134        |\n",
      "|    n_updates            | 640           |\n",
      "|    policy_gradient_loss | -0.0112       |\n",
      "|    reward               | -0.0042230124 |\n",
      "|    std                  | 0.95          |\n",
      "|    value_loss           | 0.000781      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35013.3515625\n",
      "Final accumulative portfolio value: 0.3501335084438324\n",
      "Maximum DrawDown: -0.6717312537636093\n",
      "Sharpe ratio: -0.7331026885384867\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 1420         |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011257283  |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -41          |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0012       |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00965     |\n",
      "|    reward               | 0.0072153937 |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 0.000711     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37365.2734375\n",
      "Final accumulative portfolio value: 0.37365272641181946\n",
      "Maximum DrawDown: -0.6586913339290861\n",
      "Sharpe ratio: -0.6772699686329459\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.03         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 95            |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 1439          |\n",
      "|    total_timesteps      | 137216        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010964844   |\n",
      "|    clip_fraction        | 0.133         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.9         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0183       |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | -0.0122       |\n",
      "|    reward               | 0.00031788065 |\n",
      "|    std                  | 0.946         |\n",
      "|    value_loss           | 0.000711      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36392.33203125\n",
      "Final accumulative portfolio value: 0.3639233112335205\n",
      "Maximum DrawDown: -0.6593498370635833\n",
      "Sharpe ratio: -0.7018617593505089\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 1458        |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011571363 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 0.014137239 |\n",
      "|    std                  | 0.947       |\n",
      "|    value_loss           | 0.000775    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 35139.5703125\n",
      "Final accumulative portfolio value: 0.35139569640159607\n",
      "Maximum DrawDown: -0.6683132963818108\n",
      "Sharpe ratio: -0.7291533163310324\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 1477         |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011612959  |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.9        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0128      |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    reward               | -0.009018916 |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 0.00104      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38057.76171875\n",
      "Final accumulative portfolio value: 0.38057762384414673\n",
      "Maximum DrawDown: -0.6502115920944191\n",
      "Sharpe ratio: -0.6717935312389405\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 1496        |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011133187 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.8       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00855    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | 0.011794593 |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 0.000757    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34690.1875\n",
      "Final accumulative portfolio value: 0.34690186381340027\n",
      "Maximum DrawDown: -0.6846896822290383\n",
      "Sharpe ratio: -0.7428342287094059\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37968.51953125\n",
      "Final accumulative portfolio value: 0.3796851933002472\n",
      "Maximum DrawDown: -0.6452596403459989\n",
      "Sharpe ratio: -0.6787786160104412\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.79e+03       |\n",
      "|    ep_rew_mean          | -1.03          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 95             |\n",
      "|    iterations           | 71             |\n",
      "|    time_elapsed         | 1516           |\n",
      "|    total_timesteps      | 145408         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.011197194    |\n",
      "|    clip_fraction        | 0.131          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -40.8          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | -0.000592      |\n",
      "|    n_updates            | 700            |\n",
      "|    policy_gradient_loss | -0.00891       |\n",
      "|    reward               | -0.00073477795 |\n",
      "|    std                  | 0.943          |\n",
      "|    value_loss           | 0.000814       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39175.0859375\n",
      "Final accumulative portfolio value: 0.39175087213516235\n",
      "Maximum DrawDown: -0.6411430095306815\n",
      "Sharpe ratio: -0.6525437398277892\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 1535         |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.013059678  |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.7        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0329      |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    reward               | 0.0037219315 |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 0.000807     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40017.015625\n",
      "Final accumulative portfolio value: 0.40017014741897583\n",
      "Maximum DrawDown: -0.6372232733864078\n",
      "Sharpe ratio: -0.6328892612374366\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 1554        |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011163076 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.7       |\n",
      "|    explained_variance   | 5.96e-08    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    reward               | 0.004106542 |\n",
      "|    std                  | 0.94        |\n",
      "|    value_loss           | 0.000705    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36450.265625\n",
      "Final accumulative portfolio value: 0.3645026683807373\n",
      "Maximum DrawDown: -0.6610573486610918\n",
      "Sharpe ratio: -0.7032854345857514\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 1573         |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146835055 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0206      |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    reward               | 0.013118036  |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 0.000744     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40785.59765625\n",
      "Final accumulative portfolio value: 0.4078559875488281\n",
      "Maximum DrawDown: -0.6134091079671617\n",
      "Sharpe ratio: -0.6137048436295265\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.02       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 1592        |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009886097 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.7       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0227     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    reward               | -0.00296053 |\n",
      "|    std                  | 0.942       |\n",
      "|    value_loss           | 0.000749    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 34123.828125\n",
      "Final accumulative portfolio value: 0.3412382900714874\n",
      "Maximum DrawDown: -0.6776695927036847\n",
      "Sharpe ratio: -0.7522285748127182\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 96            |\n",
      "|    iterations           | 76            |\n",
      "|    time_elapsed         | 1610          |\n",
      "|    total_timesteps      | 155648        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.010395363   |\n",
      "|    clip_fraction        | 0.105         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.7         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000964     |\n",
      "|    n_updates            | 750           |\n",
      "|    policy_gradient_loss | -0.00825      |\n",
      "|    reward               | 0.00017057394 |\n",
      "|    std                  | 0.941         |\n",
      "|    value_loss           | 0.00103       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38747.35546875\n",
      "Final accumulative portfolio value: 0.38747355341911316\n",
      "Maximum DrawDown: -0.6422359238692161\n",
      "Sharpe ratio: -0.6525644805688045\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 96            |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 1629          |\n",
      "|    total_timesteps      | 157696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0073756557  |\n",
      "|    clip_fraction        | 0.0893        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.7         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0288       |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -0.00771      |\n",
      "|    reward               | -0.0064258957 |\n",
      "|    std                  | 0.942         |\n",
      "|    value_loss           | 0.000773      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36909.5859375\n",
      "Final accumulative portfolio value: 0.3690958619117737\n",
      "Maximum DrawDown: -0.6539140341297263\n",
      "Sharpe ratio: -0.6832579343680305\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40965.79296875\n",
      "Final accumulative portfolio value: 0.40965792536735535\n",
      "Maximum DrawDown: -0.6156580247156475\n",
      "Sharpe ratio: -0.6049071836588171\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 1648         |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011802548  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00416      |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00873     |\n",
      "|    reward               | 0.0033058063 |\n",
      "|    std                  | 0.939        |\n",
      "|    value_loss           | 0.000797     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37073.13671875\n",
      "Final accumulative portfolio value: 0.3707313537597656\n",
      "Maximum DrawDown: -0.6502626121489572\n",
      "Sharpe ratio: -0.688100153137647\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 1667         |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012066577  |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0117      |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    reward               | -0.002230328 |\n",
      "|    std                  | 0.941        |\n",
      "|    value_loss           | 0.0008       |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37431.6875\n",
      "Final accumulative portfolio value: 0.37431687116622925\n",
      "Maximum DrawDown: -0.6553319245950604\n",
      "Sharpe ratio: -0.6734744229215929\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.02        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 1686         |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010444231  |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0278      |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    reward               | 0.0076188934 |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 0.000724     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36786.26953125\n",
      "Final accumulative portfolio value: 0.3678627014160156\n",
      "Maximum DrawDown: -0.6586489989038078\n",
      "Sharpe ratio: -0.6924945298634477\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 97            |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 1705          |\n",
      "|    total_timesteps      | 165888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012484318   |\n",
      "|    clip_fraction        | 0.118         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.6         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00775      |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | -0.0103       |\n",
      "|    reward               | -0.0064173774 |\n",
      "|    std                  | 0.939         |\n",
      "|    value_loss           | 0.000773      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39621.71875\n",
      "Final accumulative portfolio value: 0.3962171971797943\n",
      "Maximum DrawDown: -0.6326200167082023\n",
      "Sharpe ratio: -0.6387386155088073\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 97            |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 1724          |\n",
      "|    total_timesteps      | 167936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.012637145   |\n",
      "|    clip_fraction        | 0.144         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.6         |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00991      |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.0117       |\n",
      "|    reward               | -0.0021851675 |\n",
      "|    std                  | 0.939         |\n",
      "|    value_loss           | 0.00074       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40538.83203125\n",
      "Final accumulative portfolio value: 0.40538832545280457\n",
      "Maximum DrawDown: -0.6314977399099256\n",
      "Sharpe ratio: -0.6193060228645112\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.02         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 97            |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 1743          |\n",
      "|    total_timesteps      | 169984        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011493087   |\n",
      "|    clip_fraction        | 0.113         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.6         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0142       |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -0.00975      |\n",
      "|    reward               | -0.0025881017 |\n",
      "|    std                  | 0.939         |\n",
      "|    value_loss           | 0.00102       |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37283.03125\n",
      "Final accumulative portfolio value: 0.3728303015232086\n",
      "Maximum DrawDown: -0.6485102981451389\n",
      "Sharpe ratio: -0.6806378884104402\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 1762         |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.010350835  |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00339     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.0134      |\n",
      "|    reward               | -0.005602108 |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 0.000777     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39487.48828125\n",
      "Final accumulative portfolio value: 0.3948748707771301\n",
      "Maximum DrawDown: -0.6293123337767865\n",
      "Sharpe ratio: -0.6374998971442132\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39338.125\n",
      "Final accumulative portfolio value: 0.3933812379837036\n",
      "Maximum DrawDown: -0.6449443281554532\n",
      "Sharpe ratio: -0.640431254252526\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 1782         |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092966035 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0151      |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00999     |\n",
      "|    reward               | -0.007264472 |\n",
      "|    std                  | 0.938        |\n",
      "|    value_loss           | 0.000765     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37554.9765625\n",
      "Final accumulative portfolio value: 0.3755497634410858\n",
      "Maximum DrawDown: -0.655124162624867\n",
      "Sharpe ratio: -0.6834631960273897\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.01         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 97            |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 1801          |\n",
      "|    total_timesteps      | 176128        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.0095776785  |\n",
      "|    clip_fraction        | 0.119         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.5         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.023        |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.0107       |\n",
      "|    reward               | -0.0039301757 |\n",
      "|    std                  | 0.936         |\n",
      "|    value_loss           | 0.000797      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37994.94921875\n",
      "Final accumulative portfolio value: 0.3799494802951813\n",
      "Maximum DrawDown: -0.6482714565593058\n",
      "Sharpe ratio: -0.6771782011779063\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 97           |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 1821         |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011254293  |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.5        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0311      |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00986     |\n",
      "|    reward               | -0.008882095 |\n",
      "|    std                  | 0.934        |\n",
      "|    value_loss           | 0.000684     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37679.84765625\n",
      "Final accumulative portfolio value: 0.37679848074913025\n",
      "Maximum DrawDown: -0.6459048675782605\n",
      "Sharpe ratio: -0.6714028907697523\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.79e+03      |\n",
      "|    ep_rew_mean          | -1.01         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 97            |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 1840          |\n",
      "|    total_timesteps      | 180224        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.011160541   |\n",
      "|    clip_fraction        | 0.12          |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -40.5         |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0142       |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | -0.0115       |\n",
      "|    reward               | -0.0016681153 |\n",
      "|    std                  | 0.937         |\n",
      "|    value_loss           | 0.000756      |\n",
      "-------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38369.484375\n",
      "Final accumulative portfolio value: 0.3836948573589325\n",
      "Maximum DrawDown: -0.6494595384165937\n",
      "Sharpe ratio: -0.6595850755427384\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1860        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010680366 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.5       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    reward               | 0.011832175 |\n",
      "|    std                  | 0.938       |\n",
      "|    value_loss           | 0.000744    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39942.265625\n",
      "Final accumulative portfolio value: 0.39942264556884766\n",
      "Maximum DrawDown: -0.6243790324731259\n",
      "Sharpe ratio: -0.6332755194456553\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.79e+03       |\n",
      "|    ep_rew_mean          | -1.01          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 98             |\n",
      "|    iterations           | 90             |\n",
      "|    time_elapsed         | 1879           |\n",
      "|    total_timesteps      | 184320         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.0112380665   |\n",
      "|    clip_fraction        | 0.138          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -40.6          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0206         |\n",
      "|    n_updates            | 890            |\n",
      "|    policy_gradient_loss | -0.0112        |\n",
      "|    reward               | -0.00046240052 |\n",
      "|    std                  | 0.94           |\n",
      "|    value_loss           | 0.000992       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38531.97265625\n",
      "Final accumulative portfolio value: 0.3853197395801544\n",
      "Maximum DrawDown: -0.648987619315357\n",
      "Sharpe ratio: -0.659409709410663\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.01       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1897        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013055215 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.6       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    reward               | 0.00847186  |\n",
      "|    std                  | 0.939       |\n",
      "|    value_loss           | 0.00074     |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36647.92578125\n",
      "Final accumulative portfolio value: 0.3664792478084564\n",
      "Maximum DrawDown: -0.6617733742970989\n",
      "Sharpe ratio: -0.6980683863913673\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 37434.9140625\n",
      "Final accumulative portfolio value: 0.3743491470813751\n",
      "Maximum DrawDown: -0.6505158328778189\n",
      "Sharpe ratio: -0.6730957045358271\n",
      "=================================\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 1.79e+03       |\n",
      "|    ep_rew_mean          | -1.01          |\n",
      "| time/                   |                |\n",
      "|    fps                  | 98             |\n",
      "|    iterations           | 92             |\n",
      "|    time_elapsed         | 1917           |\n",
      "|    total_timesteps      | 188416         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.010272737    |\n",
      "|    clip_fraction        | 0.112          |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -40.6          |\n",
      "|    explained_variance   | 0              |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 0.0108         |\n",
      "|    n_updates            | 910            |\n",
      "|    policy_gradient_loss | -0.00832       |\n",
      "|    reward               | -0.00096421223 |\n",
      "|    std                  | 0.941          |\n",
      "|    value_loss           | 0.000776       |\n",
      "--------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36440.79296875\n",
      "Final accumulative portfolio value: 0.3644079267978668\n",
      "Maximum DrawDown: -0.652759528899564\n",
      "Sharpe ratio: -0.6961434659112404\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.01        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 1936         |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01099182   |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.6        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0264      |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    reward               | 0.0008507923 |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 0.00085      |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40556.83984375\n",
      "Final accumulative portfolio value: 0.405568391084671\n",
      "Maximum DrawDown: -0.6180551989578154\n",
      "Sharpe ratio: -0.6191457775265604\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 1955         |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.012853079  |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.7        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0541      |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    reward               | -0.002946302 |\n",
      "|    std                  | 0.942        |\n",
      "|    value_loss           | 0.000727     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 40440.80078125\n",
      "Final accumulative portfolio value: 0.4044080078601837\n",
      "Maximum DrawDown: -0.6205415833535552\n",
      "Sharpe ratio: -0.6184397919428662\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 1974         |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.009703598  |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.7        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0219      |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0101      |\n",
      "|    reward               | -0.014776142 |\n",
      "|    std                  | 0.945        |\n",
      "|    value_loss           | 0.000712     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 36750.265625\n",
      "Final accumulative portfolio value: 0.3675026595592499\n",
      "Maximum DrawDown: -0.654415458756001\n",
      "Sharpe ratio: -0.6964428680797297\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 98          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1992        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011051258 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -40.7       |\n",
      "|    explained_variance   | -1.19e-07   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    reward               | 0.018538892 |\n",
      "|    std                  | 0.944       |\n",
      "|    value_loss           | 0.000728    |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 38143.90234375\n",
      "Final accumulative portfolio value: 0.3814390301704407\n",
      "Maximum DrawDown: -0.6445725680596497\n",
      "Sharpe ratio: -0.6719001766219486\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 2011         |\n",
      "|    total_timesteps      | 198656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.01171943   |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.7        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0376      |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    reward               | -0.004018622 |\n",
      "|    std                  | 0.943        |\n",
      "|    value_loss           | 0.000978     |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 39052.45703125\n",
      "Final accumulative portfolio value: 0.39052456617355347\n",
      "Maximum DrawDown: -0.6434802365609278\n",
      "Sharpe ratio: -0.6450671920111309\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -0.999       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 2030         |\n",
      "|    total_timesteps      | 200704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.011077748  |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -40.7        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00442     |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    reward               | -0.010115412 |\n",
      "|    std                  | 0.94         |\n",
      "|    value_loss           | 0.000762     |\n",
      "------------------------------------------\n",
      "PPO training completed in 33.86 minutes.\n",
      "Training SAC...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzitoh/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 34.93GB > 3.45GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 61956.73046875\n",
      "Final accumulative portfolio value: 0.6195672750473022\n",
      "Maximum DrawDown: -0.4989515796113747\n",
      "Sharpe ratio: -0.2869442840873654\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58612.63671875\n",
      "Final accumulative portfolio value: 0.5861263871192932\n",
      "Maximum DrawDown: -0.4964803025809811\n",
      "Sharpe ratio: -0.329417121289313\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57723.19921875\n",
      "Final accumulative portfolio value: 0.5772320032119751\n",
      "Maximum DrawDown: -0.49616043183206915\n",
      "Sharpe ratio: -0.33937586042310014\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57098.66015625\n",
      "Final accumulative portfolio value: 0.5709866285324097\n",
      "Maximum DrawDown: -0.5064193913410973\n",
      "Sharpe ratio: -0.3499467817044976\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.523      |\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 213         |\n",
      "|    total_timesteps | 7176        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 116         |\n",
      "|    critic_loss     | 2.08        |\n",
      "|    ent_coef        | 0.229       |\n",
      "|    ent_coef_loss   | -74.3       |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 7075        |\n",
      "|    reward          | 0.008527414 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 55634.9375\n",
      "Final accumulative portfolio value: 0.5563493967056274\n",
      "Maximum DrawDown: -0.5047001459822674\n",
      "Sharpe ratio: -0.3701716228993029\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 62258.78515625\n",
      "Final accumulative portfolio value: 0.6225878596305847\n",
      "Maximum DrawDown: -0.46587252492326425\n",
      "Sharpe ratio: -0.28069037343430164\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58172.12890625\n",
      "Final accumulative portfolio value: 0.581721305847168\n",
      "Maximum DrawDown: -0.4992444281387618\n",
      "Sharpe ratio: -0.33374212462402064\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57170.23046875\n",
      "Final accumulative portfolio value: 0.5717023015022278\n",
      "Maximum DrawDown: -0.5193092734211968\n",
      "Sharpe ratio: -0.348645884604879\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.528      |\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 418         |\n",
      "|    total_timesteps | 14352       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 37.2        |\n",
      "|    critic_loss     | 0.774       |\n",
      "|    ent_coef        | 0.0268      |\n",
      "|    ent_coef_loss   | -176        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 14251       |\n",
      "|    reward          | 0.008508976 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 62201.54296875\n",
      "Final accumulative portfolio value: 0.6220154166221619\n",
      "Maximum DrawDown: -0.47818584239377016\n",
      "Sharpe ratio: -0.2797793538303058\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 63929.94140625\n",
      "Final accumulative portfolio value: 0.6392993927001953\n",
      "Maximum DrawDown: -0.4600737248524329\n",
      "Sharpe ratio: -0.26031858351052645\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 65537.5234375\n",
      "Final accumulative portfolio value: 0.6553752422332764\n",
      "Maximum DrawDown: -0.45374838012004015\n",
      "Sharpe ratio: -0.2385560462862658\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 76935.0234375\n",
      "Final accumulative portfolio value: 0.7693502306938171\n",
      "Maximum DrawDown: -0.4063089568570777\n",
      "Sharpe ratio: -0.11134082611609418\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.483      |\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 626         |\n",
      "|    total_timesteps | 21528       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 31.2        |\n",
      "|    critic_loss     | 0.333       |\n",
      "|    ent_coef        | 0.0033      |\n",
      "|    ent_coef_loss   | -220        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 21427       |\n",
      "|    reward          | 0.007340366 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 78791.9765625\n",
      "Final accumulative portfolio value: 0.7879197597503662\n",
      "Maximum DrawDown: -0.38897768738956906\n",
      "Sharpe ratio: -0.09288707477563578\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 69111.65625\n",
      "Final accumulative portfolio value: 0.6911165714263916\n",
      "Maximum DrawDown: -0.44903661257528893\n",
      "Sharpe ratio: -0.19624451527021905\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 73960.546875\n",
      "Final accumulative portfolio value: 0.7396054863929749\n",
      "Maximum DrawDown: -0.4161543349582473\n",
      "Sharpe ratio: -0.14211994362066557\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 86163.265625\n",
      "Final accumulative portfolio value: 0.8616326451301575\n",
      "Maximum DrawDown: -0.40562140959395276\n",
      "Sharpe ratio: -0.024397674907487142\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.427      |\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 856         |\n",
      "|    total_timesteps | 28704       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 25          |\n",
      "|    critic_loss     | 0.347       |\n",
      "|    ent_coef        | 0.000409    |\n",
      "|    ent_coef_loss   | -239        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 28603       |\n",
      "|    reward          | 0.007846841 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 94409.0390625\n",
      "Final accumulative portfolio value: 0.9440903663635254\n",
      "Maximum DrawDown: -0.36828623640031866\n",
      "Sharpe ratio: 0.04361369172673968\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 95816.6875\n",
      "Final accumulative portfolio value: 0.9581668972969055\n",
      "Maximum DrawDown: -0.3620866127584974\n",
      "Sharpe ratio: 0.05519714995736468\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 97020.8359375\n",
      "Final accumulative portfolio value: 0.9702083468437195\n",
      "Maximum DrawDown: -0.36206483492912345\n",
      "Sharpe ratio: 0.06627289007564978\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 122689.3671875\n",
      "Final accumulative portfolio value: 1.226893663406372\n",
      "Maximum DrawDown: -0.31806666894430835\n",
      "Sharpe ratio: 0.24927932831629962\n",
      "=================================\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 1.79e+03   |\n",
      "|    ep_rew_mean     | -0.336     |\n",
      "| time/              |            |\n",
      "|    episodes        | 20         |\n",
      "|    fps             | 32         |\n",
      "|    time_elapsed    | 1111       |\n",
      "|    total_timesteps | 35880      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 18.9       |\n",
      "|    critic_loss     | 0.0311     |\n",
      "|    ent_coef        | 6.7e-05    |\n",
      "|    ent_coef_loss   | -92.4      |\n",
      "|    learning_rate   | 0.0003     |\n",
      "|    n_updates       | 35779      |\n",
      "|    reward          | 0.00887698 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 115505.6796875\n",
      "Final accumulative portfolio value: 1.1550568342208862\n",
      "Maximum DrawDown: -0.32179641858945285\n",
      "Sharpe ratio: 0.20266751773451785\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 125636.203125\n",
      "Final accumulative portfolio value: 1.2563620805740356\n",
      "Maximum DrawDown: -0.31731859941209273\n",
      "Sharpe ratio: 0.2700076678958468\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 133151.15625\n",
      "Final accumulative portfolio value: 1.3315116167068481\n",
      "Maximum DrawDown: -0.3149944787751744\n",
      "Sharpe ratio: 0.31448209866640964\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 146781.734375\n",
      "Final accumulative portfolio value: 1.4678173065185547\n",
      "Maximum DrawDown: -0.3339830596714932\n",
      "Sharpe ratio: 0.38488879686049643\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.235      |\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 1361        |\n",
      "|    total_timesteps | 43056       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 16.4        |\n",
      "|    critic_loss     | 0.0364      |\n",
      "|    ent_coef        | 2.91e-05    |\n",
      "|    ent_coef_loss   | 46.6        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 42955       |\n",
      "|    reward          | 0.008773707 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 152813.875\n",
      "Final accumulative portfolio value: 1.5281387567520142\n",
      "Maximum DrawDown: -0.33737235956990663\n",
      "Sharpe ratio: 0.41432459213742123\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149270.125\n",
      "Final accumulative portfolio value: 1.4927012920379639\n",
      "Maximum DrawDown: -0.3364490237873303\n",
      "Sharpe ratio: 0.3985198925821377\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150185.75\n",
      "Final accumulative portfolio value: 1.5018575191497803\n",
      "Maximum DrawDown: -0.3414200705389122\n",
      "Sharpe ratio: 0.40448375102350814\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 145202.953125\n",
      "Final accumulative portfolio value: 1.4520295858383179\n",
      "Maximum DrawDown: -0.33734094978054807\n",
      "Sharpe ratio: 0.38154128151299416\n",
      "=================================\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 1.79e+03   |\n",
      "|    ep_rew_mean     | -0.143     |\n",
      "| time/              |            |\n",
      "|    episodes        | 28         |\n",
      "|    fps             | 31         |\n",
      "|    time_elapsed    | 1601       |\n",
      "|    total_timesteps | 50232      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 13.1       |\n",
      "|    critic_loss     | 0.0281     |\n",
      "|    ent_coef        | 1.14e-05   |\n",
      "|    ent_coef_loss   | 41.8       |\n",
      "|    learning_rate   | 0.0003     |\n",
      "|    n_updates       | 50131      |\n",
      "|    reward          | 0.00786328 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 164924.359375\n",
      "Final accumulative portfolio value: 1.6492435932159424\n",
      "Maximum DrawDown: -0.31362705097772003\n",
      "Sharpe ratio: 0.4893794416374123\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 151535.65625\n",
      "Final accumulative portfolio value: 1.5153565406799316\n",
      "Maximum DrawDown: -0.31828039918703876\n",
      "Sharpe ratio: 0.42481886456926127\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149975.28125\n",
      "Final accumulative portfolio value: 1.4997527599334717\n",
      "Maximum DrawDown: -0.3166998413339396\n",
      "Sharpe ratio: 0.412050400164712\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 152424.484375\n",
      "Final accumulative portfolio value: 1.524244785308838\n",
      "Maximum DrawDown: -0.3055158683424025\n",
      "Sharpe ratio: 0.42791770524344047\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.0697     |\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 1834        |\n",
      "|    total_timesteps | 57408       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 10.1        |\n",
      "|    critic_loss     | 0.0058      |\n",
      "|    ent_coef        | 1.12e-05    |\n",
      "|    ent_coef_loss   | -20.4       |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 57307       |\n",
      "|    reward          | 0.008904982 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 158437.921875\n",
      "Final accumulative portfolio value: 1.5843791961669922\n",
      "Maximum DrawDown: -0.3089319840055669\n",
      "Sharpe ratio: 0.447029211154733\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 160388.515625\n",
      "Final accumulative portfolio value: 1.6038851737976074\n",
      "Maximum DrawDown: -0.31875814969308425\n",
      "Sharpe ratio: 0.4549296335573933\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 156130.859375\n",
      "Final accumulative portfolio value: 1.5613086223602295\n",
      "Maximum DrawDown: -0.3126916763909433\n",
      "Sharpe ratio: 0.43797998998878446\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 155529.78125\n",
      "Final accumulative portfolio value: 1.5552978515625\n",
      "Maximum DrawDown: -0.3128611164416707\n",
      "Sharpe ratio: 0.43508997371546393\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | -0.0104     |\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2059        |\n",
      "|    total_timesteps | 64584       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 8.15        |\n",
      "|    critic_loss     | 0.00659     |\n",
      "|    ent_coef        | 1.13e-05    |\n",
      "|    ent_coef_loss   | -10.4       |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 64483       |\n",
      "|    reward          | 0.007918041 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 144481.484375\n",
      "Final accumulative portfolio value: 1.4448148012161255\n",
      "Maximum DrawDown: -0.30778599976416965\n",
      "Sharpe ratio: 0.3809186262657155\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140123.640625\n",
      "Final accumulative portfolio value: 1.4012364149093628\n",
      "Maximum DrawDown: -0.3107440108417635\n",
      "Sharpe ratio: 0.35838069035048087\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 123208.921875\n",
      "Final accumulative portfolio value: 1.2320891618728638\n",
      "Maximum DrawDown: -0.3303273938026696\n",
      "Sharpe ratio: 0.25487207384584265\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129982.53125\n",
      "Final accumulative portfolio value: 1.2998253107070923\n",
      "Maximum DrawDown: -0.3310074512068819\n",
      "Sharpe ratio: 0.2971918592519407\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 1.79e+03     |\n",
      "|    ep_rew_mean     | 0.0208       |\n",
      "| time/              |              |\n",
      "|    episodes        | 40           |\n",
      "|    fps             | 31           |\n",
      "|    time_elapsed    | 2277         |\n",
      "|    total_timesteps | 71760        |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 6.2          |\n",
      "|    critic_loss     | 0.000931     |\n",
      "|    ent_coef        | 4.01e-06     |\n",
      "|    ent_coef_loss   | 7.61         |\n",
      "|    learning_rate   | 0.0003       |\n",
      "|    n_updates       | 71659        |\n",
      "|    reward          | 0.0079355445 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 137123.375\n",
      "Final accumulative portfolio value: 1.3712337017059326\n",
      "Maximum DrawDown: -0.33617732210533424\n",
      "Sharpe ratio: 0.33643728372058723\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 135463.921875\n",
      "Final accumulative portfolio value: 1.3546391725540161\n",
      "Maximum DrawDown: -0.321832116142588\n",
      "Sharpe ratio: 0.3289751313527661\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 137879.34375\n",
      "Final accumulative portfolio value: 1.378793478012085\n",
      "Maximum DrawDown: -0.3170002243185164\n",
      "Sharpe ratio: 0.34357926404205263\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 136132.5625\n",
      "Final accumulative portfolio value: 1.3613256216049194\n",
      "Maximum DrawDown: -0.3224700264453447\n",
      "Sharpe ratio: 0.33644955369882334\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.048       |\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2503        |\n",
      "|    total_timesteps | 78936       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 4.57        |\n",
      "|    critic_loss     | 0.00496     |\n",
      "|    ent_coef        | 3.02e-06    |\n",
      "|    ent_coef_loss   | 24.2        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 78835       |\n",
      "|    reward          | 0.007340011 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 132042.84375\n",
      "Final accumulative portfolio value: 1.320428490638733\n",
      "Maximum DrawDown: -0.32472863139680785\n",
      "Sharpe ratio: 0.31238224608243736\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129072.828125\n",
      "Final accumulative portfolio value: 1.2907283306121826\n",
      "Maximum DrawDown: -0.3203318477528041\n",
      "Sharpe ratio: 0.29482435590081024\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 126076.40625\n",
      "Final accumulative portfolio value: 1.2607641220092773\n",
      "Maximum DrawDown: -0.3251963628793513\n",
      "Sharpe ratio: 0.2734133706604438\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149860.421875\n",
      "Final accumulative portfolio value: 1.49860417842865\n",
      "Maximum DrawDown: -0.310339920448636\n",
      "Sharpe ratio: 0.41283279925206245\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.069       |\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2762        |\n",
      "|    total_timesteps | 86112       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 3.42        |\n",
      "|    critic_loss     | 0.00592     |\n",
      "|    ent_coef        | 2.36e-06    |\n",
      "|    ent_coef_loss   | 45.4        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 86011       |\n",
      "|    reward          | 0.007838798 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150501.78125\n",
      "Final accumulative portfolio value: 1.5050177574157715\n",
      "Maximum DrawDown: -0.3332778997444247\n",
      "Sharpe ratio: 0.4093334980924025\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149641.515625\n",
      "Final accumulative portfolio value: 1.496415138244629\n",
      "Maximum DrawDown: -0.3213405912311804\n",
      "Sharpe ratio: 0.40756938135616044\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 141704.234375\n",
      "Final accumulative portfolio value: 1.4170423746109009\n",
      "Maximum DrawDown: -0.31709316971381174\n",
      "Sharpe ratio: 0.3633441058330122\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149705.90625\n",
      "Final accumulative portfolio value: 1.4970591068267822\n",
      "Maximum DrawDown: -0.3191038996820229\n",
      "Sharpe ratio: 0.4055476069521065\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.0944      |\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 3041        |\n",
      "|    total_timesteps | 93288       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.36        |\n",
      "|    critic_loss     | 0.00146     |\n",
      "|    ent_coef        | 3.36e-06    |\n",
      "|    ent_coef_loss   | -1.46       |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 93187       |\n",
      "|    reward          | 0.008324331 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 144409.296875\n",
      "Final accumulative portfolio value: 1.4440929889678955\n",
      "Maximum DrawDown: -0.3212225373119365\n",
      "Sharpe ratio: 0.3788286294032646\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 146401.84375\n",
      "Final accumulative portfolio value: 1.46401846408844\n",
      "Maximum DrawDown: -0.3220498393241964\n",
      "Sharpe ratio: 0.3921456013897396\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 148306.5625\n",
      "Final accumulative portfolio value: 1.4830656051635742\n",
      "Maximum DrawDown: -0.3048836439874184\n",
      "Sharpe ratio: 0.40321943975200736\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 154298.09375\n",
      "Final accumulative portfolio value: 1.5429809093475342\n",
      "Maximum DrawDown: -0.3175878677457339\n",
      "Sharpe ratio: 0.43117514099635035\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.116       |\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 3317        |\n",
      "|    total_timesteps | 100464      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.85        |\n",
      "|    critic_loss     | 0.000358    |\n",
      "|    ent_coef        | 2.03e-06    |\n",
      "|    ent_coef_loss   | 11.7        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 100363      |\n",
      "|    reward          | 0.008426705 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 156040.90625\n",
      "Final accumulative portfolio value: 1.5604090690612793\n",
      "Maximum DrawDown: -0.32053607493621283\n",
      "Sharpe ratio: 0.44063309421289637\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 153736.765625\n",
      "Final accumulative portfolio value: 1.5373677015304565\n",
      "Maximum DrawDown: -0.32259048765880727\n",
      "Sharpe ratio: 0.4304372717163247\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150139.890625\n",
      "Final accumulative portfolio value: 1.5013989210128784\n",
      "Maximum DrawDown: -0.32203258211738606\n",
      "Sharpe ratio: 0.4068372264249049\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 145565.34375\n",
      "Final accumulative portfolio value: 1.455653429031372\n",
      "Maximum DrawDown: -0.32956980851355333\n",
      "Sharpe ratio: 0.38226947769567593\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.137       |\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 3583        |\n",
      "|    total_timesteps | 107640      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.24        |\n",
      "|    critic_loss     | 0.000177    |\n",
      "|    ent_coef        | 1.7e-06     |\n",
      "|    ent_coef_loss   | -18.8       |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 107539      |\n",
      "|    reward          | 0.008066576 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150428.046875\n",
      "Final accumulative portfolio value: 1.5042804479599\n",
      "Maximum DrawDown: -0.3304007364172371\n",
      "Sharpe ratio: 0.4017437895187268\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 154643.5\n",
      "Final accumulative portfolio value: 1.546434998512268\n",
      "Maximum DrawDown: -0.3311102736336189\n",
      "Sharpe ratio: 0.423073435603714\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 157005.84375\n",
      "Final accumulative portfolio value: 1.5700584650039673\n",
      "Maximum DrawDown: -0.3381382323068991\n",
      "Sharpe ratio: 0.43322753401336206\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 151460.046875\n",
      "Final accumulative portfolio value: 1.5146005153656006\n",
      "Maximum DrawDown: -0.33469148068948773\n",
      "Sharpe ratio: 0.4097288786574727\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.156       |\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 29          |\n",
      "|    time_elapsed    | 3868        |\n",
      "|    total_timesteps | 114816      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.953       |\n",
      "|    critic_loss     | 0.000141    |\n",
      "|    ent_coef        | 2.1e-06     |\n",
      "|    ent_coef_loss   | 6.14        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 114715      |\n",
      "|    reward          | 0.008194989 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 157116.3125\n",
      "Final accumulative portfolio value: 1.5711631774902344\n",
      "Maximum DrawDown: -0.33594583006157785\n",
      "Sharpe ratio: 0.43935353521415216\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150366.078125\n",
      "Final accumulative portfolio value: 1.503660798072815\n",
      "Maximum DrawDown: -0.3384667571234735\n",
      "Sharpe ratio: 0.4034982442483098\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 144432.046875\n",
      "Final accumulative portfolio value: 1.4443204402923584\n",
      "Maximum DrawDown: -0.3346604107161293\n",
      "Sharpe ratio: 0.3731352573042206\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 142795.65625\n",
      "Final accumulative portfolio value: 1.4279565811157227\n",
      "Maximum DrawDown: -0.3308003076554633\n",
      "Sharpe ratio: 0.36545329087837175\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.17        |\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 29          |\n",
      "|    time_elapsed    | 4168        |\n",
      "|    total_timesteps | 121992      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.685       |\n",
      "|    critic_loss     | 0.000144    |\n",
      "|    ent_coef        | 1.74e-06    |\n",
      "|    ent_coef_loss   | 3.56        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 121891      |\n",
      "|    reward          | 0.009379252 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 143843.375\n",
      "Final accumulative portfolio value: 1.4384337663650513\n",
      "Maximum DrawDown: -0.33684933239613446\n",
      "Sharpe ratio: 0.3689659002317136\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 141571.921875\n",
      "Final accumulative portfolio value: 1.4157192707061768\n",
      "Maximum DrawDown: -0.33384145593864833\n",
      "Sharpe ratio: 0.35709586223583073\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 148332.890625\n",
      "Final accumulative portfolio value: 1.483328938484192\n",
      "Maximum DrawDown: -0.32258676967245825\n",
      "Sharpe ratio: 0.39722199765614985\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 149738.78125\n",
      "Final accumulative portfolio value: 1.4973877668380737\n",
      "Maximum DrawDown: -0.31965891979191385\n",
      "Sharpe ratio: 0.4069399336882263\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.182       |\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 28          |\n",
      "|    time_elapsed    | 4518        |\n",
      "|    total_timesteps | 129168      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.499       |\n",
      "|    critic_loss     | 7.89e-05    |\n",
      "|    ent_coef        | 1.41e-06    |\n",
      "|    ent_coef_loss   | -8.7        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 129067      |\n",
      "|    reward          | 0.008844605 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 144757.0\n",
      "Final accumulative portfolio value: 1.4475699663162231\n",
      "Maximum DrawDown: -0.319060103578082\n",
      "Sharpe ratio: 0.37846113882258137\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 133481.65625\n",
      "Final accumulative portfolio value: 1.334816575050354\n",
      "Maximum DrawDown: -0.3260882222901518\n",
      "Sharpe ratio: 0.31324301106882785\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 133171.09375\n",
      "Final accumulative portfolio value: 1.331710934638977\n",
      "Maximum DrawDown: -0.32485545892969125\n",
      "Sharpe ratio: 0.31322267974816015\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 80880.6484375\n",
      "Final accumulative portfolio value: 0.8088064789772034\n",
      "Maximum DrawDown: -0.4579068106119256\n",
      "Sharpe ratio: -0.07691881212097544\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.183       |\n",
      "| time/              |             |\n",
      "|    episodes        | 76          |\n",
      "|    fps             | 27          |\n",
      "|    time_elapsed    | 4873        |\n",
      "|    total_timesteps | 136344      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.477       |\n",
      "|    critic_loss     | 9.95e-05    |\n",
      "|    ent_coef        | 1.1e-07     |\n",
      "|    ent_coef_loss   | -810        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 136243      |\n",
      "|    reward          | 0.007385215 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58512.984375\n",
      "Final accumulative portfolio value: 0.5851298570632935\n",
      "Maximum DrawDown: -0.5044408699299093\n",
      "Sharpe ratio: -0.3320861056299481\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 61574.83984375\n",
      "Final accumulative portfolio value: 0.615748405456543\n",
      "Maximum DrawDown: -0.46749007961230227\n",
      "Sharpe ratio: -0.29071362032833714\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 63390.0390625\n",
      "Final accumulative portfolio value: 0.6339004039764404\n",
      "Maximum DrawDown: -0.46345496828873634\n",
      "Sharpe ratio: -0.26900982388207706\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 59988.27734375\n",
      "Final accumulative portfolio value: 0.5998827815055847\n",
      "Maximum DrawDown: -0.4770919714217452\n",
      "Sharpe ratio: -0.31087950781422363\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.149       |\n",
      "| time/              |             |\n",
      "|    episodes        | 80          |\n",
      "|    fps             | 27          |\n",
      "|    time_elapsed    | 5178        |\n",
      "|    total_timesteps | 143520      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.323       |\n",
      "|    critic_loss     | 0.000133    |\n",
      "|    ent_coef        | 1.21e-08    |\n",
      "|    ent_coef_loss   | -914        |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 143419      |\n",
      "|    reward          | 0.006821322 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 59497.81640625\n",
      "Final accumulative portfolio value: 0.5949781537055969\n",
      "Maximum DrawDown: -0.5012149491281098\n",
      "Sharpe ratio: -0.3144714627661632\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60143.95703125\n",
      "Final accumulative portfolio value: 0.6014395952224731\n",
      "Maximum DrawDown: -0.48505077554338105\n",
      "Sharpe ratio: -0.3121949653005517\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58101.05078125\n",
      "Final accumulative portfolio value: 0.5810105204582214\n",
      "Maximum DrawDown: -0.49067591543308586\n",
      "Sharpe ratio: -0.3361194281880797\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60057.4296875\n",
      "Final accumulative portfolio value: 0.6005743145942688\n",
      "Maximum DrawDown: -0.48934886978300485\n",
      "Sharpe ratio: -0.3088999382070527\n",
      "=================================\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 1.79e+03   |\n",
      "|    ep_rew_mean     | 0.118      |\n",
      "| time/              |            |\n",
      "|    episodes        | 84         |\n",
      "|    fps             | 27         |\n",
      "|    time_elapsed    | 5498       |\n",
      "|    total_timesteps | 150696     |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.218      |\n",
      "|    critic_loss     | 0.000124   |\n",
      "|    ent_coef        | 1.41e-09   |\n",
      "|    ent_coef_loss   | -1.03e+03  |\n",
      "|    learning_rate   | 0.0003     |\n",
      "|    n_updates       | 150595     |\n",
      "|    reward          | 0.00724652 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57448.1484375\n",
      "Final accumulative portfolio value: 0.5744814872741699\n",
      "Maximum DrawDown: -0.5036822454765275\n",
      "Sharpe ratio: -0.34639517986781854\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60140.8515625\n",
      "Final accumulative portfolio value: 0.6014085412025452\n",
      "Maximum DrawDown: -0.4765928707083865\n",
      "Sharpe ratio: -0.31055274233237756\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60370.68359375\n",
      "Final accumulative portfolio value: 0.6037068367004395\n",
      "Maximum DrawDown: -0.47499232316855644\n",
      "Sharpe ratio: -0.3079003273194236\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60729.15234375\n",
      "Final accumulative portfolio value: 0.6072915196418762\n",
      "Maximum DrawDown: -0.48802245892640617\n",
      "Sharpe ratio: -0.300705716670582\n",
      "=================================\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 1.79e+03   |\n",
      "|    ep_rew_mean     | 0.0891     |\n",
      "| time/              |            |\n",
      "|    episodes        | 88         |\n",
      "|    fps             | 27         |\n",
      "|    time_elapsed    | 5795       |\n",
      "|    total_timesteps | 157872     |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 0.149      |\n",
      "|    critic_loss     | 0.000125   |\n",
      "|    ent_coef        | 1.64e-10   |\n",
      "|    ent_coef_loss   | -1.14e+03  |\n",
      "|    learning_rate   | 0.0003     |\n",
      "|    n_updates       | 157771     |\n",
      "|    reward          | 0.00762611 |\n",
      "-----------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60593.0\n",
      "Final accumulative portfolio value: 0.605929970741272\n",
      "Maximum DrawDown: -0.477121561437686\n",
      "Sharpe ratio: -0.30558570009920216\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57384.78515625\n",
      "Final accumulative portfolio value: 0.5738478302955627\n",
      "Maximum DrawDown: -0.4992007706787698\n",
      "Sharpe ratio: -0.34562858831965676\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57175.9375\n",
      "Final accumulative portfolio value: 0.5717594027519226\n",
      "Maximum DrawDown: -0.4974412675766542\n",
      "Sharpe ratio: -0.34661251915677604\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58967.41796875\n",
      "Final accumulative portfolio value: 0.589674174785614\n",
      "Maximum DrawDown: -0.498062865409833\n",
      "Sharpe ratio: -0.326800944458099\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.0623      |\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 27          |\n",
      "|    time_elapsed    | 6083        |\n",
      "|    total_timesteps | 165048      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0993      |\n",
      "|    critic_loss     | 9.23e-05    |\n",
      "|    ent_coef        | 1.91e-11    |\n",
      "|    ent_coef_loss   | -1.25e+03   |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 164947      |\n",
      "|    reward          | 0.008277042 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60123.25390625\n",
      "Final accumulative portfolio value: 0.6012325286865234\n",
      "Maximum DrawDown: -0.4737890593107482\n",
      "Sharpe ratio: -0.31234919064403593\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 63402.8359375\n",
      "Final accumulative portfolio value: 0.6340283751487732\n",
      "Maximum DrawDown: -0.47178611042499174\n",
      "Sharpe ratio: -0.26769710042637407\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58751.0546875\n",
      "Final accumulative portfolio value: 0.5875105261802673\n",
      "Maximum DrawDown: -0.5036551939546423\n",
      "Sharpe ratio: -0.32708941662393215\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 61956.8046875\n",
      "Final accumulative portfolio value: 0.6195680499076843\n",
      "Maximum DrawDown: -0.47792959313080186\n",
      "Sharpe ratio: -0.2864123967956511\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 1.79e+03     |\n",
      "|    ep_rew_mean     | 0.0394       |\n",
      "| time/              |              |\n",
      "|    episodes        | 96           |\n",
      "|    fps             | 27           |\n",
      "|    time_elapsed    | 6373         |\n",
      "|    total_timesteps | 172224       |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.0684       |\n",
      "|    critic_loss     | 0.000108     |\n",
      "|    ent_coef        | 2.23e-12     |\n",
      "|    ent_coef_loss   | -1.35e+03    |\n",
      "|    learning_rate   | 0.0003       |\n",
      "|    n_updates       | 172123       |\n",
      "|    reward          | 0.0072905445 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 64568.98828125\n",
      "Final accumulative portfolio value: 0.6456899046897888\n",
      "Maximum DrawDown: -0.4540383589957757\n",
      "Sharpe ratio: -0.25407226581707176\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60743.1171875\n",
      "Final accumulative portfolio value: 0.607431173324585\n",
      "Maximum DrawDown: -0.46788153764505647\n",
      "Sharpe ratio: -0.3037958056535252\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 59334.75390625\n",
      "Final accumulative portfolio value: 0.5933475494384766\n",
      "Maximum DrawDown: -0.49258537800261504\n",
      "Sharpe ratio: -0.32383743393795245\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 56746.14453125\n",
      "Final accumulative portfolio value: 0.5674614310264587\n",
      "Maximum DrawDown: -0.514633695019338\n",
      "Sharpe ratio: -0.35312047456493645\n",
      "=================================\n",
      "-------------------------------------\n",
      "| rollout/           |              |\n",
      "|    ep_len_mean     | 1.79e+03     |\n",
      "|    ep_rew_mean     | 0.0179       |\n",
      "| time/              |              |\n",
      "|    episodes        | 100          |\n",
      "|    fps             | 26           |\n",
      "|    time_elapsed    | 6645         |\n",
      "|    total_timesteps | 179400       |\n",
      "| train/             |              |\n",
      "|    actor_loss      | 0.046        |\n",
      "|    critic_loss     | 0.000156     |\n",
      "|    ent_coef        | 2.6e-13      |\n",
      "|    ent_coef_loss   | -1.46e+03    |\n",
      "|    learning_rate   | 0.0003       |\n",
      "|    n_updates       | 179299       |\n",
      "|    reward          | 0.0070693367 |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60489.046875\n",
      "Final accumulative portfolio value: 0.6048904657363892\n",
      "Maximum DrawDown: -0.47840151388828844\n",
      "Sharpe ratio: -0.3081158958108943\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 61214.34375\n",
      "Final accumulative portfolio value: 0.6121434569358826\n",
      "Maximum DrawDown: -0.47460297541762475\n",
      "Sharpe ratio: -0.29526910164414366\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 58616.53125\n",
      "Final accumulative portfolio value: 0.5861653089523315\n",
      "Maximum DrawDown: -0.4982795914561723\n",
      "Sharpe ratio: -0.32813169282409527\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 62871.00390625\n",
      "Final accumulative portfolio value: 0.6287100315093994\n",
      "Maximum DrawDown: -0.46917003608438024\n",
      "Sharpe ratio: -0.2764281091933252\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.0192      |\n",
      "| time/              |             |\n",
      "|    episodes        | 104         |\n",
      "|    fps             | 26          |\n",
      "|    time_elapsed    | 6936        |\n",
      "|    total_timesteps | 186576      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0315      |\n",
      "|    critic_loss     | 0.000177    |\n",
      "|    ent_coef        | 3.03e-14    |\n",
      "|    ent_coef_loss   | -1.58e+03   |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 186475      |\n",
      "|    reward          | 0.008170513 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60874.96875\n",
      "Final accumulative portfolio value: 0.6087496876716614\n",
      "Maximum DrawDown: -0.482922322785053\n",
      "Sharpe ratio: -0.3000830421469075\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 59674.453125\n",
      "Final accumulative portfolio value: 0.5967445373535156\n",
      "Maximum DrawDown: -0.4890788187235642\n",
      "Sharpe ratio: -0.31706873545666325\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57686.30078125\n",
      "Final accumulative portfolio value: 0.5768629908561707\n",
      "Maximum DrawDown: -0.5110845071476517\n",
      "Sharpe ratio: -0.3410227001770692\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 59648.48828125\n",
      "Final accumulative portfolio value: 0.596484899520874\n",
      "Maximum DrawDown: -0.48644754574176086\n",
      "Sharpe ratio: -0.3138135989206589\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.02        |\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 26          |\n",
      "|    time_elapsed    | 7214        |\n",
      "|    total_timesteps | 193752      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 0.0209      |\n",
      "|    critic_loss     | 0.000136    |\n",
      "|    ent_coef        | 3.51e-15    |\n",
      "|    ent_coef_loss   | -1.68e+03   |\n",
      "|    learning_rate   | 0.0003      |\n",
      "|    n_updates       | 193651      |\n",
      "|    reward          | 0.007406041 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60124.51171875\n",
      "Final accumulative portfolio value: 0.601245105266571\n",
      "Maximum DrawDown: -0.48867181039285\n",
      "Sharpe ratio: -0.31059140188281203\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 60210.140625\n",
      "Final accumulative portfolio value: 0.6021013855934143\n",
      "Maximum DrawDown: -0.48050334863880884\n",
      "Sharpe ratio: -0.30741761142193563\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 57824.73828125\n",
      "Final accumulative portfolio value: 0.5782473683357239\n",
      "Maximum DrawDown: -0.5120098257917296\n",
      "Sharpe ratio: -0.3426658057133315\n",
      "=================================\n",
      "SAC training completed in 124.53 minutes.\n",
      "Training DDPG...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzitoh/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 34.93GB > 3.19GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 220264.265625\n",
      "Final accumulative portfolio value: 2.2026426792144775\n",
      "Maximum DrawDown: -0.3370650759296996\n",
      "Sharpe ratio: 0.699655153337839\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.862       |\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 203         |\n",
      "|    total_timesteps | 7176        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -19.8       |\n",
      "|    critic_loss     | 0.00809     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 7075        |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.873       |\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 418         |\n",
      "|    total_timesteps | 14352       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -13.7       |\n",
      "|    critic_loss     | 0.00422     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14251       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.877       |\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 32          |\n",
      "|    time_elapsed    | 654         |\n",
      "|    total_timesteps | 21528       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -9.34       |\n",
      "|    critic_loss     | 0.00255     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21427       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.878       |\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 861         |\n",
      "|    total_timesteps | 28704       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -6.48       |\n",
      "|    critic_loss     | 0.00762     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 28603       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.879       |\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 1074        |\n",
      "|    total_timesteps | 35880       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -4.33       |\n",
      "|    critic_loss     | 0.00356     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 35779       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.88        |\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 1292        |\n",
      "|    total_timesteps | 43056       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -3.04       |\n",
      "|    critic_loss     | 0.00473     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 42955       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.881       |\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 1507        |\n",
      "|    total_timesteps | 50232       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -1.94       |\n",
      "|    critic_loss     | 0.00574     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 50131       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.881       |\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 1734        |\n",
      "|    total_timesteps | 57408       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -1.37       |\n",
      "|    critic_loss     | 0.000199    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 57307       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.881       |\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 32          |\n",
      "|    time_elapsed    | 1991        |\n",
      "|    total_timesteps | 64584       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.971      |\n",
      "|    critic_loss     | 0.000102    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 64483       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 32          |\n",
      "|    time_elapsed    | 2236        |\n",
      "|    total_timesteps | 71760       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.803      |\n",
      "|    critic_loss     | 0.000171    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 71659       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2474        |\n",
      "|    total_timesteps | 78936       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.562      |\n",
      "|    critic_loss     | 0.00013     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 78835       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2733        |\n",
      "|    total_timesteps | 86112       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.517      |\n",
      "|    critic_loss     | 0.000185    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 86011       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 2985        |\n",
      "|    total_timesteps | 93288       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.393      |\n",
      "|    critic_loss     | 0.000152    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 93187       |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 3211        |\n",
      "|    total_timesteps | 100464      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.411      |\n",
      "|    critic_loss     | 0.000143    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 100363      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 3439        |\n",
      "|    total_timesteps | 107640      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.254      |\n",
      "|    critic_loss     | 0.0246      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 107539      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 3667        |\n",
      "|    total_timesteps | 114816      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.168      |\n",
      "|    critic_loss     | 0.000135    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 114715      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.882       |\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 3900        |\n",
      "|    total_timesteps | 121992      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.129      |\n",
      "|    critic_loss     | 0.000125    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 121891      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 4128        |\n",
      "|    total_timesteps | 129168      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.105      |\n",
      "|    critic_loss     | 9.14e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 129067      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 76          |\n",
      "|    fps             | 31          |\n",
      "|    time_elapsed    | 4372        |\n",
      "|    total_timesteps | 136344      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0846     |\n",
      "|    critic_loss     | 0.000184    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 136243      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 80          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 4636        |\n",
      "|    total_timesteps | 143520      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0737     |\n",
      "|    critic_loss     | 0.000187    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 143419      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 84          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 4877        |\n",
      "|    total_timesteps | 150696      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0654     |\n",
      "|    critic_loss     | 0.000289    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 150595      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 88          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 5138        |\n",
      "|    total_timesteps | 157872      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0596     |\n",
      "|    critic_loss     | 8.31e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 157771      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 92          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 5385        |\n",
      "|    total_timesteps | 165048      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0553     |\n",
      "|    critic_loss     | 0.000157    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 164947      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 96          |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 5634        |\n",
      "|    total_timesteps | 172224      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0527     |\n",
      "|    critic_loss     | 0.000114    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 172123      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.883       |\n",
      "| time/              |             |\n",
      "|    episodes        | 100         |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 5915        |\n",
      "|    total_timesteps | 179400      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0496     |\n",
      "|    critic_loss     | 0.000157    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 179299      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.884       |\n",
      "| time/              |             |\n",
      "|    episodes        | 104         |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 6179        |\n",
      "|    total_timesteps | 186576      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0491     |\n",
      "|    critic_loss     | 7.69e-05    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 186475      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.884       |\n",
      "| time/              |             |\n",
      "|    episodes        | 108         |\n",
      "|    fps             | 30          |\n",
      "|    time_elapsed    | 6451        |\n",
      "|    total_timesteps | 193752      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | -0.0471     |\n",
      "|    critic_loss     | 0.000206    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 193651      |\n",
      "|    reward          | 0.008225138 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 240015.046875\n",
      "Final accumulative portfolio value: 2.4001505374908447\n",
      "Maximum DrawDown: -0.33706561270033186\n",
      "Sharpe ratio: 0.7653047713832125\n",
      "=================================\n",
      "DDPG training completed in 111.36 minutes.\n",
      "Training TD3...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mzitoh/anaconda3/envs/portfolio_opt/lib/python3.12/site-packages/stable_baselines3/common/buffers.py:242: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 34.93GB > 3.02GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 223715.171875\n",
      "Final accumulative portfolio value: 2.237151622772217\n",
      "Maximum DrawDown: -0.31264126516737234\n",
      "Sharpe ratio: 0.7136562397853964\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.894       |\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 205         |\n",
      "|    total_timesteps | 7176        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 23.3        |\n",
      "|    critic_loss     | 0.263       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 7075        |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.907       |\n",
      "| time/              |             |\n",
      "|    episodes        | 8           |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 404         |\n",
      "|    total_timesteps | 14352       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 19.9        |\n",
      "|    critic_loss     | 0.177       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 14251       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.912       |\n",
      "| time/              |             |\n",
      "|    episodes        | 12          |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 613         |\n",
      "|    total_timesteps | 21528       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 16.2        |\n",
      "|    critic_loss     | 0.413       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 21427       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.914       |\n",
      "| time/              |             |\n",
      "|    episodes        | 16          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 823         |\n",
      "|    total_timesteps | 28704       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 13.9        |\n",
      "|    critic_loss     | 0.0792      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 28603       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.915       |\n",
      "| time/              |             |\n",
      "|    episodes        | 20          |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 1022        |\n",
      "|    total_timesteps | 35880       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 11.7        |\n",
      "|    critic_loss     | 0.00935     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 35779       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.916       |\n",
      "| time/              |             |\n",
      "|    episodes        | 24          |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 1227        |\n",
      "|    total_timesteps | 43056       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 9.79        |\n",
      "|    critic_loss     | 0.0476      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 42955       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.917       |\n",
      "| time/              |             |\n",
      "|    episodes        | 28          |\n",
      "|    fps             | 35          |\n",
      "|    time_elapsed    | 1431        |\n",
      "|    total_timesteps | 50232       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 8.03        |\n",
      "|    critic_loss     | 0.00435     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 50131       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.917       |\n",
      "| time/              |             |\n",
      "|    episodes        | 32          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 1640        |\n",
      "|    total_timesteps | 57408       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 7.01        |\n",
      "|    critic_loss     | 0.0147      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 57307       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.917       |\n",
      "| time/              |             |\n",
      "|    episodes        | 36          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 1851        |\n",
      "|    total_timesteps | 64584       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 5.79        |\n",
      "|    critic_loss     | 0.00721     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 64483       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.918       |\n",
      "| time/              |             |\n",
      "|    episodes        | 40          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 2071        |\n",
      "|    total_timesteps | 71760       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 4.97        |\n",
      "|    critic_loss     | 0.0504      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 71659       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.918       |\n",
      "| time/              |             |\n",
      "|    episodes        | 44          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 2291        |\n",
      "|    total_timesteps | 78936       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 3.98        |\n",
      "|    critic_loss     | 0.0035      |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 78835       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.918       |\n",
      "| time/              |             |\n",
      "|    episodes        | 48          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 2511        |\n",
      "|    total_timesteps | 86112       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 3.26        |\n",
      "|    critic_loss     | 0.004       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 86011       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.918       |\n",
      "| time/              |             |\n",
      "|    episodes        | 52          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 2740        |\n",
      "|    total_timesteps | 93288       |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.72        |\n",
      "|    critic_loss     | 0.000264    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 93187       |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.919       |\n",
      "| time/              |             |\n",
      "|    episodes        | 56          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 2983        |\n",
      "|    total_timesteps | 100464      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.2         |\n",
      "|    critic_loss     | 0.000191    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 100363      |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.919       |\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 3214        |\n",
      "|    total_timesteps | 107640      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.84        |\n",
      "|    critic_loss     | 0.000233    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 107539      |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.919       |\n",
      "| time/              |             |\n",
      "|    episodes        | 64          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 3444        |\n",
      "|    total_timesteps | 114816      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.51        |\n",
      "|    critic_loss     | 0.000221    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 114715      |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.919       |\n",
      "| time/              |             |\n",
      "|    episodes        | 68          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 3672        |\n",
      "|    total_timesteps | 121992      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.26        |\n",
      "|    critic_loss     | 0.00019     |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 121891      |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 1.79e+03    |\n",
      "|    ep_rew_mean     | 0.919       |\n",
      "| time/              |             |\n",
      "|    episodes        | 72          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 3908        |\n",
      "|    total_timesteps | 129168      |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 1.08        |\n",
      "|    critic_loss     | 0.000148    |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 129067      |\n",
      "|    reward          | 0.009175988 |\n",
      "------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 248740.484375\n",
      "Final accumulative portfolio value: 2.4874048233032227\n",
      "Maximum DrawDown: -0.3126410149004023\n",
      "Sharpe ratio: 0.7947414458886163\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "trained_models, training_times = train_models(train_agent, model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d312bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times_df = pd.DataFrame(\n",
    "    list(training_times.items()), columns=[\"model\", \"training_duration (min)\"]\n",
    ")\n",
    "training_times_df.to_csv(f\"{results_dir}/training_times.csv\", index=False)\n",
    "\n",
    "print(\"Training summary:\")\n",
    "display(training_times_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b1712",
   "metadata": {},
   "source": [
    "## Model loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13c75e",
   "metadata": {},
   "source": [
    "Load the trained models from memory for analysis without the need for time consuming retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_configs, results_dir):\n",
    "    models = {}\n",
    "    for model_class, name, _ in model_configs:\n",
    "        model_path = f\"{results_dir}/{name.lower()}_model.zip\"\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading saved model for {name}...\")\n",
    "            models[name] = model_class.load(model_path)\n",
    "        else:\n",
    "            print(f\"No saved model found for {name}.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "# If you already trained above you can skip this; otherwise:\n",
    "# trained_models = load_models(model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ec26e",
   "metadata": {},
   "source": [
    "## Backtesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f8c6",
   "metadata": {},
   "source": [
    "- Evaluates the performance of the RL models/algorithms in a trading environment.\n",
    "- We do this by calculating the **cumulative portfolio value** and **performance metrics** for each RL model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\"initial_amount\": 100_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_backtest(model, env, initial_amount):\n",
    "    \"\"\"\n",
    "    Runs the env step by step, predicting actions with `model`, and\n",
    "    builds a DataFrame of dates, daily returns, and account values.\n",
    "    \"\"\"\n",
    "    # reset and get initial obs\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # start from initial capital\n",
    "    portfolio_value = initial_amount\n",
    "\n",
    "    dates, daily_rets, account_vals = [], [], []\n",
    "\n",
    "    while not done:\n",
    "        # predict an action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # step the environment\n",
    "        result = env.step(action)\n",
    "\n",
    "        # handle gymnasium vs. gym return signature\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "\n",
    "        # update portfolio value from the reward\n",
    "        portfolio_value *= 1 + reward\n",
    "\n",
    "        # record\n",
    "        daily_rets.append(reward)\n",
    "        account_vals.append(portfolio_value)\n",
    "\n",
    "        # grab the current date from info\n",
    "        dates.append(info[\"end_time\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"daily_return\": daily_rets,\n",
    "            \"account_value\": account_vals,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def backtest_rl_strategies_manual(models, test_env, env_kwargs):\n",
    "    out = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nManual backtest: {name}\")\n",
    "        df_ret = manual_backtest(model, test_env, env_kwargs[\"initial_amount\"])\n",
    "        # ensure it's sorted by date\n",
    "        df_ret = df_ret.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        # compute performance stats\n",
    "        stats = backtest_stats(df_ret, value_col_name=\"account_value\")\n",
    "        out[name] = {\"df\": df_ret, \"stats\": stats}\n",
    "    return out\n",
    "\n",
    "\n",
    "results = backtest_rl_strategies_manual(trained_models, test_env, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_results():\n",
    "    os.makedirs(f\"{results_dir}/backtest_plots\", exist_ok=True)\n",
    "    for name, res in results.items():\n",
    "        print(f\"Plotting {name}…\")\n",
    "        backtest_plot(\n",
    "            account_value=res[\"df\"],\n",
    "            baseline_start=test_start_date,\n",
    "            baseline_end=end_date,\n",
    "            baseline_ticker=\"SPY\",\n",
    "            value_col_name=\"account_value\",\n",
    "        )\n",
    "\n",
    "\n",
    "plot_backtest_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        df = res[\"df\"]\n",
    "        # compute cumulative returns from account_value\n",
    "        cum = df[\"account_value\"] / df[\"account_value\"].iloc[0] - 1\n",
    "        plt.plot(df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns vs. SPY\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945e551",
   "metadata": {},
   "source": [
    "## Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee740d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mpt_benchmark(test, env_kwargs):\n",
    "    dates_test = test.date.unique()\n",
    "    min_vals = [env_kwargs[\"initial_amount\"]]\n",
    "    for i in range(len(dates_test) - 1):\n",
    "        curr = test[test.date == dates_test[i]]\n",
    "        nxt = test[test.date == dates_test[i + 1]]\n",
    "        covm = np.array(curr.cov_list.values[0])\n",
    "        ef = EfficientFrontier(None, covm, weight_bounds=(0, 1))\n",
    "        ef.min_volatility()\n",
    "        w = ef.clean_weights()\n",
    "        prices = curr.close.values\n",
    "        nextp = nxt.close.values\n",
    "        shares = np.array(list(w.values())) * min_vals[-1] / prices\n",
    "        min_vals.append(np.dot(shares, nextp))\n",
    "    min_df = pd.DataFrame({\"date\": dates_test, \"account_value\": min_vals})\n",
    "    stats_mpt = backtest_stats(min_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": min_df, \"stats\": stats_mpt}\n",
    "\n",
    "\n",
    "mpt_benchmark = compute_mpt_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd051b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(test, env_kwargs):\n",
    "    ew_daily = test.groupby(\"date\")[\"close\"].apply(\n",
    "        lambda d: d.pct_change().fillna(0).mean()\n",
    "    )\n",
    "\n",
    "    ew_df = ew_daily.reset_index(name=\"daily_return\")\n",
    "    ew_df[\"account_value\"] = (ew_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": ew_df, \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(df, initial_amount=100_000):\n",
    "    # Pivot to have one column per ticker\n",
    "    price_wide = df.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).sort_index()\n",
    "\n",
    "    # Compute each ticker's daily return, then average equally\n",
    "    daily_rets = price_wide.pct_change().fillna(0).mean(axis=1)\n",
    "\n",
    "    # Build the equity curve\n",
    "    ew_df = pd.DataFrame({\"date\": daily_rets.index, \"daily_return\": daily_rets.values})\n",
    "    ew_df[\"account_value\"] = (ew_df[\"daily_return\"] + 1).cumprod() * initial_amount\n",
    "\n",
    "    # Compute performance statistics\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "\n",
    "    return {\"df\": ew_df.reset_index(drop=True), \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs[\"initial_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spy_benchmark(test, env_kwargs):\n",
    "    spy_close = get_baseline(\"SPY\", test.date.min(), test.date.max())[\"close\"]\n",
    "    spy_ret = spy_close.pct_change().dropna()\n",
    "    spy_df = pd.DataFrame({\"date\": spy_ret.index, \"daily_return\": spy_ret.values})\n",
    "    spy_df[\"account_value\"] = (spy_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_spy = backtest_stats(spy_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": spy_df, \"stats\": stats_spy}\n",
    "\n",
    "\n",
    "spy_benchmark = compute_spy_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a147661",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = {\n",
    "    \"MPT\": mpt_benchmark,\n",
    "    \"EW\": ew_benchmark,\n",
    "    \"SPY\": spy_benchmark,\n",
    "}\n",
    "\n",
    "results.update(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c912897",
   "metadata": {},
   "source": [
    "## Performance Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_stats = pd.DataFrame({key.upper(): res[\"stats\"] for key, res in results.items()})\n",
    "display(perf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        # Ensure the date column is converted to datetime\n",
    "        res[\"df\"][\"date\"] = pd.to_datetime(res[\"df\"][\"date\"])\n",
    "        # Filter data to start from the trade start date\n",
    "        filtered_df = res[\"df\"][res[\"df\"][\"date\"] >= test_start_date]\n",
    "        cum = (\n",
    "            (filtered_df[\"daily_return\"] + 1).cumprod() - 1\n",
    "            if \"daily_return\" in filtered_df\n",
    "            else filtered_df[\"account_value\"] / filtered_df[\"account_value\"].iloc[0] - 1\n",
    "        )\n",
    "        plt.plot(filtered_df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
