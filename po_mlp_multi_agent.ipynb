{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1c5a8a",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning for Portfolio Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f8e10",
   "metadata": {},
   "source": [
    "This experiement demonstrates the application of deep reinforcement learning (DRL) techniques for portfolio optimization.\n",
    "\n",
    "By leveraging state-of-the-art DRL algorithms, we aim to create a robust trading strategy that dynamically adjusts portfolio allocations to maximize returns while minimizing risks.\n",
    "\n",
    "Policy network architecture: **MLP backbone**\n",
    "\n",
    "- Compares `A2C`, `PPO`, `SAC`, `DDPG`, `TD3` all with simple MLPs\n",
    "\n",
    "The workflow includes:\n",
    "\n",
    "- Data preprocessing\n",
    "- Feature engineering\n",
    "- Environment setup\n",
    "- Training of DRL agents\n",
    "- Backtesting\n",
    "- Benchmarking against traditional strategies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dfb03e",
   "metadata": {},
   "source": [
    "## Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "b8f91ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas numpy matplotlib \\\n",
    "#                stable-baselines3 \\\n",
    "#                PyPortfolioOpt \\\n",
    "#                pandas_market_calendars quantstats gymnasium \\\n",
    "#                git+https://github.com/AI4Finance-Foundation/FinRL.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "51776d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "from stable_baselines3 import A2C, PPO, SAC, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "from finrl import config_tickers\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import (\n",
    "    backtest_stats,\n",
    "    get_daily_return,\n",
    "    get_baseline, backtest_plot\n",
    ")\n",
    "from finrl.meta.env_portfolio_optimization.env_portfolio_optimization import (\n",
    "    PortfolioOptimizationEnv,\n",
    ")\n",
    "from finrl.agents.portfolio_optimization.models import DRLAgent as PGAgent\n",
    "from finrl.agents.portfolio_optimization.architectures import EIIE\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "9e5cf3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1d8f66f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f3e16a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"portfolio_optimization_mlp_multi_agent\"\n",
    "results_dir = f\"results/models/{experiment_name}\"\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6c1461",
   "metadata": {},
   "source": [
    "## Data loading and pre-processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eefbe65",
   "metadata": {},
   "source": [
    "Define training and trading/test periods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "542703af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training period: ('2013-05-02', '2023-04-30')\n",
      "Testing period: ('2023-05-01', '2025-04-29')\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2015-01-01\"\n",
    "end_date = (datetime.now() - pd.Timedelta(days=1)).strftime(\"%Y-%m-%d\")  # Yesterday\n",
    "\n",
    "trade_period = 2  # 2 years for testing\n",
    "train_period = 10  # 10 years for training\n",
    "\n",
    "train_end_date = (\n",
    "    datetime.strptime(end_date, \"%Y-%m-%d\") - timedelta(days=trade_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "train_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") - timedelta(days=train_period * 365)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "test_start_date = (\n",
    "    datetime.strptime(train_end_date, \"%Y-%m-%d\") + timedelta(days=1)\n",
    ").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "train_dates = (train_start_date, train_end_date)\n",
    "test_dates = (test_start_date, end_date)\n",
    "\n",
    "print(f\"Training period: {train_dates}\")\n",
    "print(f\"Testing period: {test_dates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a425c",
   "metadata": {},
   "source": [
    "- Fetch historical stock data for a given list of tickers within a specified date range.\n",
    "- We use the DOW_30_TICKER stocks\n",
    "- The data includes `date`, `close`, `high`, `low`, `open`, `volume`, and `tic` (ticker symbol).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "46c577ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 2015-01-01 → 2025-04-29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (76791, 8)\n"
     ]
    }
   ],
   "source": [
    "def download_data(tickers, start_date, end_date):\n",
    "    print(f\"Downloading {start_date} → {end_date}\")\n",
    "    return YahooDownloader(\n",
    "        start_date=start_date, end_date=end_date, ticker_list=tickers\n",
    "    ).fetch_data()\n",
    "\n",
    "\n",
    "df = download_data(config_tickers.DOW_30_TICKER, start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bb738f",
   "metadata": {},
   "source": [
    "==========\n",
    "\n",
    "We apply feature engineering to the dataset of stock data:\n",
    "\n",
    "- Add technical indicators (e.g., moving averages, RSI).\n",
    "- Calculate turbulence indicators, which measure market volatility.\n",
    "\n",
    "This Enhance the dataset with features that are critical for modeling market dynamics and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "47dcd423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(df):\n",
    "    fe = FeatureEngineer(use_technical_indicator=True, use_turbulence=True)\n",
    "    return fe.preprocess_data(df)\n",
    "\n",
    "\n",
    "df_feat = preprocess_data(df)\n",
    "\n",
    "# TODO: Normalise the data??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdeb82",
   "metadata": {},
   "source": [
    "## Covariance & Returns for State\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002710f6",
   "metadata": {},
   "source": [
    "- Calculate the rolling covariance matrices and daily returns for the given dataset of stock prices.\n",
    "- This prepares the state representation (the state of the portfolio) for the RL models in the RL environments for portfolio optimization.\n",
    "- The **rolling covariance matrices** (`cov_list`) capture the relationships between asset returns, while the daily returns (`return_list`) provide information about recent price movements.\n",
    "- These metrics are critical for modeling the dynamics of the financial market and making informed trading decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "48b6f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance_and_returns(df_feat, lookback=252):\n",
    "    df_sorted = df_feat.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "    df_sorted.index = df_sorted.date.factorize()[0]\n",
    "    cov_list, return_list = [], []\n",
    "\n",
    "    dates = df_sorted.date.unique()\n",
    "    for i in range(lookback, len(dates)):\n",
    "        win = df_sorted.loc[i - lookback : i]\n",
    "        pm = win.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        rm = pm.pct_change().dropna()\n",
    "        cov_list.append(rm.cov().values)\n",
    "        return_list.append(rm)\n",
    "    df_cov = pd.DataFrame(\n",
    "        {\"date\": dates[lookback:], \"cov_list\": cov_list, \"return_list\": return_list}\n",
    "    )\n",
    "\n",
    "    return pd.merge(df_feat, df_cov, on=\"date\", how=\"left\").dropna(subset=[\"cov_list\"])\n",
    "\n",
    "\n",
    "df_all = compute_covariance_and_returns(df_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7d720",
   "metadata": {},
   "source": [
    "## Train/Trade split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "886a8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df_all, train_dates, test_dates):\n",
    "    train = data_split(df_all, *train_dates)\n",
    "    test = data_split(df_all, *test_dates)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train_df, test_df = split_data(df_all, train_dates, test_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83bcfe",
   "metadata": {},
   "source": [
    "## Environment setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17273f79",
   "metadata": {},
   "source": [
    "- Create instances of the **PortfolioOptimizationEnv** class for both training and testing datasets.\n",
    "- It also wrap the training environment for use with Stable-Baselines3 (SB3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "1bd7cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_portfolio_env(df):\n",
    "    env = PortfolioOptimizationEnv(\n",
    "        df,\n",
    "        initial_amount=100_000,\n",
    "        comission_fee_pct=0.0025,\n",
    "        time_window=50,\n",
    "        features=[\"close\", \"high\", \"low\"],\n",
    "        normalize_df=None,\n",
    "        new_gym_api=True,\n",
    "    )\n",
    "\n",
    "    env.df = df.reset_index(drop=True)\n",
    "\n",
    "    return env\n",
    "\n",
    "\n",
    "train_env = initialize_portfolio_env(train_df)\n",
    "test_env = initialize_portfolio_env(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "fc0449b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agent = DRLAgent(train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6387a",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b89e4",
   "metadata": {},
   "source": [
    "Configure model algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "2434d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_configs():\n",
    "    model_configs = [\n",
    "        (A2C, \"A2C\", {}),\n",
    "        (PPO, \"PPO\", {}),\n",
    "        (SAC, \"SAC\", {}),\n",
    "        (DDPG, \"DDPG\", {}),\n",
    "        (TD3, \"TD3\", {}),\n",
    "    ]\n",
    "\n",
    "    return model_configs\n",
    "\n",
    "\n",
    "model_configs = prepare_model_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1272b4",
   "metadata": {},
   "source": [
    "Train multiple reinforcement learning (RL) models using the specified training environment and configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e6e331f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(agent, model_configs, results_dir, total_timesteps=200_000):\n",
    "    training_times = {}\n",
    "    trained_models = {}\n",
    "    for model_class, model_name, model_kwargs in model_configs:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        model = agent.get_model(\n",
    "            model_name=model_name.lower(),\n",
    "            model_kwargs=model_kwargs,\n",
    "            policy_kwargs=model_kwargs.get(\"policy_kwargs\", {}),\n",
    "        )\n",
    "\n",
    "        trained_model = agent.train_model(\n",
    "            model,\n",
    "            tb_log_name=f\"{experiment_name}_{model_name.lower()}\",\n",
    "            total_timesteps=total_timesteps,\n",
    "        )\n",
    "\n",
    "        model_path = f\"{results_dir}/{model_name.lower()}_model\"\n",
    "        trained_model.save(model_path)\n",
    "\n",
    "        trained_models[model_name] = trained_model\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_times[model_name] = (\n",
    "            end_time - start_time\n",
    "        ) / 60  # Training time in minutes\n",
    "        print(\n",
    "            f\"{model_name} training completed in {training_times[model_name]:.2f} minutes.\"\n",
    "        )\n",
    "\n",
    "    return trained_models, training_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training A2C...\n",
      "{}\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 89          |\n",
      "|    iterations         | 100         |\n",
      "|    time_elapsed       | 5           |\n",
      "|    total_timesteps    | 500         |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 99          |\n",
      "|    policy_loss        | -0.819      |\n",
      "|    reward             | 0.015592448 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000534    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 10           |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -3.46        |\n",
      "|    reward             | -0.029930312 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.0071       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 300          |\n",
      "|    time_elapsed       | 15           |\n",
      "|    total_timesteps    | 1500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 299          |\n",
      "|    policy_loss        | -0.289       |\n",
      "|    reward             | -0.002992932 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 8.89e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 42203.0390625\n",
      "Final accumulative portfolio value: 0.42203038930892944\n",
      "Maximum DrawDown: -0.6194825718698154\n",
      "Sharpe ratio: -0.5853808582439327\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.855      |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 21          |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | -0.411      |\n",
      "|    reward             | 0.003468927 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.00011     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.855       |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 0.359        |\n",
      "|    reward             | -0.025241064 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000709     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.855       |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | -0.241       |\n",
      "|    reward             | 0.0051872665 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 3.85e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.855      |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 700         |\n",
      "|    time_elapsed       | 37          |\n",
      "|    total_timesteps    | 3500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 699         |\n",
      "|    policy_loss        | 0.0513      |\n",
      "|    reward             | 0.018293824 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 3.67e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 45861.00390625\n",
      "Final accumulative portfolio value: 0.45861002802848816\n",
      "Maximum DrawDown: -0.5858933098046528\n",
      "Sharpe ratio: -0.5145710776428546\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.813       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 43           |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | 0.201        |\n",
      "|    reward             | 0.0015994625 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.55e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.813      |\n",
      "| time/                 |             |\n",
      "|    fps                | 91          |\n",
      "|    iterations         | 900         |\n",
      "|    time_elapsed       | 48          |\n",
      "|    total_timesteps    | 4500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 899         |\n",
      "|    policy_loss        | -0.0198     |\n",
      "|    reward             | 0.004208637 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 1.13e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.813        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1000          |\n",
      "|    time_elapsed       | 54            |\n",
      "|    total_timesteps    | 5000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 999           |\n",
      "|    policy_loss        | 0.164         |\n",
      "|    reward             | -0.0015821449 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 6.89e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 66281.75\n",
      "Final accumulative portfolio value: 0.6628174781799316\n",
      "Maximum DrawDown: -0.4543703249694079\n",
      "Sharpe ratio: -0.23114631474365555\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.676        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1100          |\n",
      "|    time_elapsed       | 60            |\n",
      "|    total_timesteps    | 5500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1099          |\n",
      "|    policy_loss        | -0.215        |\n",
      "|    reward             | -0.0024053152 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.7e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.676       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 65           |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.536        |\n",
      "|    reward             | 0.0075409277 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000211     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.676       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1300         |\n",
      "|    time_elapsed       | 71           |\n",
      "|    total_timesteps    | 6500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1299         |\n",
      "|    policy_loss        | -0.00488     |\n",
      "|    reward             | 0.0014668668 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.676        |\n",
      "| time/                 |               |\n",
      "|    fps                | 91            |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 76            |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.557         |\n",
      "|    reward             | -0.0068232813 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 76036.6953125\n",
      "Final accumulative portfolio value: 0.7603669762611389\n",
      "Maximum DrawDown: -0.4066707831295555\n",
      "Sharpe ratio: -0.1255673249303122\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.574       |\n",
      "| time/                 |              |\n",
      "|    fps                | 91           |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 81           |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | 0.00289      |\n",
      "|    reward             | -0.006149445 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.14e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.574        |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1600          |\n",
      "|    time_elapsed       | 86            |\n",
      "|    total_timesteps    | 8000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1599          |\n",
      "|    policy_loss        | -0.0192       |\n",
      "|    reward             | -0.0009429727 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.37e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.574        |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1700          |\n",
      "|    time_elapsed       | 91            |\n",
      "|    total_timesteps    | 8500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1699          |\n",
      "|    policy_loss        | -0.132        |\n",
      "|    reward             | -0.0073445076 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.92e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 84717.515625\n",
      "Final accumulative portfolio value: 0.8471751809120178\n",
      "Maximum DrawDown: -0.42302071382988715\n",
      "Sharpe ratio: -0.036987051911661475\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.49         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 1800          |\n",
      "|    time_elapsed       | 97            |\n",
      "|    total_timesteps    | 9000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1799          |\n",
      "|    policy_loss        | 0.0796        |\n",
      "|    reward             | 0.00015996608 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 9.76e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.49        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 1900         |\n",
      "|    time_elapsed       | 102          |\n",
      "|    total_timesteps    | 9500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1899         |\n",
      "|    policy_loss        | 0.567        |\n",
      "|    reward             | 0.0011258937 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000224     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.49       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2000        |\n",
      "|    time_elapsed       | 106         |\n",
      "|    total_timesteps    | 10000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1999        |\n",
      "|    policy_loss        | 2.93        |\n",
      "|    reward             | 0.034614798 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00577     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.49        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 2100         |\n",
      "|    time_elapsed       | 111          |\n",
      "|    total_timesteps    | 10500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2099         |\n",
      "|    policy_loss        | -0.0753      |\n",
      "|    reward             | -0.012358423 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.69e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 111157.59375\n",
      "Final accumulative portfolio value: 1.111575961112976\n",
      "Maximum DrawDown: -0.3584738002635496\n",
      "Sharpe ratio: 0.17314460064921708\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.39       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 2200        |\n",
      "|    time_elapsed       | 117         |\n",
      "|    total_timesteps    | 11000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2199        |\n",
      "|    policy_loss        | 0.445       |\n",
      "|    reward             | 0.005130578 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.00014     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.39       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2300        |\n",
      "|    time_elapsed       | 122         |\n",
      "|    total_timesteps    | 11500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2299        |\n",
      "|    policy_loss        | -0.286      |\n",
      "|    reward             | 0.014133595 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 7.15e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.39        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 2400         |\n",
      "|    time_elapsed       | 127          |\n",
      "|    total_timesteps    | 12000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2399         |\n",
      "|    policy_loss        | 0.416        |\n",
      "|    reward             | 0.0011594724 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000167     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.39         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2500          |\n",
      "|    time_elapsed       | 131           |\n",
      "|    total_timesteps    | 12500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2499          |\n",
      "|    policy_loss        | -0.362        |\n",
      "|    reward             | -0.0033078603 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 8.13e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 116969.4375\n",
      "Final accumulative portfolio value: 1.169694423675537\n",
      "Maximum DrawDown: -0.3518820124373938\n",
      "Sharpe ratio: 0.21204287289366291\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.31       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 2600        |\n",
      "|    time_elapsed       | 138         |\n",
      "|    total_timesteps    | 13000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 2599        |\n",
      "|    policy_loss        | -0.289      |\n",
      "|    reward             | 0.004964169 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 5.95e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | -0.31          |\n",
      "| time/                 |                |\n",
      "|    fps                | 94             |\n",
      "|    iterations         | 2700           |\n",
      "|    time_elapsed       | 142            |\n",
      "|    total_timesteps    | 13500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 2699           |\n",
      "|    policy_loss        | -0.779         |\n",
      "|    reward             | -0.00092179334 |\n",
      "|    std                | 0.997          |\n",
      "|    value_loss         | 0.000405       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.31         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 147           |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | -0.966        |\n",
      "|    reward             | 0.00033313446 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 0.000527      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 143545.703125\n",
      "Final accumulative portfolio value: 1.4354569911956787\n",
      "Maximum DrawDown: -0.3495599136689215\n",
      "Sharpe ratio: 0.36895128785077036\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.225        |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 153           |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | 0.00375       |\n",
      "|    reward             | -0.0027558596 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.01e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.225        |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 157           |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.232         |\n",
      "|    reward             | -0.0011275805 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 3.59e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.225      |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3100        |\n",
      "|    time_elapsed       | 162         |\n",
      "|    total_timesteps    | 15500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3099        |\n",
      "|    policy_loss        | 0.767       |\n",
      "|    reward             | 0.015432585 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000406    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.225       |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 3200         |\n",
      "|    time_elapsed       | 167          |\n",
      "|    total_timesteps    | 16000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3199         |\n",
      "|    policy_loss        | -0.931       |\n",
      "|    reward             | -0.017573083 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000611     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 132991.890625\n",
      "Final accumulative portfolio value: 1.3299188613891602\n",
      "Maximum DrawDown: -0.35600754095690956\n",
      "Sharpe ratio: 0.30984856708523206\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.167        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3300          |\n",
      "|    time_elapsed       | 172           |\n",
      "|    total_timesteps    | 16500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3299          |\n",
      "|    policy_loss        | 0.159         |\n",
      "|    reward             | -0.0019212331 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.5e-05       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.167      |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 3400        |\n",
      "|    time_elapsed       | 178         |\n",
      "|    total_timesteps    | 17000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 3399        |\n",
      "|    policy_loss        | -0.0926     |\n",
      "|    reward             | 0.011656744 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 1.19e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.167        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 183           |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | 0.533         |\n",
      "|    reward             | -0.0038585505 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 126444.1015625\n",
      "Final accumulative portfolio value: 1.2644410133361816\n",
      "Maximum DrawDown: -0.35856685070674454\n",
      "Sharpe ratio: 0.2706598799577274\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.126        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3600          |\n",
      "|    time_elapsed       | 188           |\n",
      "|    total_timesteps    | 18000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3599          |\n",
      "|    policy_loss        | -0.00785      |\n",
      "|    reward             | -0.0018486768 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 4.67e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.126        |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 193           |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.838        |\n",
      "|    reward             | -0.0019188444 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000415      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.126       |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 3800         |\n",
      "|    time_elapsed       | 198          |\n",
      "|    total_timesteps    | 19000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3799         |\n",
      "|    policy_loss        | 0.353        |\n",
      "|    reward             | 0.0040957383 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000338     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.126       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 3900         |\n",
      "|    time_elapsed       | 203          |\n",
      "|    total_timesteps    | 19500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3899         |\n",
      "|    policy_loss        | 1.25         |\n",
      "|    reward             | -0.002340849 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000881     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 126861.3203125\n",
      "Final accumulative portfolio value: 1.2686132192611694\n",
      "Maximum DrawDown: -0.35592582481637225\n",
      "Sharpe ratio: 0.27319533930436163\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0924      |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 4000         |\n",
      "|    time_elapsed       | 208          |\n",
      "|    total_timesteps    | 20000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3999         |\n",
      "|    policy_loss        | 0.0714       |\n",
      "|    reward             | 0.0009309487 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 8.5e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0924     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4100        |\n",
      "|    time_elapsed       | 213         |\n",
      "|    total_timesteps    | 20500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4099        |\n",
      "|    policy_loss        | -0.6        |\n",
      "|    reward             | 0.011192631 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000267    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0924      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4200         |\n",
      "|    time_elapsed       | 218          |\n",
      "|    total_timesteps    | 21000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4199         |\n",
      "|    policy_loss        | -0.205       |\n",
      "|    reward             | 0.0064898683 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 4.13e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0924     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4300        |\n",
      "|    time_elapsed       | 222         |\n",
      "|    total_timesteps    | 21500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4299        |\n",
      "|    policy_loss        | -0.299      |\n",
      "|    reward             | 0.010687023 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.000226    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 124121.28125\n",
      "Final accumulative portfolio value: 1.2412128448486328\n",
      "Maximum DrawDown: -0.3512368658661901\n",
      "Sharpe ratio: 0.2576780631021987\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.066       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4400         |\n",
      "|    time_elapsed       | 228          |\n",
      "|    total_timesteps    | 22000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4399         |\n",
      "|    policy_loss        | 0.177        |\n",
      "|    reward             | -0.007324573 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 2.6e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.066        |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 4500          |\n",
      "|    time_elapsed       | 233           |\n",
      "|    total_timesteps    | 22500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4499          |\n",
      "|    policy_loss        | 0.305         |\n",
      "|    reward             | -0.0063065253 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 6.02e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.066       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4600         |\n",
      "|    time_elapsed       | 238          |\n",
      "|    total_timesteps    | 23000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4599         |\n",
      "|    policy_loss        | -0.313       |\n",
      "|    reward             | -0.011577551 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 8e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129162.9765625\n",
      "Final accumulative portfolio value: 1.2916297912597656\n",
      "Maximum DrawDown: -0.34965364398762555\n",
      "Sharpe ratio: 0.2862014159363205\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0405      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 4700         |\n",
      "|    time_elapsed       | 243          |\n",
      "|    total_timesteps    | 23500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4699         |\n",
      "|    policy_loss        | 0.138        |\n",
      "|    reward             | 0.0030084848 |\n",
      "|    std                | 0.992        |\n",
      "|    value_loss         | 1.27e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4800        |\n",
      "|    time_elapsed       | 248         |\n",
      "|    total_timesteps    | 24000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4799        |\n",
      "|    policy_loss        | -0.873      |\n",
      "|    reward             | -0.02190463 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000519    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 4900        |\n",
      "|    time_elapsed       | 253         |\n",
      "|    total_timesteps    | 24500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4899        |\n",
      "|    policy_loss        | 2.1         |\n",
      "|    reward             | 0.018977972 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.00303     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | -0.0405     |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 5000        |\n",
      "|    time_elapsed       | 258         |\n",
      "|    total_timesteps    | 25000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 4999        |\n",
      "|    policy_loss        | -0.714      |\n",
      "|    reward             | 0.037600756 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 0.000428    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 130862.4140625\n",
      "Final accumulative portfolio value: 1.3086241483688354\n",
      "Maximum DrawDown: -0.3604165431887063\n",
      "Sharpe ratio: 0.29571252710758833\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.0178       |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 263           |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | 0.234         |\n",
      "|    reward             | -0.0029327918 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 6.73e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | -0.0178       |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 5200          |\n",
      "|    time_elapsed       | 268           |\n",
      "|    total_timesteps    | 26000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 2.38e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5199          |\n",
      "|    policy_loss        | 0.314         |\n",
      "|    reward             | 0.00028618056 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 9.18e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | -0.0178      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 273          |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | -0.0843      |\n",
      "|    reward             | 0.0063689356 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 6.62e-06     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140654.609375\n",
      "Final accumulative portfolio value: 1.4065461158752441\n",
      "Maximum DrawDown: -0.3520683914211825\n",
      "Sharpe ratio: 0.35185307208547195\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.00669      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5400         |\n",
      "|    time_elapsed       | 278          |\n",
      "|    total_timesteps    | 27000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5399         |\n",
      "|    policy_loss        | 0.121        |\n",
      "|    reward             | 0.0029016319 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 1.79e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.00669      |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 283          |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | 0.365        |\n",
      "|    reward             | 0.0029636768 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 0.00019      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.00669     |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 5600        |\n",
      "|    time_elapsed       | 288         |\n",
      "|    total_timesteps    | 28000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5599        |\n",
      "|    policy_loss        | -0.107      |\n",
      "|    reward             | 0.020141479 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 6.56e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.00669       |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 5700          |\n",
      "|    time_elapsed       | 293           |\n",
      "|    total_timesteps    | 28500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5699          |\n",
      "|    policy_loss        | -0.47         |\n",
      "|    reward             | -0.0030052476 |\n",
      "|    std                | 0.995         |\n",
      "|    value_loss         | 0.000256      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 127673.953125\n",
      "Final accumulative portfolio value: 1.276739478111267\n",
      "Maximum DrawDown: -0.3540426422134306\n",
      "Sharpe ratio: 0.2783415793240773\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 299          |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | -0.158       |\n",
      "|    reward             | -0.015962124 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 1.4e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 5900         |\n",
      "|    time_elapsed       | 303          |\n",
      "|    total_timesteps    | 29500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5899         |\n",
      "|    policy_loss        | -0.942       |\n",
      "|    reward             | 0.0077071446 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000483     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0221       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 308          |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | -0.223       |\n",
      "|    reward             | 0.0070565525 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 4e-05        |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 125440.390625\n",
      "Final accumulative portfolio value: 1.2544039487838745\n",
      "Maximum DrawDown: -0.35620513352884686\n",
      "Sharpe ratio: 0.26514735070331463\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6100        |\n",
      "|    time_elapsed       | 313         |\n",
      "|    total_timesteps    | 30500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6099        |\n",
      "|    policy_loss        | -0.647      |\n",
      "|    reward             | 0.008003428 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 0.000262    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0347       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6200         |\n",
      "|    time_elapsed       | 318          |\n",
      "|    total_timesteps    | 31000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6199         |\n",
      "|    policy_loss        | -0.125       |\n",
      "|    reward             | -0.005868934 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000137     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6300        |\n",
      "|    time_elapsed       | 323         |\n",
      "|    total_timesteps    | 31500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6299        |\n",
      "|    policy_loss        | 0.0646      |\n",
      "|    reward             | -0.07350705 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.00106     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.0347      |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 6400        |\n",
      "|    time_elapsed       | 328         |\n",
      "|    total_timesteps    | 32000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6399        |\n",
      "|    policy_loss        | -1.34       |\n",
      "|    reward             | 0.017904563 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.00125     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 128395.625\n",
      "Final accumulative portfolio value: 1.2839562892913818\n",
      "Maximum DrawDown: -0.3458452419568666\n",
      "Sharpe ratio: 0.2837786885023362\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.0471         |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 6500           |\n",
      "|    time_elapsed       | 333            |\n",
      "|    total_timesteps    | 32500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 6499           |\n",
      "|    policy_loss        | -0.0929        |\n",
      "|    reward             | -0.00024977466 |\n",
      "|    std                | 0.995          |\n",
      "|    value_loss         | 3.29e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6600         |\n",
      "|    time_elapsed       | 338          |\n",
      "|    total_timesteps    | 33000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6599         |\n",
      "|    policy_loss        | 1.05         |\n",
      "|    reward             | 0.0051692403 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.001        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 343          |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | -0.615       |\n",
      "|    reward             | 0.0025110878 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000212     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0471       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6800         |\n",
      "|    time_elapsed       | 348          |\n",
      "|    total_timesteps    | 34000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6799         |\n",
      "|    policy_loss        | -1.05        |\n",
      "|    reward             | 0.0054233563 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 0.000783     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 130804.1640625\n",
      "Final accumulative portfolio value: 1.3080416917800903\n",
      "Maximum DrawDown: -0.34228509709215793\n",
      "Sharpe ratio: 0.296825128629583\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 353          |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 0.0798       |\n",
      "|    reward             | 0.0011206544 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 9.49e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 358          |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.22        |\n",
      "|    reward             | 0.0061891084 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 4.55e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0592       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7100         |\n",
      "|    time_elapsed       | 363          |\n",
      "|    total_timesteps    | 35500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7099         |\n",
      "|    policy_loss        | 0.396        |\n",
      "|    reward             | 0.0005389192 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000138     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 127168.0078125\n",
      "Final accumulative portfolio value: 1.2716801166534424\n",
      "Maximum DrawDown: -0.3596773572110177\n",
      "Sharpe ratio: 0.2771482216946849\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7200         |\n",
      "|    time_elapsed       | 369          |\n",
      "|    total_timesteps    | 36000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7199         |\n",
      "|    policy_loss        | -0.398       |\n",
      "|    reward             | 0.0023423398 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.000103     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7300         |\n",
      "|    time_elapsed       | 374          |\n",
      "|    total_timesteps    | 36500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7299         |\n",
      "|    policy_loss        | 0.18         |\n",
      "|    reward             | 0.0029579718 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 7.3e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0687       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7400         |\n",
      "|    time_elapsed       | 378          |\n",
      "|    total_timesteps    | 37000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7399         |\n",
      "|    policy_loss        | -0.318       |\n",
      "|    reward             | 0.0008924792 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 6.81e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.0687        |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 7500          |\n",
      "|    time_elapsed       | 383           |\n",
      "|    total_timesteps    | 37500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7499          |\n",
      "|    policy_loss        | 1.03          |\n",
      "|    reward             | -0.0077558937 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.000609      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 128222.359375\n",
      "Final accumulative portfolio value: 1.2822235822677612\n",
      "Maximum DrawDown: -0.34373425571461413\n",
      "Sharpe ratio: 0.28425737660550493\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.0777        |\n",
      "| time/                 |               |\n",
      "|    fps                | 97            |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 389           |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | -0.0637       |\n",
      "|    reward             | -0.0092035765 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 5.71e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0777       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 393          |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.375        |\n",
      "|    reward             | -0.003449422 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000105     |\n",
      "----------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1.79e+03  |\n",
      "|    ep_rew_mean        | 0.0777    |\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 399       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.5     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | -0.228    |\n",
      "|    reward             | 0.0160957 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 3.59e-05  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 138982.25\n",
      "Final accumulative portfolio value: 1.3898224830627441\n",
      "Maximum DrawDown: -0.33196688210943404\n",
      "Sharpe ratio: 0.34749508895763503\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 404          |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | -0.308       |\n",
      "|    reward             | -0.004431875 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 6.33e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.0895         |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 8000           |\n",
      "|    time_elapsed       | 409            |\n",
      "|    total_timesteps    | 40000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | -1.19e-07      |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 7999           |\n",
      "|    policy_loss        | 0.385          |\n",
      "|    reward             | -0.00083511166 |\n",
      "|    std                | 0.999          |\n",
      "|    value_loss         | 0.000148       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8100         |\n",
      "|    time_elapsed       | 415          |\n",
      "|    total_timesteps    | 40500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8099         |\n",
      "|    policy_loss        | 1.2          |\n",
      "|    reward             | -0.027833818 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.0895       |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8200         |\n",
      "|    time_elapsed       | 420          |\n",
      "|    total_timesteps    | 41000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8199         |\n",
      "|    policy_loss        | -0.586       |\n",
      "|    reward             | 0.0088782795 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 0.000188     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 150584.34375\n",
      "Final accumulative portfolio value: 1.5058434009552002\n",
      "Maximum DrawDown: -0.34707410719884935\n",
      "Sharpe ratio: 0.40717694200805654\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.104       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8300        |\n",
      "|    time_elapsed       | 426         |\n",
      "|    total_timesteps    | 41500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8299        |\n",
      "|    policy_loss        | 0.558       |\n",
      "|    reward             | 0.001215077 |\n",
      "|    std                | 0.999       |\n",
      "|    value_loss         | 0.000196    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.104       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8400        |\n",
      "|    time_elapsed       | 431         |\n",
      "|    total_timesteps    | 42000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8399        |\n",
      "|    policy_loss        | 0.282       |\n",
      "|    reward             | 0.002215195 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 7.89e-05    |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.104          |\n",
      "| time/                 |                |\n",
      "|    fps                | 97             |\n",
      "|    iterations         | 8500           |\n",
      "|    time_elapsed       | 436            |\n",
      "|    total_timesteps    | 42500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 8499           |\n",
      "|    policy_loss        | 0.785          |\n",
      "|    reward             | -0.00012195854 |\n",
      "|    std                | 0.998          |\n",
      "|    value_loss         | 0.000446       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.104        |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 441          |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.161        |\n",
      "|    reward             | -0.006812359 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 2.92e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 153761.28125\n",
      "Final accumulative portfolio value: 1.537612795829773\n",
      "Maximum DrawDown: -0.34008839976226757\n",
      "Sharpe ratio: 0.4214480430552383\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.118        |\n",
      "| time/                 |              |\n",
      "|    fps                | 97           |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 447          |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.0107      |\n",
      "|    reward             | 0.0067299134 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.27e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.118       |\n",
      "| time/                 |             |\n",
      "|    fps                | 97          |\n",
      "|    iterations         | 8800        |\n",
      "|    time_elapsed       | 452         |\n",
      "|    total_timesteps    | 44000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8799        |\n",
      "|    policy_loss        | -0.255      |\n",
      "|    reward             | 0.008403654 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000121    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.118      |\n",
      "| time/                 |            |\n",
      "|    fps                | 97         |\n",
      "|    iterations         | 8900       |\n",
      "|    time_elapsed       | 458        |\n",
      "|    total_timesteps    | 44500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8899       |\n",
      "|    policy_loss        | -1.37      |\n",
      "|    reward             | 0.01119546 |\n",
      "|    std                | 0.999      |\n",
      "|    value_loss         | 0.00117    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140565.15625\n",
      "Final accumulative portfolio value: 1.405651569366455\n",
      "Maximum DrawDown: -0.35708407826606703\n",
      "Sharpe ratio: 0.3519841532714884\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.127         |\n",
      "| time/                 |               |\n",
      "|    fps                | 96            |\n",
      "|    iterations         | 9000          |\n",
      "|    time_elapsed       | 464           |\n",
      "|    total_timesteps    | 45000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8999          |\n",
      "|    policy_loss        | 0.0977        |\n",
      "|    reward             | -0.0040004295 |\n",
      "|    std                | 0.998         |\n",
      "|    value_loss         | 9.16e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.127        |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 469          |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | -0.196       |\n",
      "|    reward             | -0.021341236 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 2.66e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.127       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9200        |\n",
      "|    time_elapsed       | 475         |\n",
      "|    total_timesteps    | 46000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9199        |\n",
      "|    policy_loss        | 0.739       |\n",
      "|    reward             | 0.016495282 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 0.000387    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.127      |\n",
      "| time/                 |            |\n",
      "|    fps                | 96         |\n",
      "|    iterations         | 9300       |\n",
      "|    time_elapsed       | 480        |\n",
      "|    total_timesteps    | 46500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9299       |\n",
      "|    policy_loss        | -1.65      |\n",
      "|    reward             | 0.02571982 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 0.00194    |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 140039.0625\n",
      "Final accumulative portfolio value: 1.400390625\n",
      "Maximum DrawDown: -0.35194919906794453\n",
      "Sharpe ratio: 0.3507700881447386\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.135        |\n",
      "| time/                 |              |\n",
      "|    fps                | 96           |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 488          |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.018        |\n",
      "|    reward             | 0.0006462631 |\n",
      "|    std                | 0.999        |\n",
      "|    value_loss         | 2.44e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.135       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9500        |\n",
      "|    time_elapsed       | 493         |\n",
      "|    total_timesteps    | 47500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9499        |\n",
      "|    policy_loss        | -0.992      |\n",
      "|    reward             | 0.014292257 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.000508    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.135       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9600        |\n",
      "|    time_elapsed       | 499         |\n",
      "|    total_timesteps    | 48000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9599        |\n",
      "|    policy_loss        | 0.194       |\n",
      "|    reward             | 0.006407787 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 4.86e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 154017.171875\n",
      "Final accumulative portfolio value: 1.54017174243927\n",
      "Maximum DrawDown: -0.34980522965350014\n",
      "Sharpe ratio: 0.42101892146439207\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.147        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 9700         |\n",
      "|    time_elapsed       | 505          |\n",
      "|    total_timesteps    | 48500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9699         |\n",
      "|    policy_loss        | 0.235        |\n",
      "|    reward             | -0.007876579 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 4.02e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 510         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -0.44       |\n",
      "|    reward             | 0.004107017 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000175    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 9900        |\n",
      "|    time_elapsed       | 515         |\n",
      "|    total_timesteps    | 49500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9899        |\n",
      "|    policy_loss        | 1.85        |\n",
      "|    reward             | 0.023079114 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 0.00205     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.147       |\n",
      "| time/                 |             |\n",
      "|    fps                | 96          |\n",
      "|    iterations         | 10000       |\n",
      "|    time_elapsed       | 520         |\n",
      "|    total_timesteps    | 50000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9999        |\n",
      "|    policy_loss        | -0.896      |\n",
      "|    reward             | 0.015103857 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000609    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 143596.125\n",
      "Final accumulative portfolio value: 1.4359612464904785\n",
      "Maximum DrawDown: -0.3562998409309548\n",
      "Sharpe ratio: 0.36760496983263513\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.155         |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 10100         |\n",
      "|    time_elapsed       | 526           |\n",
      "|    total_timesteps    | 50500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 10099         |\n",
      "|    policy_loss        | 0.0807        |\n",
      "|    reward             | 0.00093368796 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 8.26e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.155        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10200        |\n",
      "|    time_elapsed       | 532          |\n",
      "|    total_timesteps    | 51000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10199        |\n",
      "|    policy_loss        | -0.153       |\n",
      "|    reward             | 0.0019317077 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 6.2e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.155        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10300        |\n",
      "|    time_elapsed       | 538          |\n",
      "|    total_timesteps    | 51500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10299        |\n",
      "|    policy_loss        | -0.66        |\n",
      "|    reward             | 0.0025957483 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000327     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.155      |\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 10400      |\n",
      "|    time_elapsed       | 544        |\n",
      "|    total_timesteps    | 52000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10399      |\n",
      "|    policy_loss        | 0.248      |\n",
      "|    reward             | 0.00127556 |\n",
      "|    std                | 0.998      |\n",
      "|    value_loss         | 7.04e-05   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 129229.4375\n",
      "Final accumulative portfolio value: 1.2922943830490112\n",
      "Maximum DrawDown: -0.3588775663346685\n",
      "Sharpe ratio: 0.287587057776887\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.159        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10500        |\n",
      "|    time_elapsed       | 550          |\n",
      "|    total_timesteps    | 52500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10499        |\n",
      "|    policy_loss        | 0.0225       |\n",
      "|    reward             | 0.0008219678 |\n",
      "|    std                | 0.999        |\n",
      "|    value_loss         | 6.08e-06     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.159       |\n",
      "| time/                 |             |\n",
      "|    fps                | 95          |\n",
      "|    iterations         | 10600       |\n",
      "|    time_elapsed       | 555         |\n",
      "|    total_timesteps    | 53000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 10599       |\n",
      "|    policy_loss        | 0.0274      |\n",
      "|    reward             | 0.004208755 |\n",
      "|    std                | 0.996       |\n",
      "|    value_loss         | 2.2e-05     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.159      |\n",
      "| time/                 |            |\n",
      "|    fps                | 95         |\n",
      "|    iterations         | 10700      |\n",
      "|    time_elapsed       | 561        |\n",
      "|    total_timesteps    | 53500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 10699      |\n",
      "|    policy_loss        | -0.0232    |\n",
      "|    reward             | -0.0080957 |\n",
      "|    std                | 0.997      |\n",
      "|    value_loss         | 7.13e-06   |\n",
      "--------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 138972.84375\n",
      "Final accumulative portfolio value: 1.3897284269332886\n",
      "Maximum DrawDown: -0.35485688869471077\n",
      "Sharpe ratio: 0.342904792976134\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.165          |\n",
      "| time/                 |                |\n",
      "|    fps                | 95             |\n",
      "|    iterations         | 10800          |\n",
      "|    time_elapsed       | 567            |\n",
      "|    total_timesteps    | 54000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 10799          |\n",
      "|    policy_loss        | 0.0508         |\n",
      "|    reward             | -1.6331805e-05 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 3.49e-06       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.165        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 10900        |\n",
      "|    time_elapsed       | 572          |\n",
      "|    total_timesteps    | 54500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10899        |\n",
      "|    policy_loss        | -0.386       |\n",
      "|    reward             | -0.008907293 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000278     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.165        |\n",
      "| time/                 |              |\n",
      "|    fps                | 95           |\n",
      "|    iterations         | 11000        |\n",
      "|    time_elapsed       | 578          |\n",
      "|    total_timesteps    | 55000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 10999        |\n",
      "|    policy_loss        | 1.28         |\n",
      "|    reward             | -0.012402537 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00177      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.165         |\n",
      "| time/                 |               |\n",
      "|    fps                | 95            |\n",
      "|    iterations         | 11100         |\n",
      "|    time_elapsed       | 584           |\n",
      "|    total_timesteps    | 55500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11099         |\n",
      "|    policy_loss        | 0.528         |\n",
      "|    reward             | -0.0035754507 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000217      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 165873.390625\n",
      "Final accumulative portfolio value: 1.6587339639663696\n",
      "Maximum DrawDown: -0.3561764780241655\n",
      "Sharpe ratio: 0.47647295072425966\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.176         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11200         |\n",
      "|    time_elapsed       | 590           |\n",
      "|    total_timesteps    | 56000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11199         |\n",
      "|    policy_loss        | 0.213         |\n",
      "|    reward             | -0.0029642365 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 2.85e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.176        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11300        |\n",
      "|    time_elapsed       | 595          |\n",
      "|    total_timesteps    | 56500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11299        |\n",
      "|    policy_loss        | 0.0864       |\n",
      "|    reward             | -0.004045792 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 8.6e-06      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.176       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 11400       |\n",
      "|    time_elapsed       | 601         |\n",
      "|    total_timesteps    | 57000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11399       |\n",
      "|    policy_loss        | -0.438      |\n",
      "|    reward             | 0.007732341 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.00013     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 164032.15625\n",
      "Final accumulative portfolio value: 1.6403216123580933\n",
      "Maximum DrawDown: -0.3588011620144612\n",
      "Sharpe ratio: 0.4665900428480805\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.186        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11500        |\n",
      "|    time_elapsed       | 606          |\n",
      "|    total_timesteps    | 57500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11499        |\n",
      "|    policy_loss        | 0.132        |\n",
      "|    reward             | -0.002180568 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.14e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11600         |\n",
      "|    time_elapsed       | 612           |\n",
      "|    total_timesteps    | 58000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11599         |\n",
      "|    policy_loss        | 0.368         |\n",
      "|    reward             | 0.00021157411 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000114      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11700         |\n",
      "|    time_elapsed       | 617           |\n",
      "|    total_timesteps    | 58500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11699         |\n",
      "|    policy_loss        | -0.726        |\n",
      "|    reward             | -0.0042642546 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000322      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.186         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 11800         |\n",
      "|    time_elapsed       | 622           |\n",
      "|    total_timesteps    | 59000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 11799         |\n",
      "|    policy_loss        | -0.0583       |\n",
      "|    reward             | -0.0017226863 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 5.2e-05       |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 178872.375\n",
      "Final accumulative portfolio value: 1.7887237071990967\n",
      "Maximum DrawDown: -0.3549404799894449\n",
      "Sharpe ratio: 0.5346801891763973\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.198        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 11900        |\n",
      "|    time_elapsed       | 628          |\n",
      "|    total_timesteps    | 59500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 11899        |\n",
      "|    policy_loss        | -0.17        |\n",
      "|    reward             | 0.0056288075 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 1.73e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.198       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12000       |\n",
      "|    time_elapsed       | 633         |\n",
      "|    total_timesteps    | 60000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 11999       |\n",
      "|    policy_loss        | -0.511      |\n",
      "|    reward             | 0.008489827 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000229    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.198       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12100       |\n",
      "|    time_elapsed       | 639         |\n",
      "|    total_timesteps    | 60500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12099       |\n",
      "|    policy_loss        | 0.0359      |\n",
      "|    reward             | -0.01387401 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.94e-06    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 172574.109375\n",
      "Final accumulative portfolio value: 1.7257411479949951\n",
      "Maximum DrawDown: -0.34605314908286766\n",
      "Sharpe ratio: 0.5096920167663502\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.209        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12200        |\n",
      "|    time_elapsed       | 645          |\n",
      "|    total_timesteps    | 61000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12199        |\n",
      "|    policy_loss        | 0.481        |\n",
      "|    reward             | 0.0011156532 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000177     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.209       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12300       |\n",
      "|    time_elapsed       | 650         |\n",
      "|    total_timesteps    | 61500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12299       |\n",
      "|    policy_loss        | 0.248       |\n",
      "|    reward             | 0.002526427 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.52e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.209        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12400        |\n",
      "|    time_elapsed       | 656          |\n",
      "|    total_timesteps    | 62000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12399        |\n",
      "|    policy_loss        | 1.49         |\n",
      "|    reward             | -0.054196123 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.209         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 12500         |\n",
      "|    time_elapsed       | 661           |\n",
      "|    total_timesteps    | 62500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12499         |\n",
      "|    policy_loss        | 0.501         |\n",
      "|    reward             | -0.0066839415 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000274      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 162369.109375\n",
      "Final accumulative portfolio value: 1.6236910820007324\n",
      "Maximum DrawDown: -0.3458314194077733\n",
      "Sharpe ratio: 0.46651864791749537\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.217         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 12600         |\n",
      "|    time_elapsed       | 667           |\n",
      "|    total_timesteps    | 63000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12599         |\n",
      "|    policy_loss        | 0.114         |\n",
      "|    reward             | -0.0028549018 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.91e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.217        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12700        |\n",
      "|    time_elapsed       | 673          |\n",
      "|    total_timesteps    | 63500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12699        |\n",
      "|    policy_loss        | 0.982        |\n",
      "|    reward             | 0.0020724502 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.00117      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.217       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 12800       |\n",
      "|    time_elapsed       | 678         |\n",
      "|    total_timesteps    | 64000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 12799       |\n",
      "|    policy_loss        | -0.186      |\n",
      "|    reward             | -0.01260726 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 6.73e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.217        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 12900        |\n",
      "|    time_elapsed       | 683          |\n",
      "|    total_timesteps    | 64500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | -2.38e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 12899        |\n",
      "|    policy_loss        | -0.798       |\n",
      "|    reward             | -0.012247453 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000598     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184883.21875\n",
      "Final accumulative portfolio value: 1.848832130432129\n",
      "Maximum DrawDown: -0.3464806048397485\n",
      "Sharpe ratio: 0.5624926206269237\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.228         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13000         |\n",
      "|    time_elapsed       | 689           |\n",
      "|    total_timesteps    | 65000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 12999         |\n",
      "|    policy_loss        | -0.392        |\n",
      "|    reward             | 0.00041345155 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 9.14e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.228       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 13100       |\n",
      "|    time_elapsed       | 695         |\n",
      "|    total_timesteps    | 65500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13099       |\n",
      "|    policy_loss        | 0.0585      |\n",
      "|    reward             | 0.008829598 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 1.49e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.228        |\n",
      "| time/                 |              |\n",
      "|    fps                | 94           |\n",
      "|    iterations         | 13200        |\n",
      "|    time_elapsed       | 700          |\n",
      "|    total_timesteps    | 66000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13199        |\n",
      "|    policy_loss        | 0.67         |\n",
      "|    reward             | -0.011907138 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000329     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 211704.609375\n",
      "Final accumulative portfolio value: 2.1170461177825928\n",
      "Maximum DrawDown: -0.34749542139225464\n",
      "Sharpe ratio: 0.6605597220083652\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13300         |\n",
      "|    time_elapsed       | 706           |\n",
      "|    total_timesteps    | 66500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13299         |\n",
      "|    policy_loss        | -0.116        |\n",
      "|    reward             | 0.00092606567 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 1.65e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 94            |\n",
      "|    iterations         | 13400         |\n",
      "|    time_elapsed       | 711           |\n",
      "|    total_timesteps    | 67000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13399         |\n",
      "|    policy_loss        | 0.0619        |\n",
      "|    reward             | -0.0002829833 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.96e-06      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.242       |\n",
      "| time/                 |             |\n",
      "|    fps                | 94          |\n",
      "|    iterations         | 13500       |\n",
      "|    time_elapsed       | 717         |\n",
      "|    total_timesteps    | 67500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 13499       |\n",
      "|    policy_loss        | -0.334      |\n",
      "|    reward             | 0.009027854 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9.53e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.242         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 13600         |\n",
      "|    time_elapsed       | 724           |\n",
      "|    total_timesteps    | 68000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13599         |\n",
      "|    policy_loss        | 0.834         |\n",
      "|    reward             | -0.0012904383 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000598      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 197814.703125\n",
      "Final accumulative portfolio value: 1.978147029876709\n",
      "Maximum DrawDown: -0.35352576300940397\n",
      "Sharpe ratio: 0.6073822080989905\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.254        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 13700        |\n",
      "|    time_elapsed       | 730          |\n",
      "|    total_timesteps    | 68500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13699        |\n",
      "|    policy_loss        | -0.0338      |\n",
      "|    reward             | 0.0036288144 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 4.71e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.254        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 13800        |\n",
      "|    time_elapsed       | 735          |\n",
      "|    total_timesteps    | 69000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13799        |\n",
      "|    policy_loss        | 0.596        |\n",
      "|    reward             | 0.0023111794 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000276     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.254         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 13900         |\n",
      "|    time_elapsed       | 740           |\n",
      "|    total_timesteps    | 69500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 13899         |\n",
      "|    policy_loss        | -0.481        |\n",
      "|    reward             | -0.0021177887 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000124      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 170874.46875\n",
      "Final accumulative portfolio value: 1.7087446451187134\n",
      "Maximum DrawDown: -0.34827366454402287\n",
      "Sharpe ratio: 0.5042979834960912\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14000        |\n",
      "|    time_elapsed       | 745          |\n",
      "|    total_timesteps    | 70000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 13999        |\n",
      "|    policy_loss        | -0.231       |\n",
      "|    reward             | -0.007986224 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 5.35e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14100        |\n",
      "|    time_elapsed       | 751          |\n",
      "|    total_timesteps    | 70500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14099        |\n",
      "|    policy_loss        | -0.137       |\n",
      "|    reward             | 0.0013069906 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.06e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.262        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14200        |\n",
      "|    time_elapsed       | 756          |\n",
      "|    total_timesteps    | 71000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14199        |\n",
      "|    policy_loss        | -0.535       |\n",
      "|    reward             | 0.0031174654 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000239     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.262         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 14300         |\n",
      "|    time_elapsed       | 761           |\n",
      "|    total_timesteps    | 71500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14299         |\n",
      "|    policy_loss        | -0.124        |\n",
      "|    reward             | -0.0015546838 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 3.64e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 159412.28125\n",
      "Final accumulative portfolio value: 1.5941227674484253\n",
      "Maximum DrawDown: -0.34591248444628786\n",
      "Sharpe ratio: 0.45304130262702\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.267        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14400        |\n",
      "|    time_elapsed       | 767          |\n",
      "|    total_timesteps    | 72000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14399        |\n",
      "|    policy_loss        | 0.228        |\n",
      "|    reward             | 0.0009797779 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 4.84e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.267       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 14500       |\n",
      "|    time_elapsed       | 773         |\n",
      "|    total_timesteps    | 72500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14499       |\n",
      "|    policy_loss        | 0.238       |\n",
      "|    reward             | 0.006871758 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 8.96e-05    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.267        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14600        |\n",
      "|    time_elapsed       | 779          |\n",
      "|    total_timesteps    | 73000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14599        |\n",
      "|    policy_loss        | 0.43         |\n",
      "|    reward             | 0.0039941072 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000168     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.267       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 14700       |\n",
      "|    time_elapsed       | 784         |\n",
      "|    total_timesteps    | 73500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 1.79e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 14699       |\n",
      "|    policy_loss        | -0.255      |\n",
      "|    reward             | 0.004053354 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.25e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 145600.328125\n",
      "Final accumulative portfolio value: 1.4560033082962036\n",
      "Maximum DrawDown: -0.3468826031339769\n",
      "Sharpe ratio: 0.382373752922527\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.27          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 14800         |\n",
      "|    time_elapsed       | 790           |\n",
      "|    total_timesteps    | 74000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14799         |\n",
      "|    policy_loss        | 0.303         |\n",
      "|    reward             | -0.0014685441 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.8e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.27         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 14900        |\n",
      "|    time_elapsed       | 795          |\n",
      "|    total_timesteps    | 74500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 14899        |\n",
      "|    policy_loss        | 0.142        |\n",
      "|    reward             | 0.0029781773 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 3.33e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.27          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15000         |\n",
      "|    time_elapsed       | 800           |\n",
      "|    total_timesteps    | 75000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 14999         |\n",
      "|    policy_loss        | -0.205        |\n",
      "|    reward             | -0.0005407603 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000351      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173816.484375\n",
      "Final accumulative portfolio value: 1.7381649017333984\n",
      "Maximum DrawDown: -0.3431131958107837\n",
      "Sharpe ratio: 0.518402556357476\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.277        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15100        |\n",
      "|    time_elapsed       | 806          |\n",
      "|    total_timesteps    | 75500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15099        |\n",
      "|    policy_loss        | -0.274       |\n",
      "|    reward             | 0.0022116266 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.61e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.277        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15200        |\n",
      "|    time_elapsed       | 811          |\n",
      "|    total_timesteps    | 76000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15199        |\n",
      "|    policy_loss        | -0.484       |\n",
      "|    reward             | -0.005395098 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.277       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 15300       |\n",
      "|    time_elapsed       | 817         |\n",
      "|    total_timesteps    | 76500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15299       |\n",
      "|    policy_loss        | 0.0973      |\n",
      "|    reward             | 0.003926189 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 5.27e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.277         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15400         |\n",
      "|    time_elapsed       | 822           |\n",
      "|    total_timesteps    | 77000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15399         |\n",
      "|    policy_loss        | 0.227         |\n",
      "|    reward             | -0.0014865714 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000197      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173916.015625\n",
      "Final accumulative portfolio value: 1.739160180091858\n",
      "Maximum DrawDown: -0.35687374059024646\n",
      "Sharpe ratio: 0.5127264537858992\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15500        |\n",
      "|    time_elapsed       | 828          |\n",
      "|    total_timesteps    | 77500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15499        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | 0.0008497203 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 6.42e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15600        |\n",
      "|    time_elapsed       | 834          |\n",
      "|    total_timesteps    | 78000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15599        |\n",
      "|    policy_loss        | -1.77        |\n",
      "|    reward             | -0.011336385 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00184      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.283        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 15700        |\n",
      "|    time_elapsed       | 840          |\n",
      "|    total_timesteps    | 78500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 15699        |\n",
      "|    policy_loss        | 0.0607       |\n",
      "|    reward             | 0.0072708996 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.14e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 180463.84375\n",
      "Final accumulative portfolio value: 1.804638385772705\n",
      "Maximum DrawDown: -0.3570378198895646\n",
      "Sharpe ratio: 0.5391624371537331\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.291         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 15800         |\n",
      "|    time_elapsed       | 846           |\n",
      "|    total_timesteps    | 79000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 15799         |\n",
      "|    policy_loss        | 0.369         |\n",
      "|    reward             | -0.0019597528 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 7.92e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.291          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 15900          |\n",
      "|    time_elapsed       | 852            |\n",
      "|    total_timesteps    | 79500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 15899          |\n",
      "|    policy_loss        | 0.48           |\n",
      "|    reward             | -0.00046478581 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 0.00014        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.291       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 16000       |\n",
      "|    time_elapsed       | 857         |\n",
      "|    total_timesteps    | 80000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 15999       |\n",
      "|    policy_loss        | 0.806       |\n",
      "|    reward             | 0.029944452 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000733    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.291         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 16100         |\n",
      "|    time_elapsed       | 863           |\n",
      "|    total_timesteps    | 80500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16099         |\n",
      "|    policy_loss        | 0.166         |\n",
      "|    reward             | -0.0049625784 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000304      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184464.3125\n",
      "Final accumulative portfolio value: 1.8446431159973145\n",
      "Maximum DrawDown: -0.3489735349392823\n",
      "Sharpe ratio: 0.5604267759398199\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.298          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 16200          |\n",
      "|    time_elapsed       | 869            |\n",
      "|    total_timesteps    | 81000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 16199          |\n",
      "|    policy_loss        | -0.115         |\n",
      "|    reward             | -0.00033962532 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 1.29e-05       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.298        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 16300        |\n",
      "|    time_elapsed       | 875          |\n",
      "|    total_timesteps    | 81500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16299        |\n",
      "|    policy_loss        | 0.411        |\n",
      "|    reward             | 0.0022004456 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.298         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 16400         |\n",
      "|    time_elapsed       | 880           |\n",
      "|    total_timesteps    | 82000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 16399         |\n",
      "|    policy_loss        | -0.779        |\n",
      "|    reward             | -0.0024115888 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000468      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.298       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 16500       |\n",
      "|    time_elapsed       | 885         |\n",
      "|    total_timesteps    | 82500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.8       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 16499       |\n",
      "|    policy_loss        | 0.352       |\n",
      "|    reward             | 0.005647774 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 9.48e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 184537.984375\n",
      "Final accumulative portfolio value: 1.8453798294067383\n",
      "Maximum DrawDown: -0.3519367119080168\n",
      "Sharpe ratio: 0.5546858094577238\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 16600        |\n",
      "|    time_elapsed       | 892          |\n",
      "|    total_timesteps    | 83000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16599        |\n",
      "|    policy_loss        | 0.378        |\n",
      "|    reward             | -0.022685992 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 8.03e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16700        |\n",
      "|    time_elapsed       | 897          |\n",
      "|    total_timesteps    | 83500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16699        |\n",
      "|    policy_loss        | -0.314       |\n",
      "|    reward             | 0.0034170116 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 7.11e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.305        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16800        |\n",
      "|    time_elapsed       | 903          |\n",
      "|    total_timesteps    | 84000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -43          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16799        |\n",
      "|    policy_loss        | -0.246       |\n",
      "|    reward             | 0.0013127052 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 3.86e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 193228.078125\n",
      "Final accumulative portfolio value: 1.9322807788848877\n",
      "Maximum DrawDown: -0.34829094952932915\n",
      "Sharpe ratio: 0.5870031888511276\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.313        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 16900        |\n",
      "|    time_elapsed       | 909          |\n",
      "|    total_timesteps    | 84500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 16899        |\n",
      "|    policy_loss        | 0.178        |\n",
      "|    reward             | 0.0002883257 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.15e-05     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.313      |\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 17000      |\n",
      "|    time_elapsed       | 915        |\n",
      "|    total_timesteps    | 85000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 16999      |\n",
      "|    policy_loss        | -0.203     |\n",
      "|    reward             | 0.00503344 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 6.61e-05   |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.313         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17100         |\n",
      "|    time_elapsed       | 920           |\n",
      "|    total_timesteps    | 85500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17099         |\n",
      "|    policy_loss        | 0.636         |\n",
      "|    reward             | -0.0062189554 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000574      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.313        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 17200        |\n",
      "|    time_elapsed       | 926          |\n",
      "|    total_timesteps    | 86000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17199        |\n",
      "|    policy_loss        | 0.00623      |\n",
      "|    reward             | -0.004166689 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000193     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 213506.625\n",
      "Final accumulative portfolio value: 2.135066270828247\n",
      "Maximum DrawDown: -0.35131759570891385\n",
      "Sharpe ratio: 0.6613833796906848\n",
      "=================================\n",
      "-------------------------------------------\n",
      "| rollout/              |                 |\n",
      "|    ep_len_mean        | 1.79e+03        |\n",
      "|    ep_rew_mean        | 0.322           |\n",
      "| time/                 |                 |\n",
      "|    fps                | 92              |\n",
      "|    iterations         | 17300           |\n",
      "|    time_elapsed       | 933             |\n",
      "|    total_timesteps    | 86500           |\n",
      "| train/                |                 |\n",
      "|    entropy_loss       | -42.9           |\n",
      "|    explained_variance | -1.19e-07       |\n",
      "|    learning_rate      | 0.0007          |\n",
      "|    n_updates          | 17299           |\n",
      "|    policy_loss        | 0.0154          |\n",
      "|    reward             | -0.000107771004 |\n",
      "|    std                | 1.01            |\n",
      "|    value_loss         | 3.14e-06        |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.322         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17400         |\n",
      "|    time_elapsed       | 938           |\n",
      "|    total_timesteps    | 87000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17399         |\n",
      "|    policy_loss        | -0.0279       |\n",
      "|    reward             | -0.0061581414 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 1.49e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.322         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17500         |\n",
      "|    time_elapsed       | 943           |\n",
      "|    total_timesteps    | 87500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17499         |\n",
      "|    policy_loss        | -0.71         |\n",
      "|    reward             | -0.0051089874 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000329      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 228232.296875\n",
      "Final accumulative portfolio value: 2.282322883605957\n",
      "Maximum DrawDown: -0.34808579252279914\n",
      "Sharpe ratio: 0.7113446540310133\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.333          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 17600          |\n",
      "|    time_elapsed       | 948            |\n",
      "|    total_timesteps    | 88000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.8          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 17599          |\n",
      "|    policy_loss        | -0.228         |\n",
      "|    reward             | -0.00031965118 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 2.8e-05        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.333        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 17700        |\n",
      "|    time_elapsed       | 953          |\n",
      "|    total_timesteps    | 88500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17699        |\n",
      "|    policy_loss        | 0.109        |\n",
      "|    reward             | 0.0051029436 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.333         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17800         |\n",
      "|    time_elapsed       | 958           |\n",
      "|    total_timesteps    | 89000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17799         |\n",
      "|    policy_loss        | -0.125        |\n",
      "|    reward             | -0.0010785911 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 9.89e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.333         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 17900         |\n",
      "|    time_elapsed       | 963           |\n",
      "|    total_timesteps    | 89500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 17899         |\n",
      "|    policy_loss        | 0.608         |\n",
      "|    reward             | -0.0049843825 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000241      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 219895.796875\n",
      "Final accumulative portfolio value: 2.198957920074463\n",
      "Maximum DrawDown: -0.3460619653530832\n",
      "Sharpe ratio: 0.6854300011376052\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.342        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 18000        |\n",
      "|    time_elapsed       | 968          |\n",
      "|    total_timesteps    | 90000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 17999        |\n",
      "|    policy_loss        | -0.115       |\n",
      "|    reward             | 0.0026340333 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 9.64e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.342        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 18100        |\n",
      "|    time_elapsed       | 973          |\n",
      "|    total_timesteps    | 90500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18099        |\n",
      "|    policy_loss        | -1.23        |\n",
      "|    reward             | -0.003904385 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.00084      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.342       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18200       |\n",
      "|    time_elapsed       | 978         |\n",
      "|    total_timesteps    | 91000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18199       |\n",
      "|    policy_loss        | 0.291       |\n",
      "|    reward             | 0.011743226 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 5.78e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 206966.921875\n",
      "Final accumulative portfolio value: 2.069669246673584\n",
      "Maximum DrawDown: -0.3436291175520626\n",
      "Sharpe ratio: 0.6432255316305194\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.35         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 18300        |\n",
      "|    time_elapsed       | 983          |\n",
      "|    total_timesteps    | 91500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18299        |\n",
      "|    policy_loss        | -1.09        |\n",
      "|    reward             | -0.006373407 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.000894     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.35         |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 18400        |\n",
      "|    time_elapsed       | 988          |\n",
      "|    total_timesteps    | 92000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 18399        |\n",
      "|    policy_loss        | 0.185        |\n",
      "|    reward             | -0.012465422 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 5.24e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.35        |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18500       |\n",
      "|    time_elapsed       | 993         |\n",
      "|    total_timesteps    | 92500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.6       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18499       |\n",
      "|    policy_loss        | -0.41       |\n",
      "|    reward             | 0.085828565 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000565    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.35          |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18600         |\n",
      "|    time_elapsed       | 998           |\n",
      "|    total_timesteps    | 93000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18599         |\n",
      "|    policy_loss        | -0.341        |\n",
      "|    reward             | -0.0022143782 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000193      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 211347.265625\n",
      "Final accumulative portfolio value: 2.1134727001190186\n",
      "Maximum DrawDown: -0.3380751891922005\n",
      "Sharpe ratio: 0.6586058357395271\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18700         |\n",
      "|    time_elapsed       | 1003          |\n",
      "|    total_timesteps    | 93500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18699         |\n",
      "|    policy_loss        | 0.136         |\n",
      "|    reward             | -0.0016349202 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 3.9e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 18800         |\n",
      "|    time_elapsed       | 1008          |\n",
      "|    total_timesteps    | 94000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18799         |\n",
      "|    policy_loss        | 0.59          |\n",
      "|    reward             | -0.0006237783 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 0.000315      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.357       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 18900       |\n",
      "|    time_elapsed       | 1013        |\n",
      "|    total_timesteps    | 94500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 18899       |\n",
      "|    policy_loss        | 0.192       |\n",
      "|    reward             | 0.012815262 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 3.88e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.357         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19000         |\n",
      "|    time_elapsed       | 1018          |\n",
      "|    total_timesteps    | 95000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 18999         |\n",
      "|    policy_loss        | 0.103         |\n",
      "|    reward             | -0.0013362152 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 6.44e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 196701.015625\n",
      "Final accumulative portfolio value: 1.9670101404190063\n",
      "Maximum DrawDown: -0.3374598700637985\n",
      "Sharpe ratio: 0.6080175945150943\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.364        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19100        |\n",
      "|    time_elapsed       | 1024         |\n",
      "|    total_timesteps    | 95500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19099        |\n",
      "|    policy_loss        | -0.0911      |\n",
      "|    reward             | 0.0017301366 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 1.43e-05     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.364          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 19200          |\n",
      "|    time_elapsed       | 1029           |\n",
      "|    total_timesteps    | 96000          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.7          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 19199          |\n",
      "|    policy_loss        | 0.411          |\n",
      "|    reward             | -0.00059962366 |\n",
      "|    std                | 1.01           |\n",
      "|    value_loss         | 0.000117       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.364        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19300        |\n",
      "|    time_elapsed       | 1033         |\n",
      "|    total_timesteps    | 96500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19299        |\n",
      "|    policy_loss        | 0.152        |\n",
      "|    reward             | 0.0019809639 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 3.26e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 182834.046875\n",
      "Final accumulative portfolio value: 1.8283404111862183\n",
      "Maximum DrawDown: -0.34428634463842445\n",
      "Sharpe ratio: 0.553873515854695\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.368        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19400        |\n",
      "|    time_elapsed       | 1039         |\n",
      "|    total_timesteps    | 97000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19399        |\n",
      "|    policy_loss        | -0.204       |\n",
      "|    reward             | -0.020188943 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 2.86e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.368         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19500         |\n",
      "|    time_elapsed       | 1044          |\n",
      "|    total_timesteps    | 97500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19499         |\n",
      "|    policy_loss        | 0.273         |\n",
      "|    reward             | -0.0008010496 |\n",
      "|    std                | 1.01          |\n",
      "|    value_loss         | 5.26e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.368         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 19600         |\n",
      "|    time_elapsed       | 1048          |\n",
      "|    total_timesteps    | 98000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 19599         |\n",
      "|    policy_loss        | 0.539         |\n",
      "|    reward             | -0.0065284222 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000178      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.368       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 19700       |\n",
      "|    time_elapsed       | 1053        |\n",
      "|    total_timesteps    | 98500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19699       |\n",
      "|    policy_loss        | -0.0494     |\n",
      "|    reward             | 0.008985678 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 4.69e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 183438.9375\n",
      "Final accumulative portfolio value: 1.834389328956604\n",
      "Maximum DrawDown: -0.33543558363653925\n",
      "Sharpe ratio: 0.5575272211541419\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.373        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19800        |\n",
      "|    time_elapsed       | 1059         |\n",
      "|    total_timesteps    | 99000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19799        |\n",
      "|    policy_loss        | 0.0429       |\n",
      "|    reward             | -0.008031707 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 7.33e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.373        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 19900        |\n",
      "|    time_elapsed       | 1065         |\n",
      "|    total_timesteps    | 99500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.7        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 19899        |\n",
      "|    policy_loss        | -0.247       |\n",
      "|    reward             | 0.0027211802 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 5.59e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.373       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 20000       |\n",
      "|    time_elapsed       | 1072        |\n",
      "|    total_timesteps    | 100000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 19999       |\n",
      "|    policy_loss        | -1.16       |\n",
      "|    reward             | 0.010208181 |\n",
      "|    std                | 1.01        |\n",
      "|    value_loss         | 0.000741    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 186220.984375\n",
      "Final accumulative portfolio value: 1.8622097969055176\n",
      "Maximum DrawDown: -0.3389816412974834\n",
      "Sharpe ratio: 0.5706011037476796\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.377          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20100          |\n",
      "|    time_elapsed       | 1078           |\n",
      "|    total_timesteps    | 100500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.6          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20099          |\n",
      "|    policy_loss        | -0.494         |\n",
      "|    reward             | -0.00056240876 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.000138       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.377         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 20200         |\n",
      "|    time_elapsed       | 1084          |\n",
      "|    total_timesteps    | 101000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20199         |\n",
      "|    policy_loss        | -1.09         |\n",
      "|    reward             | -0.0011860607 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.00071       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.377       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 20300       |\n",
      "|    time_elapsed       | 1089        |\n",
      "|    total_timesteps    | 101500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 5.96e-08    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 20299       |\n",
      "|    policy_loss        | 0.0352      |\n",
      "|    reward             | 0.017531198 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000186    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.377        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 20400        |\n",
      "|    time_elapsed       | 1094         |\n",
      "|    total_timesteps    | 102000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20399        |\n",
      "|    policy_loss        | -0.388       |\n",
      "|    reward             | 0.0035719182 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 0.000104     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 173030.03125\n",
      "Final accumulative portfolio value: 1.7303003072738647\n",
      "Maximum DrawDown: -0.33544805434916447\n",
      "Sharpe ratio: 0.515304621819255\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.381      |\n",
      "| time/                 |            |\n",
      "|    fps                | 93         |\n",
      "|    iterations         | 20500      |\n",
      "|    time_elapsed       | 1099       |\n",
      "|    total_timesteps    | 102500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 20499      |\n",
      "|    policy_loss        | 0.207      |\n",
      "|    reward             | 0.01362277 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 3.57e-05   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.381          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20600          |\n",
      "|    time_elapsed       | 1105           |\n",
      "|    total_timesteps    | 103000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20599          |\n",
      "|    policy_loss        | 0.41           |\n",
      "|    reward             | -0.00029431144 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.000171       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.381          |\n",
      "| time/                 |                |\n",
      "|    fps                | 93             |\n",
      "|    iterations         | 20700          |\n",
      "|    time_elapsed       | 1110           |\n",
      "|    total_timesteps    | 103500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 20699          |\n",
      "|    policy_loss        | 0.0251         |\n",
      "|    reward             | -0.00068282546 |\n",
      "|    std                | 0.999          |\n",
      "|    value_loss         | 6.65e-06       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.381         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 20800         |\n",
      "|    time_elapsed       | 1115          |\n",
      "|    total_timesteps    | 104000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20799         |\n",
      "|    policy_loss        | 0.127         |\n",
      "|    reward             | -0.0038039223 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 1.74e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 181422.359375\n",
      "Final accumulative portfolio value: 1.8142236471176147\n",
      "Maximum DrawDown: -0.3374749909640714\n",
      "Sharpe ratio: 0.5513941747420456\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.384        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 20900        |\n",
      "|    time_elapsed       | 1120         |\n",
      "|    total_timesteps    | 104500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 20899        |\n",
      "|    policy_loss        | 0.0287       |\n",
      "|    reward             | 0.0012435331 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 1.76e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.384         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21000         |\n",
      "|    time_elapsed       | 1126          |\n",
      "|    total_timesteps    | 105000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 20999         |\n",
      "|    policy_loss        | 0.0946        |\n",
      "|    reward             | -0.0013054783 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 1.78e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.384         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21100         |\n",
      "|    time_elapsed       | 1131          |\n",
      "|    total_timesteps    | 105500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21099         |\n",
      "|    policy_loss        | 0.88          |\n",
      "|    reward             | -0.0077841263 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.000494      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192087.75\n",
      "Final accumulative portfolio value: 1.920877456665039\n",
      "Maximum DrawDown: -0.33279059305632575\n",
      "Sharpe ratio: 0.5979398762066906\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.389       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 21200       |\n",
      "|    time_elapsed       | 1137        |\n",
      "|    total_timesteps    | 106000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21199       |\n",
      "|    policy_loss        | -0.0775     |\n",
      "|    reward             | 0.001245319 |\n",
      "|    std                | 0.998       |\n",
      "|    value_loss         | 3.39e-05    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.389         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21300         |\n",
      "|    time_elapsed       | 1142          |\n",
      "|    total_timesteps    | 106500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21299         |\n",
      "|    policy_loss        | -1.67         |\n",
      "|    reward             | -0.0006260447 |\n",
      "|    std                | 0.997         |\n",
      "|    value_loss         | 0.00167       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.389        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21400        |\n",
      "|    time_elapsed       | 1147         |\n",
      "|    total_timesteps    | 107000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21399        |\n",
      "|    policy_loss        | -0.139       |\n",
      "|    reward             | -0.008336025 |\n",
      "|    std                | 0.997        |\n",
      "|    value_loss         | 5.93e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.389        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21500        |\n",
      "|    time_elapsed       | 1152         |\n",
      "|    total_timesteps    | 107500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21499        |\n",
      "|    policy_loss        | -1.02        |\n",
      "|    reward             | -0.022397328 |\n",
      "|    std                | 0.996        |\n",
      "|    value_loss         | 0.000616     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 195808.0625\n",
      "Final accumulative portfolio value: 1.9580806493759155\n",
      "Maximum DrawDown: -0.32804040241931953\n",
      "Sharpe ratio: 0.6136271330708907\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.394       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 21600       |\n",
      "|    time_elapsed       | 1158        |\n",
      "|    total_timesteps    | 108000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 21599       |\n",
      "|    policy_loss        | -0.595      |\n",
      "|    reward             | -0.01230339 |\n",
      "|    std                | 0.997       |\n",
      "|    value_loss         | 0.000245    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.394        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21700        |\n",
      "|    time_elapsed       | 1163         |\n",
      "|    total_timesteps    | 108500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21699        |\n",
      "|    policy_loss        | -0.528       |\n",
      "|    reward             | -0.028434854 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000409     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.394         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 21800         |\n",
      "|    time_elapsed       | 1169          |\n",
      "|    total_timesteps    | 109000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21799         |\n",
      "|    policy_loss        | -0.411        |\n",
      "|    reward             | -0.0016845937 |\n",
      "|    std                | 0.995         |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 191619.4375\n",
      "Final accumulative portfolio value: 1.9161943197250366\n",
      "Maximum DrawDown: -0.32901325741562815\n",
      "Sharpe ratio: 0.595373621207974\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.398        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 21900        |\n",
      "|    time_elapsed       | 1174         |\n",
      "|    total_timesteps    | 109500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 21899        |\n",
      "|    policy_loss        | -0.0625      |\n",
      "|    reward             | -0.005998506 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 1.76e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.398         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22000         |\n",
      "|    time_elapsed       | 1180          |\n",
      "|    total_timesteps    | 110000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 21999         |\n",
      "|    policy_loss        | 0.602         |\n",
      "|    reward             | -0.0036745744 |\n",
      "|    std                | 0.996         |\n",
      "|    value_loss         | 0.000248      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.398        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22100        |\n",
      "|    time_elapsed       | 1185         |\n",
      "|    total_timesteps    | 110500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22099        |\n",
      "|    policy_loss        | 0.443        |\n",
      "|    reward             | -0.012296149 |\n",
      "|    std                | 0.995        |\n",
      "|    value_loss         | 0.000151     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.398       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22200       |\n",
      "|    time_elapsed       | 1191        |\n",
      "|    total_timesteps    | 111000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22199       |\n",
      "|    policy_loss        | 0.827       |\n",
      "|    reward             | 0.015277627 |\n",
      "|    std                | 0.995       |\n",
      "|    value_loss         | 0.000456    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 185147.078125\n",
      "Final accumulative portfolio value: 1.8514708280563354\n",
      "Maximum DrawDown: -0.31978213221148644\n",
      "Sharpe ratio: 0.5723249415793829\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.402        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22300        |\n",
      "|    time_elapsed       | 1198         |\n",
      "|    total_timesteps    | 111500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22299        |\n",
      "|    policy_loss        | -0.104       |\n",
      "|    reward             | -0.002977269 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 7.39e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.402         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22400         |\n",
      "|    time_elapsed       | 1204          |\n",
      "|    total_timesteps    | 112000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22399         |\n",
      "|    policy_loss        | 0.149         |\n",
      "|    reward             | -0.0067380667 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 5.85e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.402       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22500       |\n",
      "|    time_elapsed       | 1209        |\n",
      "|    total_timesteps    | 112500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22499       |\n",
      "|    policy_loss        | 0.465       |\n",
      "|    reward             | 0.011832882 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000171    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.402       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22600       |\n",
      "|    time_elapsed       | 1214        |\n",
      "|    total_timesteps    | 113000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22599       |\n",
      "|    policy_loss        | -0.163      |\n",
      "|    reward             | 0.012391366 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 8.19e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210759.125\n",
      "Final accumulative portfolio value: 2.107591152191162\n",
      "Maximum DrawDown: -0.3198476280189463\n",
      "Sharpe ratio: 0.6710842808996748\n",
      "=================================\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.408       |\n",
      "| time/                 |             |\n",
      "|    fps                | 93          |\n",
      "|    iterations         | 22700       |\n",
      "|    time_elapsed       | 1220        |\n",
      "|    total_timesteps    | 113500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 22699       |\n",
      "|    policy_loss        | -0.698      |\n",
      "|    reward             | 0.018693114 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.000275    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.408        |\n",
      "| time/                 |              |\n",
      "|    fps                | 93           |\n",
      "|    iterations         | 22800        |\n",
      "|    time_elapsed       | 1225         |\n",
      "|    total_timesteps    | 114000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22799        |\n",
      "|    policy_loss        | -0.998       |\n",
      "|    reward             | 0.0059015313 |\n",
      "|    std                | 0.991        |\n",
      "|    value_loss         | 0.000586     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.408         |\n",
      "| time/                 |               |\n",
      "|    fps                | 93            |\n",
      "|    iterations         | 22900         |\n",
      "|    time_elapsed       | 1231          |\n",
      "|    total_timesteps    | 114500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 22899         |\n",
      "|    policy_loss        | -0.989        |\n",
      "|    reward             | -0.0053972555 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 0.000525      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 210398.4375\n",
      "Final accumulative portfolio value: 2.1039843559265137\n",
      "Maximum DrawDown: -0.3203782583069823\n",
      "Sharpe ratio: 0.6686239736646316\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.413        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 23000        |\n",
      "|    time_elapsed       | 1236         |\n",
      "|    total_timesteps    | 115000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 22999        |\n",
      "|    policy_loss        | 0.0236       |\n",
      "|    reward             | 0.0033041427 |\n",
      "|    std                | 0.99         |\n",
      "|    value_loss         | 7.62e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.413         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23100         |\n",
      "|    time_elapsed       | 1242          |\n",
      "|    total_timesteps    | 115500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23099         |\n",
      "|    policy_loss        | -0.9          |\n",
      "|    reward             | -0.0018620531 |\n",
      "|    std                | 0.988         |\n",
      "|    value_loss         | 0.000674      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.413       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23200       |\n",
      "|    time_elapsed       | 1248        |\n",
      "|    total_timesteps    | 116000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42         |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23199       |\n",
      "|    policy_loss        | 0.349       |\n",
      "|    reward             | 0.015010737 |\n",
      "|    std                | 0.987       |\n",
      "|    value_loss         | 0.000154    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.413       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23300       |\n",
      "|    time_elapsed       | 1253        |\n",
      "|    total_timesteps    | 116500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.1       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23299       |\n",
      "|    policy_loss        | 1.17        |\n",
      "|    reward             | 0.004762022 |\n",
      "|    std                | 0.988       |\n",
      "|    value_loss         | 0.000973    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 205517.203125\n",
      "Final accumulative portfolio value: 2.0551719665527344\n",
      "Maximum DrawDown: -0.32305161360556\n",
      "Sharpe ratio: 0.6512330583343678\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23400         |\n",
      "|    time_elapsed       | 1260          |\n",
      "|    total_timesteps    | 117000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23399         |\n",
      "|    policy_loss        | -0.21         |\n",
      "|    reward             | 0.00096679665 |\n",
      "|    std                | 0.988         |\n",
      "|    value_loss         | 2.92e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23500         |\n",
      "|    time_elapsed       | 1265          |\n",
      "|    total_timesteps    | 117500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23499         |\n",
      "|    policy_loss        | -0.106        |\n",
      "|    reward             | -0.0030733438 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 1.52e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.418         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23600         |\n",
      "|    time_elapsed       | 1271          |\n",
      "|    total_timesteps    | 118000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23599         |\n",
      "|    policy_loss        | -0.492        |\n",
      "|    reward             | -0.0012702065 |\n",
      "|    std                | 0.99          |\n",
      "|    value_loss         | 0.000192      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 188340.984375\n",
      "Final accumulative portfolio value: 1.883409857749939\n",
      "Maximum DrawDown: -0.3232876286659049\n",
      "Sharpe ratio: 0.5861717194661993\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.421         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 23700         |\n",
      "|    time_elapsed       | 1277          |\n",
      "|    total_timesteps    | 118500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 23699         |\n",
      "|    policy_loss        | -0.1          |\n",
      "|    reward             | -0.0011096791 |\n",
      "|    std                | 0.989         |\n",
      "|    value_loss         | 9.56e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.421        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 23800        |\n",
      "|    time_elapsed       | 1282         |\n",
      "|    total_timesteps    | 119000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23799        |\n",
      "|    policy_loss        | -0.198       |\n",
      "|    reward             | 0.0040381565 |\n",
      "|    std                | 0.989        |\n",
      "|    value_loss         | 2.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.421       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 23900       |\n",
      "|    time_elapsed       | 1288        |\n",
      "|    total_timesteps    | 119500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 23899       |\n",
      "|    policy_loss        | 0.704       |\n",
      "|    reward             | 0.004986469 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.000334    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.421        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 24000        |\n",
      "|    time_elapsed       | 1293         |\n",
      "|    total_timesteps    | 120000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 23999        |\n",
      "|    policy_loss        | 0.106        |\n",
      "|    reward             | -0.008007012 |\n",
      "|    std                | 0.992        |\n",
      "|    value_loss         | 4.65e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 187872.40625\n",
      "Final accumulative portfolio value: 1.8787240982055664\n",
      "Maximum DrawDown: -0.318643163233704\n",
      "Sharpe ratio: 0.5855130441736071\n",
      "=================================\n",
      "--------------------------------------\n",
      "| rollout/              |            |\n",
      "|    ep_len_mean        | 1.79e+03   |\n",
      "|    ep_rew_mean        | 0.424      |\n",
      "| time/                 |            |\n",
      "|    fps                | 92         |\n",
      "|    iterations         | 24100      |\n",
      "|    time_elapsed       | 1300       |\n",
      "|    total_timesteps    | 120500     |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 24099      |\n",
      "|    policy_loss        | -0.436     |\n",
      "|    reward             | 0.00544861 |\n",
      "|    std                | 0.993      |\n",
      "|    value_loss         | 0.000161   |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.424          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 24200          |\n",
      "|    time_elapsed       | 1305           |\n",
      "|    total_timesteps    | 121000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.2          |\n",
      "|    explained_variance | 1.19e-07       |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 24199          |\n",
      "|    policy_loss        | -0.0788        |\n",
      "|    reward             | -0.00019379347 |\n",
      "|    std                | 0.993          |\n",
      "|    value_loss         | 8.4e-05        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.424         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24300         |\n",
      "|    time_elapsed       | 1311          |\n",
      "|    total_timesteps    | 121500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24299         |\n",
      "|    policy_loss        | 0.201         |\n",
      "|    reward             | -0.0013668934 |\n",
      "|    std                | 0.991         |\n",
      "|    value_loss         | 3.92e-05      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192780.96875\n",
      "Final accumulative portfolio value: 1.927809715270996\n",
      "Maximum DrawDown: -0.3228689582774158\n",
      "Sharpe ratio: 0.6043957496090421\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.428         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24400         |\n",
      "|    time_elapsed       | 1318          |\n",
      "|    total_timesteps    | 122000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24399         |\n",
      "|    policy_loss        | -0.177        |\n",
      "|    reward             | -0.0004554832 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 0.00041       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.428        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 24500        |\n",
      "|    time_elapsed       | 1323         |\n",
      "|    total_timesteps    | 122500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24499        |\n",
      "|    policy_loss        | -0.305       |\n",
      "|    reward             | -0.003540398 |\n",
      "|    std                | 0.993        |\n",
      "|    value_loss         | 0.000111     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.428       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 24600       |\n",
      "|    time_elapsed       | 1328        |\n",
      "|    total_timesteps    | 123000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24599       |\n",
      "|    policy_loss        | -0.535      |\n",
      "|    reward             | 0.050319597 |\n",
      "|    std                | 0.991       |\n",
      "|    value_loss         | 0.0013      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.428         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24700         |\n",
      "|    time_elapsed       | 1334          |\n",
      "|    total_timesteps    | 123500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24699         |\n",
      "|    policy_loss        | 0.218         |\n",
      "|    reward             | -0.0035956097 |\n",
      "|    std                | 0.99          |\n",
      "|    value_loss         | 0.000132      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 192860.890625\n",
      "Final accumulative portfolio value: 1.9286088943481445\n",
      "Maximum DrawDown: -0.32272353122749253\n",
      "Sharpe ratio: 0.6035211936904459\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.431         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 24800         |\n",
      "|    time_elapsed       | 1340          |\n",
      "|    total_timesteps    | 124000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 24799         |\n",
      "|    policy_loss        | 0.15          |\n",
      "|    reward             | -0.0035595992 |\n",
      "|    std                | 0.992         |\n",
      "|    value_loss         | 1.45e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.431       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 24900       |\n",
      "|    time_elapsed       | 1346        |\n",
      "|    total_timesteps    | 124500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 24899       |\n",
      "|    policy_loss        | 0.912       |\n",
      "|    reward             | 0.008496328 |\n",
      "|    std                | 0.992       |\n",
      "|    value_loss         | 0.000713    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.431        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25000        |\n",
      "|    time_elapsed       | 1352         |\n",
      "|    total_timesteps    | 125000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 24999        |\n",
      "|    policy_loss        | 0.265        |\n",
      "|    reward             | 0.0005005537 |\n",
      "|    std                | 0.994        |\n",
      "|    value_loss         | 4.56e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.431       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25100       |\n",
      "|    time_elapsed       | 1357        |\n",
      "|    total_timesteps    | 125500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.2       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25099       |\n",
      "|    policy_loss        | 0.219       |\n",
      "|    reward             | 0.008518786 |\n",
      "|    std                | 0.993       |\n",
      "|    value_loss         | 6.54e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 195846.53125\n",
      "Final accumulative portfolio value: 1.958465337753296\n",
      "Maximum DrawDown: -0.31902913744359984\n",
      "Sharpe ratio: 0.6174449526789049\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.435         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25200         |\n",
      "|    time_elapsed       | 1363          |\n",
      "|    total_timesteps    | 126000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.2         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25199         |\n",
      "|    policy_loss        | 0.142         |\n",
      "|    reward             | 0.00092630385 |\n",
      "|    std                | 0.993         |\n",
      "|    value_loss         | 1.37e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.435        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25300        |\n",
      "|    time_elapsed       | 1369         |\n",
      "|    total_timesteps    | 126500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25299        |\n",
      "|    policy_loss        | 0.122        |\n",
      "|    reward             | 0.0050506387 |\n",
      "|    std                | 0.991        |\n",
      "|    value_loss         | 5.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.435       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25400       |\n",
      "|    time_elapsed       | 1375        |\n",
      "|    total_timesteps    | 127000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.3       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25399       |\n",
      "|    policy_loss        | 0.0975      |\n",
      "|    reward             | 0.003212769 |\n",
      "|    std                | 0.994       |\n",
      "|    value_loss         | 1.22e-05    |\n",
      "---------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 185393.375\n",
      "Final accumulative portfolio value: 1.8539336919784546\n",
      "Maximum DrawDown: -0.3225158087855913\n",
      "Sharpe ratio: 0.5720806788216989\n",
      "=================================\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25500        |\n",
      "|    time_elapsed       | 1381         |\n",
      "|    total_timesteps    | 127500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25499        |\n",
      "|    policy_loss        | 0.0564       |\n",
      "|    reward             | -0.012094023 |\n",
      "|    std                | 0.998        |\n",
      "|    value_loss         | 8.01e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.438        |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 25600        |\n",
      "|    time_elapsed       | 1386         |\n",
      "|    total_timesteps    | 128000       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 25599        |\n",
      "|    policy_loss        | -0.0331      |\n",
      "|    reward             | -0.002322388 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 2.44e-05     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.438       |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 25700       |\n",
      "|    time_elapsed       | 1391        |\n",
      "|    total_timesteps    | 128500      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 25699       |\n",
      "|    policy_loss        | 0.626       |\n",
      "|    reward             | 0.014500828 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000279    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.438         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25800         |\n",
      "|    time_elapsed       | 1397          |\n",
      "|    total_timesteps    | 129000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25799         |\n",
      "|    policy_loss        | -1.27         |\n",
      "|    reward             | -0.0067292457 |\n",
      "|    std                | 0.999         |\n",
      "|    value_loss         | 0.000962      |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 172050.515625\n",
      "Final accumulative portfolio value: 1.7205051183700562\n",
      "Maximum DrawDown: -0.32235672432337414\n",
      "Sharpe ratio: 0.513792870916961\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.439         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 25900         |\n",
      "|    time_elapsed       | 1403          |\n",
      "|    total_timesteps    | 129500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25899         |\n",
      "|    policy_loss        | -0.0386       |\n",
      "|    reward             | 0.00027843413 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 1.7e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.439         |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26000         |\n",
      "|    time_elapsed       | 1409          |\n",
      "|    total_timesteps    | 130000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 25999         |\n",
      "|    policy_loss        | -0.356        |\n",
      "|    reward             | -0.0028850888 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 0.000101      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.439          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 26100          |\n",
      "|    time_elapsed       | 1415           |\n",
      "|    total_timesteps    | 130500         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.4          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26099          |\n",
      "|    policy_loss        | -0.0703        |\n",
      "|    reward             | -0.00050384575 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 0.00011        |\n",
      "------------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 160206.6875\n",
      "Final accumulative portfolio value: 1.6020668745040894\n",
      "Maximum DrawDown: -0.3272440518496649\n",
      "Sharpe ratio: 0.459532452801975\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.44          |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26200         |\n",
      "|    time_elapsed       | 1421          |\n",
      "|    total_timesteps    | 131000        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26199         |\n",
      "|    policy_loss        | -0.14         |\n",
      "|    reward             | -0.0007255921 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 5.41e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/              |               |\n",
      "|    ep_len_mean        | 1.79e+03      |\n",
      "|    ep_rew_mean        | 0.44          |\n",
      "| time/                 |               |\n",
      "|    fps                | 92            |\n",
      "|    iterations         | 26300         |\n",
      "|    time_elapsed       | 1427          |\n",
      "|    total_timesteps    | 131500        |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 26299         |\n",
      "|    policy_loss        | -0.0416       |\n",
      "|    reward             | -0.0012321312 |\n",
      "|    std                | 1             |\n",
      "|    value_loss         | 6.98e-05      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/              |             |\n",
      "|    ep_len_mean        | 1.79e+03    |\n",
      "|    ep_rew_mean        | 0.44        |\n",
      "| time/                 |             |\n",
      "|    fps                | 92          |\n",
      "|    iterations         | 26400       |\n",
      "|    time_elapsed       | 1432        |\n",
      "|    total_timesteps    | 132000      |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.5       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 26399       |\n",
      "|    policy_loss        | -0.222      |\n",
      "|    reward             | 0.023019468 |\n",
      "|    std                | 1           |\n",
      "|    value_loss         | 0.000285    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/              |              |\n",
      "|    ep_len_mean        | 1.79e+03     |\n",
      "|    ep_rew_mean        | 0.44         |\n",
      "| time/                 |              |\n",
      "|    fps                | 92           |\n",
      "|    iterations         | 26500        |\n",
      "|    time_elapsed       | 1438         |\n",
      "|    total_timesteps    | 132500       |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -42.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 26499        |\n",
      "|    policy_loss        | -0.124       |\n",
      "|    reward             | -0.026992273 |\n",
      "|    std                | 1            |\n",
      "|    value_loss         | 4.33e-05     |\n",
      "----------------------------------------\n",
      "=================================\n",
      "Initial portfolio value:100000\n",
      "Final portfolio value: 169917.515625\n",
      "Final accumulative portfolio value: 1.6991751194000244\n",
      "Maximum DrawDown: -0.3203557257222416\n",
      "Sharpe ratio: 0.5066751788225196\n",
      "=================================\n",
      "------------------------------------------\n",
      "| rollout/              |                |\n",
      "|    ep_len_mean        | 1.79e+03       |\n",
      "|    ep_rew_mean        | 0.441          |\n",
      "| time/                 |                |\n",
      "|    fps                | 92             |\n",
      "|    iterations         | 26600          |\n",
      "|    time_elapsed       | 1444           |\n",
      "|    total_timesteps    | 133000         |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -42.5          |\n",
      "|    explained_variance | 0              |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 26599          |\n",
      "|    policy_loss        | 0.158          |\n",
      "|    reward             | -2.4259385e-05 |\n",
      "|    std                | 1              |\n",
      "|    value_loss         | 2.13e-05       |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_models, training_times = train_models(train_agent, model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d312bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_times_df = pd.DataFrame(\n",
    "    list(training_times.items()), columns=[\"model\", \"training_duration (min)\"]\n",
    ")\n",
    "training_times_df.to_csv(f\"{results_dir}/training_times.csv\", index=False)\n",
    "\n",
    "print(\"Training summary:\")\n",
    "display(training_times_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b1712",
   "metadata": {},
   "source": [
    "## Model loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13c75e",
   "metadata": {},
   "source": [
    "Load the trained models from memory for analysis without the need for time consuming retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_configs, results_dir):\n",
    "    models = {}\n",
    "    for model_class, name, _ in model_configs:\n",
    "        model_path = f\"{results_dir}/{name.lower()}_model.zip\"\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Loading saved model for {name}...\")\n",
    "            models[name] = model_class.load(model_path)\n",
    "        else:\n",
    "            print(f\"No saved model found for {name}.\")\n",
    "    return models\n",
    "\n",
    "\n",
    "# If you already trained above you can skip this; otherwise:\n",
    "# trained_models = load_models(model_configs, results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ec26e",
   "metadata": {},
   "source": [
    "## Backtesting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5f8c6",
   "metadata": {},
   "source": [
    "- Evaluates the performance of the RL models/algorithms in a trading environment.\n",
    "- We do this by calculating the **cumulative portfolio value** and **performance metrics** for each RL model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_kwargs = {\"initial_amount\": 100_000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_backtest(model, env, initial_amount):\n",
    "    \"\"\"\n",
    "    Runs the env step by step, predicting actions with `model`, and\n",
    "    builds a DataFrame of dates, daily returns, and account values.\n",
    "    \"\"\"\n",
    "    # reset and get initial obs\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "\n",
    "    # start from initial capital\n",
    "    portfolio_value = initial_amount\n",
    "\n",
    "    dates, daily_rets, account_vals = [], [], []\n",
    "\n",
    "    while not done:\n",
    "        # predict an action\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        # step the environment\n",
    "        result = env.step(action)\n",
    "\n",
    "        # handle gymnasium vs. gym return signature\n",
    "        if len(result) == 5:\n",
    "            obs, reward, terminated, truncated, info = result\n",
    "            done = terminated or truncated\n",
    "        else:\n",
    "            obs, reward, done, info = result\n",
    "\n",
    "        # update portfolio value from the reward\n",
    "        portfolio_value *= 1 + reward\n",
    "\n",
    "        # record\n",
    "        daily_rets.append(reward)\n",
    "        account_vals.append(portfolio_value)\n",
    "\n",
    "        # grab the current date from info\n",
    "        dates.append(info[\"end_time\"])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"daily_return\": daily_rets,\n",
    "            \"account_value\": account_vals,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def backtest_rl_strategies_manual(models, test_env, env_kwargs):\n",
    "    out = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nManual backtest: {name}\")\n",
    "        df_ret = manual_backtest(model, test_env, env_kwargs[\"initial_amount\"])\n",
    "        # ensure it's sorted by date\n",
    "        df_ret = df_ret.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "        # compute performance stats\n",
    "        stats = backtest_stats(df_ret, value_col_name=\"account_value\")\n",
    "        out[name] = {\"df\": df_ret, \"stats\": stats}\n",
    "    return out\n",
    "\n",
    "\n",
    "results = backtest_rl_strategies_manual(trained_models, test_env, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_results():\n",
    "    os.makedirs(f\"{results_dir}/backtest_plots\", exist_ok=True)\n",
    "    for name, res in results.items():\n",
    "        print(f\"Plotting {name}…\")\n",
    "        backtest_plot(\n",
    "            account_value=res[\"df\"],\n",
    "            baseline_start=test_start_date,\n",
    "            baseline_end=end_date,\n",
    "            baseline_ticker=\"SPY\",\n",
    "            value_col_name=\"account_value\",\n",
    "        )\n",
    "\n",
    "\n",
    "plot_backtest_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        df = res[\"df\"]\n",
    "        # compute cumulative returns from account_value\n",
    "        cum = df[\"account_value\"] / df[\"account_value\"].iloc[0] - 1\n",
    "        plt.plot(df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns vs. SPY\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945e551",
   "metadata": {},
   "source": [
    "## Benchmarks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee740d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mpt_benchmark(test, env_kwargs):\n",
    "    dates_test = test.date.unique()\n",
    "    min_vals = [env_kwargs[\"initial_amount\"]]\n",
    "    for i in range(len(dates_test) - 1):\n",
    "        curr = test[test.date == dates_test[i]]\n",
    "        nxt = test[test.date == dates_test[i + 1]]\n",
    "        covm = np.array(curr.cov_list.values[0])\n",
    "        ef = EfficientFrontier(None, covm, weight_bounds=(0, 1))\n",
    "        ef.min_volatility()\n",
    "        w = ef.clean_weights()\n",
    "        prices = curr.close.values\n",
    "        nextp = nxt.close.values\n",
    "        shares = np.array(list(w.values())) * min_vals[-1] / prices\n",
    "        min_vals.append(np.dot(shares, nextp))\n",
    "    min_df = pd.DataFrame({\"date\": dates_test, \"account_value\": min_vals})\n",
    "    stats_mpt = backtest_stats(min_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": min_df, \"stats\": stats_mpt}\n",
    "\n",
    "\n",
    "mpt_benchmark = compute_mpt_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd051b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(test, env_kwargs):\n",
    "    ew_daily = test.groupby(\"date\")[\"close\"].apply(\n",
    "        lambda d: d.pct_change().fillna(0).mean()\n",
    "    )\n",
    "\n",
    "    ew_df = ew_daily.reset_index(name=\"daily_return\")\n",
    "    ew_df[\"account_value\"] = (ew_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": ew_df, \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_equal_weighted_benchmark(df, initial_amount=100_000):\n",
    "    # Pivot to have one column per ticker\n",
    "    price_wide = df.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).sort_index()\n",
    "\n",
    "    # Compute each ticker's daily return, then average equally\n",
    "    daily_rets = price_wide.pct_change().fillna(0).mean(axis=1)\n",
    "\n",
    "    # Build the equity curve\n",
    "    ew_df = pd.DataFrame({\"date\": daily_rets.index, \"daily_return\": daily_rets.values})\n",
    "    ew_df[\"account_value\"] = (ew_df[\"daily_return\"] + 1).cumprod() * initial_amount\n",
    "\n",
    "    # Compute performance statistics\n",
    "    stats_ew = backtest_stats(ew_df, value_col_name=\"account_value\")\n",
    "\n",
    "    return {\"df\": ew_df.reset_index(drop=True), \"stats\": stats_ew}\n",
    "\n",
    "\n",
    "ew_benchmark = compute_equal_weighted_benchmark(test_df, env_kwargs[\"initial_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80c086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spy_benchmark(test, env_kwargs):\n",
    "    spy_close = get_baseline(\"SPY\", test.date.min(), test.date.max())[\"close\"]\n",
    "    spy_ret = spy_close.pct_change().dropna()\n",
    "    spy_df = pd.DataFrame({\"date\": spy_ret.index, \"daily_return\": spy_ret.values})\n",
    "    spy_df[\"account_value\"] = (spy_df.daily_return + 1).cumprod() * env_kwargs[\n",
    "        \"initial_amount\"\n",
    "    ]\n",
    "    stats_spy = backtest_stats(spy_df, value_col_name=\"account_value\")\n",
    "    return {\"df\": spy_df, \"stats\": stats_spy}\n",
    "\n",
    "\n",
    "spy_benchmark = compute_spy_benchmark(test_df, env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a147661",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = {\n",
    "    \"MPT\": mpt_benchmark,\n",
    "    \"EW\": ew_benchmark,\n",
    "    \"SPY\": spy_benchmark,\n",
    "}\n",
    "\n",
    "results.update(benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c912897",
   "metadata": {},
   "source": [
    "## Performance Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d75bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_stats = pd.DataFrame({key.upper(): res[\"stats\"] for key, res in results.items()})\n",
    "display(perf_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_returns(results):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for name, res in results.items():\n",
    "        # Ensure the date column is converted to datetime\n",
    "        res[\"df\"][\"date\"] = pd.to_datetime(res[\"df\"][\"date\"])\n",
    "        # Filter data to start from the trade start date\n",
    "        filtered_df = res[\"df\"][res[\"df\"][\"date\"] >= test_start_date]\n",
    "        cum = (\n",
    "            (filtered_df[\"daily_return\"] + 1).cumprod() - 1\n",
    "            if \"daily_return\" in filtered_df\n",
    "            else filtered_df[\"account_value\"] / filtered_df[\"account_value\"].iloc[0] - 1\n",
    "        )\n",
    "        plt.plot(filtered_df[\"date\"], cum, label=name)\n",
    "    plt.title(\"Cumulative Returns\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative Return\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_cumulative_returns(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
